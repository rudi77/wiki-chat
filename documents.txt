C:\Users\rudi\source\repos\Tools\README.md - Chunk 0
Create virtual environment

NOTE: It is tested with python 3.8.10

sh PS> python -m venv .env PS> .env/Scripts/Activate.ps1 PS> python -m pip install --upgrade pip PS> pip install -r ./requirements.txt

TOOL App

Streamlit Application Features

This tool is designed to act as a simplified internal developer platform for BluDelta. It is intended to be used by developers, the support team, and anyone else working on BluDelta. New features will be added as appropriate to extend the functionality of the platform and aid in the development and support processes.

The current version of the tool consists of the following features:

Bludelta Environment Builder: This feature retrieves a Docker Compose file from a provided service URL and displays it within the application with syntax highlighting. It also saves the Docker Compose file locally as updated_docker_compose.yaml.

C:\Users\rudi\source\repos\Tools\README.md - Chunk 1
Bludelta Capture Service: This feature allows users to input various parameters, including a service URL, an x-apikey, and a document to be captured. The document can be a PDF, PNG, JPG, JPEG, or TIFF file. The feature sends a POST request to the service URL, including the entered parameters and the base64-encoded document.

New Customer: This feature facilitates the creation of a new customer record. Users can input the required details for the new customer in a provided form. Upon form submission, these details are inserted into the Customer table in a specified SQL Server database.

List Customers: This feature fetches and displays all records from the Customer table in a specified SQL Server database. The records are displayed in table format within the application. A search functionality is also provided, which allows users to filter the displayed table based on a regular expression.

C:\Users\rudi\source\repos\Tools\README.md - Chunk 2
Each feature is implemented as a separate Python script and can be accessed from a sidebar menu in the main Streamlit application. This modular design makes it easy to add new features as needed - simply create a new Python script for each feature and add it to the pages dictionary in the main application.

Please note that the current implementation of these features is basic and lacks extensive error handling or security measures. For a production application, it would be necessary to implement robust error handling, input validation, and security measures.

Start Frontend

sh cd Bennu/Frontend streamlit.cmd run .\app.py

Bennu Introduction

Bennu

Docker

Build Docker Image

sh cd BludeltaEnvProvider/Frontend docker build -t blumatixdevregistry.azurecr.io/bennu:version-number . docker push blumatixdevregistry.azurecr.io/bennu:version-number

Tag Repository

C:\Users\rudi\source\repos\Tools\README.md - Chunk 3
sh cd BludeltaEnvProvider/Frontend docker build -t blumatixdevregistry.azurecr.io/bennu:version-number . docker push blumatixdevregistry.azurecr.io/bennu:version-number

Tag Repository

Please tag the repo with the version number, e.g. 1.0.0 after having built the image! sh git tag -a 1.0.0 -m "Version 1.0.0" git push origin 1.0.0

Run Docker Image

On our linux machines, e.g. 78, 80 or 88 sh docker run --rm -d -p 8511:8501 \ -v /mnt/trainingsdata/bennu/image_classfication:/image_classification \ -v /mnt/mlflow:/mlflow -e GIT_USERNAME='YOUR_USERNAME' \ -e GIT_PASSWORD='YOUR_GIT_PASSWORD' \ -e APIKEY='YOUR_API_KEY' \ blumatixdevregistry.azurecr.io/bennu:version-number

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\app.py - Chunk 0
import streamlit as st
from bludelta_environment_feature import load_feature as bludelta_environment_feature
from bludelta_capture_feature import load_feature as bludelta_capture_feature
from customer_feature import customer_feature
from dynamic_config_feature import dynamic_config_feature
from package_upload_feature import package_upload
from json_plugin_feature import json_plugin_feature
from plugin_info_feature import plugin_info_feature
from llm_chat_feature import llm_chat_feature
from workflow_feature import document_bounding_boxes_feature
from bludelta_logfile_viewer_feature import log_file_viewer_feature
from document_page_classification_feature import doc_page_classification_feature
from document_page_classification_prediction_feature import doc_classification_prediction_feature
from code_ripeye_config_editor_feature import ripeye_config_editor_feature
from llm_workflow_feature import llm_workflow_feature
from ocr_feature import ocr_feature

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\app.py - Chunk 1
from code_ripeye_config_editor_feature import ripeye_config_editor_feature
from llm_workflow_feature import llm_workflow_feature
from ocr_feature import ocr_feature
from code_label_package_allocator import label_package_allocator_feature
from code_mlflow_explorer import mlflow_explorer_feature
from llm_bm_tool import llm_bm_tool
# from document_splitting_feature import document_splitting_feature
from document_splitting_bm_analysis import benchmark_comparison_feature
#from code_customer_registration import customer_registration_feature
from http_client_feature import http_client_feature
from label_qa_control_feature import qa_control

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\app.py - Chunk 2
st.set_page_config(layout="wide")
st.sidebar.title("Bennu - Blumatix Internal Tools :sunglasses:\n\nMenu")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\app.py - Chunk 3
# Define a dictionary of pages and their corresponding functions
pages = {
  # "Bludelta Environment Builder": bludelta_environment_feature,
    "Bludelta Capture Service": bludelta_capture_feature,
    "Bludelta Customers": customer_feature,
    "Dynamic Config": dynamic_config_feature,
    "Upload Package": package_upload,
    "Json Plugin": json_plugin_feature,
    "System or Plugin Info": plugin_info_feature,
    # "LLM ChatBot" : start_chatbot,
    # "LlM Invoice Extractor": invoice_extractor_feature,
    "Bludelta Workflows": document_bounding_boxes_feature,
    "Log File Analyzer": log_file_viewer_feature,
    "Document Page Classification": doc_page_classification_feature,
    "Document Page Classification Prediction": doc_classification_prediction_feature,
    "RIPEye Config Editor": ripeye_config_editor_feature,
    #"Customer Registration": customer_registration_feature,
    "OCR": ocr_feature,
    "Label Package Allocator": label_package_allocator_feature,

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\app.py - Chunk 4
#"Customer Registration": customer_registration_feature,
    "OCR": ocr_feature,
    "Label Package Allocator": label_package_allocator_feature,
    #"CodeKickstarter": kickstarter_feature,
    "MLflow Explorer": mlflow_explorer_feature,
    # "Document Splitting Workflows": document_splitting_feature,
    "Document Splitting BM Analysis": benchmark_comparison_feature,
    "ChatBot": llm_chat_feature,
    "Send to Workflow": llm_workflow_feature,
    "LLM Benchmark Tool": llm_bm_tool,
    "HTTP Client": http_client_feature,
    "Label QA Control": qa_control
}

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\app.py - Chunk 5
# Display a selectbox in the sidebar with the dictionary keys
page = st.sidebar.selectbox("Choose a page", list(pages.keys()))

# Call the function associated with the selected page
pages[page]()

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\bludelta_capture_feature.py - Chunk 0
import requests
import streamlit as st
from streamlit_pdf_viewer import pdf_viewer
import base64
import json

class BludeltaCaptureServiceConfig:
    def __init__(self):
        self.x_apikey = ""
        self.x_api_identifier = ""
        self.url = "https://api.bludelta.ai/v1-18/invoicedetail/detect"
        self.filter_val = 0
        self.format_val = 0
        self.property_store = {}
        self.create_result_pdf = False
        self.add_ocr_result = False
        self.add_document_text = False
        self.languages = ""

def create_capture_sidebar() -> BludeltaCaptureServiceConfig:
    with st.sidebar:
        st.title('ðŸ’¬ Bludelta Capture Service')
        st.subheader('Service Configuration')

        x_apikey = st.text_input("Enter the x-apikey of your service:", "")
        x_api_identifier = st.text_input("Enter the x-api-identifier of your service:", "")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\bludelta_capture_feature.py - Chunk 1
x_apikey = st.text_input("Enter the x-apikey of your service:", "")
        x_api_identifier = st.text_input("Enter the x-api-identifier of your service:", "")

        # Input field for service URL
        url = st.text_input("Enter the URL of your service:", "https://api.bludelta.ai/v1-18/invoicedetail/detect")

        # Input fields for the parameters
        filter_val = st.number_input("Filter:", value=0, format="%d")
        format_val = st.number_input("Format:", value=0, format="%d")
        property_store_str = st.text_input("PropertyStore (input as 'key1:value1,key2:value2,...'):", "")
        create_result_pdf = st.checkbox("CreateResultPdf")
        add_ocr_result = st.checkbox("AddOcrResult")
        add_document_text = st.checkbox("AddDocumentText")
        languages = st.text_input("Languages:", "")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\bludelta_capture_feature.py - Chunk 2
# Convert the PropertyStore string into a dictionary
        property_store = dict(item.split(":") for item in property_store_str.split(",")) if property_store_str else {}

        config = BludeltaCaptureServiceConfig()
        config.x_apikey = x_apikey
        config.x_api_identifier = x_api_identifier
        config.url = url
        config.filter_val = filter_val
        config.format_val = format_val
        config.property_store = property_store
        config.create_result_pdf = create_result_pdf
        config.add_ocr_result = add_ocr_result
        config.add_document_text = add_document_text
        config.languages = languages

        return config

def load_feature():
    st.title("Bludelta Capture Service")

    # Create the sidebar
    config = create_capture_sidebar()

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\bludelta_capture_feature.py - Chunk 3
return config

def load_feature():
    st.title("Bludelta Capture Service")

    # Create the sidebar
    config = create_capture_sidebar()

    # File uploader for the document to be captured
    document = st.file_uploader("Upload a document to capture:", type=["pdf", "png", "jpg", "jpeg", "tiff", "xml"])
    # Convert the document to a base64 string
    if document is not None:
        document_base64 = base64.b64encode(document.read()).decode('utf-8')

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\bludelta_capture_feature.py - Chunk 4
# Button to send the request
    if st.button("Send Request"):
        # Prepare the headers and payload
        headers = {
            "X-ApiKey": config.x_apikey,
            "X-ApiIdentifier": config.x_api_identifier,
            "Content-Type": "application/json",
            'User-Agent': 'CaputreService/1.0'}
        
        payload = {
            "Filter": None,
            "Invoice": document_base64,
            "Format": None,
            "PropertyStore": config.property_store,
            "CreateResultPdf": config.create_result_pdf,
            "AddOcrResult": config.add_ocr_result,
            "AddDocumentText": config.add_document_text,
            "Languages": config.languages,
        }


        # Send the request
        response = requests.post(config.url, headers=headers, json=payload)

        # Check if the request was successful
        if response.status_code == 200:
            tab1, tab2, tab3 = st.tabs(["JSON Result", "Embedded PDF", "Request Body"])

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\bludelta_capture_feature.py - Chunk 5
json_result = response.json()
            # Display the JSON response
            with tab1:                
                st.json(json_result)
            # Display the embedded PDF
            with tab2:
                try:
                    base64_pdf = json_result['EInvoice']['DocumentBinaries'][0]['Embedding']
                    # Decode the base64 string into PDF content
                    pdf_bytes = base64.b64decode(base64_pdf)
                    # create two columns
                    col1, col2 = st.columns((3,1))
                    # Display the JSON response
                    with col1:
                        st.write("### PDF Preview:")
                        pdf_viewer(pdf_bytes)            
                    with col2:
                        st.download_button(label="Download PDF", data=pdf_bytes, file_name="invoice.pdf", mime="application/pdf")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\bludelta_capture_feature.py - Chunk 6
with col2:
                        st.download_button(label="Download PDF", data=pdf_bytes, file_name="invoice.pdf", mime="application/pdf")
                        st.write("To view the PDF in an external pdf reader, please download it above.")                    
                except Exception as e:
                    st.error(f"An error occurred: {e}")
        
            # Display the request body
            with tab3:
                st.json(payload)
        else:
            print(response.text)
            st.error(f"An error occurred: {response.text}")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\bludelta_environment_feature.py - Chunk 0
import requests
import streamlit as st
import yaml

def load_feature():
    st.title("Bludelta Environment - Docker Compose Updater")

    # Input field for service URL
    url = st.text_input("Enter the URL of your service:", "")

    if url:
        if st.button("Update Docker Compose"):
            # Send request to the service
            response = requests.get(url)

            # Check if the request was successful
            if response.status_code == 200:
                # Parse and format the YAML content
                docker_compose = yaml.safe_load(response.text)
                formatted_yaml = yaml.dump(docker_compose, default_flow_style=False, sort_keys=False)

                # Display the YAML content with syntax highlighting
                st.code(formatted_yaml, language="yaml")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\bludelta_environment_feature.py - Chunk 1
# Display the YAML content with syntax highlighting
                st.code(formatted_yaml, language="yaml")

                # Save the YAML content to disk
                with open("updated_docker_compose.yaml", "w") as f:
                    f.write(formatted_yaml)
                st.success("Docker Compose file saved as updated_docker_compose.yaml")
            else:
                st.error(f"An error occurred: {response.text}")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\bludelta_logfile_viewer_feature.py - Chunk 0
import streamlit as st
import pandas as pd
import re
from collections import defaultdict
import statistics
import matplotlib.pyplot as plt


def log_file_viewer_feature():

    # Streamlit page configuration
    st.title('Log File Analyzer')
    st.write('Upload your log file for analysis.')

    # File uploader
    uploaded_file = st.file_uploader("Choose a log file", type=['log'])
    if uploaded_file is not None:
        # Reading log file
        log_lines = uploaded_file.readlines()
        log_lines = [line.decode('utf-8') for line in log_lines]

        # Regex pattern from the notebook
        log_pattern = re.compile(
            r'\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3} INFO \[.*\]: PID \d+: (\w+): (Start|End): ([\w\s]+):? ([\d\.,]+)? \[sec\]?')

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\bludelta_logfile_viewer_feature.py - Chunk 1
# Replicating the parsing logic from the notebook
        executions = defaultdict(lambda: defaultdict(list))
        for line in log_lines:
            match = log_pattern.search(line)
            if match:
                execution_id, phase, step_name, exec_time = match.groups()
                if phase == "End" and exec_time:
                    exec_time = exec_time.replace(',', '.')
                    executions[execution_id][step_name].append(float(exec_time))

        # Statistical analysis (adapted from the notebook)
        step_times = defaultdict(list)
        for steps in executions.values():
            for step, time in steps.items():
                step_times[step].append(time[0])  # Assuming [0] contains the execution time

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\bludelta_logfile_viewer_feature.py - Chunk 2
stats_results = defaultdict(dict)
        for step, times in step_times.items():
            if times:
                stats_results[step]['Average Time'] = statistics.mean(times)
                stats_results[step]['Median Time'] = statistics.median(times)
                stats_results[step]['Max Time'] = max(times)
                if len(times) > 1:
                    stats_results[step]['Standard Deviation'] = statistics.stdev(times)
                else:
                    stats_results[step]['Standard Deviation'] = 'N/A (single measurement)'


        # Create two columns
        col1, col2 = st.columns(2)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\bludelta_logfile_viewer_feature.py - Chunk 3
# Add statistical analysis to the first column
        with col1:
            # Display statistics
            st.write('Statistical Analysis Results:')
            
            # Sort criteria selection
            sort_criteria = st.selectbox('Sort Criteria', ['Max Time', 'Average Time', 'Median Time'])
            
            table_header = "| Step | Average Time | Median Time | Max Time | Standard Deviation |\n"
            table_divider = "| --- | --- | --- | --- | --- |\n"
            table_rows = ""
            
            # Sort the results based on the selected criteria
            sorted_results = sorted(stats_results.items(), key=lambda x: x[1][sort_criteria], reverse=True)
            
            for step, metrics in sorted_results:
                metrics = {k: round(v, 2) if isinstance(v, float) else v for k, v in metrics.items()}

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\bludelta_logfile_viewer_feature.py - Chunk 4
for step, metrics in sorted_results:
                metrics = {k: round(v, 2) if isinstance(v, float) else v for k, v in metrics.items()}
                table_rows += f"| {step} | {metrics['Average Time']} | {metrics['Median Time']} | {metrics['Max Time']} | {metrics['Standard Deviation']} |\n"

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\bludelta_logfile_viewer_feature.py - Chunk 5
markdown_table = table_header + table_divider + table_rows

            st.write('Statistical Analysis Results:')
            st.markdown(markdown_table)

        # Add plots to the second column
        with col2:
            # Visualization (adapted from the notebook)
            fig, axs = plt.subplots(4, 1, figsize=(12, 30))
            steps = list(stats_results.keys())
            average_times = [stats_results[step]['Average Time'] for step in steps]
            median_times = [stats_results[step]['Median Time'] for step in steps]
            max_times = [stats_results[step]['Max Time'] for step in steps]
            std_devs = [stats_results[step]['Standard Deviation'] if isinstance(stats_results[step]['Standard Deviation'], float) else 0 for step in steps]

            axs[0].barh(steps, average_times)
            axs[0].set_title('Average Execution Time per Step')

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\bludelta_logfile_viewer_feature.py - Chunk 6
axs[0].barh(steps, average_times)
            axs[0].set_title('Average Execution Time per Step')

            axs[1].barh(steps, median_times)
            axs[1].set_title('Median Execution Time per Step')

            axs[2].barh(steps, max_times)
            axs[2].set_title('Max Execution Time per Step')

            axs[3].barh(steps, std_devs)
            axs[3].set_title('Standard Deviation of Execution Time per Step')

            plt.tight_layout()
            st.pyplot(fig)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_customer_registration.py - Chunk 0
import streamlit as st
import sys
import pyodbc

# BACK END

def connect_to_database(server, database, user, password): #driver, 
    """ Create a database connection using pyodbc """

    if sys.platform == 'linux':
        driver_name = 'ODBC Driver 17 for SQL Server'
    elif sys.platform == 'win32':
        driver_name = 'SQL Server'      

    try:
        conn_string = f'DRIVER={{{driver_name}}};SERVER={server};DATABASE={database};UID={user};PWD={password}'
        conn = pyodbc.connect(conn_string)
        return conn
    except pyodbc.Error as e:
        st.sidebar.error("Database connection failed: " + str(e))
        return None
    
# Simulate existing partners and customers (in a real app, this would come from a database)
existing_partners = ["Partner A", "Partner B", "Partner C"]

existing_customers = ["Customer A", "Customer B", "Customer C"]

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_customer_registration.py - Chunk 1
existing_customers = ["Customer A", "Customer B", "Customer C"]

def get_partner(conn):
    """ Fetch customer list from the database where customers have configurations """
    if conn is not None:
        with conn.cursor() as cur:
            cur.execute("""
                        SELECT Id, Name 
                        FROM Customer
                        WHERE BcsId is not NULL;""")
            partner = cur.fetchall()
        return partner
    return []


def get_customer(conn, partner_id):
    """ Fetch customer list from the database where customers have configurations """
    if conn is not None:
        with conn.cursor() as cur:
            cur.execute("""
                        SELECT Id, Name 
                        FROM Customer
                        WHERE CustomerId = ?;""", (partner_id,))
            customers = cur.fetchall()
        return customers
    return []

###############################################################################
# FRONT END

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_customer_registration.py - Chunk 2
###############################################################################
# FRONT END

def customer_registration_feature():
    st.title("BLU DELTA Customer Registration")

    # Database connection parameters
    st.sidebar.title("Database Connection")
    #db = st.sidebar.selectbox('Select Database', ('smedbdev_current', 'Database2'))
    #driver = st.sidebar.text_input('Driver', 'SQL Server')
    
    server = st.sidebar.selectbox('Server', ('bcdbserverdev.database.windows.net', 'bcdbserver.database.windows.net'))
    database = st.sidebar.selectbox('Select RIPEye Database', ('smedbdev_current', 'smedbtest', 'smedb-v1.0'))
    database2 = st.sidebar.selectbox('Select BLU DELTA Database', ('bcsdb-auth', 'test'))
    user = st.sidebar.text_input('Username', 'user')
    password = st.sidebar.text_input('Password', 'password', type="password")
    conn = connect_to_database(server, database, user, password) #driver,

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_customer_registration.py - Chunk 3
# Create tabs
    tab1, tab2 = st.tabs(["BLU DELTA Registration", "RIPEye Registration"])

    with tab1:
        st.header("Register a new BLU DELTA Customer")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_customer_registration.py - Chunk 4
with tab2:
        st.header("Register a new RIPEye Customer")
    
        # Step 1: Choose or Create a Partner
        st.header("Step 1: Choose an existing Partner or create a new one.")
        #st.subheader("Choose an existing Partner or create a new one.")
        st.markdown("""
                    ***ATTENTION:*** Partners follow the naming convention: ***'partner.partnername'***.
                    However, there are exceptions such as ***'Ramsauer & StÃ¼rmer Software GmbH'*** (= Aptean AT) and ***'RVS Production Partner'***.
                    Also, ***'partner.aptean'*** is reserved for Aptean DACH and is usually only used for Aptean DACH customers who would like to provide Feedback for Training via RIPEye.
                    """)
        
        # Simulate existing partners (in a real app, this would come from a database)
        #existing_partners = ["Partner A", "Partner B", "Partner C"]
        existing_partners = get_partner(conn)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_customer_registration.py - Chunk 5
#existing_partners = ["Partner A", "Partner B", "Partner C"]
        existing_partners = get_partner(conn)
        partner_names = [name for _, name in existing_partners]
        partner_choice = st.selectbox("Choose a Partner", options=["Create New Partner"] + partner_names)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_customer_registration.py - Chunk 6
if partner_choice == "Create New Partner":
            partner_name = st.text_input("New Partner Name", placeholder="Enter new partner name such as partner.blumatix")
            contact_email = st.text_input("Contact Email", placeholder="Enter contact email...")
            partner_document_limit = st.number_input("Partner Document Limit (Default = 10000)", min_value=1, value=10000)
            partner_expiration_date = st.text_input("Partner Expiration Date (Default = 2100-01-01)", value='2100-01-01')
        else:
            partner_name = partner_choice
            #contact_email = st.text_input("Contact Email", placeholder="Enter contact email for the chosen partner...")
            selected_partner_id = [id for id, name in existing_partners if name == partner_name][0]

        

        st.markdown("---")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_customer_registration.py - Chunk 7
st.markdown("---")

        # Step 2: Add a Customer to the Chosen Partner
        st.header("Step 2: Add a new customer to the chosen or created partner.")
        #st.subheader("Add a new customer to the chosen or created partner.")
        st.markdown("""
                    ***ATTENTION:*** Customers follow the naming convention: ***'partner.partnername.customername'***.
                    However, there are exceptions such as ***'traunerverlag'*** which is an Aptean AT (former Ramsauer & StÃ¼rmer Software GmbH) customer.
                    New Aptean AT customers should be named ***'partner.ramsauerstuermer.customername'***.
                    """)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_customer_registration.py - Chunk 8
#existing_customers = ["Customer A", "Customer B", "Customer C"]
        
        if partner_choice == "Create New Partner":
            customer_names = []
        else:
            existing_customers = get_customer(conn, selected_partner_id) or []
            customer_names = [name for _, name in existing_customers] if existing_customers else []
        
        customer_choice = st.selectbox("Choose a Customer", options=["Create New Customer"] + customer_names)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_customer_registration.py - Chunk 9
if customer_choice == "Create New Customer":
            customer_name = st.text_input("Customer Name", placeholder="Enter customer name such as partner.blumatix.customer1")
            customer_contact_email = st.text_input("Customer Contact Email", placeholder="Enter customer contact email...")
            customer_config_path = st.text_input("Customer Config Path", value="\\\\nas-01\\CustomerData\\ripeye\\RIPEyeDefaultConfig.json")
            delete_data_days = st.number_input("Delete Data After X Days (Default = 90) from DB and Inbox", min_value=1, value=90)
            customer_document_limit = st.number_input("Customer Document Limit (Default = 10000)", min_value=1, value=10000)
            customer_expiration_date = st.text_input("Customer Expiration Date (Default = 2100-01-01)", value='2100-01-01')
        
            # Optional fields
            st.markdown("""

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_customer_registration.py - Chunk 10
customer_expiration_date = st.text_input("Customer Expiration Date (Default = 2100-01-01)", value='2100-01-01')
        
            # Optional fields
            st.markdown("""
                        ***Attention**** Aptean AT Customer/Mandator: Add the e-mail address according the csv from Aptean AT. Aptean AT usually needs this for their client/mandator logic.
                        
                        Also, don't put the ***same address for mandator and customer***, this causes problems. If a customer has mandators, there should be specific E-Mail Adresses for each mandator. It's possible to add the Invoice Listener only to the mandator (see Step 3).
                        """)
            invoice_listener_email = st.text_input("Email for Invoice Listener (Optional)", placeholder="Enter invoice listener email...")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_customer_registration.py - Chunk 11
""")
            invoice_listener_email = st.text_input("Email for Invoice Listener (Optional)", placeholder="Enter invoice listener email...")
            feedback_email = st.text_input("Feedback Email informing the Customer about Issues with the received E-Mail (Optional)", placeholder="Enter feedback email...")
            receiver_vat_id = st.text_input("Receiver VAT ID (Optional)", placeholder="Enter Receiver VAT ID provided by the Partner or Customer")
        else:
            customer_name = customer_choice

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_customer_registration.py - Chunk 12
st.markdown("---")

        # Step 3: Add a Client (Mandator) to the Created Customer (Optional)
        st.header("Step 3: Add a Client (Mandator) to the Customer (Optional)")
        #st.subheader("Add a new client (mandator) to the created customer.")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_customer_registration.py - Chunk 13
mandator_name = st.text_input("Mandator Name", placeholder="Enter mandator name such as partner.blumatix.customer1.mandator1")
        mandator_id = st.text_input("Mandator ID", placeholder="Enter mandator ID such as 100 provided by the Partner or Customer")
        
        # Optional fields for Mandator
        st.markdown("""
                    ***Attention**** Aptean AT Customer/Mandator: Add the e-mail address according the csv from Aptean AT. Aptean AT usually needs this for their client/mandator logic.
                    
                    Also, don't put the ***same address for mandator and customer***, this causes problems. If a customer has mandators, there should be specific E-Mail Adresses for each mandator.
                    """)
        mandator_invoice_listener_email = st.text_input("Mandator Email for Invoice Listener (Optional)", placeholder="Enter invoice listener email...")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_customer_registration.py - Chunk 14
""")
        mandator_invoice_listener_email = st.text_input("Mandator Email for Invoice Listener (Optional)", placeholder="Enter invoice listener email...")
        mandator_feedback_email = st.text_input("Mandator Feedback Email informing the Customer about Issues with the received E-Mail (Optional)", placeholder="Enter feedback email...")
        mandator_receiver_vat_id = st.text_input("Mandator Receiver VAT ID (Optional)", placeholder="Enter Receiver VAT ID provided by the Partner or Customer")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_customer_registration.py - Chunk 15
st.markdown("---")

        # Step 4: Create a User for the Customer or Mandator
        st.header("Step 4: Create a User for the Customer or Mandator")
        #st.subheader("Create a User for the above Customer or Mandator.")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_customer_registration.py - Chunk 16
# add Option if the user should be related to the customer or mandator.
        st.markdown("""
                    Aptean AT Customers: Access RIPEye directly. They don't need a user. Other Customers might need a user to access RIPEye (such as Lagerhaus/RVS). 
                    Please check the Wiki for Customer Specific Requirements such as password policies.
                    
                    Please add an internal user (***'customername_internal'***) for our Support-Team to access RIPEye for troubleshooting.
                    """)
        username = st.text_input("Username", placeholder="Enter username such as customer1_internal")
        password = st.text_input("Password", placeholder="Enter password...", type="password")
        

        st.markdown("---")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_customer_registration.py - Chunk 17
st.markdown("---")

        # Submit button to finalize registration
        if st.button("Register Customer"):
            st.success("Customer registration is successful!")
            st.write(f"Partner Name: {partner_name}")
            st.write(f"Customer Name: {customer_name}")
            st.write(f"Customer Config Path: {customer_config_path}")
            st.write(f"Data Deletion After: {delete_data_days} days")
            if mandator_name:
                st.write(f"Mandator Name: {mandator_name}")
            st.write(f"Username: {username}")
            st.write("API Identifier has been generated and sent to the customer.")

if __name__ == "__main__":
    customer_registration_feature()

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_kickstarter_feature.py - Chunk 0
import streamlit as st

def kickstarter_feature():
    # Title for the feature
    st.title("CodeKickstarter")

    # Form for user inputs
    with st.form("project_form", clear_on_submit=True):
        project_name = st.text_input("Project Name", help="Enter the name of your new project.")
        project_lang = st.selectbox("Language", ["Python", "C#"], help="Select the project language.")
        template_choice = st.selectbox("Template", ["Template 1", "Template 2"], help="Select a template for your project.")
        submit_button = st.form_submit_button("Create Project")

    if submit_button:
        # Placeholder for success message
        create_and_push_project(project_name, project_lang, template_choice)
        st.success("Project created and pushed successfully!")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_kickstarter_feature.py - Chunk 1
def create_and_push_project(name, lang, template):
    # 1. Generate project using Cookiecutter based on user selections
    generate_project(name, lang, template)
    # 2. Create a new repo in Azure DevOps
    repo_url = create_azure_devops_repo(name)
    # 3. Initialize git in the generated project, add, commit, and push to the new repo
    push_project_to_repo(name, repo_url)

def generate_project(name, lang, template):
    # Placeholder for Cookiecutter project generation logic
    pass

def create_azure_devops_repo(name):
    # Placeholder for Azure DevOps repo creation logic
    return "https://dev.azure.com/yourOrganization/yourProject/_git/" + name

def push_project_to_repo(name, repo_url):
    # Placeholder for git initialization, add, commit, and push logic
    pass

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 0
import streamlit as st
import pyodbc
import sys
import random
from scipy import stats
from scipy.stats import bootstrap
import numpy as np
import pandas as pd
from collections import defaultdict
import openpyxl
from datetime import datetime
import os

def connect_to_database(server, database, user, password): #driver, 
    """ Create a database connection using pyodbc """

    if sys.platform == 'linux':
        driver_name = 'ODBC Driver 17 for SQL Server'
    elif sys.platform == 'win32':
        driver_name = 'SQL Server'      

    try:
        conn_string = f'DRIVER={{{driver_name}}};SERVER={server};DATABASE={database};UID={user};PWD={password}'
        conn = pyodbc.connect(conn_string)
        return conn
    except pyodbc.Error as e:
        st.sidebar.error("Database connection failed: " + str(e))
        return None

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 1
def get_label_types(conn):
    """ Fetch label types from the database and return them as a list of strings """
    if conn is not None:
        with conn.cursor() as cur:
            cur.execute("SELECT Name FROM LabelType;")
            # Fetch all results and extract the 'Name' from each tuple in the list
            label_types = [row[0] for row in cur.fetchall()]  # Converts list of tuples to list of strings
        return label_types
    return []


def get_username(conn):
    """Fetch a dictionary of user IDs to usernames."""
    if conn is not None:
        with conn.cursor() as cur:
            cur.execute("SELECT Id, UserName FROM [User];")
            users = cur.fetchall()
            # Create a dictionary mapping user IDs to usernames
            user_dict = {row[0]: row[1] for row in users}
        return user_dict
    return {}

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 2
def get_label_data(conn, label_types, min_data_points, max_data_points):
    """ Fetch label data from the database based on given conditions """
    if conn is not None:
        with conn.cursor() as cur:
            placeholders = ', '.join(['?'] * len(label_types))
            sql_query = f"""
                SELECT * FROM Label 
                WHERE Type IN (SELECT [Id] FROM LabelType WHERE Name IN ({placeholders})) 
                AND Verified = 1 
                AND CreatedBy_Id IN (SELECT [Id] FROM [User] WHERE Email IS NOT NULL) 
                AND Created >= DATEADD(day, -185, GETDATE());
            """
            cur.execute(sql_query, label_types)
            label_data = fetch_data_as_dict(cur)
            # Debug: print the first few rows to check structure
            #st.write("Debug: Sample label data:", label_data[:5])

        # Get usernames
        user_dict = get_username(conn)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 3
# Get usernames
        user_dict = get_username(conn)

        # Group data by CreatedBy_Id
        grouped_data = defaultdict(list)
        for row in label_data:
            row['UserName'] = user_dict.get(row['CreatedBy_Id'], 'Unknown')
            grouped_data[row['CreatedBy_Id']].append(row)

        # Filter out groups with fewer than min_data_points
        filtered_data = []
        for labeler, data in grouped_data.items():
            if len(data) >= min_data_points:
                if len(data) > max_data_points:
                    data = random.sample(data, max_data_points)  # Randomly sample to max_data_points
                filtered_data.extend(data)
            #else:
            #    st.write(f"Labeler {labeler} has fewer than {min_data_points} data points and will be excluded.")

        return filtered_data
    return []

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 4
return filtered_data
    return []


def fetch_data_as_dict(cursor):
    """ Convert cursor rows to a list of dictionaries based on cursor description. """
    columns = [col[0] for col in cursor.description]
    return [dict(zip(columns, row)) for row in cursor.fetchall()]


def get_metrics_by_labeler(run_bootstrap_calculation, label_data, n_bootstrap_runs, confidence_level, min_data_points):
    if run_bootstrap_calculation and label_data:
        metrics_by_labeler = {}
        labelers = set(row['CreatedBy_Id'] for row in label_data)

        for labeler in labelers:
            labeler_data = [row['Correct'] for row in label_data if row['CreatedBy_Id'] == labeler]

            # Debug: Print the data for each labeler to check before bootstrap
            #st.write(f"Data for labeler {labeler}: {labeler_data}")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 5
# Debug: Print the data for each labeler to check before bootstrap
            #st.write(f"Data for labeler {labeler}: {labeler_data}")

            if len(labeler_data) < min_data_points:
                st.write(f"Not enough data for labeler {labeler}. At least two data points are required.")
                continue

            try:
                results = bootstrap((np.array(labeler_data),), np.mean, confidence_level=confidence_level, n_resamples=n_bootstrap_runs)
                metrics_by_labeler[labeler] = {
                    'mean': np.mean(labeler_data),
                    'confidence_interval': (results.confidence_interval.low, results.confidence_interval.high),
                    'N': len(labeler_data)
                }
            except Exception as e:
                st.write(f"Bootstrap calculation failed for labeler {labeler}: {e}")

        return metrics_by_labeler
    return {}

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 6
return metrics_by_labeler
    return {}


def get_label_type_ids(conn, label_type_names):
    """Fetch label type IDs from the LabelType table given a list of names."""
    if conn is not None:
        with conn.cursor() as cur:
            placeholders = ', '.join(['?'] * len(label_type_names))
            sql_query = f"SELECT Id, Name FROM LabelType WHERE Name IN ({placeholders});"
            cur.execute(sql_query, label_type_names)
            label_types = cur.fetchall()
            # Create a dictionary mapping names to IDs
            label_type_dict = {row[1]: row[0] for row in label_types}
        return label_type_dict
    return {}       


def extend_allocated_package_history(selected_users, label_package_name, combined_label_types, document_ids_input, conn):
    # File and sheet information
    excel_file = r"\\nas-01\CustomerData\data_ValueDelivery\zugewiesenePakete_BennuAllocator_2024-08-21.xlsx"
    sheet_name = "LabelerPakete"

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 7
# Ensure the directory exists
    directory = os.path.dirname(excel_file)
    if not os.path.exists(directory):
        try:
            os.makedirs(directory)
            print(f"Directory created: {directory}")
        except OSError as e:
            print(f"Error creating directory {directory}: {e}")
            return

    # Ensure the Excel file exists
    if not os.path.exists(excel_file):
        try:
            # Create a new file with the required columns if it does not exist
            df = pd.DataFrame(columns=["User Id", "Username", "Label Package Name", "Label Types", "Document Ids", "Timestamp"])
            with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name=sheet_name, index=False)
            print(f"Excel file created: {excel_file}")
        except Exception as e:
            print(f"Error creating Excel file {excel_file}: {e}")
            return

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 8
# Load the existing Excel file
    try:
        df = pd.read_excel(excel_file, sheet_name=sheet_name)
    except Exception as e:
        print(f"Error reading Excel file {excel_file}: {e}")
        return

    # Convert combined_label_types and document_ids_input to strings if they are lists
    label_types_str = combined_label_types #', '.join(combined_label_types)
    document_ids_str = document_ids_input #', '.join(map(str, document_ids_input))

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 9
# Get the current timestamp
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # Get usernames for the selected users
    username_dict = get_username(conn)
    
    # Append new data for each selected user
    for user_id in selected_users:
        username = username_dict.get(user_id, "Unknown")
        new_row = {
            "User Id": user_id,
            "Username": username,
            "Label Package Name": label_package_name,
            "Label Types": label_types_str,
            "Document Ids": document_ids_str,
            "Timestamp": timestamp
        }
        df = df.append(new_row, ignore_index=True)
    
    # Save the updated DataFrame back to the Excel file
    try:
        with pd.ExcelWriter(excel_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:
            df.to_excel(writer, sheet_name=sheet_name, index=False)
        print(f"Data successfully appended to {excel_file}")
    except Exception as e:

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 10
df.to_excel(writer, sheet_name=sheet_name, index=False)
        print(f"Data successfully appended to {excel_file}")
    except Exception as e:
        print(f"Error writing to Excel file {excel_file}: {e}")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 11
###############################################################################

def label_package_allocator_feature():
    """ Main function to render the Streamlit app """
    st.title('Label Package Allocator')

    # Database connection parameters
    st.sidebar.title("Database Connection")
    server = st.sidebar.selectbox('Server', ('serverbdsql01.ad.blumatix.com,62434', 'serverbdsql01.ad.blumatix.com,62442', 'SERVERBDSQL01\BLUDELTA', '192.168.137.60,62434'))
    database = st.sidebar.selectbox('Select Database', ('bcidb', 'bcidb_dev'))
    user = st.sidebar.text_input('Username', 'user')
    password = st.sidebar.text_input('Password', 'password', type="password")
    
    conn = connect_to_database(server, database, user, password)


    # Selecting label types from the LabelType table
    st.write('Please select the label types you want to include in the label package.')

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 12
# Selecting label types from the LabelType table
    st.write('Please select the label types you want to include in the label package.')

    # Define sets of label types
    label_type_sets = {
        'Invoice': ['DocumentType', 'InvoiceCurrency', 'DeliveryDate', 'InvoiceDate', 'InvoiceId', 'CustomerId', 'GrandTotalAmount', 
                    'NetAmount', 'VatRate', 'VatAmount', 'SenderVatId', 'ReceiverVatId', 'Iban', 'Bic', 'ReceiverOrderId', 
                    'SenderOrderId', 'ReceiverOrderDate', 'SenderOrderDate', 'TotalNetAmount', 'TotalVatAmount', 'DeliveryNoteId', 
                    'BankCode', 'BankAccount', 'DeliveryPeriodKey', 'DeliveryPeriodValue', 'ReceiverTaxId', 'SenderTaxId'],

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 13
'OrderConfirmation': ['DocumentType', 'InvoiceCurrency', 'DeliveryDate', 'CustomerId', 'GrandTotalAmount', 'NetAmount', 'VatRate',
                              'VatAmount', 'SenderVatId', 'ReceiverVatId', 'Iban', 'Bic', 'ReceiverOrderId', 'SenderOrderId',
                              'ReceiverOrderDate', 'SenderOrderDate', 'TotalNetAmount', 'TotalVatAmount', 'BankCode', 'BankAccount',
                              'ReceiverTaxId', 'SenderTaxId', 'OrderConfirmationId', 'OrderConfirmationDate', 'SurchargeType', 'SurchargeRate',
                              'SurchargeAmount', 'DeliveryTerm'],

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 14
'Quotation': ['DocumentType', 'InvoiceCurrency', 'DeliveryDate', 'CustomerId', 'GrandTotalAmount', 'NetAmount', 'VatRate',
                              'VatAmount', 'SenderVatId', 'ReceiverVatId', 'Iban', 'Bic', 'ReceiverOrderId', 'SenderOrderId',
                              'ReceiverOrderDate', 'SenderOrderDate', 'TotalNetAmount', 'TotalVatAmount', 'BankCode', 'BankAccount',
                              'ReceiverTaxId', 'SenderTaxId', 'QuotationId', 'QuotationDate'],

        'Contact': ['ContactName', 'Street', 'ZipCode', 'City', 'Country', 'SenderReceiverClassification', 'AttentionName', 'Region'],

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 15
'LineItems': ['LineItemPositionNumberHeader', 'LineItemDescriptionHeader', 'LineItemArticleNumberHeader', 'LineItemQuantityHeader', 
                      'LineItemUnitHeader', 'LineItemUnitPriceHeader', 'LineItemVatRateHeader', 'LineItemAmountHeader', 'LineItemCustomDetailHeader', 
                      'LineItemPositionNumber', 'LineItemDescription', 'LineItemArticleNumber', 'LineItemQuantity', 'LineItemUnit', 'LineItemUnitPrice', 
                      'LineItemVatRate', 'LineItemAmount', 'LineItemCustomDetail', 'LineItemBufferText', 'LineItemDeliveryNoteIdHeader', 
                      'LineItemDeliveryDateHeader', 'LineItemOrderIdHeader', 'LineItemUnitPriceCoefficientHeader', 'LineItemDiscountHeader', 
                      'LineItemDeliveryNoteId', 'LineItemDeliveryDate', 'LineItemOrderId', 'LineItemUnitPriceCoefficient', 'LineItemDiscount', 'LineItemCount'],

        'Automotive': ['FirstRegistrationDate', 'PlateId', 'Mileage', 'VehicleIdentificationNumber']
    }

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 16
'Automotive': ['FirstRegistrationDate', 'PlateId', 'Mileage', 'VehicleIdentificationNumber']
    }

    # Predefined sets selection
    selected_sets = st.multiselect('Select Predefined Label Type Sets', list(label_type_sets.keys()))

    # Combine selected predefined sets into a single list
    combined_label_types = []
    for set_name in selected_sets:
        combined_label_types.extend(label_type_sets[set_name])

    # Allow selection of individual types and combine with predefined sets
    label_types = get_label_types(conn)
    selected_individual_types = st.multiselect('Select or add Individual Label Types', label_types, default=label_types[1])

    # Combine individual selections with predefined sets, remove duplicates
    combined_label_types.extend(selected_individual_types)
    combined_label_types = list(set(combined_label_types))  # Remove duplicates
    st.write(f"Selected Label Types: {combined_label_types}")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 17
st.write('Let\'s find out who the best labeler is for the selected label types. Please provide the following information to calculate the label quality metrics.')

    # Min data length by CreatedBy_Id
    min_data_points = st.text_input('Min Data Points', '10')
    max_data_points = st.text_input('Max Data Points', '10000')

    try:
        min_data_points = int(min_data_points)  # Convert input to integer
        max_data_points = int(max_data_points)  # Convert input to integer
    except ValueError:
        st.error("Please enter a valid integer for minimum data points > 2.")
        return
    
    # Get label data based on the selected label types
    label_data = get_label_data(conn, combined_label_types, min_data_points, max_data_points)

    # User input for the number of bootstrap runs
    bootstrap_run_options = [1000, 10000, 100000]
    n_bootstrap_runs = st.selectbox('Select the number of bootstrap runs:', bootstrap_run_options, index=0)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 18
# User input for confidence interval
    confidence_level_options = [0.95, 0.9, 0.99]
    confidence_level = st.selectbox('Select the confidence level:', confidence_level_options)

    # Run button to initiate bootstrap calculation and display the best labeler for the selected label types
    if st.button("Calculate Label Quality Metrics"):
        # Set a flag to indicate that the button is pressed
        run_bootstrap_calculation = True
        # Ensure the correct arguments are passed, including the run_bootstrap_calculation flag
        metrics = get_metrics_by_labeler(run_bootstrap_calculation, label_data, n_bootstrap_runs, confidence_level, min_data_points)
        #st.write(metrics)

        # Convert metrics to DataFrame
        metrics_df = pd.DataFrame.from_dict(metrics, orient='index')
        metrics_df.reset_index(inplace=True)
        metrics_df.columns = ['Labeler Id', 'Mean', 'Confidence Interval', 'N']

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 19
# Get usernames and map them to the DataFrame
        username_dict = get_username(conn)
        metrics_df['Username'] = metrics_df['Labeler Id'].map(username_dict)

        # Round values to 3 decimal places
        metrics_df['Mean'] = metrics_df['Mean'].round(3)

        # Split Confidence Interval into two columns
        metrics_df[['CI.Low', 'CI.High']] = pd.DataFrame(metrics_df['Confidence Interval'].tolist(), index=metrics_df.index)

        # Round CI values to 3 decimal places
        metrics_df['CI.Low'] = metrics_df['CI.Low'].round(3)
        metrics_df['CI.High'] = metrics_df['CI.High'].round(3)

        # Drop the original Confidence Interval column
        metrics_df.drop(columns=['Confidence Interval'], inplace=True)

        # Sort by Mean in descending order
        metrics_df = metrics_df.sort_values(by='Mean', ascending=False)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 20
# Sort by Mean in descending order
        metrics_df = metrics_df.sort_values(by='Mean', ascending=False)

        # Reorder columns for better readability
        metrics_df = metrics_df[['Labeler Id', 'Username', 'Mean', 'CI.Low', 'CI.High', 'N']]

        # Reset the index to remove the index column from the display
        metrics_df.reset_index(drop=True, inplace=True)

        # Show the DataFrame as a table
        st.dataframe(metrics_df)

        # Extract user IDs for dynamic selection
        user_ids_from_metrics = metrics_df['Labeler Id'].tolist()
    else:
        run_bootstrap_calculation = False
        user_ids_from_metrics = []

    st.write('Please allocate the label package to your prefered users.')

    # Input for package IDs
    try:

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 21
st.write('Please allocate the label package to your prefered users.')

    # Input for package IDs
    try:

        selected_users_input = st.text_input('Enter User IDs', '540, 2')
        selected_users = [int(user.strip()) for user in selected_users_input.split(',') if user.strip().isdigit()]
        st.write(f"Selected User IDs: {selected_users}")
    except ValueError as e:
        st.error("Please enter valid integers for User IDs separated by commas.")
    """
    if user_ids_from_metrics:
        selected_users = st.multiselect('Select Users', user_ids_from_metrics)
    else:
        selected_users = []
    """
    document_ids_input = st.text_input('Document IDs', '1, 2, 3, 4, 5')
    st.write(f"You selected: {document_ids_input}")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 22
# Input for label package name
    st.write('Please provide a short description of the label package. The name should clearly indicate the content of the package such as Customer_Benchmark or ValueDelivery2024-05.')
    label_package_name = st.text_input('Label Package Name/Description')

    # Update user table in bcidb
    if st.button("Allocate Label Package"):
        try:
            document_ids = [int(x.strip()) for x in document_ids_input.split(',') if x.strip().isdigit()]

            # Fetch the label type IDs using the selected label type names
            label_type_ids_dict = get_label_type_ids(conn, combined_label_types)
            label_type_ids = [label_type_ids_dict[name] for name in combined_label_types]

            # Join list of document ids and label type ids into a string
            assigned_labels = ','.join(map(str, label_type_ids))
            assigned_invoice_ids = ','.join(map(str, document_ids))

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 23
# Ensure user IDs are integers
            #selected_users = [int(user.strip()) for user in selected_users if user.strip().isdigit()]

            # Generate the SQL update statement
            sql_update = f"""
                UPDATE [bcidb].[dbo].[User]
                SET AssignedLabels = '{assigned_labels}', 
                AssignedInvoiceIds = '{assigned_invoice_ids}'
                WHERE Id IN ({','.join(['?' for _ in selected_users])});
            """
                
            with conn.cursor() as cur:
                # Unpack the selected_users list to match the placeholders
                cur.execute(sql_update, *selected_users)
                conn.commit()
            st.success("Labels and document IDs allocated successfully.")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_label_package_allocator.py - Chunk 24
# If label allcoation was successful, add the package information to the 
            # zugewiesenePakete.xlsx file where the history of allocated packages is stored.
            extend_allocated_package_history(selected_users, label_package_name, combined_label_types, document_ids_input, conn)

        except Exception as e:
            st.error(f"An error occurred: {e}")

      

if __name__ == "__main__":
    label_package_allocator_feature()

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_mlflow_explorer.py - Chunk 0
import streamlit as st
import mlflow
from mlflow.tracking import MlflowClient
import pandas as pd
#from io import BytesIO
import os
import sys

"""
# Tried to use the MLflow API to download artifacts, but it didn't work
def list_experiment_ids():
    experiments = mlflow.search_experiments()
    experiment_info = [(experiment.experiment_id, experiment.name) for experiment in experiments]
    return experiment_info

def list_run_artifacts(run_id):
    client = MlflowClient()
    artifacts = client.list_artifacts(run_id)
    return [artifact.path for artifact in artifacts]

def load_artifact_as_dataframe(run_id, artifact_path):
    client = MlflowClient()
    artifact_data = client.download_artifacts(run_id, artifact_path)
    
    # Read the artifact data directly into a pandas DataFrame
    df = pd.read_csv(BytesIO(artifact_data), sep='\t')
    
    return df

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_mlflow_explorer.py - Chunk 1
def search_document_ids(df, document_ids):
    # Convert document_ids to integers if they are numeric
    document_ids = [int(doc_id.strip()) for doc_id in document_ids]
    
    # Search for the document IDs in the 'invoice_id' column
    found_ids = df[df['invoice_id'].isin(document_ids)]
    return found_ids
"""

def load_artifact_as_dataframe(file_path, has_header=True):
    if has_header:
        df = pd.read_csv(file_path, sep='\t')
    else:
        df = pd.read_csv(file_path, sep='\t', header=None)
    
    # Debug: Print the header of the DataFrame
    #st.write("DataFrame Header:", df.head())  # Display the first few rows of the DataFrame in Streamlit
    
    return df


def search_document_ids(df, document_ids):
    # Ensure document_ids are integers
    document_ids = [int(doc_id.strip()) for doc_id in document_ids]

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_mlflow_explorer.py - Chunk 2
def search_document_ids(df, document_ids):
    # Ensure document_ids are integers
    document_ids = [int(doc_id.strip()) for doc_id in document_ids]

    try:
        if 'invoice_id' in df.columns:
            # Case 1: DataFrame with header and 'invoice_id' column
            filtered_df = df[df['invoice_id'].isin(document_ids)]
            
            # Drop duplicates to ensure each 'invoice_id' is counted only once
            unique_invoice_ids = filtered_df['invoice_id'].drop_duplicates()
        
        else:
            # Case 2: DataFrame without header where IDs are in the first column
            filtered_df = df[df.iloc[:, 0].isin(document_ids)]
            
            # Drop duplicates to ensure each ID is counted only once
            unique_invoice_ids = filtered_df.iloc[:, 0].drop_duplicates()

    except Exception as e:
        st.error(f"An error occurred while searching for document IDs: {e}")
        return pd.DataFrame(), 0

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_mlflow_explorer.py - Chunk 3
except Exception as e:
        st.error(f"An error occurred while searching for document IDs: {e}")
        return pd.DataFrame(), 0

    # The 'filtered_df' will still contain all rows including duplicates, but the count will be based on unique IDs
    found_count = unique_invoice_ids.shape[0]
    
    return filtered_df, found_count


    
###############################################################################
def mlflow_explorer_feature():
    st.title("MLflow Artifact Explorer")

    tracking_uri = st.text_input("MLflow Tracking URI", "http://192.168.137.78:30200")
    mlflow.set_tracking_uri(tracking_uri)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_mlflow_explorer.py - Chunk 4
tracking_uri = st.text_input("MLflow Tracking URI", "http://192.168.137.78:30200")
    mlflow.set_tracking_uri(tracking_uri)

    # Define base path on NAS
    if sys.platform == 'linux':
        base_path = "/mlflow/development/artifacts/artifacts"    
    elif sys.platform == 'win32':
        base_path = r"\\nas-01\MLFlow\development\artifacts\artifacts"
    
    
    # Select Experiment ID
    selected_experiment_id = st.text_input("Experiment Id", "12")
    """
    experiment_info = list_experiment_ids()
    experiment_dict = {name: experiment_id for experiment_id, name in experiment_info}

    selected_experiment = st.selectbox("Choose an Experiment", list(experiment_dict.keys()))
    selected_experiment_id = experiment_dict[selected_experiment]
    """

    client = MlflowClient()
    runs = client.search_runs(experiment_ids=[selected_experiment_id])
    run_dict = {run.data.tags.get("mlflow.runName", run.info.run_id): run.info.run_id for run in runs}

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_mlflow_explorer.py - Chunk 5
selected_run_name = st.selectbox("Choose a Run", list(run_dict.keys()))
    selected_run_id = run_dict[selected_run_name]

    document_ids_input = st.text_input("Document IDs (comma-separated)", "1, 2, 3")
    document_ids = [doc_id.strip() for doc_id in document_ids_input.split(',')]
    len_document_ids = len(document_ids)

    # Define the file names for train, validation, and test sets
    file_sets = {
        "Train": "train_index.tsv",
        "Validation": "val_index.tsv",
        "Test": "test_index.tsv"
    }

        # Construct the full path to the artifacts directory
    artifacts_dir = os.path.join(base_path, selected_experiment_id, selected_run_id, "artifacts")

    # Specify the path to the log_exception file
    #log_exception_input = st.text_input("Path to log_exception file")
    st.markdown("Choose a log_exception file from `\\\\nas-01\TrainingsDataExt4` -> model_name -> logs_exceptions")
    log_exception_input = st.file_uploader("Choose a file")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_mlflow_explorer.py - Chunk 6
if st.button("Search Document IDs in Artifacts"):
        #st.write("Button clicked!")  # This should display when the button is clicked
        results = {}
        for set_name, file_name in file_sets.items():
            file_path = os.path.join(artifacts_dir, file_name)
            #st.write(f"Checking for file: {file_path}")  # Display the file being checked

            if os.path.exists(file_path):
                #st.write(f"Processing file: {file_name}")  # Confirm the file is being processed
                
                try:
                    # Load the artifact directly into a DataFrame
                    df = load_artifact_as_dataframe(file_path)
                    
                    # Search for the document IDs in the DataFrame
                    found_ids_df, found_count = search_document_ids(df, document_ids)
                    #found_count = found_ids_df.shape[0]

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_mlflow_explorer.py - Chunk 7
# Store the result
                    results[set_name] = {
                        "found_ids": found_ids_df,
                        "count": found_count
                    }
                    #st.write(f"DataFrame dimensions (rows, columns): {found_ids_df.shape}")
                except Exception as e:
                    st.error(f"An error occurred while processing {file_name}: {e}")
            else:
                st.warning(f"File {file_name} not found at {file_path}.")
                results[set_name] = {
                    "found_ids": pd.DataFrame(),
                    "count": 0
                }
        
        # Display the results
        for set_name, result in results.items():
            st.write(f"**{set_name} Set**")
            if result["count"] > 0:
                st.success(f"{result['count']} document IDs from {len_document_ids} found in {file_sets[set_name]}:")
                st.write(result["found_ids"])
            else:

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_mlflow_explorer.py - Chunk 8
st.success(f"{result['count']} document IDs from {len_document_ids} found in {file_sets[set_name]}:")
                st.write(result["found_ids"])
            else:
                st.warning(f"No document IDs found in {file_sets[set_name]}.")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_mlflow_explorer.py - Chunk 9
results_log_exception = {}
        if log_exception_input is not None:
            try:
                # Load the artifact directly into a DataFrame
                df = pd.read_csv(log_exception_input, header=None, sep='\t')
                
                # Search for the document IDs in the DataFrame
                found_ids_df, found_count = search_document_ids(df, document_ids)
                #found_count = found_ids_df.shape[0]

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_mlflow_explorer.py - Chunk 10
# Store the result
                results_log_exception = {
                    "found_ids": found_ids_df,
                    "count": found_count
                }
                #st.write(f"DataFrame dimensions (rows, columns): {found_ids_df.shape}")
            except Exception as e:
                st.error(f"An error occurred while processing {log_exception_input}: {e}")
                results_log_exception = {
                    "found_ids": pd.DataFrame(),
                    "count": 0
                }
        else:
            st.warning(f"No file uploaded yet.")
            results_log_exception = {
                "found_ids": pd.DataFrame(),
                "count": 0
            }

        # Display the results
        st.write(f"**Log Exception File**")
        if results_log_exception["count"] > 0:
            st.success(f"{results_log_exception['count']} document IDs from {len_document_ids} found in log_exception:")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_mlflow_explorer.py - Chunk 11
# Check if the first row is mistakenly being treated as a header
            if results_log_exception["found_ids"].columns[0] == results_log_exception["found_ids"].iloc[0, 0]:
                # Reset the header if the first row is being treated as the header
                results_log_exception["found_ids"].columns = [f"Column_{i}" for i in range(results_log_exception["found_ids"].shape[1])]
            
            # Use st.dataframe for better display control
            st.dataframe(results_log_exception["found_ids"], height=400, width=800)
        else:
            st.warning(f"No document IDs found in log_exception.")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_mlflow_explorer.py - Chunk 12
"""
    # Tried to use the MLflow API to download artifacts, but it didn't work
    if st.button("Search Document IDs in Artifacts"):
        st.write("Button clicked!")  # This should display when the button is clicked
        results = {}
        for set_name, file_name in file_sets.items():
            if file_name in artifacts:
                st.write(f"Processing file: {file_name}")  # This should display the file name being processed
                try:
                    # Load the artifact directly into a DataFrame
                    df = load_artifact_as_dataframe(selected_run_id, file_name)
                    
                    # Debug: Print the header of the DataFrame
                    st.write(f"DataFrame Header for {file_name}:")
                    st.write(df.head())  # Display the first few rows of the DataFrame in Streamlit

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_mlflow_explorer.py - Chunk 13
# Search for the document IDs in the DataFrame
                    found_ids_df = search_document_ids(df, document_ids)
                    found_count = found_ids_df.shape[0]

                    # Store the result
                    results[set_name] = {
                        "found_ids": found_ids_df,
                        "count": found_count
                    }

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_mlflow_explorer.py - Chunk 14
# Store the result
                    results[set_name] = {
                        "found_ids": found_ids_df,
                        "count": found_count
                    }

                except Exception as e:
                    st.error(f"An error occurred while processing {file_name}: {e}")
            else:
                results[set_name] = {
                    "found_ids": pd.DataFrame(),
                    "count": 0
                }
        
        # Display the results
        for set_name, result in results.items():
            st.write(f"**{set_name} Set**")
            if result["count"] > 0:
                st.success(f"{result['count']} document IDs found in {file_sets[set_name]}:")
                st.write(result["found_ids"])
            else:
                st.warning(f"No document IDs found in {file_sets[set_name]}.")
"""
if __name__ == "__main__":
    mlflow_explorer_feature()

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_ripeye_config_editor_feature.py - Chunk 0
import streamlit as st
import pyodbc
import json
import sys

def connect_to_database(server, database, user, password): #driver, 
    """ Create a database connection using pyodbc """

    if sys.platform == 'linux':
        driver_name = 'ODBC Driver 17 for SQL Server'
    elif sys.platform == 'win32':
        driver_name = 'SQL Server'

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_ripeye_config_editor_feature.py - Chunk 1
try:
        conn_string = f'DRIVER={{{driver_name}}};SERVER={server};DATABASE={database};UID={user};PWD={password}'
        conn = pyodbc.connect(conn_string)
        return conn
    except pyodbc.Error as e:
        st.sidebar.error("Database connection failed: " + str(e))
        return None
'''
def get_customers(conn):
    """ Fetch customer list from the database """
    if conn is not None:
        with conn.cursor() as cur:
            cur.execute("SELECT Id, Name FROM Customer;")
            customers = cur.fetchall()
        return customers
    return []
'''
def get_customers(conn):
    """ Fetch customer list from the database where customers have configurations """
    if conn is not None:
        with conn.cursor() as cur:
            #cur.execute("SELECT Id, Name FROM Customer;")
            cur.execute("""
                SELECT c.Id, c.Name 
                FROM Customer c
                JOIN CustomerConfiguration cc ON c.Id = cc.CustomerId;
            """)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_ripeye_config_editor_feature.py - Chunk 2
cur.execute("""
                SELECT c.Id, c.Name 
                FROM Customer c
                JOIN CustomerConfiguration cc ON c.Id = cc.CustomerId;
            """)
            customers = cur.fetchall()
        return customers
    return []

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_ripeye_config_editor_feature.py - Chunk 3
'''
def get_customer_config(conn, customer_id):
    """ Fetch the configuration JSON for a specific customer """
    if conn is not None:
        with conn.cursor() as cur:
            cur.execute("SELECT ConfigurationJson FROM CustomerConfiguration WHERE CustomerId = ?;", (customer_id,))
            config_json = cur.fetchone()
        return config_json[0] if config_json else "{}"
    return "{}"
'''
def get_customer_config(conn, customer_id):
    """ Fetch the configuration JSON for a specific customer, formatted for readability """
    if conn is not None:
        with conn.cursor() as cur:
            cur.execute("SELECT ConfigurationJson FROM CustomerConfiguration WHERE CustomerId = ?;", (customer_id,))
            result = cur.fetchone()
        # Check if result is not None and not empty
        if result and result[0]:
            # Parse JSON string into Python dictionary
            config_data = json.loads(result[0])

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_ripeye_config_editor_feature.py - Chunk 4
# Check if result is not None and not empty
        if result and result[0]:
            # Parse JSON string into Python dictionary
            config_data = json.loads(result[0])
            # Convert dictionary back to JSON string with indentation
            formatted_json = json.dumps(config_data, indent=4)
            return formatted_json
        else:
            return "{}"
    return "{}"

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_ripeye_config_editor_feature.py - Chunk 5
def update_customer_config(conn, customer_id, new_json):
    """ Update the customer configuration JSON """
    if conn is not None:
        with conn.cursor() as cur:
            cur.execute("UPDATE CustomerConfiguration SET ConfigurationJson = ? WHERE CustomerId = ?;", (new_json, customer_id))
            conn.commit()

def ripeye_config_editor_feature():
    """ Main function to render the Streamlit app """
    st.title('Customer Configuration Editor')

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_ripeye_config_editor_feature.py - Chunk 6
def ripeye_config_editor_feature():
    """ Main function to render the Streamlit app """
    st.title('Customer Configuration Editor')

    # Database connection parameters
    st.sidebar.title("Database Connection")
    #db = st.sidebar.selectbox('Select Database', ('smedbdev_current', 'Database2'))
    #driver = st.sidebar.text_input('Driver', 'SQL Server')
    server = st.sidebar.selectbox('Server', ('bcdbserverdev.database.windows.net', 'bcdbserver.database.windows.net'))
    database = st.sidebar.selectbox('Select Database', ('smedbdev_current', 'smedbtest', 'smedb-v1.0'))
    user = st.sidebar.text_input('Username', 'user')
    password = st.sidebar.text_input('Password', 'password', type="password")
    conn = connect_to_database(server, database, user, password) #driver,

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_ripeye_config_editor_feature.py - Chunk 7
# Check if the connection was successful
    if conn is not None:
        try:
            customers = get_customers(conn)
            if customers:
                customer_names = [name for _, name in customers]
                selected_customer_name = st.selectbox('Select a Customer', customer_names)
                selected_customer_id = [id for id, name in customers if name == selected_customer_name][0]
                
                # Fetch and edit JSON configuration
                json_config = get_customer_config(conn, selected_customer_id)
                edited_json = st.text_area("Edit JSON Configuration", json_config, height=800)
                if st.button('Save Changes'):
                    update_customer_config(conn, selected_customer_id, edited_json)
                    st.success("Configuration updated successfully!")
            else:
                st.error("No customers found.")
        except Exception as e:

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_ripeye_config_editor_feature.py - Chunk 8
st.success("Configuration updated successfully!")
            else:
                st.error("No customers found.")
        except Exception as e:
            st.error(f"An error occurred: {e}")
    else:
        st.sidebar.error("Failed to establish a database connection.")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\code_ripeye_config_editor_feature.py - Chunk 9
if __name__ == "__main__":
    ripeye_config_editor_feature()

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\constants.py - Chunk 0
BOS, EOS = "<s>", "</s>"

B_INST, E_INST = "[INST]", "[/INST]"

B_SYS, E_SYS = "<<SYS>>\n", "\n<</SYS>>\n\n"

inst_msg = """User: Extract all contacts from the invoice and return them as a JSON object.
{invoice}
"""

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\customer_feature.py - Chunk 0
import sys
import streamlit as st
import pyodbc
import pandas as pd

from utils import get_api_identifier, get_api_key

def get_db_connection():
    # Create three columns
    col1, col2, col3 = st.columns(3)

    # add a selectbox from where the user can select the database
    database = col1.selectbox("Select the database", ["None", "bcsdbdev", "bcsdb-auth"])

    conn = None
    # check if the user has selected a database and if so, connect to it
    if database == "None":
        return

    username = col2.text_input("Username:", value='None')
    password = col3.text_input("Password:", type="password", value='None')

    if username == 'None' or password == 'None':
        return

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\customer_feature.py - Chunk 1
username = col2.text_input("Username:", value='None')
    password = col3.text_input("Password:", type="password", value='None')

    if username == 'None' or password == 'None':
        return

    if sys.platform == 'linux':
        driver_name = 'ODBC Driver 17 for SQL Server'
    elif sys.platform == 'win32':
        driver_name = 'SQL Server'
        
    if database == "bcsdbdev":
        conn = pyodbc.connect(f"DRIVER={{{driver_name}}};SERVER=bcdbserverdev.database.windows.net;DATABASE=bcsdbdev;UID={username};PWD={password};")
    elif database == "bcsdb-auth":
        conn = pyodbc.connect(f"DRIVER={{{driver_name}}};SERVER=bcdbserver.database.windows.net;DATABASE=bcsdb-auth;UID={username};PWD={password};")

    return conn


def customer_feature():
    st.title("Bludelta Customer")
    conn = get_db_connection()
    if conn == None:
        return

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\customer_feature.py - Chunk 2
return conn


def customer_feature():
    st.title("Bludelta Customer")
    conn = get_db_connection()
    if conn == None:
        return

    # Initialize the session state
    # Session State also supports attribute based syntax
    if 'apiKey' not in st.session_state:
        st.session_state.apiKey= None

    if 'apiIdentifier' not in st.session_state:
        st.session_state.apiIdentifier = None

    with st.expander("New Customer"):

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\customer_feature.py - Chunk 3
# Input fields for the customer details
        name = st.text_input("Name", "") or None  # Empty string will be converted to None
        token = st.text_input("Token", value=st.session_state.apiKey or get_api_key()) or None
        token = None if token == None else token
        limit = st.number_input("Limit", value=5000, format="%d")  # -1 represents None
        expiration_date = st.date_input("Expiration Date")
        invoice_detail_types = st.number_input("Invoice Detail Types", value=-2, format="%d")  # -1 represents None
        invoice_detail_types = None if invoice_detail_types == -1 else invoice_detail_types
        email = st.text_input("Email", "") or None  # Empty string will be converted to None
        is_refused = st.selectbox("Is Refused", options=[0, 1])  # None is an option
        version = st.number_input("Version", value=0, format="%d")  # -1 represents None

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\customer_feature.py - Chunk 4
is_refused = st.selectbox("Is Refused", options=[0, 1])  # None is an option
        version = st.number_input("Version", value=0, format="%d")  # -1 represents None
        api_identifier_key = st.text_input("API Identifier Key", value=st.session_state.apiIdentifier or get_api_identifier()) or None
        api_identifier_key = None if api_identifier_key == None else api_identifier_key
        customer_id = st.number_input("Customer ID", value=-1, format="%d")  # -1 represents None
        customer_id = None if customer_id == -1 else customer_id

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\customer_feature.py - Chunk 5
# Update the session state
        st.session_state.apiKey = token
        st.session_state.apiIdentifier = api_identifier_key

        # Button to insert the data into the database
        if st.button("Create Customer"):                    
            # Create a cursor
            cursor = conn.cursor()

            # Prepare the INSERT statement
            sql = """
            INSERT INTO [dbo].[Customer]
                ([Name], [Token], [Limit], [ExpirationDate], [InvoiceDetailTypes], [Email], [IsRefused], [Version], [ApiIdentifierKey], [CustomerId])
            VALUES
                (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """

            # Execute the INSERT statement
            cursor.execute(sql, name, token, limit, expiration_date.isoformat(), invoice_detail_types, email, is_refused, version, api_identifier_key, customer_id)

            # Commit the transaction
            conn.commit()

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\customer_feature.py - Chunk 6
# Commit the transaction
            conn.commit()

            st.session_state.apiKey = None
            st.session_state.apiIdentifier = None

            st.success("Customer created successfully!")


    with st.expander("List Customers"):
        # Execute the SELECT statement
        query = """
            SELECT [Id], [Name], [Token], [Limit], [ExpirationDate], [InvoiceDetailTypes], [Email], [IsRefused], [Version], [ApiIdentifierKey], [CustomerId]
            FROM dbo.Customer
        """
        df = pd.read_sql(query, conn)

        # Search field
        search_query = st.text_input("Search for a customer (using regex):", "")

        if search_query:
            # Filter the DataFrame using the search query
            df = df[df['Name'].str.contains(search_query, regex=True, na=False, case=False)]

        # Display the results in a table
        st.dataframe(df, use_container_width=True, height=900)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\customer_feature.py - Chunk 7
# Display the results in a table
        st.dataframe(df, use_container_width=True, height=900)

    with st.expander("Update Customer"):
        # Input for customer ID
        customer_id = st.number_input("Customer ID:", value=0, format="%d", key="customer_id_update")

        # # Inputs for each field in the SQL table
        # name = st.text_input("Name:")
        # # ... add the rest of your fields here ...

        # # Button to update the customer in the database
        # if st.button("Update Customer"):
        #     cursor = conn.cursor()

        #     # Execute the UPDATE statement
        #     cursor.execute("""
        #         UPDATE dbo.Customer
        #         SET Name = ?, ...
        #         WHERE Id = ?
        #     """, name, ..., customer_id)

        #     # Commit the changes
        #     conn.commit()

        #     st.success("Customer updated successfully!")
        pass

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\customer_feature.py - Chunk 8
#     # Commit the changes
        #     conn.commit()

        #     st.success("Customer updated successfully!")
        pass

    with st.expander("Delete Customer"):
        # Input for customer ID
        customer_id = st.number_input("Customer ID:", value=0, format="%d", key="customer_id_delete")

        # # Button to delete the customer from the database
        # if st.button("Delete Customer"):
        #     cursor = conn.cursor()

        #     # Execute the DELETE statement
        #     cursor.execute("""
        #         DELETE FROM dbo.Customer
        #         WHERE Id = ?
        #     """, customer_id)

        #     # Commit the changes
        #     conn.commit()

        #     st.success("Customer deleted successfully!")
        pass

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_page_classification_feature.py - Chunk 0
from io import BytesIO
import os
import streamlit as st
from streamlit_pdf_viewer import pdf_viewer
from PIL import Image
from pdf2image import convert_from_bytes

#@st.cache_data(hash_funcs={Image.Image: id})
def convert_pdf_to_images(file_bytes):
    return convert_from_bytes(file_bytes)

def resize_image(image: Image.Image, base_width=150) -> Image.Image:
    # w_percent = (base_width / float(image.size[0]))
    # h_size = int((float(image.size[1]) * float(w_percent)))
    # return image.resize((base_width, h_size), Image.ANTIALIAS)
    return image.resize((300, 361), Image.Resampling.LANCZOS)

def display_thumbnails(images, reset_categories):
    cols = st.columns(3)  # Adjust the number of columns based on your layout preference
    for index, image in enumerate(images):
        with cols[index % 3]:
            resized_image = resize_image(image)
            st.image(resized_image, caption=f"Page {index + 1}")
            category_key = f"category_{index}"

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_page_classification_feature.py - Chunk 1
if category_key not in st.session_state or reset_categories:
                st.session_state[category_key] = "Default"
            options = st.session_state.categories            
            selected_option = st.selectbox("Category", options, index=options.index(st.session_state[category_key]), key=category_key)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_page_classification_feature.py - Chunk 2
def batch_save_images_to_categories(folder_path, images):
    for index, image in enumerate(images):
        category_key = f"category_{index}"
        if category_key in st.session_state and st.session_state[category_key]:
            category = st.session_state[category_key]
            category_path = os.path.join(folder_path, category)
            os.makedirs(category_path, exist_ok=True)
            selected_file = st.session_state.selected_file
            image_path = os.path.join(category_path, f"{selected_file.split('.')[0]}_page_{index + 1}.png")
            image.save(image_path)
    st.success("All pages saved successfully to their categories.")

def doc_page_classification_feature():
    st.title("Split & Classify")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_page_classification_feature.py - Chunk 3
def doc_page_classification_feature():
    st.title("Split & Classify")

    if 'categories' not in st.session_state:
        st.session_state.categories = ["Invoice", "Agb", "Lieferschein", "Frachtbrief", "Ladeauftrag", "Wareneingangsbeleg", "Other", "Default"]
    
    new_category = st.sidebar.text_input("Add a new category")
    if st.sidebar.button("Add Category") and new_category:
        if new_category not in st.session_state.categories:
            st.session_state.categories.append(new_category)
            st.sidebar.success(f"Added category: {new_category}")
            

    folder_name = st.sidebar.text_input("Enter the name of the root folder with the pdf documents. Note: The folder must be inside the \\\\nas-01\\traininsdata\\bennu\\image_classification folder because this folder is mounted into the docker container as /image_classification")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_page_classification_feature.py - Chunk 4
# check if os is linux
    if os.name == 'posix':
        folder_path = os.path.join("/image_classification", folder_name)
    else:
        folder_path = folder_name

    if not os.path.exists(folder_path):
        st.sidebar.error(f"Folder {folder_path} does not exist")
        return

    pdf_files = [file for file in os.listdir(folder_path) if file.lower().endswith(".pdf")]

    with st.sidebar.expander("Documents", expanded=True):
        selected_file = st.radio("Select a PDF file", pdf_files)

    if selected_file:
        file_path = os.path.join(folder_path, selected_file)
        with open(file_path, "rb") as file:
            file_bytes = file.read()

        # show the images in one tab and the pdf file in another tab

        tab1, tab2 = st.tabs(["Classify Pages", "Document Preview"])

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_page_classification_feature.py - Chunk 5
# show the images in one tab and the pdf file in another tab

        tab1, tab2 = st.tabs(["Classify Pages", "Document Preview"])

        with tab1:
            old_selected_file = st.session_state.get("selected_file")
            reset_categories = old_selected_file != selected_file
            st.session_state.selected_file = selected_file

            images = convert_pdf_to_images(file_bytes)
            display_thumbnails(images, reset_categories=reset_categories)

            if st.button("Save Classified Pages"):
                batch_save_images_to_categories(folder_path, images)

        with tab2:
            pdf_viewer(file_bytes)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_page_classification_prediction_feature.py - Chunk 0
import streamlit as st
import http.client
import json
from PIL import Image
from io import BytesIO
from pdf2image import convert_from_bytes

class ModelConfig:
    def __init__(self):
        self.Name = ""
        self.Version = ""
        self.Height = 0
        self.Width = 0
        self.Names = []

class DocPageClassifierClient:
    def __init__(self, url, endpoint):
        self.url = url
        self.endpoint = endpoint
        self.boundary = '----WebKitFormBoundary7MA4YWxkTrZu0gW'
        self.headers = {
            'Content-Type': f'multipart/form-data; boundary={self.boundary}'
        }

    def post_image(self, image_bytes, model_config):
        """
        Posts an image to the server for classification
        :param image_bytes: The image bytes
        :param model_config: The model configuration
        :return: The server response
        """

        # Convert the model configuration to JSON
        json_content = json.dumps({"ModelConfig": model_config.__dict__})

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_page_classification_prediction_feature.py - Chunk 1
# Convert the model configuration to JSON
        json_content = json.dumps({"ModelConfig": model_config.__dict__})

        # Prepare the multipart/form-data body
        body = (
            f'--{self.boundary}\r\n'
            'Content-Disposition: form-data; name="json"\r\n'
            'Content-Type: application/json\r\n\r\n'
            f'{json_content}\r\n'
            f'--{self.boundary}\r\n'
            'Content-Disposition: form-data; name="item0"; filename="item0.png"\r\n'
            'Content-Type: image/png\r\n\r\n'
        )
        footer = f'\r\n--{self.boundary}--\r\n'

        # Create a connection to the server
        conn = http.client.HTTPConnection(self.url)
        conn.request("POST", self.endpoint, body=body.encode('utf-8') + image_bytes + footer.encode('utf-8'), headers=self.headers)

        # Handle the server response
        response = conn.getresponse()
        if response.status != 200:
            return None

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_page_classification_prediction_feature.py - Chunk 2
# Handle the server response
        response = conn.getresponse()
        if response.status != 200:
            return None

        return json.loads(response.read())

# implement the feature here
def doc_classification_prediction_feature():
    """
    This feature allows the user to classify document pages. The user can upload a PDF file and view the pages as images.
    Moreover, each page is classified into one of the predefined categories. For the classfication the DocPageClassifierClient
    is used to send the images to the server for classification.
    At the sidebar the user can add new categories and set the url of the server.    
    """

    st.title("Document Page Classification")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_page_classification_prediction_feature.py - Chunk 3
st.title("Document Page Classification")

    server_url = st.sidebar.text_input("Enter the server URL. Only http is currently support", value="52.236.159.89")
    if not server_url:
        st.sidebar.error("Please enter the server URL")
        return
    
    endpoint = st.sidebar.text_input("Enter the endpoint", value="/doc-page-classifier/v1/classification_result")
    if not endpoint:
        st.sidebar.error("Please enter the endpoint")
        return

    uploaded_file = st.file_uploader("Upload a PDF file", type=["pdf"])
    
    if uploaded_file:
        images = convert_from_bytes(uploaded_file.read(), dpi=96, fmt="png")
        poster = DocPageClassifierClient(server_url, endpoint=endpoint)

        model_config = ModelConfig()
        model_config.Name = "junk_detection"
        model_config.Version = "1"
        model_config.Height = 224
        model_config.Width = 224
        model_config.Names = ["CMRConsignmentNote", "TermsAndConditions", "Invoice"]

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_page_classification_prediction_feature.py - Chunk 4
cols_per_row = 3  # You can adjust the number of columns based on your preference and screen size
        cols = st.columns(cols_per_row)
        
        for index, image in enumerate(images):
            resized_image = image.resize((224, 224))
            image_byte_array = BytesIO()
            image.save(image_byte_array, format="PNG")
            image_bytes = image_byte_array.getvalue()
            response = poster.post_image(image_bytes, model_config)
            
            # Determine which column to place this image in
            col = cols[index % cols_per_row]
            with col:
                if response:
                    page_type = response['ResponseItems'][0]['PageType']
                    col.image(resized_image, caption=f"Page {index + 1}, Class: {page_type}")
                    col.success(f"Classified as: {page_type}, Score: {response['ResponseItems'][0]['Score']:.2f}")
                else:

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_page_classification_prediction_feature.py - Chunk 5
col.success(f"Classified as: {page_type}, Score: {response['ResponseItems'][0]['Score']:.2f}")
                else:
                    col.error(f"Failed to classify page {index + 1}")
# Example usage:
if __name__ == "__main__":
    poster = DocPageClassifierClient('52.236.159.89', '/doc-page-classifier/v1/classification_result')

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_page_classification_prediction_feature.py - Chunk 6
# Load the image
    image_path = r"H:\mlnet_prosa_detector\Frachtbrief\0004AC1E5729ABD5A08D22BE20002C38_page_10.png"
    image = Image.open(image_path)
    image = image.resize((224, 224))

    # Convert image to bytes
    image_byte_array = BytesIO()
    image.save(image_byte_array, format="PNG")
    image_bytes = image_byte_array.getvalue()
    
    model_config = ModelConfig()
    model_config.Name = "junk_detection"
    model_config.Version = "1"
    model_config.Height = 224
    model_config.Width = 224
    model_config.Names = ["CMRConsignmentNote", "TermsAndConditions", "Invoice"]  # Example list of class names

    response = poster.post_image(image_bytes, model_config)
    print(response)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_splitting_bm_analysis.py - Chunk 0
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import openai
import re
import traceback
import os
import requests

# Import necessary modules for metrics calculation
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix


system_prompt = (
    "You are an assistant for benchmark analysis. "
    "You have access to a pandas DataFrame called 'metrics_df'. "
    "You can use pandas as 'pd', numpy as 'np', matplotlib.pyplot as 'plt', seaborn as 'sns', and streamlit as 'st'. "
    "DO NOT include import statements in your code. "
    "DO NOT use 'print' statements; instead, use 'st.write()' to display outputs. "
    "**When creating plots, use 'st.pyplot(fig)' instead of 'plt.show()'.** "
    "Provide Python code for any data manipulations or visualizations, enclosed within triple backticks (```python ... ```)."
)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_splitting_bm_analysis.py - Chunk 1
summary_prompt="""
Generate a management report. Explain in detail why we shall use model x (take only top 3 models into account) for our document splitting app where customers can upload a pdf files which may contain multipe independent documents. Models predicts for every page whether it is the start page of a document or not. One import requirement is that manual work shall be reduced to a minimum, i.e. splitting document manually.
Additional information. This is our current model which is used in production:

| Model                                   | Accuracy | Precision  | Recall  | F1 Score  | False Positives (FP) | False Negatives (FN) | Sprint |
|-----------------------------------------|----------|------------|---------|-----------|----------------------|----------------------|--------|
| **Prod-Model (t=0.75)**                 | 0.8145   | 0.9237     | 0.5112  | 0.6581    | 51                   | 590                  |        |
"""

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_splitting_bm_analysis.py - Chunk 2
top_5_models = """
Give me the top 5 models based on the accuracy. Proved the results in a table.
"""


user_prompts = {
    "SummaryReport" : summary_prompt,
    "Top5Models" : top_5_models,
    "PlotAccuracy" : "Plot the accuracy of the models in a bar chart."
}


# Function to query GPT model
def ask_llm(question, context):
    openai.api_key = st.secrets["OPENAI_API_KEY"]  # Use Streamlit secrets for API keys

    # System prompt to guide the LLM
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"Data:\n{context}\n\nQuestion:\n{question}"}
        ],
        max_tokens=4096,
        temperature=0  # Lower temperature for more predictable outputs
    )

    return response['choices'][0]['message']['content']

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_splitting_bm_analysis.py - Chunk 3
return response['choices'][0]['message']['content']


# Function to query Azure OpenAI model
def ask_azure_gpt(question, context):
    # Replace with your Azure OpenAI API details
    api_base = st.secrets["AZURE_OPENAI_API_BASE"]  # The base URL of your Azure OpenAI resource
    api_key = st.secrets["AZURE_OPENAI_API_KEY"]    # The API key for your Azure OpenAI resource
    deployment_id = st.secrets["AZURE_OPENAI_DEPLOYMENT_ID"]  # The deployment name for your Azure OpenAI model
    api_version = "2024-02-15-preview"  # API version to use for Azure OpenAI (adjust as needed)

    # Azure OpenAI endpoint for completions
    endpoint = f"https://{api_base}.openai.azure.com/openai/deployments/{deployment_id}/chat/completions?api-version={api_version}"

    headers = {
        "Content-Type": "application/json",
        "api-key": api_key
    }

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_splitting_bm_analysis.py - Chunk 4
headers = {
        "Content-Type": "application/json",
        "api-key": api_key
    }

    # Construct the payload for the API call
    payload = {
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"Data:\n{context}\n\nQuestion:\n{question}"}
        ],
        "max_tokens": 4096,
        "temperature": 0
    }

    # Send the request to Azure OpenAI
    try:
        response = requests.post(endpoint, headers=headers, json=payload)
        response.raise_for_status()
        completion = response.json()
        return completion['choices'][0]['message']['content']
    except Exception as e:
        st.error(f"Error querying Azure OpenAI: {e}")
        return None

# Function to handle the chat interface
def chat_interface():
    st.subheader("Chat with your Benchmarks")

    # Initialize conversation history
    if 'conversation' not in st.session_state:
        st.session_state.conversation = []

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_splitting_bm_analysis.py - Chunk 5
# Initialize conversation history
    if 'conversation' not in st.session_state:
        st.session_state.conversation = []

    # User input
    col_input, col_predefine_prompt = st.columns([3, 2])

    with col_input:
        user_input = st.text_area("Ask the LLM about your benchmark results:")
    # with col_predefine_prompt:
    #     prompt = st.selectbox("Choose a predefined prompt:", list(user_prompts.keys()))        
    #     user_input = user_prompts[prompt]
    #     # also show it in the text area
    #     st.text_area("Ask the LLM about your benchmark results:", value=user_input)


    if user_input and 'metrics_df' in st.session_state:
        # Check if the same input has already been processed
        if 'last_user_input' not in st.session_state or user_input != st.session_state.last_user_input:
            st.session_state.last_user_input = user_input

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_splitting_bm_analysis.py - Chunk 6
# Convert DataFrame to CSV for context
            context = st.session_state.metrics_df.to_csv(index=False)

            # Get response from LLM
            #response = ask_llm(user_input, context)
            response = ask_azure_gpt(user_input, context)

            # Save conversation
            st.session_state.conversation.append((user_input, response))

            # Display LLM response
            #st.markdown(f"**LLM:** {response}")

            # Process LLM response
            process_llm_response(response)
    elif user_input:
        st.warning("Please upload and process benchmark data before asking questions.")

# Function to process the LLM response
def process_llm_response(response):
    # Display the response. Remove the code blocks first
    response_ = re.sub(r"```python(.*?)```", "", response, flags=re.DOTALL)
    st.markdown(response_)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_splitting_bm_analysis.py - Chunk 7
# Extract code blocks from the response
    code_blocks = re.findall(r"```python(.*?)```", response, re.DOTALL)

    if code_blocks:
        for code in code_blocks:
            col1, col2 = st.columns([3,2])
            
            with col2:
                st.markdown("**Generated Code:**")
                st.code(code, language='python')
            
            with col1:
                st.markdown("**Executing generated code:**")
                # Execute the code safely
                execute_generated_code(code)
    else:
        st.markdown("**LLM did not provide any code to execute.**")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_splitting_bm_analysis.py - Chunk 8
# Function to execute the generated code safely
def execute_generated_code(code):
    # Preprocess code: remove import statements
    code = re.sub(r'^\s*import .+$', '', code, flags=re.MULTILINE)
    # Replace print statements with st.write
    code = code.replace('print(', 'st.write(')
    # Replace plt.show() with st.pyplot()
    code = code.replace('plt.show()', 'st.pyplot(plt.gcf())')

    # Replace str.replace without regex parameter to include regex=False
    code = re.sub(r"str\.replace\(([^,]+), ([^)]+)\)", r"str.replace(\1, \2, regex=False)", code)

    # Define safe built-in functions
    safe_builtins = {
        'len': len,
        'range': range,
        'min': min,
        'max': max,
        'sum': sum,
        'abs': abs,
    }

    # Safe execution environment
    safe_globals = {
        "__builtins__": safe_builtins,
        "pd": pd,
        "np": np,
        "plt": plt,
        "sns": sns,
        "st": st,
    }

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_splitting_bm_analysis.py - Chunk 9
# Safe execution environment
    safe_globals = {
        "__builtins__": safe_builtins,
        "pd": pd,
        "np": np,
        "plt": plt,
        "sns": sns,
        "st": st,
    }

    safe_locals = {
        "metrics_df": st.session_state.metrics_df.copy()
    }

    try:
        exec(code, safe_globals, safe_locals)
    except Exception as e:
        st.error("An error occurred while executing the code.")
        st.error(traceback.format_exc())

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_splitting_bm_analysis.py - Chunk 10
try:
        exec(code, safe_globals, safe_locals)
    except Exception as e:
        st.error("An error occurred while executing the code.")
        st.error(traceback.format_exc())

# Function to calculate metrics from benchmark data
def calc_metrics(df):
    y_true = df['label'].apply(lambda x: 1 if x.lower() == 'first' else 0)
    y_pred = df['prediction'].apply(lambda x: 1 if x.lower() == 'first' else 0)
    conf_matrix = confusion_matrix(y_true, y_pred)
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, zero_division=0)
    recall = recall_score(y_true, y_pred, zero_division=0)
    f1 = f1_score(y_true, y_pred, zero_division=0)
    tn, fp, fn, tp = conf_matrix.ravel()

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_splitting_bm_analysis.py - Chunk 11
# Exclude 'confusion_matrix' from the returned dictionary
    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'tp': tp,
        'fp': fp,
        'fn': fn,
        'tn': tn,
    }, conf_matrix  # Return confusion matrix separately

def calc_error_rate(df):
    try:
        LLM_SCORE = 0.99

        # get the errors, which is shown in the 'correct' column. A value of 0 means the model was wrong
        errors = df[df['correct'] == 0]

        errors_llm = errors[errors['score'] == LLM_SCORE]     
        errors_not_llm = errors[errors['score'] != LLM_SCORE]

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_splitting_bm_analysis.py - Chunk 12
errors_llm = errors[errors['score'] == LLM_SCORE]     
        errors_not_llm = errors[errors['score'] != LLM_SCORE]

        # calculate the the accuracy for each group. get all results where the score is 0.99 and calculate the accuracy
        # for this group
        predictions_llm = df[df['score'] == 0.99]
        accuracy_llm = 1 - (len(errors_llm)/ len(predictions_llm))
        
        # calculate the accuracy for the other group
        predictions_not_llm = df[df['score'] != 0.99]
        accuracy_not_llm = 1 - (len(errors_not_llm) / len(predictions_not_llm))

        return accuracy_llm, accuracy_not_llm
    except Exception as e:
        #st.error(f"Error calculating error rate: {e}")
        return None, None

# Main function
def benchmark_comparison_feature():
    st.title("LLM-Powered Benchmark Analysis Tool")

    # Upload benchmark data
    uploaded_files = st.file_uploader("Upload Benchmark Result Files (TSV)", type="tsv", accept_multiple_files=True)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_splitting_bm_analysis.py - Chunk 13
# Upload benchmark data
    uploaded_files = st.file_uploader("Upload Benchmark Result Files (TSV)", type="tsv", accept_multiple_files=True)

    if uploaded_files:
        all_metrics = []
        conf_matrices = {}  # Dictionary to store confusion matrices

        for uploaded_file in uploaded_files:
            df = pd.read_csv(uploaded_file, sep='\t')
            accuracy_llm, accuracy_not_llm = calc_error_rate(df)
            metrics, conf_matrix = calc_metrics(df)
            model_name = os.path.basename(uploaded_file.name)
            metrics['model'] = model_name
            metrics['accuracy_llm'] = accuracy_llm
            metrics['accuracy_not_llm'] = accuracy_not_llm

            # Store confusion matrix separately
            conf_matrices[model_name] = conf_matrix

            all_metrics.append(metrics)

        # Create a DataFrame from all metrics
        metrics_df = pd.DataFrame(all_metrics)
        st.session_state.metrics_df = metrics_df

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_splitting_bm_analysis.py - Chunk 14
all_metrics.append(metrics)

        # Create a DataFrame from all metrics
        metrics_df = pd.DataFrame(all_metrics)
        st.session_state.metrics_df = metrics_df

        st.success("Files uploaded and processed successfully!")

        # add two streamlit columns one the datafame and another one for a plot
        col1, col2 = st.columns([3, 2])

        with col1:
            # Display the DataFrame
            st.subheader("Metrics Data")
            st.dataframe(metrics_df)

        with col2:
            # Display a bar plot of accuracy for each model
            st.subheader("Accuracy Comparison")
            fig, ax = plt.subplots()
            sns.barplot(x='model', y='accuracy', data=metrics_df, palette='viridis', ax=ax)
            ax.set_title("Accuracy Comparison")
            ax.set_ylabel("Accuracy")
            ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')
            st.pyplot(fig)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_splitting_bm_analysis.py - Chunk 15
# Optionally, display confusion matrices
        # st.subheader("Confusion Matrices")
        # for model_name, conf_matrix in conf_matrices.items():
        #     st.write(f"Confusion Matrix for {model_name}:")
        #     fig, ax = plt.subplots()
        #     sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", ax=ax)
        #     ax.set_title(f"Confusion Matrix for {model_name}")
        #     ax.set_xlabel('Predicted')
        #     ax.set_ylabel('Actual')
        #     st.pyplot(fig)

        # Launch chat interface
        chat_interface()
    else:
        st.info("Please upload benchmark result files to get started.")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_splitting_feature.py - Chunk 0
import os
import json
import streamlit as st
import httpx
from PIL import Image, ImageDraw
import io
from pdf2image import convert_from_bytes
import base64
import requests
from requests_toolbelt.multipart.encoder import MultipartEncoder
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import pandas as pd



def create_sidebar():
    with st.sidebar:
        st.title('Document Splitting Workflows')

        # List of predefined URLs to choose from
        predefined_urls = [
            "http://localhost:8080/llm-doc-splitter"
        ]

        # Display a text input field for the URL
        selected_url_index = st.selectbox("Select URL", [(url, idx) for idx, url in enumerate(predefined_urls)], format_func=lambda x: x[0])

        # Retrieve the selected URL
        selected_url = selected_url_index[0]

        # Allow users to edit the URL directly
        edited_url = st.text_input("Edit URL (Final URL)", selected_url)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_splitting_feature.py - Chunk 1
# Allow users to edit the URL directly
        edited_url = st.text_input("Edit URL (Final URL)", selected_url)

        # If the edited URL is different from the selected URL, update it
        if edited_url != selected_url:
            selected_url = edited_url

        timeout = st.text_input("Enter timeout [sec]", "120")
        # convert to int
        try:
            timeout = int(timeout)
        except ValueError:
            st.error("Timeout must be an integer")
            return

        return selected_url, timeout

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_splitting_feature.py - Chunk 2
return selected_url, timeout

def add_customer_name_role_to_header(header, customer_name, customer_role):
    """
    Add the CustomerName and CustomerRole to the header.
    @param header: The header dictionary to which the CustomerName and CustomerRole will be added.
    @param customer_name: The customer name to be added.
    @param customer_role: The customer role to be added.
    """
    if customer_name:
        header["X-CustomerName"] = customer_name
    if customer_role:
        header["X-Role"] = customer_role
    return header

def calc_metrics(y_true, y_pred):

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_splitting_feature.py - Chunk 3
def calc_metrics(y_true, y_pred):

    conf_matrix = confusion_matrix(y_true, y_pred)
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    tn, fp, fn, tp = conf_matrix.ravel()
    
    #return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1, 'confusion_matrix': conf_matrix, 'tp': tp, 'fp': fp, 'fn': fn, 'tn': tn}
    return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1, 'tp': tp, 'fp': fp, 'fn': fn, 'tn': tn}


def document_splitting_feature():
    st.title("Document Splitting Workflows")

    url, timeout = create_sidebar()
    st.write("URL:", url)
    st.write("Timeout:", timeout)

    uploaded_file = st.file_uploader("Choose a document (pdf)", type=["pdf"])
    ground_truth_file = st.file_uploader("Choose a ground truth file (json)", type=["json"])

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_splitting_feature.py - Chunk 4
uploaded_file = st.file_uploader("Choose a document (pdf)", type=["pdf"])
    ground_truth_file = st.file_uploader("Choose a ground truth file (json)", type=["json"])

    # read APIKey from env variable, check if it exists
    if 'APIKEY' not in os.environ:
        st.error("APIKEY not found in environment variables")
        return
    apiKey = os.environ['APIKEY']


    # Define the URL and headers        
    url = url
    headers = {
        "X-ApiKey": apiKey,
        "User-Agent": "Bludelta Workflow Client"
    }

    if uploaded_file is None:
        return

    #headers = add_customer_name_role_to_header(headers, customer_name, customer_role)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_splitting_feature.py - Chunk 5
if uploaded_file is None:
        return

    #headers = add_customer_name_role_to_header(headers, customer_name, customer_role)

    payload = None
    # Make the POST request
    if payload is not None:
        m = MultipartEncoder(
            fields={
                'json': ('json_data', payload, 'application/json'),  # JSON part with explicit content type
                'files': ('file', uploaded_file.getvalue(), 'application/octet-stream')  # File part
            }
        )
    else:   
        m = MultipartEncoder(
            fields={
                'files': ('file', uploaded_file.getvalue(), 'application/octet-stream')  # File part
            }
        )

    headers['Content-Type'] = m.content_type  # Setting the content type to multipart/form-data

    response = requests.post(f"{url}", data=m, headers=headers)        

    data = response.json()

    tab1, tab2 = st.tabs(["Splitting Result", "Analysis Result"])

    with tab1:
        st.json(data)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\document_splitting_feature.py - Chunk 6
data = response.json()

    tab1, tab2 = st.tabs(["Splitting Result", "Analysis Result"])

    with tab1:
        st.json(data)

    with tab2:
        if ground_truth_file is not None:
            ground_truth = json.load(ground_truth_file)

            # convert the ground truth to a pandas dataframe
            df_ground_truth = pd.DataFrame(ground_truth)
            y_true = df_ground_truth['Class'].map({'First': 1, 'Other': 0}).tolist()
            df_prediction = pd.DataFrame(data)
            y_pred = df_prediction['Class'].map({'First': 1, 'Other': 0}).tolist()

            metrics = calc_metrics(y_true, y_pred)

            metrics_df = pd.DataFrame([metrics])
            # write as markdown
            st.write(metrics_df.to_markdown(index=False))

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\dynamic_config_feature.py - Chunk 0
import os
import shutil
import json
import requests
from git import Repo, GitCommandError
import streamlit as st

def get_repo(repo_url, repo_dir):
    if os.path.exists(repo_dir):
        repo = Repo(repo_dir)
        try:
            origin = repo.remotes.origin
            origin.pull()
        except Exception as e:
            st.error(f"Error updating the local repo: {e}")
    else:
        try:
            git_username = os.environ['GIT_USERNAME']
            git_password = os.environ['GIT_PASSWORD']
            git_credentials_url = repo_url.replace("https://", f"https://{git_username}:{git_password}@")
            print(repo_url)
            repo = Repo.clone_from(git_credentials_url, repo_dir)
        except Exception as e:
            st.error(f"Error cloning the repo: {e}")
    return repo

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\dynamic_config_feature.py - Chunk 1
def load_config(repo_dir):
    # Load the dynamic_config.json file
    with open(os.path.join(repo_dir, "CaptureSdk", "dynamic_config.json"), "r", encoding="utf-8") as f:
        config = json.load(f)
    return config

def push_config(repo, commit_comment):
    repo.git.add("CaptureSdk/dynamic_config.json")
    repo.git.commit("-m", f"{commit_comment}")
    repo.remotes.origin.push()
    st.success("Config saved and pushed successfully!")

def undo_last_checkin(repo):
    repo.git.reset("--hard", "HEAD~1")
    repo.remotes.origin.push(force=True)
    st.success("Last checkin undone successfully!")

def tag_repo(repo, tag_name):
    repo.create_tag(tag_name)
    repo.remotes.origin.push("--tags")
    st.success("Repo tagged successfully!")

def dynamic_config_feature():
    st.title("Bludelta Dynamic Config")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\dynamic_config_feature.py - Chunk 2
def dynamic_config_feature():
    st.title("Bludelta Dynamic Config")

    # Clone the dynamic_config repo
    repo_dir = "dynamic_config"
    repo_url = "https://blumatix.visualstudio.com/DefaultCollection/Rechnungserkennung/_git/DynamicConfig"
    repo = get_repo(repo_url, repo_dir)

    # get the latest tag
    latest_tag = repo.git.describe("--tags", "--abbrev=0")

    # load and display the config
    config = load_config(repo_dir)
    col1, col2 = st.columns([1,1])
    config_str = col1.text_area("Dynamic Config", json.dumps(config, indent=4, ensure_ascii=False), height=900)
    col2.code(config_str, language='json')

    # Save the config to the file
    if col1.button("Save dynamic_config.json", key="SaveDynamic"):
        config = json.loads(config_str)    
        with open(os.path.join(repo_dir, "CaptureSdk", "dynamic_config.json"), "w", encoding="utf-8") as f:
            json.dump(config, f, indent=4, ensure_ascii=False)
    
    col1.markdown("---")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\dynamic_config_feature.py - Chunk 3
# Push config. Align the button and text input in a single row
    commit_comment = col1.text_input("Comment", "Write a commit comment e.g. Update dynamic_config.json")
    if col1.button("Push Config", use_container_width=True):
        push_config(repo, commit_comment)

    # Add a button which can be used to remove the latest checkin
    if col1.button("Undo Last Checkin", key="UndoLastCheckin"):
        undo_last_checkin(repo)

    col1.markdown("---")

    # Button to tag the repo and push the tag
    if col1.button("Tag Repo"):
        tag_name = st.text_input("Tag name", "")
        if tag_name:
            tag_repo(repo, tag_name)
            # on success delete local repo
            if os.path.exists(repo_dir):
                shutil.rmtree(repo_dir)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\http_client_feature.py - Chunk 0
import streamlit as st
import requests
import json
import requests_toolbelt
from streamlit_ace import st_ace

def http_client_feature():
    st.title("Postman-like API Client")

    # Use form to group URL input, method dropdown, and send button for better alignment
    col1, col2, col3 = st.columns([1, 4, 1])

    # HTTP method selector
    with col1:
        method = st.selectbox("Method", ["GET", "POST", "PUT", "DELETE", "PATCH"])

    # URL input field
    with col2:
        url = st.text_input("Enter the URL", "https://")

    # Tabs for params, authorization, headers, body, etc.
    tabs = st.tabs(["Params", "Authorization", "Headers", "Body", "Response scripting"])

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\http_client_feature.py - Chunk 1
# Tabs for params, authorization, headers, body, etc.
    tabs = st.tabs(["Params", "Authorization", "Headers", "Body", "Response scripting"])

    # Params Tab
    with tabs[0]:
        st.subheader("Params")
        params_data = {}
        num_params = st.number_input("Number of Params", min_value=0, step=1)
        for i in range(num_params):
            param_key = st.text_input(f"Param {i+1} Key", key=f"param_key_{i}")
            param_value = st.text_input(f"Param {i+1} Value", key=f"param_value_{i}")
            params_data[param_key] = param_value

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\http_client_feature.py - Chunk 2
# Headers Tab (aligned horizontally)
    with tabs[2]:
        st.subheader("Headers")
        headers_data = {}
        num_headers = st.number_input("Number of Headers", min_value=0, step=1)
        
        for i in range(num_headers):
            col1, col2 = st.columns([1, 3])
            with col1:
                header_key = st.text_input(f"Header {i+1} Key", key=f"header_key_{i}")
            with col2:
                header_value = st.text_input(f"Header {i+1} Value", key=f"header_value_{i}")
            headers_data[header_key] = header_value

    # Body Tab with multipart/form-data handling
    with tabs[3]:
        st.subheader("Body")
        body_type = st.radio("Body Type", ["none", "form-data", "raw", "file"], horizontal=True)

        form_data = {}
        uploaded_files = []

        if body_type == "form-data":
            num_fields = st.number_input("Number of Fields", min_value=1, step=1)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\http_client_feature.py - Chunk 3
form_data = {}
        uploaded_files = []

        if body_type == "form-data":
            num_fields = st.number_input("Number of Fields", min_value=1, step=1)

            # Create columns for form-data fields
            for i in range(num_fields):
                col1, col2, col3 = st.columns([1, 2, 3])
                with col1:
                    field_key = st.text_input(f"Field {i+1} Key", key=f"form_key_{i}")
                with col2:
                    field_type = st.selectbox(f"Field {i+1} Type", ["Text", "File"], key=f"field_type_{i}")
                with col3:
                    if field_type == "Text":
                        # use a text area instead of text input to allow for multi-line values
                        field_value = st.text_area(f"Field {i+1} Value", key=f"form_value_{i}", height=100)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\http_client_feature.py - Chunk 4
form_data[field_key] = field_value
                    elif field_type == "File":
                        uploaded_file = st.file_uploader(f"Upload File for {field_key}", key=f"form_file_{i}")
                        if uploaded_file:
                            uploaded_files.append((field_key, uploaded_file))

        elif body_type == "raw":
            raw_data = st.text_area("Raw JSON Body", "{}")
            form_data['json'] = json.dumps(raw_data)

        elif body_type == "file":
            uploaded_files = st.file_uploader("Upload Files", accept_multiple_files=True)
            for uploaded_file in uploaded_files:
                form_data[uploaded_file.name] = uploaded_file

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\http_client_feature.py - Chunk 5
# Scripting Tab with Ace Editor
    # with tabs[4]:
    #     st.subheader("Response Scripting")
    #     test_script = st_ace(
    #         language='python',
    #         theme='chrome',
    #         value="""# Example test cases
    # # response.status_code == 200
    # assert response.status_code == 200, 'Expected status code 200, but got ' + str(response.status_code)
    # """,
    #         height=200,
    #         key="test_script_editor"
    #     )

    # Send button
    submit_button = st.button("Send", use_container_width=True)
    if submit_button:
        try:
            # Prepare multipart form-data using requests_toolbelt.MultipartEncoder
            if body_type == "form-data" or body_type == "file":
                fields = {**form_data}

                if 'json' in fields:
                    fields['json'] = ('json_data', fields['json'], 'application/json')

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\http_client_feature.py - Chunk 6
if 'json' in fields:
                    fields['json'] = ('json_data', fields['json'], 'application/json')

                for file_key, file in uploaded_files:
                    fields[file_key] = (file.name, file, 'application/octet-stream')

                m = requests_toolbelt.MultipartEncoder(fields=fields)
                headers_data['Content-Type'] = m.content_type

                response = requests.post(url, headers=headers_data, data=m)

            elif body_type == "raw":
                response = requests.post(url, headers=headers_data, json=json.loads(raw_data))

            else:  # Handle GET or methods without a body
                response = requests.get(url, params=params_data, headers=headers_data)

            # Display response
            st.subheader("Response")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\http_client_feature.py - Chunk 7
# Display response
            st.subheader("Response")

            st.write(f"Status Code: {response.status_code}")
            st.write("Headers:", response.headers)
            st.write("Body:")
            st.json(response.json())

            # # Executing the script in the Scripting tab
            # st.subheader("Script Execution")
            # try:
            #     # Execute the script (using the response object in the script context)
            #     exec(test_script, {'response': response})
            #     st.success("Script executed successfully!")
            # except AssertionError as e:
            #     st.error(f"Assertion Error: {e}")
            # except Exception as e:
            #     st.error(f"Error executing script: {e}")

        except Exception as e:
            st.error(f"An error occurred: {e}")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\json_plugin_feature.py - Chunk 0
import streamlit as st
import json

def json_plugin_feature():
    st.title("JSON Plugin Editor")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\json_plugin_feature.py - Chunk 1
# Load the JSON data
    json_data = """
                {
                "Version": "1.0.0",
                "PluginName": "DachserPurchaseOrderIdSmartFilters",
                "CustomerName": "Dachser",
                "ApiKeys": [
                ],
                "CustomerNames": [
                    "Dachser Dev",
                    "dachser",
                    "Dachser Test",
                    "dachser.integration"
                ],
                "InvoiceDetailTypeName": "DachserPurchaseOrderId",
                "ValueToSet": null,
                "ReturnSingleResult": "false",
                "OverwriteExistingPrediction": "false",
                "Patterns": [
                    {
                    "PatternName": "SelfMatchRegexLength10Prefix2",
                    "MatchOnlyIfFalse": "false",
                    "Topology": "Self",
                    "TopologyPositionSpecifier": "1",
                    "PatternType": "Regex",

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\json_plugin_feature.py - Chunk 2
"MatchOnlyIfFalse": "false",
                    "Topology": "Self",
                    "TopologyPositionSpecifier": "1",
                    "PatternType": "Regex",
                    "IncludeMatchInValue": "true",
                    "PatternProperties": {
                        "RegexString": "^[^a-zA-Z0-9]*(Charge){0,1}(PO|P0){0,1}(45)[0-9]{8}([^a-zA-Z0-9]*|[^a-zA-Z0-9]{1,3}[0-9]{0,4})$",
                        "RegexesExcludeInValue": [
                        "(PO|P0)",
                        "(?<=(^[^a-zA-Z0-9]*(Charge){0,1}(PO|P0){0,1}(45)[0-9]{8}))[^a-zA-Z0-9]{1,3}[0-9]{0,4}",
                        "[^a-zA-Z0-9]*",
                        "(Charge)"
                        ],
                        "AdditionalSplitSigns": [
                        "+",
                        ","
                        ]
                    }
                    }
                ],
                "PatternGroups": [
                    {

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\json_plugin_feature.py - Chunk 3
","
                        ]
                    }
                    }
                ],
                "PatternGroups": [
                    {
                    "ContinueAfterGroupMatches": "true",
                    "SkipIdPostProcessing": "true",
                    "PatternNames": [
                        "SelfMatchRegexLength10Prefix2"
                    ]
                    }
                ]
                }
                """

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\json_plugin_feature.py - Chunk 4
# Convert the JSON string to a Python dictionary
    data = json.loads(json_data)

    st.markdown("## Plugin Details")

    # Create 3 columns
    col1, col2, col3 = st.columns(3)

    # Assign fields to each column
    with col1:
        data["Version"] = st.text_input("Version:", data["Version"])
        data["PluginName"] = st.text_input("Plugin Name:", data["PluginName"])
        data["CustomerName"] = st.text_input("Customer Name:", data["CustomerName"])

    with col2:
        data["InvoiceDetailTypeName"] = st.text_input("Invoice Detail Type Name:", data["InvoiceDetailTypeName"])
        data["ValueToSet"] = st.text_input("Value To Set:", str(data["ValueToSet"]))
        data["ReturnSingleResult"] = st.selectbox("Return Single Result:", ["true", "false"], index=0 if data["ReturnSingleResult"] == "true" else 1)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\json_plugin_feature.py - Chunk 5
with col3:
        data["OverwriteExistingPrediction"] = st.selectbox("Overwrite Existing Prediction:", ["true", "false"], index=0 if data["OverwriteExistingPrediction"] == "true" else 1)


    st.markdown("## API Keys")
    api_keys = st.multiselect("API Keys", options=data["ApiKeys"])
    
    st.markdown("## Customer Names")
    selected_customer_names = st.multiselect("Customer Names", options=data["CustomerNames"], default=data["CustomerNames"])

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\json_plugin_feature.py - Chunk 6
st.markdown("## Patterns")
    for pattern in data["Patterns"]:
        st.subheader(pattern["PatternName"])
        pattern["MatchOnlyIfFalse"] = st.selectbox(f"{pattern['PatternName']} - Match Only If False:", ["true", "false"], index=0 if pattern["MatchOnlyIfFalse"] == "true" else 1)
        pattern["Topology"] = st.text_input(f"{pattern['PatternName']} - Topology:", pattern["Topology"])
        pattern["TopologyPositionSpecifier"] = st.text_input(f"{pattern['PatternName']} - Topology Position Specifier:", pattern["TopologyPositionSpecifier"])
        pattern["PatternType"] = st.text_input(f"{pattern['PatternName']} - Pattern Type:", pattern["PatternType"])
        pattern["IncludeMatchInValue"] = st.selectbox(f"{pattern['PatternName']} - Include Match In Value:", ["true", "false"], index=0 if pattern["IncludeMatchInValue"] == "true" else 1)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\json_plugin_feature.py - Chunk 7
pattern["IncludeMatchInValue"] = st.selectbox(f"{pattern['PatternName']} - Include Match In Value:", ["true", "false"], index=0 if pattern["IncludeMatchInValue"] == "true" else 1)
        pattern["PatternProperties"]["RegexString"] = st.text_area(f"{pattern['PatternName']} - Regex String:", pattern["PatternProperties"]["RegexString"])

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\json_plugin_feature.py - Chunk 8
st.markdown("## Pattern Groups")
    for group in data["PatternGroups"]:
        group["ContinueAfterGroupMatches"] = st.selectbox("Continue After Group Matches:", ["true", "false"], index=0 if group["ContinueAfterGroupMatches"] == "true" else 1)
        group["SkipIdPostProcessing"] = st.selectbox("Skip Id Post Processing:", ["true", "false"], index=0 if group["SkipIdPostProcessing"] == "true" else 1)
        selected_pattern_names = st.multiselect("Pattern Names", options=group["PatternNames"], default=group["PatternNames"])

    # Button to save the changes
    if st.button("Save Configuration"):
        # Here you can serialize the 'data' dictionary back to JSON and save it
        with open("updated_config.json", "w") as f:
            json.dump(data, f, indent=4)
        st.success("Configuration saved successfully!")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\label_qa_control_feature.py - Chunk 0
import sys
import streamlit as st
import requests
import pyodbc
import pandas as pd
import json

def connect_to_database(server, database, user, password):
    """ Create a database connection using pyodbc """

    if sys.platform == 'linux':
        driver_name = 'ODBC Driver 17 for SQL Server'
    elif sys.platform == 'win32':
        driver_name = 'SQL Server'      

    try:
        conn_string = f'DRIVER={{{driver_name}}};SERVER={server};DATABASE={database};UID={user};PWD={password}'
        conn = pyodbc.connect(conn_string)
        return conn
    except pyodbc.Error as e:
        st.sidebar.error("Database connection failed: " + str(e))
        return None

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\label_qa_control_feature.py - Chunk 1
def get_label_values_query(users, label_values):
    if label_values == "":
        return ""
    label_values = label_values.split(",")
    query_string = f""
    for label_value in label_values:
        key,value = label_value.split(":")
        query_string += f"""InvoiceEntity_Id IN (SELECT InvoiceEntity_Id FROM Label WHERE Type = '{key}' AND Text = '{value}')
        AND"""
    return query_string

def get_tags_query(tags):
    tags_list = tags.split(",")
    tag_string = ""
    for tag in tags_list:
        tag_string + f"('{tag}'), "
    tag_string = tag_string[:-2] + ";" # remove ", "    

    return f"""
    DECLARE @TagNames TABLE (TagName NVARCHAR(255));
    INSERT INTO @TagNames (TagName)
    VALUES {tag_string}    
    """

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\label_qa_control_feature.py - Chunk 2
return f"""
    DECLARE @TagNames TABLE (TagName NVARCHAR(255));
    INSERT INTO @TagNames (TagName)
    VALUES {tag_string}    
    """

def get_label_query(users, label_types, label_group_types, label_values):
    
    if label_types == "" and label_group_types == "" and label_values == "":
        return ""
    
    query = """AND Id IN (SELECT [InvoiceEntity_Id] FROM Label
                    WHERE"""

    if label_types != "":
        # THIS ONLY WORKS FOR ONE USER TODO
        # with 2 Users only one needs a label
        label_types_str = ",".join(f"'{label}'" for label in label_types)
        query += f""" Type IN (SELECT [Id] FROM LabelType WHERE Name IN ({label_types_str}))
                    AND released = 1 
                    AND CreatedBy_Id IN ({users})
                    AND"""
    if label_values != "":
        label_values_query = get_label_values_query(users, label_values)
        query += label_values_query

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\label_qa_control_feature.py - Chunk 3
if label_types != "" or label_values != "":
        # remove last AND
        query = query[:-3]+")\nAND"

    if label_group_types != "":
        formated_groups = ",".join([f"'{name.strip()}'" for name in label_group_types.split(",")])
        query += f"""Id IN (SELECT [InvoiceEntity_Id] FROM LabelGroup
                    WHERE Type IN (SELECT [Id] FROM LabelType WHERE Name IN ({formated_groups}))
                    AND ReleaseItem_Id != NULL
                    AND CreatedBy_Id IN ({users})) 
                    AND"""
        
    return query[:-3] #remove last AND


def get_invoices_query(users, timeframe, doc_count, docs_per_cluster, label_types, label_group_types, tags, label_values, excluded_ids):
              
    sql_query = ""

    if tags != "":
        tags_query = get_tags_query(tags)
        sql_query += tags_query

    # add clusterinfo to query
    sql_query += f"""

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\label_qa_control_feature.py - Chunk 4
if tags != "":
        tags_query = get_tags_query(tags)
        sql_query += tags_query

    # add clusterinfo to query
    sql_query += f"""                

        WITH ClusterInvoiceRanked AS (
            SELECT 
                [Invoice_Id],
                ROW_NUMBER() OVER (PARTITION BY [Cluster_Id] ORDER BY [Created] DESC) AS RowNum
            FROM [bcidb].[dbo].[ClusterInvoice]
        )
        """
    # filter invoices by timeframe    
    sql_query += f"""SELECT TOP({doc_count}) Id FROM Invoice 
        WHERE Created >= DATEADD(day, -{timeframe}, GETDATE())"""
    
    label_query = get_label_query(users, label_types, label_group_types, label_values)
    sql_query += label_query

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\label_qa_control_feature.py - Chunk 5
if tags != "":
        sql_query += f"""AND Id IN (SELECT DISTINCT di.InvoiceId
                FROM [bcidb].[dbo].[DocumentInfo] di
                INNER JOIN [bcidb].[dbo].[Package] p ON di.PackageId = p.Id
                INNER JOIN [bcidb].[dbo].[PackageTag] pt ON p.Id = pt.PackageId
                INNER JOIN [bcidb].[dbo].[Tag] t ON pt.TagId = t.Id
                WHERE t.TagName IN (SELECT TagName FROM @TagNames)
                GROUP BY di.InvoiceId
                HAVING COUNT(DISTINCT t.TagName) = (SELECT COUNT(DISTINCT TagName) FROM @TagNames)
                AND di.InvoiceId IS NOT NULL)"""  
    
    sql_query += f"""AND Id IN (SELECT 
            [Invoice_Id]
            FROM ClusterInvoiceRanked
            WHERE RowNum <= {docs_per_cluster})
            ORDER BY Created DESC
            """
    
    if excluded_ids != "":            
        sql_query = f"AND Id NOT IN ({excluded_ids})"
    return sql_query

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\label_qa_control_feature.py - Chunk 6
def fetch_data_as_dict(cursor):
    """ Convert cursor rows to a list of dictionaries based on cursor description. """
    columns = [col[0] for col in cursor.description]
    return [dict(zip(columns, row)) for row in cursor.fetchall()]

def get_label_types(conn):
    """ Fetch label types from the database and return them as a list of strings """
    if conn is not None:
        with conn.cursor() as cur:
            cur.execute("SELECT Name FROM LabelType;")
            # Fetch all results and extract the 'Name' from each tuple in the list
            label_types = [row[0] for row in cur.fetchall()]  # Converts list of tuples to list of strings
        return label_types
    return []

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\label_qa_control_feature.py - Chunk 7
def qa_control():
    st.title("Label QA Control")
    # Database connection parameters
    st.sidebar.title("Database Connection")
    server = st.sidebar.selectbox('Server', ('serverbdsql01.ad.blumatix.com,62434', 'serverbdsql01.ad.blumatix.com,62442', 'SERVERBDSQL01\BLUDELTA', '192.168.137.60,62434'))
    database = st.sidebar.selectbox('Select Database', ('bcidb', 'bcidb_dev'))
    user = st.sidebar.text_input('Username', 'user')
    password = st.sidebar.text_input('Password', 'password', type="password")
    
    conn = connect_to_database(server, database, user, password)
    
    st.markdown("""
    ### Description: what does the feature do
    """)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\label_qa_control_feature.py - Chunk 8
# Define sets of label types
    label_type_sets = {
        'Invoice': ['DocumentType', 'InvoiceCurrency', 'DeliveryDate', 'InvoiceDate', 'InvoiceId', 'CustomerId', 'GrandTotalAmount', 
                    'NetAmount', 'VatRate', 'VatAmount', 'SenderVatId', 'ReceiverVatId', 'Iban', 'Bic', 'ReceiverOrderId', 
                    'SenderOrderId', 'ReceiverOrderDate', 'SenderOrderDate', 'TotalNetAmount', 'TotalVatAmount', 'DeliveryNoteId', 
                    'BankCode', 'BankAccount', 'DeliveryPeriodKey', 'DeliveryPeriodValue', 'ReceiverTaxId', 'SenderTaxId'],

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\label_qa_control_feature.py - Chunk 9
'OrderConfirmation': ['DocumentType', 'InvoiceCurrency', 'DeliveryDate', 'CustomerId', 'GrandTotalAmount', 'NetAmount', 'VatRate',
                              'VatAmount', 'SenderVatId', 'ReceiverVatId', 'Iban', 'Bic', 'ReceiverOrderId', 'SenderOrderId',
                              'ReceiverOrderDate', 'SenderOrderDate', 'TotalNetAmount', 'TotalVatAmount', 'BankCode', 'BankAccount',
                              'ReceiverTaxId', 'SenderTaxId', 'OrderConfirmationId', 'OrderConfirmationDate', 'SurchargeType', 'SurchargeRate',
                              'SurchargeAmount', 'DeliveryTerm'],

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\label_qa_control_feature.py - Chunk 10
'Quotation': ['DocumentType', 'InvoiceCurrency', 'DeliveryDate', 'CustomerId', 'GrandTotalAmount', 'NetAmount', 'VatRate',
                              'VatAmount', 'SenderVatId', 'ReceiverVatId', 'Iban', 'Bic', 'ReceiverOrderId', 'SenderOrderId',
                              'ReceiverOrderDate', 'SenderOrderDate', 'TotalNetAmount', 'TotalVatAmount', 'BankCode', 'BankAccount',
                              'ReceiverTaxId', 'SenderTaxId', 'QuotationId', 'QuotationDate'],

        'Contact': ['ContactName', 'Street', 'ZipCode', 'City', 'Country', 'SenderReceiverClassification', 'AttentionName', 'Region'],

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\label_qa_control_feature.py - Chunk 11
'LineItems': ['LineItemPositionNumberHeader', 'LineItemDescriptionHeader', 'LineItemArticleNumberHeader', 'LineItemQuantityHeader', 
                      'LineItemUnitHeader', 'LineItemUnitPriceHeader', 'LineItemVatRateHeader', 'LineItemAmountHeader', 'LineItemCustomDetailHeader', 
                      'LineItemPositionNumber', 'LineItemDescription', 'LineItemArticleNumber', 'LineItemQuantity', 'LineItemUnit', 'LineItemUnitPrice', 
                      'LineItemVatRate', 'LineItemAmount', 'LineItemCustomDetail', 'LineItemBufferText', 'LineItemDeliveryNoteIdHeader', 
                      'LineItemDeliveryDateHeader', 'LineItemOrderIdHeader', 'LineItemUnitPriceCoefficientHeader', 'LineItemDiscountHeader', 
                      'LineItemDeliveryNoteId', 'LineItemDeliveryDate', 'LineItemOrderId', 'LineItemUnitPriceCoefficient', 'LineItemDiscount', 'LineItemCount'],

        'Automotive': ['FirstRegistrationDate', 'PlateId', 'Mileage', 'VehicleIdentificationNumber']
    }

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\label_qa_control_feature.py - Chunk 12
'Automotive': ['FirstRegistrationDate', 'PlateId', 'Mileage', 'VehicleIdentificationNumber']
    }

    
    
    users = st.text_input("Users to Evaluate")
    col1, col2, col3 = st.columns(3)
    timeframe = col1.number_input("Timeframe in days", value=180)
    doc_count = col2.number_input("Number of Documents ", value=100)
    docs_per_cluster = col3.number_input("Maximum Number of Documents per Cluster", value=3)

    # Predefined sets selection
    selected_sets = st.multiselect('Select Predefined Label Type Sets', list(label_type_sets.keys()))

    # Combine selected predefined sets into a single list
    combined_label_types = []
    for set_name in selected_sets:
        combined_label_types.extend(label_type_sets[set_name])

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\label_qa_control_feature.py - Chunk 13
# Combine selected predefined sets into a single list
    combined_label_types = []
    for set_name in selected_sets:
        combined_label_types.extend(label_type_sets[set_name])

    # Allow selection of individual types and combine with predefined sets
    label_types = get_label_types(conn)
    selected_individual_types = st.multiselect('Select or add Individual Label Types', label_types, default=label_types[1])
    # Combine individual selections with predefined sets, remove duplicates
    combined_label_types.extend(selected_individual_types)
    combined_label_types = list(set(combined_label_types))  # Remove duplicates
    st.write(f"Selected Label Types: {combined_label_types}")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\label_qa_control_feature.py - Chunk 14
label_group_types = st.text_input("LabelGroupTypes to Evaluate")
    tags = st.text_input("List of Tags (comma-separated)")
    label_values = st.text_input("List of Label Values to filter by (e.g. DocumentType\:ForwardingOrder,ReceiverCountry\:TW)")
    excluded_ids = st.text_input("List of ids to exclude from sample (comma-separated)")
    ci_check = st.checkbox("Set Necessary CI Interval")
    if ci_check:        
        ci_low = st.number_input("Confidence Interval (low) to achieve", value=0.95)

   


    submit = st.button("Submit")
    if submit:
        query = get_invoices_query(users, timeframe, doc_count, docs_per_cluster, combined_label_types, label_group_types, tags, label_values, excluded_ids)
        with conn.cursor() as cur:
            cur.execute(query)
            data = fetch_data_as_dict(cur)
            ids = [str(item['Id']) for item in data]
            ids_comma_separated = ", ".join(ids)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\label_qa_control_feature.py - Chunk 15
st.subheader("Invoice Ids for Evaluation:")
            st.success(ids_comma_separated)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_chatbot_feature.py - Chunk 0
import streamlit as st
from llms.llm_llama2 import LLM_Llama2
from text_generation import Client
import os

@st.cache_resource()
def ChatModel(url, timeout, temperature, top_p):
    client = Client(url, timeout=timeout)
    def generate(prompt):
        return client.generate(prompt, temperature=temperature, top_p=top_p, max_new_tokens=2048, return_full_text=False).generated_text    
    return generate


@st.cache_resource()
def LLama2Chatbot(url, timeout, temperature, top_p):
    return LLM_Llama2(url, timeout, temperature, top_p)


def create_llm_sidebar():
    with st.sidebar:
        st.title('ðŸ’¬ LLM Chatbot')

        st.subheader('Text-Generation-Inference Url')
        url = st.text_input('Enter Url', 'http://192.168.137.80:8090')
        timeout_sec = st.text_input('Enter timeout [sec]', '120')

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_chatbot_feature.py - Chunk 1
st.subheader('Text-Generation-Inference Url')
        url = st.text_input('Enter Url', 'http://192.168.137.80:8090')
        timeout_sec = st.text_input('Enter timeout [sec]', '120')

        # check timeout and convert to int
        try:
            timeout = int(timeout_sec)
        except ValueError:
            st.error('Timeout must be an integer')
            return

        # Refactored from <https://github.com/a16z-infra/llama2-chatbot>
        st.subheader('Models and parameters')
        
        temperature = st.sidebar.slider('temperature', min_value=0.01, max_value=2.0, value=0.1, step=0.01)
        top_p = st.sidebar.slider('top_p', min_value=0.01, max_value=1.0, value=0.9, step=0.01)
        return url, timeout, temperature, top_p
        

def start_chatbot():
    url, timeout, temperature, top_p= create_llm_sidebar()
    chat_model =ChatModel(url, timeout, temperature, top_p)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_chatbot_feature.py - Chunk 2
def start_chatbot():
    url, timeout, temperature, top_p= create_llm_sidebar()
    chat_model =ChatModel(url, timeout, temperature, top_p)   

    # Store LLM generated responses
    if "messages" not in st.session_state.keys():
        st.session_state.messages = [{"role": "assistant", "content": "How may I assist you today?"}]

    # Display or clear chat messages
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])

    def clear_chat_history():
        st.session_state.messages = [{"role": "assistant", "content": "How may I assist you today?"}]
    st.sidebar.button('Clear Chat History', on_click=clear_chat_history)

    # Function for generating LLaMA2 response
    def generate_llama2_response(prompt_input):
        string_dialogue = "You are a helpful assistant. You do not respond as 'User' or pretend to be 'User'. You only respond once as 'Assistant'."

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_chatbot_feature.py - Chunk 3
for dict_message in st.session_state.messages:
            if dict_message["role"] == "user":
                string_dialogue += "User: " + dict_message["content"] + "\\n\\n"
            else:
                string_dialogue += "Assistant: " + dict_message["content"] + "\\n\\n"
        output = chat_model(f"prompt {string_dialogue} {prompt_input} Assistant: ")
        return output

    # User-provided prompt
    prompt = st.chat_input()
    if prompt:
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.write(prompt)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_chatbot_feature.py - Chunk 4
# Generate a new response if last message is not from assistant
    if st.session_state.messages[-1]["role"] != "assistant":
        with st.chat_message("assistant"):
            with st.spinner("Thinking..."):
                response = generate_llama2_response(prompt)
                placeholder = st.empty()
                full_response = ''
                for item in response:
                    full_response += item
                    placeholder.markdown(full_response)
                placeholder.markdown(full_response)
        message = {"role": "assistant", "content": full_response}
        st.session_state.messages.append(message)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_prompt_example.py - Chunk 0
from torch import cuda, bfloat16
import transformers
from typing import Union
import json

from langchain import LLMChain, PromptTemplate
from langchain.memory import ConversationBufferWindowMemory

#model_id = 'meta-llama/Llama-2-70b-chat-hf'
model_id = 'meta-llama/Llama-2-13b-chat-hf'


device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'

# set quantization configuration to load large model with less GPU memory
# this requires the `bitsandbytes` library
bnb_config = transformers.BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type='nf4',
    bnb_4bit_use_double_quant=True,
    bnb_4bit_compute_dtype=bfloat16
)

# begin initializing HF items, need auth token for these
hf_auth = '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'
model_config = transformers.AutoConfig.from_pretrained(
    model_id,
    use_auth_token=hf_auth
)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_prompt_example.py - Chunk 1
model = transformers.AutoModelForCausalLM.from_pretrained(
    model_id,
    trust_remote_code=True,
    config=model_config,
    quantization_config=bnb_config,
    device_map='auto',
    use_auth_token=hf_auth
)
model.eval()
print(f"Model loaded on {device}")

tokenizer = transformers.AutoTokenizer.from_pretrained(
    model_id,
    use_auth_token=hf_auth
)

generate_text = transformers.pipeline(
    model=model, tokenizer=tokenizer,
    return_full_text=True,  # langchain expects the full text
    task='text-generation',
    # we pass model parameters here too
    temperature=0.0,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max
    max_new_tokens=256,  # mex number of tokens to generate in the output
    repetition_penalty=1.1  # without this output begins repeating
)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_prompt_example.py - Chunk 2
# create a Llama2 chat template for contact extraction from invoices
BOS, EOS = "<s>", "</s>"
B_INST, E_INST = "[INST]", "[/INST]"
B_SYS, E_SYS = "<<SYS>>\n", "\n<</SYS>>\n\n"
sys_msg = B_SYS + """Assistant, your primary and ONLY objective is to extract contact information from invoices and present it DIRECTLY in the specified JSON format. Do NOT add any additional context, framing, or explanation. The output should be a JSON object and nothing else.

The exact structure of the desired JSON output is:

```json
{{
    "action": "Final Answer",
    "action_input": {{
        "sender": {{
            "name": "<Sender Name>",
            "address": "<Sender Address>"
        }},
        "receiver": {{
            "name": "<Receiver Name>",
            "address": "<Receiver Address>"
        }}
    }}
}}
```
Note: The fields <Sender Name>, <Sender Address>, <Receiver Name>, and <Receiver Address> are placeholders and should be replaced with the relevant details extracted from the invoice.

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_prompt_example.py - Chunk 3
To guide you, here are two examples of previous interactions that were correctly handled:

User: Extract all contacts from the invoice and return them as a JSON object. Differentiate between invoice sender and receiver.

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_prompt_example.py - Chunk 4
### Invoice:
RECHNUNG
Handelsagentur Fux
DATUM: 25.03.2020
Rechnung Nr.: 1954746731
KUNDEN-ID: HVK1A
SchwarzstraÃŸe 45 5020 Salzburg
RECHNUNGSADRESSE LIEFERADRESSE
Massimo Mustermann
Match GmbH
BergheimerstraÃŸe 14
5020 Salzburg
+436608553947
Rechnungsadresse
Bestellnummer: 258934 Bestelldatum: 15.3.2020
Auftragsnummer: A1237B Auftragsdatum: 15.3.2020
BESCHREIBUNG
Menge Steuersatz Preis (netto)
Lieferdatum: 20.3.2020 Lieferscheinnummer: LS185
Steinway Konzert FlÃ¼gel WeiÃŸ 1 20 % 499 000.00 â‚¬
Dirigierstab Elfenbein 1 20 % 780.00 â‚¬
Lieferdatum: 22.3.2020 Lieferscheinnummer: LS187
nVidia GPU M60 'Tesla'
4 20 % 28 560.00 â‚¬
Mars Riegel
1000 10 % 800.00 â‚¬
Gesamtbetrag netto 529 140.00 â‚¬
10 % 20 %
Steuerbetrag 80.00 â‚¬ 105 668.00 â‚¬ 105 748.00 â‚¬
Netto Betrag
800.00 â‚¬
528 340.00 â‚¬ 529 140.00 â‚¬
Summe brutto 880.00 â‚¬ 634 008.00 â‚¬ 634 888.00 â‚¬
Zahlung: innerhalb von 10 Tagen 2 % Skonto
30 Tage netto
Alle Zahlungen an Handelsagentur Fux
###

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_prompt_example.py - Chunk 5
Assistant: ```json
{{"action": "Final Answer",
    "action_input": {{
        "sender": {{
            "name": "Handelsagentur Fux",
            "address": "SchwarzstraÃŸe 45 5020 Salzburg",
        }},
        "receiver": {{
            "name": "Massimo Mustermann",
            "address": "Match GmbH, BergheimerstraÃŸe 14, 5020 Salzburg"
        }}
    }}
}}
```

User: Extract all contacts from the invoice and return them as a JSON object. Differentiate between invoice sender and receiver.

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_prompt_example.py - Chunk 6
User: Extract all contacts from the invoice and return them as a JSON object. Differentiate between invoice sender and receiver.

### Invoice:
Verwaltung
und BraustÃ¤tte
Landgrabengasse 15-18
90321 NÃ¼rnberg
Telefon
0911 2211-0
Telefax
0911 2211-111
enju.istiÄ±Ä±er-ZrÃ£u Ã†trnÃ­erj
Rechnung
Abr Per : Tagesfaktura Angustiner
Bitte bei Zahlung /RÃ¼ckfrage angeben
Datum Belegnr. Kundennr. Seite
28.02.2016 16616022803 56899865 1/1
WarenempfÃ¤nger: 56899865
Angustiner-BrÃ¤u NÃ¼rnberg AG I Landgrabengasse 15-18 190321 NÃ¼rnberg
An
Sebastian Becker
LudwigstraÃŸe 83
91765 NÃ¼rnberg
ART-NR BEZEICHNUNG / INHALT Menge HL/LTR Preis Betrag - EUR
LIEFERUNG 512864812 vom 28.02.2016 Ab: Depot RoÃŸtal
1820 Angustiner Kellerbier dunkel P-Keg .20 L 8 1,600 135,00 1.080,00
1252 Angustiner Lagerbier hell P-Keg .20 L 5 1,000 143,00 715,00
6200 Angustiner Spezi MixgetrÃ¤nk 20/0,5 57 5,700 8,00 456,00
Summe Warenwert 2.251,00
###

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_prompt_example.py - Chunk 7
Assistant: ```json
{{"action": "Final Answer",
    "action_input": {{
        "sender": {{
            "name": "Angustiner-BrÃ¤u NÃ¼rnberg AG",
            "address": "Landgrabengasse 15-18, 90321 NÃ¼rnberg"
        }},
        "receiver": {{
            "name": "Sebastian Becker",
            "address": "LudwigstraÃŸe 83, 91765 NÃ¼rnberg"
        }}
    }}
}}
```

Process the invoice provided by the user and extract the necessary contact details. Remember to STRICTLY adhere to the aforementioned JSON structure and provide NO additional context or explanation.""" + E_SYS



inst_msg = """User: Extract all contacts from the invoice and return them as a JSON object.

{invoice}
"""

template = B_INST + sys_msg  + inst_msg + E_INST
prompt_template = PromptTemplate(input_variables=["invoice"], template=template)

from langchain.llms import HuggingFacePipeline

llm = HuggingFacePipeline(pipeline=generate_text)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_prompt_example.py - Chunk 8
from langchain.llms import HuggingFacePipeline

llm = HuggingFacePipeline(pipeline=generate_text)

llama2_chain = LLMChain(
    llm=llm,
    prompt=prompt_template,
    verbose=False,
    memory=ConversationBufferWindowMemory(k=1),
    llm_kwargs={"max_length": 4096}
)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_prompt_example.py - Chunk 9
invoice_text = """ \
### Invoice:
Elektronikartikel Hergl
Baumweg 92
92330 NÃ¼rnberg
Rechnungsdatum
Rechnungsnummer
03.12.2015
BS35-158213
327623
30 Tage
02.01.2016
EmpfÃ¤nger:
Herr
Sebastian Becker
LudwigstraÃŸe 83
91765 NÃ¼rnberg
Kundennummer
Zahlungsziel
FÃ¤lligkeitsdatum
USt. %
Gesamt
Bezeichnung
Anzahl
Einheit
NP/Einheit
USt. ?
StÃ¼ck
StÃ¼ck
Taschenradio ,Vox'
20,25 ?
7,70 ?
48,20 ?
2
19 %
50,23 ?
9,54 ?
59,77 ?
MP3-Player Medion BestSound
1
19 %
90,73 ?
Nettobetrag
USt.
17,24 ?
Gesamtbetrag
107,97 ?
ZusÃ¤tzliche Informationen
Wenn Sie innerhalb von 15 Tagen nach Rechnungsausstellung zahlen erhalten Sie 2 % Skonto.
Elektronikartikel Hergl
Baumweg 92
92330 NÃ¼rnberg
Deutschland
USt.-IdNr. DE 379233689
Kontaktinformationen
Heimrich Hergl
Telefon +49 91 223135-0
Bankverbindung
IBAN
SWIFT/ BIC
DE71362500002542863326
SPMHDE3EXXX
Email: heinrich.hergl@elektronik.de
www.herglpowergmbh.de
###
"""

response = llama2_chain.predict(
    invoice=invoice_text
)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_prompt_example.py - Chunk 10
response = llama2_chain.predict(
    invoice=invoice_text
)

try:
    print(json.dumps(json.loads(response), indent=4, sort_keys=True))
except:
    print(response)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_prompt_example.py - Chunk 11
invoice_text = """ \
### Invoice:
Sulzbacher StraÃŸe 11
73731 Dekkendorf
Tel: 08 22 / 123 44 00
Mobil: 01 22 / 123 45 00
Alb
1
Glaserei Galler Â»
DÃ¶Ã¶rtherweg 11
12321 MÃ¼nsterberg
Tel: 01 23 / 383 683 500
Mobil: 01 22 / 123 45 00
 Ihr Fenster Service
Sebastian Becker
LudwigstraÃŸe 83 RECHNUNG
91765 NÃ¼rnberg Kunden-Nr. 98556
Wohnanlage Mieter RECHNUNGS-N R. 036589
DATUM 03.01.16
AUFTRAG NR.
BESCHREIBUNG
MENGE EURO EURO
Montage von 1 Alu Panzer Fenster eingestellt
und geÃ¶lt.
Arbeiten erledigt am 01.01.2016 und am
03.01.2016
Alu- Rollopanzer; Sondermodell 5,11 159,00 812,49
Kleinmaterial Ã–l Schauben Entsorgung von 1 5,30 5,30
Kleinteilen usw.)
Entsorgung von Altpanzer pauschal 1 25,00 25,00
Arbeitszeit 5 50,00 250,00
Anfahrtspauschale fÃ¼r 2 Monteure 1 25,00 25,00
Zahlbar sofort rein netto.
Zwischensumme Euro
1.117, 79
Wir gewÃ¤hren Ihnen fÃ¼r die von uns ausgefÃ¼hrten
MwSt -19 % Euro
212,38
Arbeiten eine Garantie von 2 Jahren.
Gesamt Euro ?
1.330,17
Besonderer Hinweis:

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_prompt_example.py - Chunk 12
Zwischensumme Euro
1.117, 79
Wir gewÃ¤hren Ihnen fÃ¼r die von uns ausgefÃ¼hrten
MwSt -19 % Euro
212,38
Arbeiten eine Garantie von 2 Jahren.
Gesamt Euro ?
1.330,17
Besonderer Hinweis:
Aufgrund einer Vorschrift des Finanzamtes gilt fÃ¼r jede
Rechnung eine Aufbewahrungsfrist von 2 Jahren!
Bankverbindungen:
Volksbank KÃ¶ln Nord Berliner Volksbank
IBAN: DE02362500001233567104 DE61100900001544867110
BIC: SPMHDE3EXXX BIC: BEVODEBBXXX
www.gute fensterl.de
USt-ID: 111111168
fenster@t-onlinel.de
###
"""

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_prompt_example.py - Chunk 13
response = llama2_chain.predict(
    invoice=invoice_text
)

# now convert the 'response' string to a JSON object and pretty print it in the terminal use green color for the JSON keys and values
try:
    print(json.dumps(json.loads(response), indent=4, sort_keys=True))
except:
    print(response)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_prompt_example.py - Chunk 14
invoice_text = """ \
### Invoice:
Mag Verena Stienitzka
GorianstraÃŸe 12
5020 Salzburg
Oesterreich
Rechnungsnr.: 6000112131
Rechnungsdatum: 04.07.2016
Versanddatum: 04.07.2016
Kundennr.: AT70061846
Bestellnr.: AT40114458
Hotline: 08000 / 54 54 54
Rechnung
Sehr geehrte Kundin und Kunde,
herzlichen Dank fÃ¼r Ihre Bestellung vom 04.07.2016 im NIVEA Online Shop
Wir haben folgende Auftragsdaten zu Ihrer Bestellung zusammengefasst:
Zahlungsart: Online Ãœberweisung
UST %
Gesamtpreis
Brutto EUR
Art.-Nr.
Artikelbezeichnung
Menge
Einzelpreis
EUR
NIVEA Professional HyaluronsÃ¤ure Nachtpf
958140100005
958120100005
958190100006
VSK
1
1
1
1
20
26,00
26,00
26,00
3,95
26,00
26,00
26,00
3,95
NIVEA Professional HyaluronsÃ¤ure Augenpf
20
NIVEA Professional HyaluronsÃ¤ure CC Crea
20
Versandkosten
20
81,95
13,65
68,30
81,95
Bruttorechnungsbetrag
Enthaltene USt.
Nettorechnungsbetrag
zu zahlender Betrag

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_prompt_example.py - Chunk 15
20
NIVEA Professional HyaluronsÃ¤ure CC Crea
20
Versandkosten
20
81,95
13,65
68,30
81,95
Bruttorechnungsbetrag
Enthaltene USt.
Nettorechnungsbetrag
zu zahlender Betrag
Sollten Sie Fragen zu Ihrer Rechnung haben kontaktieren Sie uns bitte per Kontaktformular oder telefonisch
unter 08000 / 54 54 54kostenlos aus Ã–sterreich; Mo-Sa 9:00 - 19:00 Uhr).
Wir wÃ¼nschen Ihnen viel Freude mit unseren Produkten und freuen uns Sie bald wieder im NIVEA Online Shop begrÃ¼ÃŸen zu
dÃ¼rfen!
Herzliche GrÃ¼ÃŸe
Ihr NIVEA Team
NIVEA Online Shop Beiersdorf Ges mbH
SchleefstraÃŸe la EURO PLAZA GebÃ¤ude H
44287 Dortmund Lehrbachgasse 13
Kundenservice: A- 1120 Wien
Telefon: 08000 54 54 54 Firmenbuch und Firmenbuchnummer:
Ã–ffnungszeiten: Handelsgericht Wien FN 88176 x
Mo.-Sa. 09:00 - 19:00 Uhr Umsatzsteueridentifikationsnummer:
ATU36743707
###
"""

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_prompt_example.py - Chunk 16
response = llama2_chain.predict(
    invoice=invoice_text
)

# now convert the 'response' string to a JSON object and pretty print it in the terminal use green color for the JSON keys and values
try:
    print(json.dumps(json.loads(response), indent=4, sort_keys=True))
except:
    print(response)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_prompt_feature.py - Chunk 0
import streamlit as st
from constants import B_INST, E_INST, B_SYS, E_SYS, inst_msg
#from torch import cuda, bfloat16
#import transformers
from langchain import LLMChain, PromptTemplate
from langchain.memory import ConversationBufferWindowMemory
#from langchain.llms import HuggingFacePipeline
import json
import re

from llms.llm_llama2 import LLM_Llama2

def create_llama2_sidebar():
    with st.sidebar:
        st.title('ðŸ¦™ðŸ’¬ Blu Llama 2')

        st.subheader('Text-Generation-Inference Url')
        url = st.text_input('Enter Url', 'http://192.168.137.80:8080')
        timeout_sec = st.text_input('Enter timeout [sec]', '120')

        # check timeout and convert to int
        try:
            timeout = int(timeout_sec)
        except ValueError:
            st.error('Timeout must be an integer')
            return

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_prompt_feature.py - Chunk 1
# check timeout and convert to int
        try:
            timeout = int(timeout_sec)
        except ValueError:
            st.error('Timeout must be an integer')
            return

        # Refactored from <https://github.com/a16z-infra/llama2-chatbot>
        st.subheader('Models and parameters')
        
        temperature = st.sidebar.slider('temperature', min_value=0.01, max_value=2.0, value=0.01, step=0.01)
        top_p = st.sidebar.slider('top_p', min_value=0.0, max_value=1.0, value=0.9, step=0.01)
        return url, timeout, temperature, top_p


def invoice_extractor_feature():
    url, timeout, temperature, top_p = create_llama2_sidebar()
    llm = LLM_Llama2(url, timeout, temperature, top_p)

    with open('default_system_prompt_template.txt') as f:
        default_prompt_template_value = f.read()

    with (open('default_user_instruct_prompt_template.txt')) as f:
        default_instruction_prompt_template_value = f.read()

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_prompt_feature.py - Chunk 2
with (open('default_user_instruct_prompt_template.txt')) as f:
        default_instruction_prompt_template_value = f.read()

    # Upload a prompt template file
    uploaded_file = st.file_uploader('Upload a prompt template text file.', type=['txt'])

    if uploaded_file is not None:
        loaded_text = uploaded_file.read().decode('utf-8')
    else:
        loaded_text = default_prompt_template_value

    # Add text area component
    input_prompt_template = st.text_area('Define a prompt template.', value=loaded_text, height=300)
    
    instr_prompt_template = st.text_area('Define an instruction prompt template.', value=default_instruction_prompt_template_value, height=60)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_prompt_feature.py - Chunk 3
# Define a prompt_template
    sys_msg = B_SYS + input_prompt_template + E_SYS
    template = B_INST + sys_msg + instr_prompt_template + E_INST
    prompt_template = PromptTemplate(input_variables=['Content'], template=template)
    llama2_chain = LLMChain(
        llm=llm,
        prompt=prompt_template,
        verbose=False,
        memory=ConversationBufferWindowMemory(k=1),
        llm_kwargs={'max_length': 4096}
    )

    # Store LLM generated responses
    if 'messages' not in st.session_state.keys():
        st.session_state.messages = [{'role': 'assistant', 'content': 'How may I help you?'}]

    # Display chat messages
    for message in st.session_state.messages:
        with st.chat_message(message['role']):
            st.write(message['content'])


    # User-provided prompt
    if prompt := st.chat_input():
        st.session_state.messages.append({'role': 'user', 'content': prompt})
        with st.chat_message('user'):
            st.write(prompt)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_prompt_feature.py - Chunk 4
# Generate a new response if last message is not from assistant
    if st.session_state.messages[-1]['role'] != 'assistant':
        with st.chat_message('assistant'):
            with st.spinner('Thinking...'):
                output = llama2_chain.predict(Content=prompt)

                if output:
                    # find last [/INST] and remove everything before it
                    last_inst = output.rfind(E_INST)
                    output = output[last_inst + len(E_INST):]
                    try:
                        json_match = re.search(r'\{.*\}', output, re.DOTALL)
                        json_str = json_match.group()
                        json_data = json.loads(json_str)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llama2_prompt_feature.py - Chunk 5
# take the json_str and pretty print it
                        pretty_json = json.dumps(json_data, indent=4, ensure_ascii=False)
                        output = f'```json\n{pretty_json}\n```'
                        st.write(output)
                    except:
                        output = output.replace('\n', '\n\n')
                        st.write(output)
                else:
                    output = 'Please try again later.'
                    st.write(output)

        message = {'role': 'assistant', 'content': output}
        st.session_state.messages.append(message)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 0
import streamlit as st
from llm_workflow_feature import predict, create_llm_sidebar
import zipfile
import os
import pandas as pd
import json
import tempfile
import shutil
import re
import matplotlib.pyplot as plt
import seaborn as sns

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 1
def initialize_session_state():
    if 'headers' not in st.session_state:
        st.session_state.headers = None
    if 'additional_properties' not in st.session_state:
        st.session_state.additional_properties = None
    if 'outputs' not in st.session_state:
        st.session_state.outputs = []
    if 'dataframes' not in st.session_state:
        st.session_state.dataframes = []
    if 'last_error_message' not in st.session_state:
        st.session_state.last_error_message = ''
    if 'code_to_execute' not in st.session_state:
        st.session_state.code_to_execute = ''
    if 'log_messages' not in st.session_state:
        st.session_state.log_messages = []
    if 'sent_requests' not in st.session_state:
        st.session_state.sent_requests = []


def llm_bm_tool():
    st.title("LLM-based Benchmarking Tool")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 2
def llm_bm_tool():
    st.title("LLM-based Benchmarking Tool")

    # Use the sidebar to set up the URL and other settings
    url, config, customer_name, customer_role = create_llm_sidebar(
        default_endpoint="simple-llm-chat",
        customer_role_default="Admin",
        model_name_default="gpt-4o",
        temperature_default=0.0,
        max_tokens_default=4096,
        seed_default="random",
        override_instruct_prompt_default="{Content}",
        override_system_prompt_default="You are an assistant that processes data.",
    )

    initialize_session_state()

    # Wrap the file upload, additional instructions, and process button in a container
    with st.container():
        st.subheader("Upload Files")
        col1, col2 = st.columns(2)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 3
# Wrap the file upload, additional instructions, and process button in a container
    with st.container():
        st.subheader("Upload Files")
        col1, col2 = st.columns(2)

        with col1:
            label_zip = st.file_uploader("Upload Labels ZIP File", type=['zip'], key='label_zip')
        with col2:
            prediction_zip = st.file_uploader("Upload Predictions ZIP File", type=['zip'], key='prediction_zip')

        # Add a text field for additional instructions
        st.subheader("Additional Instructions")
        user_instructions = st.text_area(
            "Enter any additional instructions or information to include in the prompt:",
            value='',
            height=150
        )

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 4
# Move the Process Files button here
        if st.button("Process Files"):
            if label_zip and prediction_zip:
                with st.spinner("Processing files..."):
                    process_files(
                        label_zip, prediction_zip, url, config,
                        customer_name, customer_role, user_instructions
                    )
            else:
                st.error("Please upload both Labels and Predictions ZIP files.")

    # Define tabs here
    tab1, tab2, tab3, tab4 = st.tabs([
        "Processed Output", "ðŸ“¤ Sent Requests", "ðŸ“¥ Received Responses", "Log"
    ])

    # Now, fill the placeholders in the tabs
    with tab1:
        if st.session_state.dataframes:
            ordered_columns = ['file_name', 'detail_name', 'label_text', 'prediction_text', 'tp', 'fp', 'fn', 'tn']

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 5
combined_df = pd.concat(st.session_state.dataframes, ignore_index=True)
            combined_df = combined_df[
                ordered_columns + [col for col in combined_df.columns if col not in ordered_columns]]

            # Create columns for layout
            col_left, col_right = st.columns([2, 1])

            with col_left:
                st.write("### Combined DataFrame")
                # Download button above the DataFrame
                tsv = combined_df.to_csv(sep='\t', index=False)
                st.download_button(
                    label="Download as TSV",
                    data=tsv,
                    file_name='results.tsv',
                    mime='text/tab-separated-values'
                )
                # Convert DataFrame to markdown
                st.dataframe(combined_df, use_container_width=True)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 6
with col_right:
                # Add confusion matrix at the top
                st.write("### Confusion Matrix")
                # Calculate total tp, fp, fn, tn
                total_tp = combined_df['tp'].sum()
                total_fp = combined_df['fp'].sum()
                total_fn = combined_df['fn'].sum()
                total_tn = combined_df['tn'].sum()

                # Calculate metrics
                accuracy, precision, recall, f1 = calculate_metrics(total_tp, total_fp, total_fn, total_tn)

                # Create a figure with 2 rows: one for metrics and one for confusion matrix
                fig, (ax_metrics, ax_cm) = plt.subplots(2, 1, figsize=(6, 8), gridspec_kw={'height_ratios': [1, 4]})

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 7
# Display metrics on the first subplot
                ax_metrics.axis('off')  # Turn off the axis
                metrics_text = (f"Accuracy: {accuracy:.2%}\n"
                                f"Precision: {precision:.2%}\n"
                                f"Recall: {recall:.2%}\n"
                                f"F1 Score: {f1:.2%}")
                ax_metrics.text(0.5, 0.5, metrics_text, ha='center', va='center', fontsize=12, fontweight='bold')

                cm = pd.DataFrame({
                    'Predicted Positive': [total_tp, total_fp],
                    'Predicted Negative': [total_fn, total_tn]
                }, index=['Actual Positive', 'Actual Negative'])

                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax_cm)
                ax_cm.set_title('Confusion Matrix')
                st.pyplot(fig)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 8
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax_cm)
                ax_cm.set_title('Confusion Matrix')
                st.pyplot(fig)

                # Add bar chart for accuracy per file_name
                st.write("### Accuracy per File Name")
                file_accuracy = combined_df.groupby('file_name').apply(
                    lambda x: (x['tp'].sum() + x['tn'].sum()) / (
                            x['tp'].sum() + x['fp'].sum() + x['fn'].sum() + x['tn'].sum())
                ).reset_index(name='accuracy')
                file_accuracy['accuracy'] = file_accuracy['accuracy'] * 100  # Convert to percentage

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 9
fig_acc, ax_acc = plt.subplots()
                sns.barplot(x='file_name', y='accuracy', data=file_accuracy, ax=ax_acc)
                ax_acc.set_ylabel('Accuracy (%)')
                ax_acc.set_xlabel('File Name')
                ax_acc.set_title('Accuracy per File Name')
                plt.xticks(rotation=90)
                st.pyplot(fig_acc)

        else:
            st.write("No data to display.")

    with tab2:
        st.write("### Sent Requests")
        if st.session_state.sent_requests:
            for idx, request in enumerate(st.session_state.sent_requests):
                st.write(f"#### Request {idx + 1}")
                st.json(request)
        else:
            st.write("No request data available.")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 10
with tab3:
        st.write("### Received Responses")
        if st.session_state.outputs:
            for idx, output in enumerate(st.session_state.outputs):
                st.write(f"#### Response {idx + 1}")
                st.code(output, language='json')
        else:
            st.write("No response data available.")

    with tab4:
        st.write("### Log")
        if 'log_messages' in st.session_state:
            st.write("\n\n".join(st.session_state.log_messages))
        else:
            st.write("No logs available.")



def process_files(label_zip, prediction_zip, url, config, customer_name, customer_role, user_instructions):
    # Initialize log messages in session state
    st.session_state.log_messages = []
    log_messages = st.session_state.log_messages

    # Reset session state variables
    st.session_state.dataframes = []
    st.session_state.outputs = []
    st.session_state.sent_requests = []

    log_messages.append("### Starting file processing...")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 11
log_messages.append("### Starting file processing...")

    # Create temporary directories
    temp_dir = tempfile.mkdtemp()
    label_dir = os.path.join(temp_dir, 'labels')
    prediction_dir = os.path.join(temp_dir, 'predictions')
    os.makedirs(label_dir, exist_ok=True)
    os.makedirs(prediction_dir, exist_ok=True)
    log_messages.append(f"Temporary directories created at `{temp_dir}`")

    try:
        # Save and extract label ZIP
        log_messages.append("Extracting Labels ZIP file...")
        label_zip_path = os.path.join(temp_dir, 'labels.zip')
        with open(label_zip_path, 'wb') as f:
            f.write(label_zip.getbuffer())
        with zipfile.ZipFile(label_zip_path, 'r') as zip_ref:
            zip_ref.extractall(label_dir)
        log_messages.append("Labels ZIP extracted.")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 12
# Save and extract prediction ZIP
        log_messages.append("Extracting Predictions ZIP file...")
        prediction_zip_path = os.path.join(temp_dir, 'predictions.zip')
        with open(prediction_zip_path, 'wb') as f:
            f.write(prediction_zip.getbuffer())
        with zipfile.ZipFile(prediction_zip_path, 'r') as zip_ref:
            zip_ref.extractall(prediction_dir)
        log_messages.append("Predictions ZIP extracted.")

        # Get list of all label files recursively
        label_files = {}
        for root, dirs, files in os.walk(label_dir):
            for f in files:
                base_name = os.path.splitext(f)[0]
                label_files[base_name] = os.path.join(root, f)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 13
# Get list of all prediction files recursively
        prediction_files = {}
        for root, dirs, files in os.walk(prediction_dir):
            for f in files:
                base_name = os.path.splitext(f)[0]
                prediction_files[base_name] = os.path.join(root, f)

        log_messages.append(f"Total label files: {len(label_files)}, Total prediction files: {len(prediction_files)}")

        # Match files by basename
        common_files = set(label_files.keys()) & set(prediction_files.keys())
        log_messages.append(f"Found {len(common_files)} matching files: {list(common_files)}")

        if not common_files:
            st.error("No matching files found between labels and predictions.")
            return

        # Initialize progress bar
        progress_bar = st.progress(0)
        total_files = len(common_files)
        current_file = 0

        # Process each file pair individually
        dataframes = []

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 14
# Process each file pair individually
        dataframes = []

        for base_name in common_files:
            current_file += 1
            progress = current_file / total_files
            progress_bar.progress(progress)

            label_file_path = label_files[base_name]
            prediction_file_path = prediction_files[base_name]

            # Read contents
            with open(label_file_path, 'r') as f:
                label_content = f.read()
            with open(prediction_file_path, 'r') as f:
                prediction_content = f.read()

            # Prepare prompt
            prompt = generate_prompt(label_content, prediction_content, user_instructions)

            # Prepare additional properties for the predict function
            config["LLMConfig"]["LLMFeatureOverrides"]["OverrideContent"] = prompt

            # Store the sent request
            st.session_state.sent_requests.append(config.copy())

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 15
# Store the sent request
            st.session_state.sent_requests.append(config.copy())

            # Send to LLM and get response
            output, headers = predict(
                None, config, url, customer_name, customer_role)

            if output:
                llm_output = output.get('LlmOutput', "No output received.")
                log_messages.append(f"Received response for file {base_name}")
                # Log the LLM response
                st.session_state.outputs.append(llm_output)
            else:
                log_messages.append(f"No response received for file {base_name}")
                continue

            # Store headers
            st.session_state.headers = headers

            # Parse the response into a DataFrame
            df = parse_llm_output(llm_output)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 16
# Store headers
            st.session_state.headers = headers

            # Parse the response into a DataFrame
            df = parse_llm_output(llm_output)

            if df is not None:
                df['file_name'] = base_name
                # Move 'file_name' to the first column
                cols = df.columns.tolist()
                cols.insert(0, cols.pop(cols.index('file_name')))
                df = df[cols]

                # Normalize values
                df['label_text'] = df['label_text'].apply(normalize_value)
                df['prediction_text'] = df['prediction_text'].apply(normalize_value)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 17
# Normalize values
                df['label_text'] = df['label_text'].apply(normalize_value)
                df['prediction_text'] = df['prediction_text'].apply(normalize_value)

                # Calculate tp, fp, fn, tn for each row
                df['tp'] = ((df['label_text'] == df['prediction_text']) & (
                            df['label_text'] != '')).astype(int)
                df['tn'] = ((df['label_text'] == '') & (df['prediction_text'] == '')).astype(int)
                df['fp'] = (((df['label_text'] == '') & (df['prediction_text'] != '')) |
                            ((df['label_text'] != df['prediction_text']) & (
                                        df['prediction_text'] != ''))).astype(int)
                df['fn'] = ((df['label_text'] != '') & (df['prediction_text'] == '')).astype(int)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 18
# Ensure that each row has exactly one of tp, fp, fn, tn equal to 1
                df[['tp', 'fp', 'fn', 'tn']] = df[['tp', 'fp', 'fn', 'tn']].astype(int)
                dataframes.append(df)
            else:
                log_messages.append(f"Failed to parse LLM output for file {base_name}")

        progress_bar.empty()  # Remove the progress bar

        if dataframes:
            combined_df = pd.concat(dataframes, ignore_index=True)
            st.session_state.dataframes.append(combined_df)
        else:
            st.error("No dataframes were created.")
            log_messages.append("No dataframes were created.")

        log_messages.append("### File processing completed.")

    except Exception as e:
        st.error(f"An error occurred during file processing: {e}")
        log_messages.append(f"An error occurred during file processing: {e}")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 19
except Exception as e:
        st.error(f"An error occurred during file processing: {e}")
        log_messages.append(f"An error occurred during file processing: {e}")

    finally:
        # Clean up temporary directories
        shutil.rmtree(temp_dir)
        log_messages.append("Temporary files cleaned up.")
        # Store log messages in session state
        st.session_state.log_messages = log_messages

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 20
def generate_prompt(label_content, prediction_content, user_instructions):
    prompt = (
        "You are a data analyst. Given the label content and prediction content in JSON format, "
        "extract the relevant details from both, including nested details, and compare them.\n\n"
        "Provide the output as a JSON array with the following fields for each detail:\n\n"
        "- detail_name: The key detail name (e.g., 'Name', 'ID number', including nested keys).\n"
        "- label_text: The formated value extracted from the label content.\n"
        "- prediction_text: The formated value extracted from the prediction content.\n"
        "- label_text_raw: The unformatted value extracted from the label content.\n"
        "- prediction_text_raw: The unformatted value extracted from the prediction content.\n"
        "**Normalize the values before writing to account for formatting differences.** "
        "For example:\n"

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 21
"**Normalize the values before writing to account for formatting differences.** "
        "For example:\n"
        "- Convert numbers with commas to periods (e.g., '38,5' to '38.5').\n"
        "- Remove leading zeros from numbers (e.g., '0700' to '700').\n"
        "- Ensure dates are in the same format.\n"
        "- Treat text like 'vorhanden' and '(vorhanden)' as equal.\n"
        "- Remove extra spaces and special characters.\n"
        "- If two dates are the same, but only the year is missing, then remove the year for comparison.\n"
        "- Do not change the values itself, but use the same format for comparison.\n"
        "\n"
        "Label Content:\n"
        f"{label_content}\n\n"
        "Prediction Content:\n"
        f"{prediction_content}\n\n"
    )

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 22
# Append user instructions if provided
    if user_instructions.strip():
        prompt += "Additional instructions:\n\n"
        prompt += user_instructions.strip() + "\n\n"

    # Final instructions
    prompt += (
        "Provide only the JSON array as output, enclosed between <BEGIN OUTPUT> and <END OUTPUT>. "
        "Do not include any explanations or additional text."
    )

    return prompt


def parse_llm_output(llm_output):
    try:
        # Extract JSON from the output
        json_match = re.search(r'<BEGIN OUTPUT>\s*(.*?)\s*<END OUTPUT>', llm_output, re.DOTALL)
        if json_match:
            json_content = json_match.group(1)
            # Parse the JSON content
            data = json.loads(json_content)
            df = pd.DataFrame(data)
            return df
        else:
            return None
    except Exception as e:
        return None

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 23
def normalize_value(value):
    if isinstance(value, str):
        # Replace commas with periods in numbers
        value = re.sub(r'(\d+),(\d+)', r'\1.\2', value)
        # Remove leading zeros from numbers
        value = re.sub(r'\b0+(\d+)\b', r'\1', value)
        # Normalize specific strings
        value = value.lower()
        value = value.replace('(vorhanden)', 'vorhanden')
        value = value.replace('leer', '')
        value = value.replace('/', '')
        value = value.replace('----', '')

        value = value.replace(' ', '')

        # Strip whitespace
        value = value.strip()
    return value

def calculate_metrics(tp, fp, fn, tn):
    # Total samples
    total = tp + fp + fn + tn

    # Accuracy: This is the best, folks, itâ€™s just how well you did overall.
    accuracy = (tp + tn) / total if total > 0 else 0

    # Precision: Weâ€™re talking about how many selected items are relevant!
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool.py - Chunk 24
# Precision: Weâ€™re talking about how many selected items are relevant!
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0

    # Recall: Thatâ€™s your sensitivity, how many relevant items were selected.
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0

    # F1 Score: The harmonic mean of precision and recall â€“ simply amazing!
    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

    return accuracy, precision, recall, f1

if __name__ == "__main__":
    llm_bm_tool()

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 0
import streamlit as st
from llm_workflow_feature import predict, create_llm_sidebar
import zipfile
import os
import pandas as pd
import json
import tempfile
import shutil
import re

def initialize_session_state():
    if 'headers' not in st.session_state:
        st.session_state.headers = None
    if 'additional_properties' not in st.session_state:
        st.session_state.additional_properties = None
    if 'outputs' not in st.session_state:
        st.session_state.outputs = []
    if 'dataframes' not in st.session_state:
        st.session_state.dataframes = []
    if 'last_error_message' not in st.session_state:
        st.session_state.last_error_message = ''
    if 'code_to_execute' not in st.session_state:
        st.session_state.code_to_execute = ''

def llm_bm_tool():
    st.title("LLM-based Benchmarking Tool")

    # Use the sidebar to set up the URL and other settings
    url, model, api_key, _, _, customer_name, customer_role = create_llm_sidebar(simple_sidebar=True)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 1
# Use the sidebar to set up the URL and other settings
    url, model, api_key, _, _, customer_name, customer_role = create_llm_sidebar(simple_sidebar=True)

    initialize_session_state()

    st.subheader("Upload Files")
    col1, col2 = st.columns(2)

    with col1:
        label_zip = st.file_uploader("Upload Labels ZIP File", type=['zip'], key='label_zip')
    with col2:
        prediction_zip = st.file_uploader("Upload Predictions ZIP File", type=['zip'], key='prediction_zip')

    # Add a text field for additional instructions
    st.subheader("Additional Instructions")
    user_instructions = st.text_area(
        "Enter any additional instructions or information to include in the prompt:",
        value='',
        height=150
    )

    # Define tabs here
    tab1, tab2, tab3, tab4 = st.tabs(["Processed Output", "ðŸ“¤ Sent Request", "ðŸ“¥ Received Response", "Log"])

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 2
# Define tabs here
    tab1, tab2, tab3, tab4 = st.tabs(["Processed Output", "ðŸ“¤ Sent Request", "ðŸ“¥ Received Response", "Log"])

    with tab1:
        pass  # Placeholder for Processed Output
    with tab2:
        pass  # Placeholder for Sent Request
    with tab3:
        pass  # Placeholder for Received Response
    with tab4:
        log_container = st.container()

    if st.button("Process Files"):
        if label_zip and prediction_zip:
            with st.spinner("Processing files..."):
                process_files(label_zip, prediction_zip, url, api_key, customer_name, customer_role, user_instructions, log_container)
        else:
            st.error("Please upload both Labels and Predictions ZIP files.")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 3
# Now, fill the placeholders in the tabs
    with tab1:
        if st.session_state.dataframes:
            combined_df = pd.concat(st.session_state.dataframes, ignore_index=True)
            st.write("### Combined DataFrame")
            st.write(combined_df)

            # Download button for TSV
            tsv = combined_df.to_csv(sep='\t', index=False)
            st.download_button(
                label="Download as TSV",
                data=tsv,
                file_name='results.tsv',
                mime='text/tab-separated-values'
            )
        else:
            st.write("No data to display.")

    with tab2:
        st.write("### Sent Request")
        if st.session_state.headers and st.session_state.additional_properties:
            st.json(st.session_state.headers)
            st.json(st.session_state.additional_properties)
        else:
            st.write("No request data available.")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 4
with tab3:
        st.write("### Received Response")
        if st.session_state.outputs:
            last_output = st.session_state.outputs[-1]
            st.code(last_output, language='python')
        else:
            st.write("No response data available.")

def process_files(label_zip, prediction_zip, url, api_key, customer_name, customer_role, user_instructions, log_container):
    log_container.write("### Starting file processing...")

    # Reset the DataFrame list at the beginning of a new run
    st.session_state.dataframes = []

    # Create temporary directories
    temp_dir = tempfile.mkdtemp()
    label_dir = os.path.join(temp_dir, 'labels')
    prediction_dir = os.path.join(temp_dir, 'predictions')
    os.makedirs(label_dir, exist_ok=True)
    os.makedirs(prediction_dir, exist_ok=True)
    log_container.write(f"Temporary directories created at `{temp_dir}`")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 5
try:
        # Save and extract label ZIP
        log_container.write("Extracting Labels ZIP file...")
        label_zip_path = os.path.join(temp_dir, 'labels.zip')
        with open(label_zip_path, 'wb') as f:
            f.write(label_zip.getbuffer())
        with zipfile.ZipFile(label_zip_path, 'r') as zip_ref:
            zip_ref.extractall(label_dir)
        log_container.write("Labels ZIP extracted.")

        # Save and extract prediction ZIP
        log_container.write("Extracting Predictions ZIP file...")
        prediction_zip_path = os.path.join(temp_dir, 'predictions.zip')
        with open(prediction_zip_path, 'wb') as f:
            f.write(prediction_zip.getbuffer())
        with zipfile.ZipFile(prediction_zip_path, 'r') as zip_ref:
            zip_ref.extractall(prediction_dir)
        log_container.write("Predictions ZIP extracted.")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 6
# Get list of all label files recursively
        label_files = {}
        for root, dirs, files in os.walk(label_dir):
            for f in files:
                base_name = os.path.splitext(f)[0]
                label_files[base_name] = os.path.join(root, f)

        # Get list of all prediction files recursively
        prediction_files = {}
        for root, dirs, files in os.walk(prediction_dir):
            for f in files:
                base_name = os.path.splitext(f)[0]
                prediction_files[base_name] = os.path.join(root, f)

        log_container.write(f"Total label files: {len(label_files)}, Total prediction files: {len(prediction_files)}")

        # Match files by basename
        common_files = set(label_files.keys()) & set(prediction_files.keys())
        log_container.write(f"Found {len(common_files)} matching files: {list(common_files)}")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 7
if not common_files:
            st.error("No matching files found between labels and predictions.")
            return

        # Read contents and collect all data
        all_base_names = []
        label_contents_dict = {}  # Mapping from base_name to label content
        prediction_contents_dict = {}  # Mapping from base_name to prediction content

        for base_name in common_files:
            label_file_path = label_files[base_name]
            prediction_file_path = prediction_files[base_name]

            # Read contents
            with open(label_file_path, 'r') as f:
                label_content = f.read()
            with open(prediction_file_path, 'r') as f:
                prediction_content = f.read()

            all_base_names.append(base_name)
            label_contents_dict[base_name] = label_content
            prediction_contents_dict[base_name] = prediction_content

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 8
all_base_names.append(base_name)
            label_contents_dict[base_name] = label_content
            prediction_contents_dict[base_name] = prediction_content

        # Transform all labels upfront
        log_container.write("Transforming all label files...")
        transformed_label_contents_dict = transform_labels(
            label_contents_dict, api_key, url, customer_name, customer_role, log_container)

        if transformed_label_contents_dict is None:
            st.error("Failed to transform all labels.")
            return

        # Now prepare examples for code generation using transformed labels
        example_files = list(common_files)[:10]
        log_container.write(f"Using {len(example_files)} examples to generate code.")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 9
examples = []
        for base_name in example_files:
            examples.append({
                'base_name': base_name,
                'transformed_label_content': transformed_label_contents_dict[base_name],
                'prediction_content': prediction_contents_dict[base_name]
            })

        log_container.write("Generating code using the selected examples.")

        # Generate the initial prompt
        prompt = generate_prompt(examples, user_instructions=user_instructions)

        # Prepare additional properties for the predict function
        st.session_state.additional_properties = {
            "SystemPrompt": "You are an assistant that writes Python code.",
            "InstructPrompt": "{Content}",
            "Content": prompt,
            "ApiKey": api_key
        }

        # Try executing the generated code
        max_attempts = 3
        attempt = 0
        code_executed = False
        code_to_execute = None  # Initialize code_to_execute

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 10
# Try executing the generated code
        max_attempts = 3
        attempt = 0
        code_executed = False
        code_to_execute = None  # Initialize code_to_execute

        while attempt < max_attempts and not code_executed:
            attempt += 1
            log_container.write(f"Attempt {attempt} to generate and execute code...")
            try:
                # Get the assistant's response
                output, headers = predict(
                    None, st.session_state.additional_properties, url, customer_name, customer_role)

                if output:
                    llm_output = output.get('LlmOutput', "No output received.")
                    log_container.write("Received response from LLM.")
                else:
                    llm_output = "No response received, please try again."
                    st.error(llm_output)
                    break  # Exit the loop if no response is received

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 11
# Store outputs and headers
                st.session_state.outputs.append(llm_output)
                st.session_state.headers = headers

                # Extract code from llm_output using custom markers
                code_match = re.search(r'<BEGIN CODE>\s*(.*?)\s*<END CODE>', llm_output, re.DOTALL)
                if code_match:
                    code_to_execute = code_match.group(1)
                    st.session_state.code_to_execute = code_to_execute
                    log_container.code(code_to_execute, language='python')
                else:
                    st.error("LLM response does not contain code in expected format.")
                    log_container.error("LLM response does not contain code in expected format.")
                    log_container.code(llm_output)
                    st.session_state.last_error_message = "LLM response does not contain code in expected format."
                    continue  # Try again

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 12
# Execute the generated code safely
                log_container.write("Executing generated code with example data...")
                # Use the example data to test the code
                test_base_names = [ex['base_name'] for ex in examples]
                test_transformed_label_contents = [ex['transformed_label_content'] for ex in examples]
                test_prediction_contents = [ex['prediction_content'] for ex in examples]

                df = execute_generated_code(
                    code_to_execute,
                    test_base_names,
                    test_transformed_label_contents,
                    test_prediction_contents
                )

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 13
if df is not None:
                    log_container.write("DataFrame created with example data.")
                    # Do not append the test df to st.session_state.dataframes
                    code_executed = True
                else:
                    error_message = st.session_state.last_error_message
                    st.error("Failed to create DataFrame with example data.")
                    log_container.error("Failed to create DataFrame with example data.")
                    # Prepare prompt with the failing code and error
                    log_container.write("Resending request to LLM with failing code and error message...")

                    # Generate a new prompt with the error message
                    prompt = generate_prompt(
                        examples, error_message, code_to_execute, user_instructions=user_instructions)
                    st.session_state.additional_properties["Content"] = prompt

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 14
except Exception as e:
                error_message = str(e)
                st.error(f"An error occurred while processing example data: {error_message}")
                log_container.error(f"An error occurred while processing example data: {error_message}")
                st.session_state.last_error_message = error_message
                # Prepare prompt with the failing code and error
                log_container.write("Resending request to LLM with failing code and error message...")

                # Generate a new prompt with the error message
                prompt = generate_prompt(
                    examples, error_message, code_to_execute, user_instructions=user_instructions)
                st.session_state.additional_properties["Content"] = prompt

        if not code_executed:
            st.error("Failed to execute code after multiple attempts.")
            log_container.error("Failed to execute code after multiple attempts.")
            return

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 15
log_container.write(f"Total files to process: {len(all_base_names)}")

        # Prepare lists for code execution
        all_transformed_label_contents = [transformed_label_contents_dict[base_name] for base_name in all_base_names]
        all_prediction_contents = [prediction_contents_dict[base_name] for base_name in all_base_names]

        # Execute the code with all data
        df = execute_generated_code(
            st.session_state.code_to_execute,
            all_base_names,
            all_transformed_label_contents,
            all_prediction_contents
        )

        if df is not None:
            log_container.write("DataFrame created for all files.")
            st.session_state.dataframes.append(df)
        else:
            st.error("Failed to create DataFrame for all files.")
            log_container.error("Failed to create DataFrame for all files.")

        log_container.write("### File processing completed.")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 16
log_container.write("### File processing completed.")

    except Exception as e:
        st.error(f"An error occurred during file processing: {e}")
        log_container.error(f"An error occurred during file processing: {e}")

    finally:
        # Clean up temporary directories
        shutil.rmtree(temp_dir)
        log_container.write("Temporary files cleaned up.")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 17
finally:
        # Clean up temporary directories
        shutil.rmtree(temp_dir)
        log_container.write("Temporary files cleaned up.")

def transform_label(label_content, api_key, url, customer_name, customer_role, log_container):
    # Prepare the prompt with updated instructions
    prompt = (
        "You are an assistant that transforms data. "
        "Given the following label content, convert it into a JSON format similar to the prediction files. "
        "Ensure that the structure matches the prediction format so that they can be compared directly. "
        "**Treat any occurrences of '/' or 'leer' as empty strings ('').**\n\n"
        "Label Content:\n"
        f"{label_content}\n\n"
        "Provide the output in JSON format, enclosed between <BEGIN JSON> and <END JSON>."
    )

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 18
additional_properties = {
        "SystemPrompt": "You are an assistant that transforms data.",
        "InstructPrompt": "{Content}",
        "Content": prompt,
        "ApiKey": api_key
    }

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 19
try:
        output, headers = predict(
            None, additional_properties, url, customer_name, customer_role)
        if output:
            llm_output = output.get('LlmOutput', "No output received.")
            # Extract JSON from the output
            json_match = re.search(r'<BEGIN JSON>\s*(.*?)\s*<END JSON>', llm_output, re.DOTALL)
            if json_match:
                transformed_label_content = json_match.group(1)
                log_container.code(transformed_label_content, language='json')
                return transformed_label_content
            else:
                log_container.error("LLM response does not contain JSON in expected format.")
                log_container.code(llm_output)
                return None
        else:
            log_container.error("No response received from LLM.")
            return None
    except Exception as e:
        log_container.error(f"An error occurred while transforming label: {e}")
        return None

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 20
def transform_labels(label_contents_dict, api_key, url, customer_name, customer_role, log_container):
    transformed_label_contents_dict = {}
    for base_name, label_content in label_contents_dict.items():
        log_container.write(f"Transforming label for file {base_name}...")
        transformed_label = transform_label(
            label_content, api_key, url, customer_name, customer_role, log_container)
        if transformed_label is not None:
            transformed_label_contents_dict[base_name] = transformed_label
        else:
            log_container.error(f"Failed to transform label for file {base_name}.")
            return None
    return transformed_label_contents_dict

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 21
def execute_generated_code(code_to_execute, base_names, transformed_label_contents, prediction_contents):
    # Preprocess code: remove import statements
    code_to_execute = re.sub(r'^\s*import .+$', '', code_to_execute, flags=re.MULTILINE)
    # Replace print statements with st.write
    code_to_execute = code_to_execute.replace('print(', 'st.write(')
    # Set up a restricted execution environment
    import builtins

    # Create a filtered copy of __builtins__
    safe_builtins = {}
    for builtin_name in dir(builtins):
        if builtin_name in ['eval', 'exec', 'compile', 'open', '__import__', 'input', 'help', 'dir']:
            continue  # Exclude potentially unsafe built-ins
        safe_builtins[builtin_name] = getattr(builtins, builtin_name)

    # Include necessary built-ins for function definitions
    safe_builtins['__build_class__'] = builtins.__build_class__
    safe_builtins['globals'] = globals
    safe_builtins['locals'] = locals

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 22
# Include necessary built-ins for function definitions
    safe_builtins['__build_class__'] = builtins.__build_class__
    safe_builtins['globals'] = globals
    safe_builtins['locals'] = locals

    safe_globals = {
        "__builtins__": safe_builtins,
        "re": re,
        "pd": pd,
        "json": json,
        "base_names": base_names,
        "label_contents": transformed_label_contents,
        "prediction_contents": prediction_contents
    }
    safe_locals = {}

    try:
        # Execute the code
        exec(code_to_execute, safe_globals, safe_locals)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 23
try:
        # Execute the code
        exec(code_to_execute, safe_globals, safe_locals)

        # Retrieve the DataFrame
        df = safe_locals.get('df')
        if df is not None and isinstance(df, pd.DataFrame):
            return df
        else:
            error_message = "Generated code did not produce a DataFrame named 'df'."
            st.error(error_message)
            st.session_state.last_error_message = error_message
            return None
    except Exception as e:
        error_message = f"Error executing generated code: {e}"
        st.error(error_message)
        st.session_state.last_error_message = error_message
        return None

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 24
def generate_prompt(examples, error_message=None, code_to_execute=None, user_instructions=''):
    prompt = (
        "You are a data analyst. Given lists of base names and contents of transformed label files and prediction files, "
        "both in JSON format, analyze the examples provided and generate Python code to create a pandas DataFrame. "
        "The DataFrame should include relevant details extracted from the JSON data. "
        "Think about what key information is present in both labels and predictions, such as 'Name', 'ID number', etc., "
        "and generate code to extract those details.\n\n"
        "The DataFrame should have the following columns:\n\n"
        "- file_name: The base name of the files (from the list 'base_names').\n"
        "- detail_name: The key detail name (e.g., 'Name', 'ID number').\n"
        "- label: The value extracted from the label JSON content.\n"
        "- prediction: The value extracted from the prediction JSON content.\n"

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 25
"- label: The value extracted from the label JSON content.\n"
        "- prediction: The value extracted from the prediction JSON content.\n"
        "- correct: 1 if the label and prediction values match, else 0.\n\n"
        "The variables 'base_names', 'label_contents', and 'prediction_contents' are lists of strings, "
        "where each string contains the JSON content of a file.\n\n"
        "Check the Label and the Prediction Content on how to extract and "
        "match the details and also nested details for each. "
        "Your task is to write Python code to process the data and create the DataFrame 'df'.\n\n"
    )

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 26
if error_message and code_to_execute:
        prompt += (
            f"You provided the following code which failed to execute:\n\n"
            f"<BEGIN CODE>\n{code_to_execute}\n<END CODE>\n\n"
            f"It failed with the following error:\n\n"
            f"{error_message}\n\n"
            "Please correct the code so that it works with the given lists of data.\n\n"
        )

    prompt += "Here are examples of the contents of the files:\n\n"

    for i, example in enumerate(examples, start=1):
        prompt += f"Example {i}:\nBase Name: {example['base_name']}\n"
        prompt += f"Transformed Label Content (JSON):\n{example['transformed_label_content']}\n\n"
        prompt += f"Prediction File Content (JSON):\n{example['prediction_content']}\n\n"

    # Append user instructions if provided
    if user_instructions.strip():
        prompt += "Additional instructions:\n\n"
        prompt += user_instructions.strip() + "\n\n"

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 27
# Append user instructions if provided
    if user_instructions.strip():
        prompt += "Additional instructions:\n\n"
        prompt += user_instructions.strip() + "\n\n"

    prompt += (
        "Provide only the Python code to process the lists 'base_names', 'label_contents', and 'prediction_contents', "
        "and create the DataFrame 'df'. Do not include any explanations. "
        "Do not define 'base_names', 'label_contents', or 'prediction_contents'; they are already provided. "
        "Do not include any file reading code and do not include any import statements. "
        "Assume that all needed modules are already imported."
        "Enclose the code between <BEGIN CODE> and <END CODE>."
    )

    return prompt

if __name__ == "__main__":
    llm_bm_tool()

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_bm_tool_old.py - Chunk 28
return prompt

if __name__ == "__main__":
    llm_bm_tool()


"""
Process Button Position: Moved the "Process Files" button to be above the tabs, directly under the "Additional Instructions" field.
maybe make a container around the upload files, additonal instructions and the process button?

DataFrame Display: Displayed the DataFrame as markdown using st.markdown() with code formatting for better readability.

make a Confusion Matrix for the dataframe, if we need any more info, then adjust the building of the df in the prompt to include that info

Plot the counts for each unique detail_name using a bar chart
"""

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_chat_feature.py - Chunk 0
import streamlit as st
from llm_helpers import predict, create_llm_sidebar
import re


def initialize_session_state():
    if 'conversation' not in st.session_state:
        st.session_state.conversation = []
    if 'headers' not in st.session_state:
        st.session_state.headers = None
    if 'config' not in st.session_state:
        st.session_state.config = None
    if 'output' not in st.session_state:
        st.session_state.output = None
    if 'memory' not in st.session_state:
        st.session_state.memory = ''


def handle_clear_memory():
    st.session_state.memory = ''
    st.experimental_rerun()


def handle_clear_conversation():
    st.session_state.conversation = []
    st.experimental_rerun()


def handle_clear_everything():
    st.session_state.memory = ''
    st.session_state.conversation = []
    st.experimental_rerun()

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_chat_feature.py - Chunk 1
def handle_clear_everything():
    st.session_state.memory = ''
    st.session_state.conversation = []
    st.experimental_rerun()


def split_text_into_chunks(text, max_words):
    words = text.split()
    chunks = []
    for i in range(0, len(words), max_words):
        chunk = ' '.join(words[i:i + max_words])
        chunks.append(chunk)
    return chunks


def get_first_last_n_words(text, n):
    words = text.split()
    if len(words) <= 2 * n:
        return text
    else:
        return " ".join(words[:n]), " ".join(words[-n:])


def build_prompt(user_input):
    prompt_components = []

    if st.session_state.memory:
        prompt_components.append(f"==>Memory:{st.session_state.memory}\n")

    prompt_components.append(f"==>New User Input:\n{user_input}\n")

    max_tokens = 128000
    max_tokens = int(max_tokens / 2.59)
    token_count = sum(len(component.split()) for component in prompt_components)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_chat_feature.py - Chunk 2
max_tokens = 128000
    max_tokens = int(max_tokens / 2.59)
    token_count = sum(len(component.split()) for component in prompt_components)

    reversed_conversation = st.session_state.conversation[::-1]
    included_messages = []

    for message in reversed_conversation:
        if message['role'] == 'user' and message['content'] == user_input:
            continue

        message_text = f"{message['role'].capitalize()}:\n{message['content']}\n"
        message_tokens = len(message_text.split())

        if token_count + message_tokens <= max_tokens:
            included_messages.append(message_text)
            token_count += message_tokens
        else:
            break

    print(f"Used Tokens: {token_count}/{max_tokens}")
    included_messages = included_messages[::-1]
    conversation_history = f"Conversation History:\n{''.join(included_messages)}"
    full_prompt = f"==>{conversation_history}" + f"{''.join(prompt_components)}"

    return full_prompt

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_chat_feature.py - Chunk 3
return full_prompt


def handle_send_action(user_input, url, config, customer_name, customer_role):
    user_input = user_input.strip()

    if user_input:
        max_tokens = 128000
        max_tokens = int(max_tokens / 2.59)
        reserved_tokens = 5000
        max_input_tokens = max_tokens - reserved_tokens
        user_input_tokens = len(user_input.split())

        # Save the config in session state for consistency and debugging purposes
        st.session_state.config = config

        if user_input_tokens > max_input_tokens:
            print("Use Chunking")
            original_system_prompt = config["LLMConfig"]["LLMFeatureOverrides"]["OverrideSystemPrompt"]
            chunk_sytem_prompt = "You are an advanced LLM chatbot ready to assist the user. Please provide a concise summary of the information so far or fulfill what the user requested."
            config["LLMConfig"]["LLMFeatureOverrides"]["OverrideSystemPrompt"] = chunk_sytem_prompt

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_chat_feature.py - Chunk 4
progress_bar = st.progress(0)
            max_chunk_size = max_input_tokens // 2
            chunks = split_text_into_chunks(user_input, max_chunk_size)
            summaries = []

            N = 500
            # first_n_words, last_n_words = get_first_last_n_words(user_input, N)

            st.write("The input is too long and will be split into chunks.")
            st.write(f"Number of Chunks: {len(chunks)}")
            st.write(f"Changed System Prompt temporarily for chunking to '{chunk_sytem_prompt}'")

            for i, chunk in enumerate(chunks):
                print(f"Chunk {i + 1}/{len(chunks)}")
                progress_bar.progress((i + 1) / len(chunks))

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_chat_feature.py - Chunk 5
for i, chunk in enumerate(chunks):
                print(f"Chunk {i + 1}/{len(chunks)}")
                progress_bar.progress((i + 1) / len(chunks))

                prompt_components = []
                if st.session_state.memory:
                    prompt_components.append(f"==>Memory:{st.session_state.memory}\n")
                # prompt_components.append(f"==>First Part of User Input:\n{first_n_words}\n")
                prompt_components.append(f"==>New User Input Chunk:\n{chunk}\n")
                # prompt_components.append(f"==>Last Part of User Input:\n{last_n_words}\n")
                prompt_components.append(
                    "Please provide a concise summary of the information so far or fulfill what the user requested.\n")
                full_prompt = ''.join(prompt_components)

                # Update OverrideContent within config for the current chunk
                config["LLMConfig"]["LLMFeatureOverrides"]["OverrideContent"] = full_prompt

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_chat_feature.py - Chunk 6
# Update OverrideContent within config for the current chunk
                config["LLMConfig"]["LLMFeatureOverrides"]["OverrideContent"] = full_prompt

                try:
                    output, headers = predict(
                        None, config, url, customer_name, customer_role)
                    summary = output.get('LlmOutput', "No output received.")
                    summaries.append(summary.strip())
                    st.session_state.headers = headers
                    st.session_state.output = output
                except Exception as e:
                    st.session_state.conversation.append({'role': 'assistant', 'content': f"An error occurred: {e}"})
                    st.write(f"An error occurred: {e}")
                    st.session_state.output = {'error': str(e)}
                    st.session_state.headers = None

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_chat_feature.py - Chunk 7
final_prompt_components = []
            if st.session_state.memory:
                final_prompt_components.append(f"==>Memory:{st.session_state.memory}\n")
            # final_prompt_components.append(f"==>First Part of User Input:\n{first_n_words}\n")
            final_prompt_components.append("==>Summaries of Chunks:\n")
            for i, summary in enumerate(summaries):
                final_prompt_components.append(f"Summary of next Chunk:\n{summary}\n")
            # final_prompt_components.append(f"==>Last Part of User Input:\n{last_n_words}\n")
            final_prompt_components.append("Please fulfill what the user requested in his input.\n")
            full_prompt = ''.join(final_prompt_components)

            # Update OverrideContent with the final prompt
            config["LLMConfig"]["LLMFeatureOverrides"]["OverrideSystemPrompt"] = original_system_prompt
            config["LLMConfig"]["LLMFeatureOverrides"]["OverrideContent"] = full_prompt

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_chat_feature.py - Chunk 8
try:
                st.session_state.output, st.session_state.headers = predict(
                    None, config, url, customer_name, customer_role)
                if st.session_state.output:
                    llm_output = st.session_state.output.get('LlmOutput', "No output received.")
                else:
                    llm_output = "No response received, please try again."

                memory_match = re.search(r'\{\{\{Memory:(.*?)\}\}\}', llm_output, re.DOTALL)
                if memory_match:
                    st.session_state.memory += ' ' + memory_match.group(1).strip()
                    llm_output = llm_output.replace(memory_match.group(0), '').strip()

                st.session_state.conversation.append({'role': 'assistant', 'content': llm_output})

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_chat_feature.py - Chunk 9
st.session_state.conversation.append({'role': 'assistant', 'content': llm_output})

            except Exception as e:
                llm_output = f"An error occurred: {e}"
                st.session_state.conversation.append({'role': 'assistant', 'content': llm_output})
                st.session_state.output = {'error': str(e)}
                st.session_state.headers = None

            st.experimental_rerun()

        else:
            st.session_state.conversation.append({'role': 'user', 'content': user_input})
            full_prompt = build_prompt(user_input)

            # Set final prompt as OverrideContent in config
            config["LLMConfig"]["LLMFeatureOverrides"]["OverrideContent"] = full_prompt

            try:
                st.session_state.output, st.session_state.headers = predict(
                    None, config, url, customer_name, customer_role)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_chat_feature.py - Chunk 10
try:
                st.session_state.output, st.session_state.headers = predict(
                    None, config, url, customer_name, customer_role)

                if st.session_state.output:
                    llm_output = st.session_state.output.get('LlmOutput', "No output received.")
                else:
                    llm_output = "No response received, please try again."

                memory_match = re.search(r'\{\{\{Memory:(.*?)\}\}\}', llm_output, re.DOTALL)
                if memory_match:
                    st.session_state.memory += ' ' + memory_match.group(1).strip()
                    llm_output = llm_output.replace(memory_match.group(0), '').strip()

                st.session_state.conversation.append({'role': 'assistant', 'content': llm_output})

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_chat_feature.py - Chunk 11
st.session_state.conversation.append({'role': 'assistant', 'content': llm_output})

            except Exception as e:
                llm_output = f"An error occurred: {e}"
                st.session_state.conversation.append({'role': 'assistant', 'content': llm_output})
                st.session_state.output = {'error': str(e)}
                st.session_state.headers = None

            st.experimental_rerun()


def display_conversation():
    if st.session_state.conversation:
        for message in reversed(st.session_state.conversation):
            with st.chat_message(message["role"]):
                st.write(message["content"])


def display_memory():
    st.markdown("### Memory")
    if st.session_state.memory:
        st.markdown(
            f"<div style='padding: 10px; border: 1px solid #ccc; border-radius: 5px;'>"
            f"{st.session_state.memory}</div>",
            unsafe_allow_html=True)
    else:
        st.write("No memory yet.")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_chat_feature.py - Chunk 12
def llm_chat_feature():
    st.title("BluDelta AzureGPT ChatBot")

    system_prompt = "You are an advanced LLM chatbot ready to assist the user. At the beginning of your response, provide a list of important infos of the conversation as Memory in the format '{{{Memory: ...}}}'. Only include new information. Do not include any other text within '{{{ }}}'. After that write the response for the user."
    instruct_prompt = "{Content}"

    url, config, customer_name, customer_role = create_llm_sidebar(
        default_endpoint="simple-llm-chat",
        customer_role_default="Admin",
        model_name_default="gpt-4o",
        temperature_default=0.7,
        max_tokens_default=4096,
        seed_default="random",
        override_instruct_prompt_default=instruct_prompt,
        override_system_prompt_default=system_prompt,
    )

    initialize_session_state()

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_chat_feature.py - Chunk 13
initialize_session_state()

    with st.form(key='input_form', clear_on_submit=True):
        user_input = st.text_area("Enter your message, send with CTRL + Enter:", value='', height=150)
        instruct_append = st.text_area("Append to instruction prompt:", value='', height=120)
        send_clicked = st.form_submit_button("Send")

    _, col1, col2, col3 = st.columns([8, 1, 1, 1])
    with col1:
        clear_memory_clicked = st.button("Clear Memory")
    with col2:
        clear_conversation_clicked = st.button("Clear Conversation")
    with col3:
        clear_everything_clicked = st.button("Clear Both")

    if clear_memory_clicked:
        handle_clear_memory()

    if clear_conversation_clicked:
        handle_clear_conversation()

    if clear_everything_clicked:
        handle_clear_everything()

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_chat_feature.py - Chunk 14
if clear_memory_clicked:
        handle_clear_memory()

    if clear_conversation_clicked:
        handle_clear_conversation()

    if clear_everything_clicked:
        handle_clear_everything()

    if send_clicked:
        config["LLMConfig"]["LLMFeatureOverrides"]["OverrideSystemPrompt"] += instruct_append
        handle_send_action(user_input, url, config, customer_name, customer_role)

    tab1, tab2, tab3 = st.tabs(["Processed Output", "ðŸ“¤ Sent Request", "ðŸ“¥ Received Response"])

    with tab1:
        conversation_col, memory_col = st.columns([3, 1])
        with conversation_col:
            display_conversation()
        with memory_col:
            display_memory()

    with tab2:
        st.write("### Sent Request Data")
        if st.session_state.headers is not None:
            st.json(st.session_state.headers)
        else:
            st.write("No headers available.")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_chat_feature.py - Chunk 15
if st.session_state.config is not None:
            st.json(st.session_state.config)
        else:
            st.write("No config available.")

    with tab3:
        st.write("### Raw Response Data")
        if st.session_state.output is not None:
            st.write(st.session_state.output)
        else:
            st.write("No response data available.")


if __name__ == "__main__":
    llm_chat_feature()

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_helpers.py - Chunk 0
import requests
import requests_toolbelt
import os
import streamlit as st
import json
import random

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_helpers.py - Chunk 1
# "http://192.168.137.106:8080")  # http://192.168.137.80:8082
def create_llm_sidebar(
        base_url_default="http://192.168.137.80:8082",
        default_endpoint="document",
        customer_name_default="default-customer",
        customer_role_default="User",
        llm_provider_default="Default",
        supports_image_processing_default="Default",
        api_key_name_default="",
        api_key_default="",
        resource_name_default="",
        deployment_id_default="",
        model_name_default="",
        api_version_default="",
        temperature_default=None,
        seed_default=None,
        max_tokens_default=None,
        top_p_default=None,
        frequency_penalty_default=None,
        presence_penalty_default=None,
        ocr_engine_default="Default",
        is_return_with_images_default="Default",
        max_pages_default=None,
        as_plain_text_default="Default",
        as_plain_text_per_page_default="Default",

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_helpers.py - Chunk 2
is_return_with_images_default="Default",
        max_pages_default=None,
        as_plain_text_default="Default",
        as_plain_text_per_page_default="Default",
        override_instruct_prompt_default="",
        override_system_prompt_default=""
):
    with st.sidebar:
        st.title('Settings')

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_helpers.py - Chunk 3
# Workflow URL Section
        st.subheader('Workflow URL')
        base_url = st.text_input("Enter Base URL", base_url_default)
        predefined_endpoints = [
            'document',
            'llm-workflow',
            'generic-llm-workflow',
            'lmdx',
            'simple-llm-chat',
            'order-confirmation',
            'quotation',
            'receipt',
            'doc-splitter',
        ]

        if default_endpoint not in predefined_endpoints:
            predefined_endpoints.insert(0, default_endpoint)

        selected_endpoint = st.selectbox(
            "Select an API Endpoint or enter below",
            predefined_endpoints,
            index=predefined_endpoints.index(default_endpoint)
        )

        custom_endpoint = st.text_input('Enter custom Endpoint', selected_endpoint)
        url = f"{base_url}/{custom_endpoint}"

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_helpers.py - Chunk 4
custom_endpoint = st.text_input('Enter custom Endpoint', selected_endpoint)
        url = f"{base_url}/{custom_endpoint}"

        if custom_endpoint == 'document':
            selected_document_type = st.selectbox(
                'Select a predefined document type or enter below',
                ['Default', 'timesheet', 'invoice', 'receipt', 'delivery-note']
            )
            document_type = st.text_input('Enter Document Type', selected_document_type)
            if document_type and document_type != 'Default':
                url += f"?document-type={document_type}"

        st.write(f"Final URL: {url}")

        # Initialize the configuration dictionary
        config = {
            "OcrConfig": {},
            "LLMConfig": {
                "LLMProviderConfig": {
                    "Settings": {}
                },
                "LLMFeatureOverrides": {},
                "LLMParameterConfig": {}
            }
        }

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_helpers.py - Chunk 5
# Customer Information Section
        st.subheader("Customer Information")
        customer_name = st.text_input('Enter Customer Name', customer_name_default)
        customer_role = st.selectbox('Select Customer Role', [customer_role_default, 'Admin'])

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_helpers.py - Chunk 6
# LLM Provider Configuration Section
        with st.expander("LLM Provider Configuration"):
            llm_provider = st.selectbox("Select LLM Provider", ["Default", "AzureGPT", "OpenAI", "Claude", "Mistral"],
                                        index=["Default", "AzureGPT", "OpenAI", "Claude", "Mistral"].index(llm_provider_default))
            supports_image_processing = st.selectbox("LLM Supports Image Processing", ["Default", True, False],
                                                     index=["Default", True, False].index(supports_image_processing_default))
            api_key_name = st.text_input("API Key Name", api_key_name_default)
            api_key = st.text_input("API Key", api_key_default, type="password")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_helpers.py - Chunk 7
st.markdown("**Settings**")
            resource_name = st.text_input("Resource Name", resource_name_default)
            deployment_id = st.text_input("Deployment ID", deployment_id_default)
            model_name = st.text_input("Model Name", model_name_default)
            api_version = st.text_input("API Version", api_version_default)

            llm_provider = llm_provider if llm_provider != 'Default' else None
            supports_image_processing = None if supports_image_processing == 'Default' else supports_image_processing
            api_key_name = api_key_name or None
            api_key = api_key or None
            resource_name = resource_name or None
            deployment_id = deployment_id or None
            model_name = model_name or None
            api_version = api_version or None

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_helpers.py - Chunk 8
config["LLMConfig"]["LLMProviderConfig"] = {
                "Name": llm_provider,
                "SupportsImageProcessing": supports_image_processing,
                "ApiKeyName": api_key_name,
                "ApiKey": api_key,
                "Settings": {
                    "ResourceName": resource_name,
                    "DeploymentId": deployment_id,
                    "ModelName": model_name,
                    "ApiVersion": api_version
                }
            }

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_helpers.py - Chunk 9
# LLM Feature Overrides Section
        with st.expander("LLM Feature Overrides"):
            enable_images = st.selectbox("Enable Images", ["Default", True, False])
            enable_text = st.selectbox("Enable Text", ["Default", True, False])
            override_content = st.text_area(
                "Override Content. Replaces '{Content}' in Instruct Prompt", value="")
            override_instruct_prompt = st.text_area("Override Instruct Prompt", value=override_instruct_prompt_default)
            override_system_prompt = st.text_area("Override System Prompt", value=override_system_prompt_default)

            enable_images = None if enable_images == 'Default' else enable_images
            enable_text = None if enable_text == 'Default' else enable_text
            override_content = override_content or None
            override_instruct_prompt = override_instruct_prompt or None
            override_system_prompt = override_system_prompt or None

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_helpers.py - Chunk 10
config["LLMConfig"]["LLMFeatureOverrides"] = {
                "EnableImages": enable_images,
                "EnableText": enable_text,
                "OverrideOcrTextContent": override_content,
                "OverrideInstructPrompt": override_instruct_prompt,
                "OverrideSystemPrompt": override_system_prompt
            }

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_helpers.py - Chunk 11
# LLM Parameter Configuration Section
        with st.expander("LLM Parameter Configuration"):
            temperature = st.text_input("Temperature", value=str(temperature_default) if temperature_default is not None else "")
            seed_value = random.randint(-2 ** 31, 2 ** 31 - 1) if seed_default == 'random' else seed_default
            seed = st.text_input("Seed", value=int(seed_value) if seed_value is not None else 42)
            max_tokens = st.text_input("Max Tokens", value=str(max_tokens_default) if max_tokens_default is not None else "")
            top_p = st.text_input("Top P", value=str(top_p_default) if top_p_default is not None else "")
            frequency_penalty = st.text_input("Frequency Penalty", value=str(frequency_penalty_default) if frequency_penalty_default is not None else "")
            presence_penalty = st.text_input("Presence Penalty", value=str(presence_penalty_default) if presence_penalty_default is not None else "")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_helpers.py - Chunk 12
config["LLMConfig"]["LLMParameterConfig"] = {
                "Temperature": float(temperature) if temperature else None,
                "Seed": int(seed) if seed else None,
                "MaxTokens": int(max_tokens) if max_tokens else None,
                "TopP": float(top_p) if top_p else None,
                "FrequencyPenalty": float(frequency_penalty) if frequency_penalty else None,
                "PresencePenality": float(presence_penalty) if presence_penalty else None
            }

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_helpers.py - Chunk 13
# OCR Configuration Section
        with st.expander("OCR Configuration"):
            ocr_engine = st.selectbox("Select OCR Engine", ["Default", "AzureRead", "Nuance"],
                                      index=["Default", "AzureRead", "Nuance"].index(ocr_engine_default))
            is_return_with_images = st.selectbox("Return with Images", ["Default", True, False],
                                                 index=["Default", True, False].index(is_return_with_images_default))
            max_pages = st.text_input("Max Pages", value=str(max_pages_default) if max_pages_default is not None else "")
            as_plain_text = st.selectbox("As Plain Text", ["Default", True, False],
                                         index=["Default", True, False].index(as_plain_text_default))
            as_plain_text_per_page = st.selectbox("As Plain Text Per Page", ["Default", True, False],

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_helpers.py - Chunk 14
as_plain_text_per_page = st.selectbox("As Plain Text Per Page", ["Default", True, False],
                                                  index=["Default", True, False].index(as_plain_text_per_page_default))

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_helpers.py - Chunk 15
config["OcrConfig"] = {
                "OcrEngine": ocr_engine if ocr_engine != 'Default' else None,
                "IsReturnWithImages": None if is_return_with_images == 'Default' else is_return_with_images,
                "MaxPages": int(max_pages) if max_pages.strip() else None,
                "AsPlainText": None if as_plain_text == 'Default' else as_plain_text,
                "AsPlainTextPerPage": None if as_plain_text_per_page == 'Default' else as_plain_text_per_page
            }

        st.subheader("Operation Data")
        customer_role = st.selectbox("Select Operation Data", ["Default", "True", "False"])
        if customer_role == "True":
            config["PropertyStore"] = {"OperationData.All": "true"}

        return url, config, customer_name, customer_role

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_helpers.py - Chunk 16
return url, config, customer_name, customer_role



# @st.cache_data(show_spinner=False)
def predict(file_path, config, workflow_endpoint, customer_name, customer_role):
    headers = {
        'X-ApiKey': 'YOUR_API_KEY',
        'X-CustomerName': customer_name,
        'X-Role': customer_role,
        'User-Agent': 'Bludelta AI Workflow Service Client',
        # Content-Type will be set by MultipartEncoder
    }

    def clean_config(d):
        if isinstance(d, dict):
            return {k: clean_config(v) for k, v in d.items() if v is not None}
        else:
            return d

    cleaned_config = clean_config(config)
    payload = json.dumps(cleaned_config)

    # Prepare the fields for the multipart request
    fields = {
        'json': ('json_data', payload, 'application/json'),  # JSON part
    }

    # If there is a file, add the file field
    if file_path:
        file_name = os.path.basename(file_path)
        print(f"Processing file {file_name}")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_helpers.py - Chunk 17
# If there is a file, add the file field
    if file_path:
        file_name = os.path.basename(file_path)
        print(f"Processing file {file_name}")

        with open(file_path, 'rb') as file:
            fields['files'] = (file_name, file, 'application/octet-stream')

            m = requests_toolbelt.MultipartEncoder(fields=fields)
            headers['Content-Type'] = m.content_type  # Set Content-Type to multipart/form-data

            response = requests.post(workflow_endpoint, data=m, headers=headers)
    else:
        print("Processing without file")

        # Create MultipartEncoder without the file field
        m = requests_toolbelt.MultipartEncoder(fields=fields)
        headers['Content-Type'] = m.content_type  # Set Content-Type to multipart/form-data

        response = requests.post(workflow_endpoint, data=m, headers=headers)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_helpers.py - Chunk 18
response = requests.post(workflow_endpoint, data=m, headers=headers)

    if response.status_code == 200:
        print("Successfully processed request")
        return response.json(), headers
    else:
        print(f"Failed to process request. Status code: {response.status_code}")
        return None, headers

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_workflow_feature.py - Chunk 0
import os
import streamlit as st

import tempfile
import json
import re
import pandas as pd
from PIL import Image
import shutil
import zipfile
from io import BytesIO
from llm_helpers import predict, create_llm_sidebar

TEMP_DIR = 'tmp'
ALLOWED_FILE_TYPES = ['pdf', 'png', 'jpg', 'jpeg', 'tiff', 'ps1']


def llm_workflow_feature():
    url, api_config, customer_name, customer_role = create_llm_sidebar()

    # Upload a document or a ZIP file
    document_file = st.file_uploader('Upload a document or ZIP file.',
                                     type=['pdf', 'png', 'jpg', 'jpeg', 'tiff', 'ps1', 'zip'])

    # Add a Send button
    send_button = st.button("Send")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_workflow_feature.py - Chunk 1
# Add a Send button
    send_button = st.button("Send")

    try:
        if send_button:
            if document_file is not None:
                if document_file.name.endswith(".zip"):
                    # Handle ZIP file upload
                    handle_zip_file(document_file, api_config, url, customer_name, customer_role)
                else:
                    # Handle single file upload
                    handle_single_file(document_file, api_config, url, customer_name, customer_role)
            else:
                # Handle request without file
                handle_request_without_file(api_config, url, customer_name, customer_role)

    except Exception as e:
        st.write(f"Error: {e}")
        print(f"Error:{e.__traceback__}\n{e}")

    cleanup_temp_dir(TEMP_DIR)


def handle_request_without_file(api_config, url, customer_name, customer_role):
    # Since no file is uploaded, set file_path to None
    file_path = None

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_workflow_feature.py - Chunk 2
cleanup_temp_dir(TEMP_DIR)


def handle_request_without_file(api_config, url, customer_name, customer_role):
    # Since no file is uploaded, set file_path to None
    file_path = None

    output, headers = predict(file_path, api_config, url, customer_name, customer_role)
    display_processed_output(output, None, headers, api_config)


def handle_single_file(document_file, api_config, url, customer_name, customer_role):
    # Process a single file (existing functionality)
    file_path = os.path.join(TEMP_DIR, document_file.name)

    # Must write the file temporarily to disk
    with open(file_path, "wb") as f:
        f.write(document_file.getbuffer())

    output, headers = predict(file_path, api_config, url, customer_name, customer_role)
    display_processed_output(output, document_file, headers, api_config)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_workflow_feature.py - Chunk 3
output, headers = predict(file_path, api_config, url, customer_name, customer_role)
    display_processed_output(output, document_file, headers, api_config)


@st.cache_data
def process_zip_file(zip_file_content, api_config, url, customer_name, customer_role):
    # Use BytesIO to read the zip file
    with zipfile.ZipFile(BytesIO(zip_file_content), 'r') as zip_ref:
        # Process files as before
        # Instead of extracting files to disk, we can process files in memory
        valid_files = [file for file in zip_ref.namelist() if file.split('.')[-1].lower() in ALLOWED_FILE_TYPES]

        total_files = len(valid_files)
        processed_json_files = []
        progress_bar = st.progress(0)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_workflow_feature.py - Chunk 4
total_files = len(valid_files)
        processed_json_files = []
        progress_bar = st.progress(0)

        # Process files and update progress
        for i, file_name in enumerate(valid_files, start=1):
            with zip_ref.open(file_name) as file:
                file_bytes = file.read()
                # Process file_bytes
                # Save to temp file if necessary
                with tempfile.NamedTemporaryFile(delete=False) as temp_file:
                    temp_file.write(file_bytes)
                    temp_file.flush()
                    temp_file_path = temp_file.name

                output, headers = predict(temp_file_path, api_config, url, customer_name, customer_role)

                # Remove temp file
                os.unlink(temp_file_path)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_workflow_feature.py - Chunk 5
output, headers = predict(temp_file_path, api_config, url, customer_name, customer_role)

                # Remove temp file
                os.unlink(temp_file_path)

                if output:
                    pretty_json, _ = process_output(output)
                    json_filename = f"{os.path.splitext(os.path.basename(file_name))[0]}.json"
                    processed_json_files.append((json_filename, pretty_json.encode('utf-8')))

            # Update progress
            progress_bar.progress(i / total_files)

    # Create ZIP of processed JSON files in memory
    result_zip_buffer = BytesIO()
    with zipfile.ZipFile(result_zip_buffer, 'w') as zipf:
        for json_filename, json_data in processed_json_files:
            zipf.writestr(json_filename, json_data)
    result_zip_buffer.seek(0)
    return result_zip_buffer

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_workflow_feature.py - Chunk 6
def process_output(predict_output):
    if 'LlmOutput' in predict_output:
        llm_output = predict_output['LlmOutput']
        # Clean up the output
        llm_output = llm_output.replace('\n', '').replace('```json', '').replace('```', '')
        json_data = json.loads(llm_output)
    elif isinstance(predict_output, dict) or isinstance(predict_output, list):
        json_data = predict_output
    else:
        json_match = re.search(r'\{.*\}', predict_output, re.DOTALL)
        json_str = json_match.group()
        json_data = json.loads(json_str)

    pretty_json = json.dumps(json_data, indent=4, ensure_ascii=False)
    return pretty_json, json_data


def handle_zip_file(zip_file, additional_properties, url, customer_name, customer_role):
    # Read zip file content
    zip_file_content = zip_file.getbuffer().tobytes()

    # Call the cached processing function
    result_zip_buffer = process_zip_file(zip_file_content, additional_properties, url, customer_name, customer_role)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_workflow_feature.py - Chunk 7
# Call the cached processing function
    result_zip_buffer = process_zip_file(zip_file_content, additional_properties, url, customer_name, customer_role)

    # Provide download button for the ZIP containing results
    st.download_button(
        label="Download Processed Results ZIP",
        data=result_zip_buffer,
        file_name="processed_results.zip",
        mime="application/zip"
    )


def display_processed_output(output, document_file, headers, additional_properties):
    # Create tabs for the default view, sent request, and received response
    tab1, tab3, tab4 = st.tabs(["Processed Output", "ðŸ“¤ Sent Request", "ðŸ“¥ Received Response"])
    col1, col2 = st.columns([1, 1])

    with tab1:
        if output:
            try:
                with col1:
                    pretty_json, json_data = process_output(output)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_workflow_feature.py - Chunk 8
with tab1:
        if output:
            try:
                with col1:
                    pretty_json, json_data = process_output(output)

                    # Provide a download button for the pretty JSON
                    st.download_button(
                        label="Download JSON",
                        data=pretty_json,
                        file_name=f"{document_file.name if document_file else 'response'}.json",
                        mime="application/json"
                    )

                    try:
                        # Flatten the JSON structure
                        flattened_json = flatten_json(json_data)
                        df = pd.DataFrame(flattened_json.items(), columns=['Key', 'Value'])
                        st.write("### Flattened JSON Table")
                        st.write(df.to_markdown(index=False))
                    except Exception as e:
                        st.write(f"Error Creating Result Table: {e}")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_workflow_feature.py - Chunk 9
# Pretty print the response JSON
                    st.write("### JSON Result")
                    st.markdown(f'```json\n{pretty_json}\n```')

                with col2:
                    if document_file and document_file.type.startswith('image/'):
                        st.write("### Uploaded Image")
                        image = Image.open(document_file)
                        st.image(image, use_column_width=True)
                    # todo render pdf
                    else:
                        st.write("### Uploaded Document")
                        st.write(f"Cannot display document preview: {document_file.name}, {document_file.type}")

            except Exception as e:
                st.write(f"Error: {e}")
        else:
            st.write('No Output fetched, please try again.')

    with tab3:
        st.write("### Sent Request Data")
        st.json(headers)
        st.json(additional_properties)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_workflow_feature.py - Chunk 10
with tab3:
        st.write("### Sent Request Data")
        st.json(headers)
        st.json(additional_properties)

    with tab4:
        st.write("### Raw Response Data")
        st.write(output)  # Display the raw received response


def flatten_json(nested_json, parent_key='', sep='.'):
    """
    Recursively flattens a nested JSON object.

    Parameters:
    nested_json (dict): The JSON object to flatten
    parent_key (str): The base key string for the nested keys
    sep (str): Separator to use between keys

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_workflow_feature.py - Chunk 11
Returns:
    dict: Flattened JSON
    """
    items = []
    if isinstance(nested_json, dict):
        for k, v in nested_json.items():
            if k == "DocumentTexts" or k == "DocumentBinaries":
                continue
            new_key = f'{parent_key}{sep}{k}' if parent_key else k
            if isinstance(v, dict):
                items.extend(flatten_json(v, new_key, sep=sep).items())
            elif isinstance(v, list):
                for i, item in enumerate(v):
                    items.extend(flatten_json(item, f'{new_key}[{i}]', sep=sep).items())
            else:
                items.append((new_key, v))
    elif isinstance(nested_json, list):
        for i, item in enumerate(nested_json):
            items.extend(flatten_json(item, f'{parent_key}[{i}]', sep=sep).items())
    else:
        items.append((parent_key, nested_json))
    return dict(items)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llm_workflow_feature.py - Chunk 12
def cleanup_temp_dir(temp_dir):
    """
    Cleans up the specified temp directory after processing is complete.
    """
    if os.path.exists(temp_dir):
        shutil.rmtree(temp_dir)
    os.makedirs(temp_dir)
    st.write(f"Temp directory {temp_dir} cleaned up.")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\ocr_feature.py - Chunk 0
import os
from typing import List
import pandas as pd
import streamlit as st
import httpx
import streamlit as st
import json
from PIL import Image, ImageDraw
import io
from pdf2image import convert_from_bytes
from utils import draw_bounding_boxes_on_image, draw_bounding_boxes_on_pdf, process_document_binaries, extract_locations_from_json

ocr_colors = {
    "AzureRead": "red",
    "NuanceOCR": "blue"
}


def create_sidebar():
    with st.sidebar:
        st.title("OCR Feature")

        # select between AzureRead and NuanceOCR
        ocr_engine = st.selectbox("Select OCR Engine:", ("AzureRead", "NuanceOCR", "Both"))

        predefined_urls = [
            "http://52.236.159.89/workflow-server",
            "http://localhost:8080"
        ]

        # Display a text input field for the URL
        selected_url_index = st.selectbox("Select URL", [(url, idx) for idx, url in enumerate(predefined_urls)], format_func=lambda x: x[0])

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\ocr_feature.py - Chunk 1
# Display a text input field for the URL
        selected_url_index = st.selectbox("Select URL", [(url, idx) for idx, url in enumerate(predefined_urls)], format_func=lambda x: x[0])

        # Retrieve the selected URL
        selected_url = selected_url_index[0]

        # Allow users to edit the URL directly
        edited_url = st.text_input("Edit URL (Final URL)", selected_url)

        # If the edited URL is different from the selected URL, update it
        if edited_url != selected_url:
            selected_url = edited_url


        # show ocr colors in form of a legend with colored rectangles
        st.markdown("__OCR Engine Colors:__")
        for engine, color in ocr_colors.items():
            st.markdown(f"<span style='color:{color}'>â– </span> {engine}", unsafe_allow_html=True)
        return ocr_engine, selected_url

def ocr_feature():
    ocr_engine, selected_url = create_sidebar()

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\ocr_feature.py - Chunk 2
def ocr_feature():
    ocr_engine, selected_url = create_sidebar()

    # Display a file uploader widget
    uploaded_file = st.file_uploader("Choose a document (pdf/png)", type=["pdf", "png", "jpg", "jpeg"])

    tab1, tab2, tab3 = st.tabs(["OCR Json", "OCR BBox Table", "Document with Bounding Boxes"])

    if uploaded_file:
        files = {"file": uploaded_file.getvalue()}

        # read APIKey from env variable, check if it exists
        apiKey = get_api_key()

        # Define the URL and headers        
        urls, colors = create_urls(selected_url, ocr_engine)

        ocr_results = [send_request(url, apiKey, files) for url in urls]

        bounding_boxes = [extract_bounding_boxes(data) for data in ocr_results]

        # display ocr_results in json format
        with tab1:
            dispay_ocr_results(urls, ocr_results)
            pass

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\ocr_feature.py - Chunk 3
# display ocr_results in json format
        with tab1:
            dispay_ocr_results(urls, ocr_results)
            pass

        with tab2:
            # create two columns for each ocr engine
            col1, col2 = st.columns(2)
            for i, bboxes in enumerate(bounding_boxes):
                table_markdown = render_bbox_table(bboxes)
                if i == 0:
                    col1.title("AzureRead")
                    col1.markdown(table_markdown)
                else:
                    col2.title("NuanceOCR")
                    col2.markdown(table_markdown)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\ocr_feature.py - Chunk 4
with tab3:        
            if uploaded_file.type == "image/png" or uploaded_file.type == "image/jpeg" or uploaded_file.type == "image/jpg":
                results = create_result_images_from_image(ocr_results, bounding_boxes, colors, uploaded_file)
                if len(results) == 1:
                    image = results[0][0]
                    st.image(image, caption="Document with Bounding Boxes", use_column_width=False)
                else:
                    col1, col2 = st.columns(2)
                    image1 = results[0][0]
                    image2 = results[1][0]

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\ocr_feature.py - Chunk 5
# resize the images to fit the column width
                    image1 = image1.resize((int(image1.width/2), int(image1.height/2)))
                    image2 = image2.resize((int(image2.width/2), int(image2.height/2)))
                    
                    col1.image(image1, caption="Document with Bounding Boxes", use_column_width=False)
                    col2.image(image2, caption="Document with Bounding Boxes", use_column_width=False)
     
            elif uploaded_file.type == "application/pdf":
                with st.expander("PDF with Bounding Boxes", expanded=True):
                    for i, ocr_result in enumerate(ocr_results):
                        # If ocr images are included in the response
                        pages = process_document_binaries(ocr_result)
                        # else take the uploaded pdf
                        if len(pages) == 0:
                            # check if there are pages and if Dpi is set

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\ocr_feature.py - Chunk 6
# else take the uploaded pdf
                        if len(pages) == 0:
                            # check if there are pages and if Dpi is set
                            if 'Pages' not in ocr_results[0] or 'Dpi' not in ocr_results[0]['Pages'][0]:
                                st.error("No pages or Dpi found in JSON response")
                                return
                            pages = convert_from_bytes(uploaded_file.getvalue(), dpi=ocr_results[0]['Pages'][0]['Dpi'])
                        
                        for j, page in enumerate(pages):
                            color = colors[i]
                            page = draw_bounding_boxes_on_image(page, bounding_boxes=bounding_boxes[i], color=color, page=j+1)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\ocr_feature.py - Chunk 7
#resize the image with bounding boxes
                            #page_with_boxes = page_with_boxes.resize((int(page_with_boxes.width/2), int(page_with_boxes.height/2)))
                            st.image(page, caption=f"Page {j+1} with Bounding Boxes", use_column_width=False)

                        st.markdown("---")
                        st.markdown("---")

def get_api_key():
    if 'APIKEY' not in os.environ:
        #st.error("APIKEY not found in environment variables")
        return ""
    return os.environ['APIKEY']

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\ocr_feature.py - Chunk 8
def get_api_key():
    if 'APIKEY' not in os.environ:
        #st.error("APIKEY not found in environment variables")
        return ""
    return os.environ['APIKEY']

def create_urls(base_url, ocr_engine) -> List:
    urls = []
    colors = {}
    if ocr_engine == "AzureRead":
        urls.append(f"{base_url}/meta-ocr")
        colors[0] = ocr_colors["AzureRead"]
    elif ocr_engine == "NuanceOCR":
        urls.append(f"{base_url}/ocr")
        colors[0] = ocr_colors["NuanceOCR"]
    elif ocr_engine == "Both":
        urls.append(f"{base_url}/meta-ocr")
        urls.append(f"{base_url}/ocr")
        colors[0] = ocr_colors["AzureRead"]
        colors[1] = ocr_colors["NuanceOCR"]

    return urls, colors

def send_request(url, apiKey, files):
    headers = {
        "X-ApiKey": apiKey,
        "User-Agent": "Bludelta Workflow Client"
    }

    response = httpx.post(url, headers=headers, files=files, timeout=120)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\ocr_feature.py - Chunk 9
response = httpx.post(url, headers=headers, files=files, timeout=120)

    if response.status_code != 200:
        st.error(f"Error: {response.status_code}")
        return {}
    return response.json()

# # Function to extract bounding boxes for all words
def extract_bounding_boxes(data):    
    """
    Parses the following JSON structure to extract bounding boxes for all words:

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\ocr_feature.py - Chunk 10
# # Function to extract bounding boxes for all words
def extract_bounding_boxes(data):    
    """
    Parses the following JSON structure to extract bounding boxes for all words:

      "DocumentTexts": [
    {
      "Line": {
        "Location": {
          "Height": 42,
          "Left": 167,
          "Page": 1,
          "Top": 60,
          "Width": 356
        },
        "Text": "Parkhaus Richthalle",
        "Words": [
          {
            "Location": {
              "Height": 42,
              "Left": 167,
              "Page": 1,
              "Top": 60,
              "Width": 151
            },
            "Text": "Parkhaus"
          },
          {
            "Location": {
              "Height": 37,
              "Left": 337,
              "Page": 1,
              "Top": 65,
              "Width": 186
            },
            "Text": "Richthalle"
          }
        ]
    
    """

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\ocr_feature.py - Chunk 11
bounding_boxes = []
    lines = data["DocumentTexts"]
    for line in lines:
        words = line['Line']['Words']
        for word in words:
            location = word['Location']
            bounding_boxes.append({
                "Text": word['Text'],
                "BoundingBox": {
                    "x": location['Left'],
                    "y": location['Top'],
                    "width": location['Width'],
                    "height": location['Height'],
                    "page": location['Page']
                }
            })
        
    return bounding_boxes

def get_plain_text(data):
    plain_text = ""
    for line in data["DocumentTexts"]:
        plain_text += line["Line"]["Text"] + "\n"
    return plain_text

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\ocr_feature.py - Chunk 12
def get_plain_text(data):
    plain_text = ""
    for line in data["DocumentTexts"]:
        plain_text += line["Line"]["Text"] + "\n"
    return plain_text

def extract_bounding_boxes_old_format(data):    
    bounding_boxes = []
    for region in data.get("Regions", []):
        for line in region.get("Lines", []):
            for word in line.get("Words", []):
                bbox = word.get("BoundingBox", {})
                bounding_boxes.append({
                    "Text": word.get("Text", ""),
                    "BoundingBox": {
                        "Left": bbox.get("Left"),
                        "Top": bbox.get("Top"),
                        "Width": bbox.get("Width"),
                        "Height": bbox.get("Height")
                    }
                })
    return bounding_boxes

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\ocr_feature.py - Chunk 13
def dispay_ocr_results(urls, ocr_results):
    for url, result in zip(urls, ocr_results):
        st.write(f"URL: {url}")
        #st.json(result)
        # write json into a markdown code block
        st.code(json.dumps(result, indent=4))

def render_bbox_table(bounding_boxes):
    # create a markdown table with bounding boxes for each ocr engine
    # there shall be a table row for bounding box of each word and it shall contain
    # the word, x, y, width, height, page, ocr engine
    # | Word | x | y | width | height | page | OCR Engine |
    table_markdown = \
"""
__Bounding Box Table__

| Word | x   | y   | width | height | page |
| ---  | --- | --- | ---   | ---    | ---  |
"""

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\ocr_feature.py - Chunk 14
| Word | x   | y   | width | height | page |
| ---  | --- | --- | ---   | ---    | ---  |
"""

            # Append each row to the markdown string
    for bbox in bounding_boxes:
        x, y, width, height = bbox['BoundingBox']['x'], bbox['BoundingBox']['y'], bbox['BoundingBox']['width'], bbox['BoundingBox']['height']
        page = bbox['BoundingBox']['page']
        text = bbox['Text']
        table_markdown += f"| {text} | {x} | {y} | {width} | {height} | {page} |\n"

    return table_markdown
   
def create_result_images_from_image(ocr_results, bounding_boxes, colors, uploaded_file):
    results = []
    assert len(ocr_results) == len(bounding_boxes), "Length of ocr_results, bounding_boxes should be the same"

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\ocr_feature.py - Chunk 15
for i in range(len(ocr_results)):
        images = process_document_binaries(ocr_results[i])
        if len(images) == 1:
            image = images[0]
        else:
            image = Image.open(uploaded_file)
        
        color = colors[i]
        image = draw_bounding_boxes_on_image(image, bounding_boxes[i], color=color)
        results.append((image, color))

    return results

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\package_upload_feature.py - Chunk 0
import sys
import streamlit as st
import requests
import pyodbc
import pandas as pd
import json

def get_bcsdb_connection(database, username, password):
    if sys.platform == 'linux':
        driver_name = 'ODBC Driver 17 for SQL Server'
    elif sys.platform == 'win32':
        driver_name = 'SQL Server'
        
    if database == "bcsdbdev":
        conn = pyodbc.connect(f"DRIVER={{{driver_name}}};SERVER=bcdbserverdev.database.windows.net;DATABASE=bcsdbdev;UID={username};PWD={password};")
    elif database == "bcsdb-auth":
        conn = pyodbc.connect(f"DRIVER={{{driver_name}}};SERVER=bcdbserver.database.windows.net;DATABASE=bcsdb-auth;UID={username};PWD={password};")

    return conn    

def get_customer_names(conn):
        # Execute the SELECT statement
        query = """
            SELECT [Name]
            FROM dbo.Customer
        """
        df = pd.read_sql(query, conn)
        return df["Name"].tolist()

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\package_upload_feature.py - Chunk 1
def package_upload():
    conn = get_bcsdb_connection("bcsdbdev", "dbadmin", "!user_123")
    if conn == None:
        return


    st.title("Bludelta Learn API - Package Upload")

    st.markdown("""
    ### Upload a package of documents with ground truth into Bludelta's training pipeline
    """)

    # Input field for the URL with default value
    url = st.text_input("Enter the API URL:", "https://learn.bludelta.ai/v1/Package", key="package-upload-url")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\package_upload_feature.py - Chunk 2
# Columns for ApiKey, ApiIdentifier, and Document Type
    col1, col2, col3 = st.columns(3)
    api_key = col1.text_input("X-ApiKey:", key="package-upload-api-key")
    api_identifier = col2.text_input("X-ApiIdentifier (optional):", key="package-upload-api-identifier")
    document_type = col3.selectbox(
        "Document Type", 
        options=["", "DeliveryNote", "Notice", "VehicleRegistration", "Order", "CertificateOfOrigin", "CustomsDutyReceipt", 
                 "DangerousGoodsNote", "TransitNoteT1", "TransitNoteT2", "ProformaInvoice", "ExportAccompanyingDocument", 
                 "DeliveryNoteCustoms", "DeliveryNoteTransit", "OrderConfirmation", "Quotation"],
        key="package-upload-document-type")
    
    customers = get_customer_names(conn)
    customer = st.selectbox("Customer (optional; DEPRECATED?)", options=customers, key="package-upload-customer")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\package_upload_feature.py - Chunk 3
tags = st.text_input("Tags (optional) comma separated such as JP, #22454:", key="package-upload-tags")
    ocr_engine = st.selectbox("OCR Engine (optional)", options=["", "AzureReadOcr"], key="package-upload-ocr-engine") #Easy OCR could be added here

    #"""
    property_store = {"OCREngine": ocr_engine} #, "Language": "" could be added.
    json_data = json.dumps(property_store)
    json_file = (None, json_data, 'application/json')
    #"""

    uploaded_package = st.file_uploader("Upload Package (ZIP file):", type=["zip", "application/x-zip-compressed"])

    # Button to trigger the upload
    if st.button("Upload Package"):
        # Check if all required fields are filled
        if not api_key or not uploaded_package or not url:
            st.error("Please fill in all required fields.")
            return

        # Headers including the authentication keys
        headers = {
            "X-ApiKey": api_key,
            "X-ApiIdentifier": api_identifier,
        }

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\package_upload_feature.py - Chunk 4
# Headers including the authentication keys
        headers = {
            "X-ApiKey": api_key,
            "X-ApiIdentifier": api_identifier,
        }

        # Multipart/form-data payload
        if ocr_engine is not None:
            files = {
                "DocumentType": (None, document_type),
                "Package": uploaded_package,
                #"CompanyName" : (None, customer),
                "Tags":(None, tags),
                "PropertyStore": json_file
            }
        else:
            files = {
                "DocumentType": (None, document_type),
                "Package": uploaded_package,
                #"CompanyName" : (None, customer),
                "Tags":(None, tags),
                #"PropertyStore": json_file
            }

        # Making the POST request
        response = requests.post(url, headers=headers, files=files)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\package_upload_feature.py - Chunk 5
# Making the POST request
        response = requests.post(url, headers=headers, files=files)

        # Handling the response
        if response.status_code == 200:
            try:
                # Ensure the response is valid JSON before accessing it
                package_id = response.json().get("packageId")
                st.success(f"Package uploaded successfully! Package ID: {package_id}")
            except ValueError:
                st.error("Received an invalid JSON response from the server.")
        else:
            try:
                # Ensure the error response is valid JSON
                error_details = response.json()
                st.error(f"Error uploading package:\nStatus: {error_details.get('status')}\nDetail: {error_details.get('detail')}")
            except ValueError:
                # Fallback if the error response is not JSON
                st.error(f"Error uploading package:\nStatus: {response.status_code}\nResponse: {response.text}")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\plugin_info_feature.py - Chunk 0
import requests
import streamlit as st
import json

def plugin_info_feature():
    st.title("System or Plugin Info")

    # Configurable URL input
    # a selection box for the user to choose a URL
    url = st.selectbox("Select a URL to fetch system or plugin info:",
                       ("https://api.bludelta.ai/v1-18/plugin/info?format=json",
                        "https://api.bludelta.ai/v1-18/system/info?format=json"))

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\plugin_info_feature.py - Chunk 1
#url = st.text_input("Enter the URL to fetch plugin info:", "https://api.bludelta.ai/v1-18/plugin/info?format=json")
    xapi_key = st.text_input("Enter the X-API-Key:", "")
    if st.button("Fetch Plugin Info"):
        try:
            headers = {'X-ApiKey': xapi_key}
            response = requests.get(url, headers=headers)
            response.raise_for_status()  # Raise an exception for HTTP errors
            plugin_data = response.json()
            st.json(plugin_data)
        except requests.RequestException as e:
            st.error(f"Error fetching data from {url}: {e}")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\utils.py - Chunk 0
import hashlib
import secrets
import base64
import pyodbc
import io
from PIL import Image, ImageDraw, ExifTags

def get_api_key():
    random_bytes = secrets.token_bytes(1024)
    sha512_hash = hashlib.sha512(random_bytes).digest()
    return base64.b64encode(sha512_hash).decode()

def get_api_identifier():
    random_bytes = secrets.token_bytes(1024)
    md5_hash = hashlib.md5(random_bytes).digest()
    return base64.b64encode(md5_hash).decode()

def draw_bounding_boxes_on_image(image, bounding_boxes, color='red', width=1, page:int=None):
    """
    Draw bounding boxes on the image using the provided bounding box data.
    """
    draw = ImageDraw.Draw(image)
    for box in bounding_boxes:
        if 'BoundingBox' in box:
            box = box['BoundingBox']
        x, y, width, height, page_ = box['x'], box['y'], box['width'], box['height'], box['page']

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\utils.py - Chunk 1
# Only draw if the box is on the specified page
        if page is not None and page == page_:
            print(f"Drawing bounding box on page {page} == {page_}")                    
            draw.rectangle([x, y, x+width, y+height], outline=color, width=1)
        elif page is None:
            draw.rectangle([x, y, x+width, y+height], outline=color, width=1)
    return image

def draw_bounding_boxes_on_pdf(pages, bounding_boxes_data):
    """
    Draw bounding boxes on each page of the PDF using the provided bounding box data.
    """
    # Group bounding boxes by page
    grouped_bboxes = {}
    for bbox_data in bounding_boxes_data:
        page = bbox_data.get("Pages")
        if page not in grouped_bboxes:
            grouped_bboxes[page] = []
        grouped_bboxes[page].append(bbox_data)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\utils.py - Chunk 2
# Draw bounding boxes on respective pages
    pages_with_boxes = []
    for i, page in enumerate(pages):
        # Only draw if there are bounding boxes for this page
        if i+1 in grouped_bboxes: 
            for box in grouped_bboxes[i+1]:
                x, y, width, height = box['Left'], box['Top'], box['Width'], box['Height']
                draw = ImageDraw.Draw(page)
                draw.rectangle([x, y, x+width, y+height], outline='red', width=2)
        pages_with_boxes.append(page)
    
    return pages_with_boxes

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\utils.py - Chunk 3
def extract_locations_from_json(data):
    """
    Recursively search for all "Location" keys in the JSON tree and return their values.
    """
    locations = []
    if isinstance(data, dict):
        for key, value in data.items():
            if key == "Location":
                locations.append(value)
            elif key == "DocumentTexts":
                continue
            else:
                locations.extend(extract_locations_from_json(value))
    elif isinstance(data, list):
        for item in data:
            locations.extend(extract_locations_from_json(item))
    return locations

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\utils.py - Chunk 4
def process_document_binaries(data):
    pages = []  # Initialize an empty list to store decoded images
    ocrImages = "OcrTransformed"  # The key to search for
    should_expand = True
    # Check if 'DocumentBinaries' exists in data
    if 'DocumentBinaries' in data:
        for item in data['DocumentBinaries']:
            if item['ContentType'] == ocrImages and 'Embedding' in item:
                embeddings = item['Embedding']
                for embedding in embeddings:
                    if isinstance(embedding, str):
                        decoded_image = base64.b64decode(embedding)
                        image = Image.open(io.BytesIO(decoded_image))

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\utils.py - Chunk 5
# Handle EXIF orientation tag
                        try:
                            for orientation in ExifTags.TAGS.keys():
                                if ExifTags.TAGS[orientation] == 'Orientation':
                                    break
                            
                            exif = image._getexif()
                            if exif is not None:
                                exif = dict(exif.items())
                                orientation = exif.get(orientation, 1)
                                
                                if orientation == 3:
                                    image = image.rotate(180, expand=should_expand)
                                elif orientation == 6:
                                    image = image.rotate(270, expand=should_expand)
                                elif orientation == 8:
                                    image = image.rotate(90, expand=should_expand)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\utils.py - Chunk 6
elif orientation == 8:
                                    image = image.rotate(90, expand=should_expand)
                        except (AttributeError, KeyError, IndexError):
                            # cases: image don't have getexif
                            pass

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\utils.py - Chunk 7
pages.append(image)                        

    return pages

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\workflow_feature.py - Chunk 0
import os
import json
import streamlit as st
import httpx
from PIL import Image, ImageDraw
import io
from pdf2image import convert_from_bytes
import base64
import requests
from requests_toolbelt.multipart.encoder import MultipartEncoder


def display_document_essential_details(json_data):
    # get all details from "DocumentEssentials" where a details has no items
    details = [item for item in json_data["DocumentEssentials"] if not item.get("Items")]

    # a details has the following structure:
    # {
    #   "Confidence":0.7882
    #   "ConfidenceThreshold":-1
    #   "Label":"Quotation.Date"
    #   "Location":{
#           "Height":30
    #       "Left":2070
    #       "Page":1
    #       "Top":1037
    #       "Width":192
    # }
    # "Text":"18.01.2022"
    # "Value":"2022-01-18"
    # }
    # take this structure and display it as markdown table

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\workflow_feature.py - Chunk 1
headers = ["Label", "Text", "Value", "Confidence", "ConfidenceThreshold"]
    markdown_table = "| " + " | ".join(headers) + " |\n" + "| " + " | ".join(["---"] * len(headers)) + " |\n"

    for detail in details:
        row = [str(detail.get(header, "N/A")) for header in headers]
        markdown_table += "| " + " | ".join(row) + " |\n"

    return markdown_table    

# Function to display all Line.Item data as a Markdown table
def display_all_line_items_as_table(json_data):
    # Extract all Line.Item entries
    line_items = [item for item in json_data["DocumentEssentials"] if item.get("Label") == "Line.Item"]
    
    if not line_items:
        st.markdown("No line items found.")
        return

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\workflow_feature.py - Chunk 2
# Assuming the structure of line items is consistent across all entries
    # Extract headers from the first line item assuming all line items have the same structure
    headers = [item["Label"].split('.')[0] for item in line_items[0]["Items"]]
    
    # Create Markdown table header
    markdown_table = "| " + " | ".join(headers) + " |\n" + "| " + " | ".join(["---"] * len(headers)) + " |\n"
    
    # Iterate through each Line.Item to add rows to the table
    for line_item in line_items:
        row = [item.get("Text", "N/A") if item.get("Text") else "N/A" for item in line_item["Items"]]
        markdown_table += "| " + " | ".join(row) + " |\n"
    
    # Display using Streamlit
    return markdown_table

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\workflow_feature.py - Chunk 3
# Function to display JSON data in Markdown format
def display_json_as_markdown(json_data):
    # Extracting and formatting basic information
    bludoc_version = json_data.get("BluDoc.Version", "")
    created_datetime = json_data.get("Created.DateTime", "")
    software_name = json_data.get("CreatorSoftware.Name", "")
    software_version = json_data.get("CreatorSoftware.Version", "")
    languages = ", ".join(json_data.get("Document.Languages", []))
    document_type = json_data.get("Document.Type", "")

    details = display_document_essential_details(json_data)
    line_item_table = display_all_line_items_as_table(json_data)
    #tables = display_document_essentials_tables(json_data)

    # Basic document information
    markdown_text = f"""
## Document Information

- **BluDoc Version**: {bludoc_version}
- **Created On**: {created_datetime}
- **Creator Software**: {software_name} v{software_version}
- **Languages**: {languages}
- **Document Type**: {document_type}

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\workflow_feature.py - Chunk 4
## Document Essentials

## Details
{details}

### Line Items
{line_item_table}
"""
    return markdown_text

def draw_bounding_boxes_on_image(image, bounding_boxes):
    """
    Draw bounding boxes on the image using the provided bounding box data.
    """
    draw = ImageDraw.Draw(image)
    for box in bounding_boxes:
        x, y, width, height = box['x'], box['y'], box['width'], box['height']
        draw.rectangle([x, y, x+width, y+height], outline='red', width=2)
    return image

def draw_bounding_boxes_on_pdf(pages, bounding_boxes_data):
    """
    Draw bounding boxes on each page of the PDF using the provided bounding box data.
    """
    # Group bounding boxes by page
    grouped_bboxes = {}
    for bbox_data in bounding_boxes_data:
        page = bbox_data["Page"]
        if page not in grouped_bboxes:
            grouped_bboxes[page] = []
        grouped_bboxes[page].append(bbox_data)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\workflow_feature.py - Chunk 5
# Draw bounding boxes on respective pages
    pages_with_boxes = []
    for i, page in enumerate(pages):
        # Only draw if there are bounding boxes for this page
        if i+1 in grouped_bboxes: 
            for box in grouped_bboxes[i+1]:
                x, y, width, height = box['Left'], box['Top'], box['Width'], box['Height']
                draw = ImageDraw.Draw(page)
                draw.rectangle([x, y, x+width, y+height], outline='red', width=2)
        pages_with_boxes.append(page)
    
    return pages_with_boxes

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\workflow_feature.py - Chunk 6
def extract_locations_from_json(data):
    """
    Recursively search for all "Location" keys in the JSON tree and return their values.
    """
    locations = []
    if isinstance(data, dict):
        for key, value in data.items():
            if key == "Location":
                locations.append(value)
            elif key == "DocumentTexts":
                continue
            else:
                locations.extend(extract_locations_from_json(value))
    elif isinstance(data, list):
        for item in data:
            locations.extend(extract_locations_from_json(item))
    return locations

def create_sidebar():
    with st.sidebar:
        st.title('Blu Delta Workflows')

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\workflow_feature.py - Chunk 7
def create_sidebar():
    with st.sidebar:
        st.title('Blu Delta Workflows')

        # List of predefined URLs to choose from
        predefined_urls = [
            "https://capture.bludelta.ai/quotation/v1/quotation",
            "https://capture.bludelta.ai/order-confirmation/v1/order-confirmation",
            "https://capture.bludelta.ai/receipt/v1/receipt",
            "https://capture-dev.bludelta.ai/quotation/v1/quotation",
            "https://capture-dev.bludelta.ai/order-confirmation/v1/order-confirmation",
            "https://capture-dev.bludelta.ai/receipt/v1/receipt",
            "http://localhost:80/quotation",
            "http://localhost:80/order-confirmation",
            "http://localhost:80/receipt"
        ]

        # Display a text input field for the URL
        selected_url_index = st.selectbox("Select URL", [(url, idx) for idx, url in enumerate(predefined_urls)], format_func=lambda x: x[0])

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\workflow_feature.py - Chunk 8
# Display a text input field for the URL
        selected_url_index = st.selectbox("Select URL", [(url, idx) for idx, url in enumerate(predefined_urls)], format_func=lambda x: x[0])

        # Retrieve the selected URL
        selected_url = selected_url_index[0]

        # Allow users to edit the URL directly
        edited_url = st.text_input("Edit URL (Final URL)", selected_url)

        # If the edited URL is different from the selected URL, update it
        if edited_url != selected_url:
            selected_url = edited_url

        timeout = st.text_input("Enter timeout [sec]", "120")
        # convert to int
        try:
            timeout = int(timeout)
        except ValueError:
            st.error("Timeout must be an integer")
            return

        return selected_url, timeout

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\workflow_feature.py - Chunk 9
return selected_url, timeout

def process_document_binaries(data):
    pages = []  # Initialize an empty list to store decoded images
    ocrImages = "OcrTransformed"  # The key to search for
    
    # Check if 'DocumentBinaries' exists in data
    if 'DocumentBinaries' in data:
        for item in data['DocumentBinaries']:
            if item['ContentType'] == ocrImages and 'Embedding' in item:
                embeddings = item['Embedding']
                for embedding in embeddings:
                    if isinstance(embedding, str):
                        decoded_image = base64.b64decode(embedding)
                        image = Image.open(io.BytesIO(decoded_image))
                        pages.append(image)
                # Once a matching entry is found and processed, break out of the loop
                break

    return pages

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\workflow_feature.py - Chunk 10
return pages

def add_property_store(property_store_str):
    """
    Convert the PropertyStore string into a dictionary.
    @param property_store_str: The PropertyStore string in the format 'key1:value1,key2:value2,...'
    """
    if property_store_str == "":
        return None

    property_store = dict(item.split(":") for item in property_store_str.split(",")) if property_store_str else {}
    json_data = {"PropertyStore": property_store}
    return json.dumps(json_data)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\workflow_feature.py - Chunk 11
property_store = dict(item.split(":") for item in property_store_str.split(",")) if property_store_str else {}
    json_data = {"PropertyStore": property_store}
    return json.dumps(json_data)

def add_customer_name_role_to_header(header, customer_name, customer_role):
    """
    Add the CustomerName and CustomerRole to the header.
    @param header: The header dictionary to which the CustomerName and CustomerRole will be added.
    @param customer_name: The customer name to be added.
    @param customer_role: The customer role to be added.
    """
    if customer_name:
        header["X-CustomerName"] = customer_name
    if customer_role:
        header["X-Role"] = customer_role
    return header

def document_bounding_boxes_feature():
    st.title("Blu Delta Workflows")

    url, timeout = create_sidebar()
    st.write("URL:", url)
    st.write("Timeout:", timeout)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\workflow_feature.py - Chunk 12
def document_bounding_boxes_feature():
    st.title("Blu Delta Workflows")

    url, timeout = create_sidebar()
    st.write("URL:", url)
    st.write("Timeout:", timeout)

    # add two columns. One for uploading the document and the other one for a list of additional properties which can be added one by one
    col1, col2 = st.columns([1, 1])

    with col1:
        # Upload the document
        uploaded_file = st.file_uploader("Choose a document (pdf/png,jpeg,jpg)", type=["pdf", "png", "jpeg", "jpg"])
    
    with col2:
        # Add PropertyStore input text field
        property_store_str = st.text_input("PropertyStore", value="OperationData.All:false")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\workflow_feature.py - Chunk 13
# Add CustomerName and CustomerRole input text fields in an expander
        with st.expander("Customer Details - only necessary when directly using BludeltaWorkflow"):
            customer_name = st.text_input("CustomerName", value="")
            customer_role = st.text_input("CustomerRole", value="")
        
    if uploaded_file:
        payload = add_property_store(property_store_str)

        # read APIKey from env variable, check if it exists
        if 'APIKEY' not in os.environ:
            st.error("APIKEY not found in environment variables")
            return
        apiKey = os.environ['APIKEY']
        
        # Define the URL and headers        
        url = url
        headers = {
            "X-ApiKey": apiKey,
            "User-Agent": "Bludelta Workflow Client"
        }

        headers = add_customer_name_role_to_header(headers, customer_name, customer_role)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\workflow_feature.py - Chunk 14
headers = add_customer_name_role_to_header(headers, customer_name, customer_role)

        # Make the POST request
        if payload is not None:
            m = MultipartEncoder(
                fields={
                    'json': ('json_data', payload, 'application/json'),  # JSON part with explicit content type
                    'files': ('file', uploaded_file.getvalue(), 'application/octet-stream')  # File part
                }
            )
        else:   
            m = MultipartEncoder(
                fields={
                    'files': ('file', uploaded_file.getvalue(), 'application/octet-stream')  # File part
                }
            )

        headers['Content-Type'] = m.content_type  # Setting the content type to multipart/form-data

        response = requests.post(f"{url}", data=m, headers=headers)        

        data = response.json()

        tab1, tab2, tab3 = st.tabs(["BluDoc Summary", "BluDoc Json Response", "Document with Bounding Boxes"])

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\workflow_feature.py - Chunk 15
data = response.json()

        tab1, tab2, tab3 = st.tabs(["BluDoc Summary", "BluDoc Json Response", "Document with Bounding Boxes"])

        # check if data has a key "Result"        
        bludoc_result = data["Result"] if "Result" in data else data

        # Extract all bounding box locations
        bounding_boxes = extract_locations_from_json(bludoc_result)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\workflow_feature.py - Chunk 16
with tab1:
            try:
                st.markdown(display_json_as_markdown(bludoc_result), unsafe_allow_html=True)
            except Exception as e:
                st.error(f"Error: {e}")
        with tab2:
            st.json(data)            
        with tab3:
            try:
                # Display the uploaded document with bounding boxes
                if uploaded_file.type == "image/png":
                    image = Image.open(uploaded_file)
                    image_with_boxes = draw_bounding_boxes_on_image(image, bounding_boxes)
                    st.image(image_with_boxes, caption="Document with Bounding Boxes", use_column_width=True)        
                elif uploaded_file.type == "application/pdf":
                    with st.expander("PDF with Bounding Boxes", expanded=True):
                        # If ocr images are included in the response
                        pages = process_document_binaries(bludoc_result)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\workflow_feature.py - Chunk 17
# If ocr images are included in the response
                        pages = process_document_binaries(bludoc_result)
                        # else take the uploaded pdf
                        if len(pages) == 0:
                            # check if there are pages and if Dpi is set
                            if 'Pages' not in bludoc_result or 'Dpi' not in bludoc_result['Pages'][0]:
                                st.error("No pages or Dpi found in JSON response")
                                return
                            pages = convert_from_bytes(uploaded_file.getvalue(), dpi=bludoc_result['Pages'][0]['Dpi'])
                        
                        pages_with_boxes = draw_bounding_boxes_on_pdf(pages, bounding_boxes)
                        for i, page_with_boxes in enumerate(pages_with_boxes):
                            st.image(page_with_boxes, caption=f"Page {i+1} with Bounding Boxes", use_column_width=True)

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\workflow_feature.py - Chunk 18
for i, page_with_boxes in enumerate(pages_with_boxes):
                            st.image(page_with_boxes, caption=f"Page {i+1} with Bounding Boxes", use_column_width=True)
            except Exception as e:
                st.error(f"Error: {e}")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llms\llm_llama2.py - Chunk 0
from typing import Any, List, Mapping, Optional
from langchain.callbacks.manager import CallbackManagerForLLMRun
from langchain.llms.base import LLM
from pydantic import Field
from text_generation import Client


class LLM_Llama2(LLM):
    """LLM for LLaMA2 chatbot"""
    llm_name = "llama2"
    llm_version = "0.1.0"
    llm_description = "LLaMA2 chatbot"
    url: str = Field("", description="Url of the LLaMA2 chatbot")
    timeout: int = Field(120, description="Timeout of the LLaMA2 chatbot")
    temperature: float = Field(0.1, description="Temperature of the LLaMA2 chatbot")
    top_p: float = Field(0.9, description="Top p of the LLaMA2 chatbot")

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llms\llm_llama2.py - Chunk 1
def __init__(self, url, timeout, temperature, top_p):
        super(LLM_Llama2, self).__init__()
        self.url = url
        self.timeout = timeout
        self.temperature  = temperature
        self.top_p = top_p
        
    @property
    def _llm_type(self) -> str:
        return self.llm_name
    
    @property
    def _identifying_params(self) -> dict:
        """
        It should return a dict that provides
        the information of all the parameters 
        that are used in the LLM. This is useful
        when we print our llm, it will give use the 
        information of all the parameters.
        """
        return {
            "url": self.url,
            "timeout": self.timeout,
            "temperature": self.temperature,
            "top_p": self.top_p,
        }
        
    def _call(
        self, 
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\llms\llm_llama2.py - Chunk 2
}
        
    def _call(
        self, 
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any
    ) -> str:
        """Generate text from prompt"""
        client = Client(self.url, timeout=self.timeout)
        return client.generate(
            prompt, 
            temperature=self.temperature, 
            top_p=self.top_p, 
            max_new_tokens=kwargs.get("max_new_tokens", 1024),
            return_full_text=True).generated_text

C:\Users\rudi\source\repos\Tools\Bennu\Service\app.py - Chunk 0
from flask import Flask, jsonify, send_from_directory, render_template
from flask_restful import Api, Resource
from flask_cors import CORS
from flasgger import Swagger, swag_from
from docker_compose_generator import DockerComposeGenerator

app = Flask(__name__, static_folder='static', static_url_path='/static')
CORS(app)
api = Api(app)

swagger_config = {
    "headers": [],
    "specs": [
        {
            "endpoint": "swagger",
            "route": "/swagger.json",
            "rule_filter": lambda rule: True,
            "model_filter": lambda tag: True,
        }
    ],
    "static_url_path": "/static",
    "swagger_ui": True,
    "specs_route": "/swagger/",
}

swagger = Swagger(app, config=swagger_config, template_file="swagger_docs/docker_compose.yml")

C:\Users\rudi\source\repos\Tools\Bennu\Service\app.py - Chunk 1
swagger = Swagger(app, config=swagger_config, template_file="swagger_docs/docker_compose.yml")

class DockerComposeResource(Resource):
    @swag_from("swagger_docs/docker_compose.yml")
    def get(self):
        generator = DockerComposeGenerator()
        updated_yaml = generator.update_docker_compose()
        return jsonify(updated_yaml)

api.add_resource(DockerComposeResource, '/bludelta/docker-compose')

REDOC_URL = '/redoc'
@app.route(REDOC_URL)
def redoc():
    return render_template('redoc.html')

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)

C:\Users\rudi\source\repos\Tools\Bennu\Service\docker_compose_generator.py - Chunk 0
import os
import configparser
import yaml
from azure.identity import ClientSecretCredential
from azure.mgmt.containerregistry import ContainerRegistryManagementClient
from azure.containerregistry import ContainerRegistryClient
import docker

class DockerComposeGenerator:
    def __init__(self):
        self.config = configparser.ConfigParser()
        self.config.read('config.ini')
        self.azure_config = self.config['azure']
        self.credentials = ClientSecretCredential(
            tenant_id=self.azure_config['tenant_id'],
            client_id=self.azure_config['client_id'],
            client_secret=self.azure_config['client_secret']
        )
        self.registry_client = ContainerRegistryManagementClient(
            self.credentials,
            self.azure_config['subscription_id']
        )

C:\Users\rudi\source\repos\Tools\Bennu\Service\docker_compose_generator.py - Chunk 1
def get_latest_image_versions(self):
        """
        Create a ContainerRegistryClient that will authenticate through Active Directory.
        All necessary credential data is stored in config.ini.
        Then get all repositories from the given azure registry. The registry name as well
        as the resource_group are also stored in the config.ini file. Iterate over all repositories
        and get the latest tag other than 'latest'.
        Return the images with their tags
        """
        images = {}
        registries = self.registry_client.registries.list_by_resource_group(
            self.azure_config['resource_group']
        )
        registry_login_server = None
        for registry in registries:
            if registry.name == self.azure_config['registry_name']:
                registry_login_server = registry.login_server
                break

        if not registry_login_server:
            raise ValueError("Registry not found")

C:\Users\rudi\source\repos\Tools\Bennu\Service\docker_compose_generator.py - Chunk 2
if not registry_login_server:
            raise ValueError("Registry not found")

        """
        Please fix this part, I get the following error:
        Exception has occurred: ValueError
        The argument audience must be set to initialize ContainerRegistryClient.
        """

        audience = "https://management.azure.com"
        repository_client = ContainerRegistryClient(
            f"https://{registry_login_server}",
            self.credentials,
            audience=audience
        )

        repositories = repository_client.list_repository_names()

        for repository in repositories:
            tags = list(repository_client.list_tag_properties(repository))
            latest_tag = max(tags, key=lambda x: x.last_updated_on)
            images[repository] = latest_tag.name

        return images

C:\Users\rudi\source\repos\Tools\Bennu\Service\docker_compose_generator.py - Chunk 3
return images

    def update_docker_compose(self):
        latest_versions = self.get_latest_image_versions()
        with open('docker-compose-prod-template.yaml', 'r') as f:
            docker_compose = yaml.safe_load(f)

        for service in docker_compose['services']:
            image = docker_compose['services'][service]['image']
            image = image.split('/')[-1]
            image_without_tag = image.split(':')[0]

            for repo, version in latest_versions.items():
                if repo == image_without_tag:
                    # TODO: make registry name configurable
                    #docker_compose['services'][service]['image'] = f'blumatixreleaseregistry.azurecr.io/{repo}:{version}'
                    docker_compose['services'][service]['image'] = f'blumatixdevregistry.azurecr.io/{repo}:{version}'
                    print(f'old_image: {image} - new_image: {repo}:{version}')
                    break

        return docker_compose

C:\Users\rudi\source\repos\Tools\requirements.txt - Chunk 0
aiohttp==3.8.5
aiosignal==1.3.1
altair==4.2.2
aniso8601==9.0.1
anyio==4.0.0
async-timeout==4.0.3
attrs==22.2.0
azure-common==1.1.28
azure-containerregistry==1.0.0
azure-core==1.26.3
azure-identity==1.7.0
azure-mgmt-containerregistry==8.1.0
azure-mgmt-core==1.3.2
backoff==2.2.1
backports.zoneinfo==0.2.1
blinker==1.5
cachetools==5.3.0
certifi==2022.12.7
cffi==1.15.1
charset-normalizer==3.1.0
clarifai==9.7.6
clarifai-grpc==9.7.5
click==8.1.3
cohere==4.21
colorama==0.4.6
cryptography==39.0.2
dataclasses-json==0.5.14
decorator==5.1.1
dill==0.3.7
docker==6.0.1
docopt==0.6.2
entrypoints==0.4
exceptiongroup==1.1.3
fastavro==1.8.2
filelock==3.12.2
flasgger==0.9.5
Flask==2.2.3
Flask-Cors==3.0.10
Flask-RESTful==0.3.9
flask-swagger-ui==4.11.1
frozenlist==1.4.0
fsspec==2023.6.0
gitdb==4.0.10
GitPython==3.1.31
googleapis-common-protos==1.60.0
greenlet==2.0.2
grpcio==1.57.0
h11==0.14.0
httpcore==0.18.0
httpx==0.25.0
hugchat==0.0.8
huggingface-hub==0.16.4
idna==3.4
importlib-metadata==6.1.0

C:\Users\rudi\source\repos\Tools\requirements.txt - Chunk 1
GitPython==3.1.31
googleapis-common-protos==1.60.0
greenlet==2.0.2
grpcio==1.57.0
h11==0.14.0
httpcore==0.18.0
httpx==0.25.0
hugchat==0.0.8
huggingface-hub==0.16.4
idna==3.4
importlib-metadata==6.1.0
importlib-resources==6.0.0
# install==1.3.5
isodate==0.6.1
itsdangerous==2.1.2
Jinja2==3.1.2
jsonschema==4.17.3
langchain==0.0.276
langsmith #==0.0.27
manifest-ml==0.0.1
markdown-it-py==2.2.0
MarkupSafe==2.1.2
marshmallow==3.20.1
mdurl==0.1.2
mistune==2.0.5
mlflow==2.11.3 #2.15.1
mpmath==1.3.0
msal==1.21.0
msal-extensions==0.3.1
msrest==0.7.1
multidict==6.0.4
mypy-extensions==1.0.0
networkx==3.1
nlpcloud==1.1.44
numexpr==2.8.5
numpy==1.24.2
oauthlib==3.2.2
openai==0.27.9
openlm==0.0.5
openpyxl==3.1.5
packaging==23.0
pandas==1.5.3
pdf2image==1.16.3
Pillow==9.4.0
pipreqs==0.4.11
pkgutil_resolve_name==1.3.10
portalocker==2.7.0
protobuf==3.20.3
pyarrow==11.0.0
pycparser==2.21
pydantic==1.10.12
pydeck==0.8.0
Pygments==2.14.0
PyJWT==2.6.0
Pympler==1.0.1
pyodbc==4.0.39
pyrsistent==0.19.3

C:\Users\rudi\source\repos\Tools\requirements.txt - Chunk 2
portalocker==2.7.0
protobuf==3.20.3
pyarrow==11.0.0
pycparser==2.21
pydantic==1.10.12
pydeck==0.8.0
Pygments==2.14.0
PyJWT==2.6.0
Pympler==1.0.1
pyodbc==4.0.39
pyrsistent==0.19.3
python-dateutil==2.8.2
python-rapidjson==1.10
pytz==2022.7.1
pytz-deprecation-shim==0.1.0.post0
pywin32==305
PyYAML==6.0
redis==5.0.0
regex==2023.8.8
requests==2.28.2
requests-oauthlib==1.3.1
requests-toolbelt==1.0.0
rich==13.4.2
safetensors==0.3.3
scipy==1.10.1
seaborn==0.13.2
semver==2.13.0
six==1.16.0
smmap==5.0.0
sniffio==1.3.0
SQLAlchemy==2.0.20
sqlitedict==2.1.0
streamlit==1.26.0
sympy==1.12
tenacity==8.2.2
text-generation==0.6.0
tokenizers==0.13.3
toml==0.10.2
toolz==0.12.0
torch==2.0.1
tornado==6.2
tqdm==4.64.1
transformers==4.32.1
tritonclient==2.34.0
typing-inspect==0.9.0
typing_extensions==4.5.0
tzdata==2022.7
tzlocal==4.3
urllib3==1.26.15
validators==0.20.0
watchdog==3.0.0
websocket-client==1.5.1
Werkzeug==2.2.3
yarg==0.1.9
yarl==1.9.2
zipp==3.15.0
streamlit_pdf_viewer==0.0.9
seaborn

C:\Users\rudi\source\repos\Tools\Bennu\requirements.txt - Chunk 0
ÿþa l t a i r = = 4 . 2 . 2 
 
 a n i s o 8 6 0 1 = = 9 . 0 . 1 
 
 a t t r s = = 2 2 . 2 . 0 
 
 a z u r e - c o m m o n = = 1 . 1 . 2 8 
 
 a z u r e - c o n t a i n e r r e g i s t r y = = 1 . 0 . 0 
 
 a z u r e - c o r e = = 1 . 2 6 . 3 
 
 a z u r e - i d e n t i t y = = 1 . 7 . 0 
 
 a z u r e - m g m t - c o n t a i n e r r e g i s t r y = = 8 . 1 . 0 
 
 a z u r e - m g m t - c o r e = = 1 . 3 . 2 
 
 b l i n k e r = = 1 . 5 
 
 c a c h e t o o l s = = 5 . 3 . 0 
 
 c e r t i f i = = 2 0 2 2 . 1 2 . 7 
 
 c f f i = = 1 . 1 5 . 1 
 
 c h a r s e t - n o r m a l i z e r = = 3 . 1 . 0 
 
 c l i c k = = 8 . 1 . 3 
 
 c o l o r a m a = = 0 . 4 . 6 
 
 c r y p t o g r a p h y = = 3 9 . 0 . 2 
 
 d e c o r a t o r = = 5 . 1 . 1 
 
 d o c k e r = = 6 . 0 . 1 
 
 d o c o p t = = 0 . 6 . 2 
 
 e n t r y p o i n t s = = 0 . 4 
 
 f l a s g g e r = = 0 . 9 . 5 
 
 F l a s k = = 2 . 2 . 3 
 
 F l a s k - C o r s = = 3 . 0 . 1 0 
 
 F l a s k - R E S T f u l = = 0 . 3 . 9 
 

C:\Users\rudi\source\repos\Tools\Bennu\requirements.txt - Chunk 1
 
 e n t r y p o i n t s = = 0 . 4 
 
 f l a s g g e r = = 0 . 9 . 5 
 
 F l a s k = = 2 . 2 . 3 
 
 F l a s k - C o r s = = 3 . 0 . 1 0 
 
 F l a s k - R E S T f u l = = 0 . 3 . 9 
 
 f l a s k - s w a g g e r - u i = = 4 . 1 1 . 1 
 
 g i t d b = = 4 . 0 . 1 0 
 
 G i t P y t h o n = = 3 . 1 . 3 1 
 
 i d n a = = 3 . 4 
 
 i m p o r t l i b - m e t a d a t a = = 6 . 1 . 0 
 
 
 
 i s o d a t e = = 0 . 6 . 1 
 
 i t s d a n g e r o u s = = 2 . 1 . 2 
 
 J i n j a 2 = = 3 . 1 . 2 
 
 j s o n s c h e m a = = 4 . 1 7 . 3 
 
 m a r k d o w n - i t - p y = = 2 . 2 . 0 
 
 M a r k u p S a f e = = 2 . 1 . 2 
 
 m d u r l = = 0 . 1 . 2 
 
 m i s t u n e = = 2 . 0 . 5 
 
 m s a l = = 1 . 2 1 . 0 
 
 m s a l - e x t e n s i o n s = = 0 . 3 . 1 
 
 m s r e s t = = 0 . 7 . 1 
 
 n u m p y = = 1 . 2 4 . 2 
 
 o a u t h l i b = = 3 . 2 . 2 
 
 o p e n p y x l = = 3 . 1 . 5 
 
 p a c k a g i n g = = 2 3 . 0 
 
 p a n d a s = = 1 . 5 . 3 
 
 P i l l o w = = 9 . 4 . 0 
 

C:\Users\rudi\source\repos\Tools\Bennu\requirements.txt - Chunk 2
 
 n u m p y = = 1 . 2 4 . 2 
 
 o a u t h l i b = = 3 . 2 . 2 
 
 o p e n p y x l = = 3 . 1 . 5 
 
 p a c k a g i n g = = 2 3 . 0 
 
 p a n d a s = = 1 . 5 . 3 
 
 P i l l o w = = 9 . 4 . 0 
 
 p i p r e q s = = 0 . 4 . 1 1 
 
 p o r t a l o c k e r = = 2 . 7 . 0 
 
 p r o t o b u f = = 3 . 2 0 . 3 
 
 p y a r r o w = = 1 1 . 0 . 0 
 
 p y c p a r s e r = = 2 . 2 1 
 
 p y d e c k = = 0 . 8 . 0 
 
 P y g m e n t s = = 2 . 1 4 . 0 
 
 P y J W T = = 2 . 6 . 0 
 
 P y m p l e r = = 1 . 0 . 1 
 
 p y r s i s t e n t = = 0 . 1 9 . 3 
 
 p y t h o n - d a t e u t i l = = 2 . 8 . 2 
 
 p y t z = = 2 0 2 2 . 7 . 1 
 
 p y t z - d e p r e c a t i o n - s h i m = = 0 . 1 . 0 . p o s t 0 
 
 p y w i n 3 2 
 
 P y Y A M L = = 6 . 0 
 
 r e q u e s t s = = 2 . 2 8 . 2 
 
 r e q u e s t s - o a u t h l i b = = 1 . 3 . 1 
 
 r i c h = = 1 3 . 3 . 2 
 
 s e m v e r = = 2 . 1 3 . 0 
 
 s i x = = 1 . 1 6 . 0 
 
 s m m a p = = 5 . 0 . 0 
 
 s t r e a m l i t = = 1 . 2 0 . 0 
 
 t o m l = = 0 . 1 0 . 2 

C:\Users\rudi\source\repos\Tools\Bennu\requirements.txt - Chunk 3
 
 r i c h = = 1 3 . 3 . 2 
 
 s e m v e r = = 2 . 1 3 . 0 
 
 s i x = = 1 . 1 6 . 0 
 
 s m m a p = = 5 . 0 . 0 
 
 s t r e a m l i t = = 1 . 2 0 . 0 
 
 t o m l = = 0 . 1 0 . 2 
 
 t o o l z = = 0 . 1 2 . 0 
 
 t o r n a d o = = 6 . 2 
 
 t y p i n g _ e x t e n s i o n s = = 4 . 5 . 0 
 
 t z d a t a = = 2 0 2 2 . 7 
 
 t z l o c a l = = 4 . 3 
 
 u r l l i b 3 = = 1 . 2 6 . 1 5 
 
 v a l i d a t o r s = = 0 . 2 0 . 0 
 
 w a t c h d o g = = 3 . 0 . 0 
 
 w e b s o c k e t - c l i e n t = = 1 . 5 . 1 
 
 W e r k z e u g = = 2 . 2 . 3 
 
 y a r g = = 0 . 1 . 9 
 
 z i p p = = 3 . 1 5 . 0 
 
 p y o d b c 
 
 l a n g c h a i n 
 
 t a b u l a t e 

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\requirements.txt - Chunk 0
pandas==1.5.3
pyodbc==4.0.39
PyYAML==6.0.1
requests==2.28.2
requests-toolbelt==1.0.0
GitPython==3.1.31
seaborn==0.13.2
#streamlit==1.12.0
streamlit-pdf-viewer==0.0.9
text_generation
langchain
pdf2image==1.16.3
httpx==0.25.0
matplotlib== 3.7.4
openpyxl==3.1.5
mlflow==2.11.3 #2.15.1


altair==4.2.2
altair==4.2.2
aniso8601==9.0.1
attrs==22.2.0
azure-common==1.1.28
azure-containerregistry==1.0.0
azure-core==1.26.3
azure-identity==1.7.0
azure-mgmt-containerregistry==8.1.0
azure-mgmt-core==1.3.2
blinker==1.5
cachetools==5.3.0
certifi==2022.12.7
cffi==1.15.1
charset-normalizer==3.1.0
click==8.1.3
colorama==0.4.6
cryptography==39.0.2
decorator==5.1.1
docker==6.0.1
docopt==0.6.2
entrypoints==0.4
flasgger==0.9.5
Flask==2.2.3
Flask-Cors==3.0.10
Flask-RESTful==0.3.9
flask-swagger-ui==4.11.1
gitdb==4.0.10
GitPython==3.1.31
idna==3.4
importlib-metadata==6.1.0

C:\Users\rudi\source\repos\Tools\Bennu\Frontend\requirements.txt - Chunk 1
isodate==0.6.1
itsdangerous==2.1.2
Jinja2==3.1.2
jsonschema==4.17.3
markdown-it-py==2.2.0
MarkupSafe==2.1.2
mdurl==0.1.2
mistune==2.0.5
msal==1.21.0
msal-extensions==0.3.1
msrest==0.7.1
numpy==1.24.2
oauthlib==3.2.2
openai==0.27.9
openpyxl==3.1.5
packaging==23.0
pandas==1.5.3
Pillow==9.4.0
pipreqs==0.4.11
portalocker==2.7.0
protobuf==3.20.3
pyarrow==11.0.0
pycparser==2.21
pydeck==0.8.0
Pygments==2.14.0
PyJWT==2.6.0
Pympler==1.0.1
pyrsistent==0.19.3
python-dateutil==2.8.2
pytz==2022.7.1
pytz-deprecation-shim==0.1.0.post0
#pywin32
#PyYAML==6.0
requests==2.28.2
requests-oauthlib==1.3.1
rich==13.3.2
semver==2.13.0
six==1.16.0
smmap==5.0.0
streamlit==1.20.0
streamlit-ace==0.1.1
toml==0.10.2
toolz==0.12.0
tornado==6.2
typing_extensions==4.5.0
tzdata==2022.7
tzlocal==4.3
urllib3==1.26.15
validators==0.20.0
watchdog==3.0.0
websocket-client==1.5.1
Werkzeug==2.2.3
yarg==0.1.9
zipp==3.15.0
pyodbc
langchain
tabulate

C:\Users\rudi\source\repos\Tools\Bennu\Service\requirements.txt - Chunk 0
azure-common==1.1.28
azure-containerregistry==1.0.0     
azure-core==1.26.3
azure-identity==1.7.0
azure-mgmt-containerregistry==8.1.0
azure-mgmt-core==1.3.2
docker_py==1.10.6
flasgger==0.9.5
Flask==2.2.3
Flask_Cors==3.0.10
Flask_RESTful==0.3.9
PyYAML==6.0.1

