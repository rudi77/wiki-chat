C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\About-this-Wiki.md - Chunk 0
Language

This Wiki is written in English.

Owner

For each main page an owner from your team must be defined to keep track of the Wiki's health. They are responsible that their pages are up to date and information can be easily found. Also, they mediate opinion conflicts. Please get in touch with the owner before you add or delete pages!

Table of contents

Currently the following main pages exist:

Architecture - Owner: Rudi

BLU DELTA Support - Owner: Andrea

Data Management Wiki - Owner: Hasch

Operations - Owner: Gü

Azure Infrastructure

Cloud Infrastructure and Deployment Strategy

Development - Owner: Bernhard

Code Wikis

!POLICIES!

Virtualization Help

Versioning Concept

Bludelta Json-Plugin Overview

ML Workflow

Entscheidungsgrenzen für normal verteilte Zufalls- Größen

How-to

Deployment Changes (or Operations?)

Net6 Conversion

SCRUM - Owner: Klemens

Product - Owner: Chris

Business Glossary

Competition (Delete?)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support.md - Chunk 0
[[TOSP]]

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture.md - Chunk 0
The following diagram gives a logical representation of the BLUDELTA service architecture. To edit the diagram please use the link below and save the updated picture in this Wiki.

[BLUDELTA Logical Architecture file to edit] C4 Model

Architecture-2_0-Rudi-Chris-Notes.pptx

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Business-Glossary.md - Chunk 0
A business glossary is a list of business terms and their definitions that organizations use to ensure the same definitions are used company-wide when analyzing data. A business glossary produces a common business vocabulary, used by everyone in an organization. A unified, common language is a key component of data governance.

A

Argentine Invoice ID

B

BCA

BlumatixCaptureAutomation

BCI

abc

BCS_Auth

abc

BCS_BI

abc

Bounding Box

abc

C

Confidence (in the JSON file)

abc

D

Delivery Date

abc

H

Header Data

abc

K

KVK

Handelskammer ID in den Niederlanden

L

Line items

A line item is a detail group that represents all necessary accounting and business information regarding one single position in the line item table. N.B.: the position of a line item is a sub-detail as well and has to be predicted. It is NOT a bijective function that counts the line items.

S

Score (in the JSON file)

abc

SIRET

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Business-Glossary.md - Chunk 1
S

Score (in the JSON file)

abc

SIRET

Eindeutige ID eines Unternehmens in Frankreich. SIREN erweitert um 5-stellige ID für Zweigniederlassungen.

Structured data

abc

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki.md - Chunk 0
This is the Data Management Wiki

[[TOC]]

[[TOSP]]

Power BI Reports

Value Delivery and Value Creation Report (including TrainingViews

Data Collection Monitoring

Labeler Billing and Quality

Data Management Requirements:

Required (customer) data delivery (PoC)

training.zip file: two documents for each supplier + ground truth as BluDoc

test.zip file (benchmark): One document for each supplier + ground truth as BluDoc

supplier_distribution.csv file: - Column 'Supplier': List of suppliers from the past 12 months - Column 'n': Number of received documents in the past 12 months for each supplier

What we would like to know about your data

Which document type(s) should we process?

How many documents (for each document type) are you processing annualy, monthly?

Is there any seasonality in the data (e.g. some suppliers only occur in December)?

How many different suppliers (or more specific document templates by document type) do you currently process?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki.md - Chunk 1
Is there any seasonality in the data (e.g. some suppliers only occur in December)?

How many different suppliers (or more specific document templates by document type) do you currently process?

If possible (hence, if the population is not to big) are you able to provide 3 documents from each document type and provider?

Are there any suppliers or document templates which are more important than others?

Which details are required (according to our online documentation)?

If you provide training data (documents plus ground truth): For each detail, whats the error rate we can expect?

For each detail: Whats the error rate you are looking for?

In case you are able to provide training data: Are you able to provide them in the following csv format considering our naming convention as defined in the online documentation)? TBD: Should we define a format as we did for the ressource service?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki.md - Chunk 2
If not: Can you please provide a mapping from your attribute names to our detail names as defined in the online documentation).

We would like to achieve a common understanding about the performance measurement of our models. Do you have any specific requirements regarding the measurement (such as a specific sample size, etc.)? Is there a defined process in your company to measure the quality?

How do you manage ambiguities (such as multiple currencies on one document)?

Are there any unique features in your data we should be aware of?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science.md - Chunk 0
[[TOSP]]

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Deployment-Changes.md - Chunk 0
Hello World

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Diplomarbeiten.md - Chunk 0
Topics

Problemstellung: Die manuelle Annotation von Semi-Strukturieren Dokumenten ist zeit- und kostenaufwendig, fehleranfällig und generell komplex. Kann man den Annotationsprozess von Dokumenten mithilfe von Large Language Models beschleunigen bzw. vereinfachen. Inwiefern könnten LLMs bei der Erzeugung von Annotationen helfen.

Forschungsfrage: Wie können Large Language Models (LLMs) effektiv in die automatische Annotation von semi-strukturierten Dokumenten integriert werden, und sowohl Text- als auch Layoutinformationen zu berücksichtigen, und wie vergleichen sich die Ergebnisse mit denen des manuellen Annotationsprozesses?

Unterfragen: - Wie unterscheiden sich die Ergebnisse von Prompt Engineering und fein-getunten LLMs in Bezug auf Genauigkeit und Konsistenz? - Wie können Layoutinformationen erfolgreich in den Annotationsprozess integriert werden?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Diplomarbeiten.md - Chunk 1
Praktischer Teil: - Vorbereitung und Datenanalyse: Verstehen der Daten und Identifizierung von Herausforderungen im aktuellen Annotationsprozess. - Modellauswahl und -anpassung: Auswahl und Anpassung eines LLMs durch Fine-Tuning oder Prompt Engineering. - Integration von Layoutinformationen: Entwicklung von Strategien zur Einbeziehung von Layoutinformationen. - Evaluierung und Vergleich: Vergleich der automatischen und manuellen Annotation in Bezug auf Effizienz, Kosten und Fehlerquote. Optimierung: Iterative Verbesserung des Modells und des Prozesses basierend auf den Evaluierungsergebnissen. Implementierung: Integration des optimierten Modells in den Unternehmensworkflow und Schulung der Mitarbeiter. Feedback und Anpassung: Kontinuierliche Verbesserung durch Sammeln von Feedback und Anpassung des Systems.

Ziel: Verbesserung und Beschleunigung des Annotationsprozesses durch Reduzierung manueller Fehler, Kostensenkung und effizienteres Labeln mithilfe automatisierter Systeme.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Diplomarbeiten.md - Chunk 2
Ziel: Verbesserung und Beschleunigung des Annotationsprozesses durch Reduzierung manueller Fehler, Kostensenkung und effizienteres Labeln mithilfe automatisierter Systeme.

Resourcen: - LMDX: Language Model-based Document Information Extraction and Localization

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ISMS.md - Chunk 0
DEPRECATED!

Compare: https://blumatix.visualstudio.com/ISMS/_wiki/wikis/ISMS.wiki/2575/About-this-Wiki

[[TOC]]

ISMS Risk Management in Azure DevOps

This chapter defines how to manage risks in our Azure DevOps projects.

Create a Work Item

If you encounter a risk such as a security issue reported during a Penetration Test please create a Technical Story and use the respective template 'ISMS Final':

Select the template ISMS Final

Provide the necessary Information: - Tag: ISMS

Title: e.g. Loss of Source Code

Description of the risk: e.g. Source code is completely lost

Threats: e.g. Disruptions in the cloud, Deliberate deletion, Hacker attack

Vulnerabilities: e.g. Possible water ingress (unlikely), High-risk user profiles (internal only; are known)

Who reported the risk: e.g. M.Loiperdinger

Which Asset is affected: e.g. BLUDELTA Service

Asset owner: e.g. M.Loiperdinger

Protection objectives: e.g. Availability

Risk owner: e.g. M.Loiperdinger

Manage Work Items

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ISMS.md - Chunk 1
Which Asset is affected: e.g. BLUDELTA Service

Asset owner: e.g. M.Loiperdinger

Protection objectives: e.g. Availability

Risk owner: e.g. M.Loiperdinger

Manage Work Items

ISMS Relevant Work Items can be found via the following Query or the Tag "ISMS".

Query: ISMS Risk Items

~~Query: ISMS_WorkItems~~

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product.md - Chunk 0
[[TOSP]]

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\SCRUM.md - Chunk 0
[[TOC]]

Sprint Data

In the following file you will find some KPIs regarding the Rechnungserkennung and RIPEye Scrum Teams: SprintCapacity.xlsx

Refinement

Story Points

In our Retrospective on April 24th 2023 we discussed that: - A Story Point is not defined as an equivalent to e.g. a certain amount of workload (e.g. 4h) but rather reflects our gut feeling about the size of the Story from experience. - During the Refinement meeting, we can compare the Story and estimated Story Points with Stories implemented in a past Sprint. - The Story will be discussed until everyboday from the DevTeam understood the Story and Acceptance Criteria and agrees with the estimate. - We agreed that simple stories such as Issue analysis or Bugs which are not discussed in detail during the refinement will get 0.5 story points.

Discuss what needs to be done, not how it will be done

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\SCRUM.md - Chunk 1
Discuss what needs to be done, not how it will be done

In our Retrospective on April 24th 2023 we discussed that: - We will no longer discuss how we will implement a Story during our Refinement meeting but will solely concentrate on WHAT needs to be done.

Sprint Review

In our Retrospective on April 24th 2023 we discussed that: - We will discuss figures showing performance improvements, model quality measures or new features - We won´t show or discuss any code, etc.

Agenda

Review model training: VAT, Header, Line Items

Review Stories and Bugs

Definition of Done (DoD)

Unit- and Integration-Tests written and passing Note: An increment should be automatically tested. Please provide an explanation if an automated test is not feasible. Also think about the relation between cost and benefit (Figure 1).

Runs on Linux

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\SCRUM.md - Chunk 2
Runs on Linux

Ready for release deployment Note: Merged back onto master (unless explicitly defined otherwise), pipelines green, automation done. Regression and new functionality tests green.

Message of procedure: How/what to monitor, cpu and memory needed.

Peer reviewed Note: 4 eye principle for quality control and to gather additional insights. Communication and coordination with the team is key. Technical experts approve the solution. Backups for every domain provide additional affirmation. (Pull requests?).

(Internal) Documentation updated Note: The documentation is saved at a central point which is known by everybody in the organization (DevOps Wiki). The availability of both code plus documentation is a prerequisite for the necessary knowledge transfer.

Online Docu Review for API (Redoc for customer APIs)

Free of known errors Note: Please consider the elimination of bugs during the story and sprint planning.

Licence checks done

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\SCRUM.md - Chunk 3
Online Docu Review for API (Redoc for customer APIs)

Free of known errors Note: Please consider the elimination of bugs during the story and sprint planning.

Licence checks done

Data privacy checks done No connection strings or authentication data in plain text (PAT Token) Note: The data privacy act must be fulfilled (GDPR).

Security checks done Note: e.g., ISMS (Integrity, Availability, Confidentiality)

Performance

Changes in the customer facing interfaces agreed with product owner

Acceptance criteria met

CI/CD ready

Continuous training, MLFlow integration

OnPremise Integration done (operation manual done and wiki page for release reminders)

Up- and Downscaling still works

Support Documentation (is an update in the Support Documentation necessary)

Check memory usage and memory limits of docker containers.

Project templates are up to date

Monitoring

Was the story implemented in the MVP mindset

TBD:

Definition of Ready (DoR)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\SCRUM.md - Chunk 4
Check memory usage and memory limits of docker containers.

Project templates are up to date

Monitoring

Was the story implemented in the MVP mindset

TBD:

Definition of Ready (DoR)

Product interface (API, UI) is defined. Deviations from standard response are documented in the story.

Resources for development such as customer master data or labelled documents are available?

Which customer configurations is necessary?

Necessary documentation (e.g. customer facing) is defined?

Does everybody understand the acceptance criteria?

Performance criteria are discussed?

Story points are defined?

OpenAPI and Client can still be autogenerated

OnPremise vs. Cloud - ist die User Story evtl. nur für eines der beiden - by default ist es für beide

Benchmark needed? -- Benchmark names in acceptance criteria -- New benchmark definition -- Benchmark detailed requirements defined

Data needed and communicated to data mgt team

Reporting

Monitoring

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\SCRUM.md - Chunk 5
Data needed and communicated to data mgt team

Reporting

Monitoring

Security -- Components in secure network (VNet, Firewall, etc.) -- Auth/User/Passwords done and encrypted -- Communication encrypted

TBD:

Work Items

Label Error Bug

If you come across a label error, please create a bug in the Rechnungserkennung project and add the following information (marked yellow):

This approach will help us address label errors promptly and maintain a structured system for tracking and resolution.

Reading Material

MPIRICS CSM Course Material

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Alerts.md - Chunk 0
Listing of the most frequent alerts incl. impact, explanation, information and/or solution. Mail Alerts (Subject Line).

[[TOC]]

Severity

Below you will find a list of severity level given in our alerts and how they relate to our issue classes. - Sev0, Severity: 0 = Potential P1 Issue - ! Please add other severity classes !

P1 Issue Alerts

Fired:Sev0 Azure Monitor Alert RabbitMQ Issue on appi-sme-validation-prod-weu-05 (microsoft.insights/components ) at 10/31/2023 11:06:52 AM

Impact: Potential P1!. Documents from RIPEye customers are not processed correctly. Therefore, an increased number of documents are placed in the 'Error' state instead of 'Released' or 'NeedForAction'. Due to changes in RIPEye v2.2.7, documents in the 'Error' state can still receive prediction results. Therefore, the impact on customers not using the front end is likely low.

Solution: Neustarten von Invoice Dispatcher, ELSA Workflow und Image Processor (-> hat bei Issue #20837 geholfen)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Alerts.md - Chunk 1
Solution: Neustarten von Invoice Dispatcher, ELSA Workflow und Image Processor (-> hat bei Issue #20837 geholfen)

Information: Call an Rabbit MQ geht schief

Rabbit MQ ist der Kommunikator zwischen Image Prozessor und Invoice Dispatcher. Hier ist bisher durch verschiedenste Komponenten, die die Connection nicht sauber disposen, das Connectionlimit vollgelaufen, wodurch keine neuen Connections mehr erzeugt werden können.

Note by @<5989DF17-A3A9-62CB-B2A1-200A78B036C1> (2023-10): Ja schon bedenklich. Letztes Mal als das passiert ist sind alle Rechnungen im Error State gelandet weil wir Probleme mit der Rabbit MQ hatten. Nachdem er nur einmal aufgetreten ist halb so wild. Wäre mal eine Investigation Wert was da los war – wir hatten nur neulich mal das Problem dass jede zweite Rechnung dieses Problem hatte und ich hab deshalb diesen Alert aufgesetzt. Eigentlich sollte es 0 mal auftreten aber dieses eine Mal sollte der Retry Mechanismus sogar abgefangen haben.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Alerts.md - Chunk 2
Note by @<5989DF17-A3A9-62CB-B2A1-200A78B036C1> (2023-12): Vereinzelt kann mit der RabbitMQ nicht sauber kommuniziert werden. Insgesamt haben wir eine Failure Rate am Invoice Dispatcher von 4% in den letzten 24h (das sind alle Fehler nicht nur die RabbitMQ related ones). Ich habe den Alert Trigger mal von einmal in 5m auf 5x in 30m gestellt.

Issues: - #21787 - #20837 - #20836 - #20414 - #19788

Fired:Sev0 Azure Monitor Alert SME Health checker failed two consecutive times on smeopstool20201224140839 ( microsoft.insights/components ) at 12/5/2023 10:08:38 AM

Impact:

Potential P1!. Basisfunktionalität des Systems ist nicht gewährleistet wenn dieser Alert kommt. Documents from RIPEye customers are not processed correctly.

Information: Der Health Checker lädt eine Rechnung hoch die autoprozessiert wird, lädt sie anschließen wieder herunter und überprüft die Werte des PredictionResults.

Solution: Unterschiedlichste Gründe -> unterschiedlichste Lösungen.

Issues:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Alerts.md - Chunk 3
Solution: Unterschiedlichste Gründe -> unterschiedlichste Lösungen.

Issues:

Azure: Activated Severity: 0 dtu percentage too high

Impact: Potential P1!. Documents from RIPEye customers are not processed correctly.

Information: Die Auslastung der Datenbank SMEDB-V1.0 ist zu hoch.

Mail Julian (17.08.2024): Der DTU Alert kann in seltenen Fällen von Klemens seinem BI Report (Mailbetreff: FW: Subscription for ripeye_MonitoringReport_v1 (StateMonitoringByDayCustomer)) getriggert werden, das ist ca. um 07:30, 12:00 und 16:00, wenn er sich selbst innerhalb von einer viertel Stunde wieder resolved kein Anlass zur Panik. Kann auch sein, dass das gar nicht auftritt.

Solution: DTU Anzahl erhöhen und monitoren, ob es das Problem löst.

Issues: - #17507

Azure: Activated Severity: 1 email invoice listener function execution count

Impact: Potential P1!. Documents from RIPEye customers sent via E-Mail are not processed.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Alerts.md - Chunk 4
Issues: - #17507

Azure: Activated Severity: 1 email invoice listener function execution count

Impact: Potential P1!. Documents from RIPEye customers sent via E-Mail are not processed.

Information: Der Email Invoice Listener wird zu selten (oder auch gar nicht) ausgeführt -> Verzögerte oder gar keine Verarbeitung von Emails

Solution: Fehleranalyse

Issues:

Email Invoice Listener completes with failure

Impact:

Information: Alle Emails können einwandfrei verarbeitet werden :) (nicht)

Solution: Fehleranalyse

Issues:

Azure: Activated Severity: DataSpaceUsedMoreThan90Percent

Impact: Potential P1 Issue

Information: Der benutzte Disk Space der SME Datenbank liegt bei über 90%. Wenn 100% der Datenbank voll sind geht nichts mehr in sie rein :)

Solution: Datenbankgröße erhöhen.

Issues:

The Invoice Container Poison Queue has entries!

Impact: Potential P1!. Documents from RIPEye customers are not processed correctly.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Alerts.md - Chunk 5
Solution: Datenbankgröße erhöhen.

Issues:

The Invoice Container Poison Queue has entries!

Impact: Potential P1!. Documents from RIPEye customers are not processed correctly.

Information: Rechnungen werden nicht verarbeitet (= landen auch nicht im Error State sondern 'bleiben hängen')

Solution: Fehleranalyse und Verarbeitung erneut anstoßen (chech the according garuda action).

Issues:

Fired:Sev0 Azure Monitor Alert V1.18 health checker not running on health-checker-v1-18 ( microsoft.logic/workflows ) at 3/13/2024 9:48:35 PM

Impact: Ist der Alert ernst? Note by Gü (2024-03): Grundsätzlich schon, aber ich habe ihn nirgends gespürt.

Information: Ist der Alert ernst? Note by Gü (2024-03): Grundsätzlich schon, aber ich habe ihn nirgends gespürt. Ich schaue aber eh dauernd auf PROD und hätte ein Problem auch so festgestellt. Kann sein das sie ein Update bei der Logic app gemacht haben.

Solution: tba

Issues: tba

Alert (firing): (DatasourceNoData)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Alerts.md - Chunk 6
Solution: tba

Issues: tba

Alert (firing): (DatasourceNoData)

This alter comes from the WorkflowServer. Currently the name of the alert is missing. So please have a look at the rule name: "Workflow Server - Error while creating channel"

Impact: This alert could be serious and could have an impact on the customer.

Information This alert is triggered when a WorkflowServer instance looses the connection to the RabbitMQ server. Loosing a connection to rabbitmq may have different causes: - WorkflowServer was restarted - A temporary network error occurred - RabbitMQ crashed

Solution Normally the WorkflowServer will recover automatically and everything will be fine. - Send a document via Bennu "Bludelta Workflows" to the workflow server - use the prod. endpoint! If a result is returned, then we are fine otherwise call one our developers.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Alerts.md - Chunk 7
Developer shall check: - Check if workflow server is running: either use k9s or azure portal: - Cluster: aks-bludelta-aks-prod-weu-118, namespace Bludelta - Check if rabbitmq is running - Cluster: aks-bludelta-ocr-aks-prod-weu-01, namespace rabbit

Email Health-Checker WorkflowServer

This email is sent whenever a request to the Quotation or OrderConfirmation Workflow fails.

Impact: This could affect the customer, so please take this email seriously.

Information This email is sent whenver a http request to the OrderConfirmation or Quotation workflow fails, i.e. when the HTTP Code is NOT 200!!! A HTTP Code other than 200 may have different causes: - Authentication issue: HTTP Code: 401 - WorkflowServer is not running - OcrBox or BludeltaEntity recognition is not running or has some issues - RabbitMQ crashed

More Infos from Gü: ApiHealthChecker

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Alerts.md - Chunk 8
More Infos from Gü: ApiHealthChecker

Solution - Send a document via Bennu "Bludelta Workflows" to the workflow server - use the prod. endpoint "Quotation" or "OrderConfirmation"! If a result is returned, then we are fine otherwise call one our developers.

Developer shall check: - Check if workflow server is running: either use k9s or azure portal: - Cluster: aks-bludelta-aks-prod-weu-118, namespace Bludelta - Check if rabbitmq is running - Cluster: aks-bludelta-ocr-aks-prod-weu-01, namespace rabbit

>= P2 Issue Alerts

URGENT - Health-Check v1-18 - EinfachsteRechnung Error

Impact:

Information: in der Cloud läuft ein Service (HealthChecker) der alle 5 Minuten eine ganz einfache Rechnung an api.bludelta.ai/v1-18 schickt. Wenn die Antwort nicht 200 OK oder der GTA nicht 96EUR ist, dann kommt dieser Alert als Mail und als SMS.

Wenn der Alert in der Nacht auftritt, ist meist ein Update von Microsoft Schuld. Dann kommt aber gleich danach wieder eine Entwarnung.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Alerts.md - Chunk 9
Wenn der Alert in der Nacht auftritt, ist meist ein Update von Microsoft Schuld. Dann kommt aber gleich danach wieder eine Entwarnung.

Werden zwei solcher Anfragen hintereinander nicht mit 200 OK beantwortet kommt ein weiter Alert der darauf hinweist. Sollte jemand den HealthChecker disablen oder löschen, kommt ein Alert das dieser nicht aktiv ist.

Solution: Was mach ich wenn ich das bekomme: - Ich sende selbst eine Rechnung und prüfe die Antwort - Ist es eine 500er Fehlermeldung -> AGW prüfen - Dauert es nur lange prüfe ich die Last und die CaptureSDK Instanz Anzahl - Gibt’s zusätzlich noch Alerts vom Cluster, wenn ja dann überprüfe ich die Pods - Wenn CaptureSDK und Cluster OK sind -> AGW prüfen

Issues:

Alert (firing): warning (KubeDaemonSetMisScheduled)

Impact:

Solution:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Alerts.md - Chunk 10
Issues:

Alert (firing): warning (KubeDaemonSetMisScheduled)

Impact:

Solution:

Information: Antwort Gü (am 11.12.2023): Der Grund der Alerts derzeit ist, dass ich ein Node für Deployments gesperrt habe, weil es ein Problem beim Pullen der Images gibt. Das ist aber schon seit 2 Wochen so.

Issues:

Alert (firing): warning (KubeDaemonSetRolloutStuck)

Impact:

Solution:

Information: Antwort Gü (am 11.12.2023): Der Grund der Alerts derzeit ist, dass ich ein Node für Deployments gesperrt habe, weil es ein Problem beim Pullen der Images gibt. Das ist aber schon seit 2 Wochen so.

Issues:

Alert (firing): info (CPUThrottlingHigh)

Impact:

Solution:

Information:

Issues:

Alert (firing): warning (KubePodNotReady)

Impact:

Solution:

Information:

Issues:

Alert (firing): warning (KubeAggregatedAPIErrors)

Impact:

Solution:

Information:

Issues:

Alert (firing): warning (KubeDeploymentReplicasMismatch)

Impact:

Solution:

Information:

Issues:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Alerts.md - Chunk 11
Alert (firing): warning (KubeAggregatedAPIErrors)

Impact:

Solution:

Information:

Issues:

Alert (firing): warning (KubeDeploymentReplicasMismatch)

Impact:

Solution:

Information:

Issues:

Alert (firing): warning (KubeContainerWaiting)

Impact:

Information:

Solution:

Issues:

Invoice Cleaner completed with function failure

Impact: P2 Issue. Customer documents in the RIPEye db and inbox are not deleted.

Information: Der Invoice Cleaner läuft nicht sauber -> Rechnungen werden nicht aufgeräumt Der Invoice Cleaner läuft nur nachts. Der Alert im Support Posteingang (zw. 00:00 und 06:20 Uhr) kann solange der Bug offen ist ignoriert werden

Solution: ~~Fehleranalyse~~

23111

Issues:

Invoice cleaner is not running

Impact: P2 Issue. Customer documents in the RIPEye db and inbox are not deleted.

Information: Der Invoice Cleaner läuft nicht -> Rechnungen werden nicht aufgeräumt

Solution: Fehleranalyse

Issues:

Alert (firing): critical (KubePersistentVolumeFillingUp)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Alerts.md - Chunk 12
Information: Der Invoice Cleaner läuft nicht -> Rechnungen werden nicht aufgeräumt

Solution: Fehleranalyse

Issues:

Alert (firing): critical (KubePersistentVolumeFillingUp)

Impact: The alert is not serious. There is no impact on the customer.

Information: description = The PersistentVolume claimed by storage-monitoring-loki-0 in Namespace monitoring is only 0.2535% free. This alert comes 2 times a day (6.54 am and 6.54 pm)

Gü will temporarily mute this alert.

Solution: The alert is not serious. There is no impact on the customer. In our case, the PersistentVolume is configured to scale automatically when the available disk space runs out.

Issues:

Fired:Sev3 Azure Monitor Alert Receipt Needed Longer Than 20 Seconds

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Alerts.md - Chunk 13
Issues:

Fired:Sev3 Azure Monitor Alert Receipt Needed Longer Than 20 Seconds

Impact: Information level alert, nothing serious Information: At least one receipt needed longer than 20 seconds for processing. Check in OTEL if there are many of those and what exactly needs so long. We told CSS that receipt should only need less than 5 seconds. There is not much we can do right now, but we should be aware of those things happening. If this happens often, we should probably use something else than Azure Read.

Check here / Keyword OTEL: ApiHealthChecker - Overview

Solution: Inform team of this. We should just become aware of the frequency of this happening.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\BLU-DELTA-Dev-Environment.md - Chunk 0
https://app-bludelta-capture-sdk-dev-weu-01.azurewebsites.net

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Current-OnPremise-Operations-Manual.md - Chunk 0
Bludelta OnPremise Operations Manual (Newest).pdf (https://blumatixconsultinggmbh.sharepoint.com/sites/MachineLearning/Freigegebene%20Dokumente/Forms/AllItems.aspx?RootFolder=%2Fsites%2FMachineLearning%2FFreigegebene%20Dokumente%2FGeneral%2FBlumatixCaptureReleases&FolderCTID=0x01200012E07AC3E90C884B85C92A411816D0EB)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics.md - Chunk 0
[[TOSP]]

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\How-to-create-an-Issue-or-a-Bug-at-Azure-Dev-Ops.md - Chunk 0
[[TOC]]

In the following Video we discussed how to create an Issue or Bug and how we will manage them: Discussion Video

1. Create Issue/Bug

Does the issue/bug belong to BluDeltaSME or Rechnungserkennung Its about the problem/issue, NOT about the Customer. If an SME customer has problems, pe. with invoice recognition, the issue belongs to Rechnungserkennung.

For RIPEye/SME use this Link: BluDeltaSme For Rechnungserkennung/API use this Link: Rechnungserkennung

Make sure that - the Area Path is BluDeltaSME\BluDeltaSME Support Team or Rechnungserkennung\Support - the iteration path in the sprint of the current month (Support sprints last 1 month; always the current calendar month)

2. Fill in all important fields

2.1. Support Issue

Title: Copy Mail Subject 1:1 as title of the issue; Optionally add comment

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\How-to-create-an-Issue-or-a-Bug-at-Azure-Dev-Ops.md - Chunk 1
2. Fill in all important fields

2.1. Support Issue

Title: Copy Mail Subject 1:1 as title of the issue; Optionally add comment

Description: Copy body of mail to Issue description incl. the incl. the sender identity !! if there is a graphic in the email, please copy and paste it separately, otherwise the graphic will NOT be included.

Client: a customer name that is traceable eg. Aptean/BÄKO not only Aptean

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\How-to-create-an-Issue-or-a-Bug-at-Azure-Dev-Ops.md - Chunk 2
Client: a customer name that is traceable eg. Aptean/BÄKO not only Aptean

Urgency Reason: Specify why it is urgent for customer; choose from the dropdown menu: --line item (anything mostly regarding line items) ---swiss code (anything mostly regarding swiss qr code) ---recognition (probably training issue) ---trouble integrating (customer has not yet tested/used the solution because of initial problems) ---authentication (something with the authentication is hiccuped) ---response missing ---configuration (customer needs a change of the configuration e.g. priority) ---new detail (rather make a new user story and assign the feature request to Chris or Klemens) ---cannot process docs (this is pretty unspecific, but maybe a good solution for mandator problems when its not our fault, that the customer has more mandators than us ¯(ツ)/¯ ) ---other (if none of the given categories fit well enough)

Attachments: add all Attachments from E-Mail

Add Task if needed

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\How-to-create-an-Issue-or-a-Bug-at-Azure-Dev-Ops.md - Chunk 3
Attachments: add all Attachments from E-Mail

Add Task if needed

Add helpful comments if you have already any related knowledge

2.2. Trainings Issue

Title: same as Support Issue

Description: same as Support Issue

Client: same as Support Issue

Urgency Reason: --- (always) recognition

Attachments: same as Support Issue

Add the Template Task 'Task for Ready for Training Issues'

Tag the Issue with 1ReadyforTraining

Add helpful comments if you have already any related knowledge

2.3. Bug

Title: Explain the Topic

Repro Steps: How can we repro

Client: a customer name that is traceable eg. Aptean/BÄKO not only Aptean

Related Work: If the BUG is releated to another WorkItem please link it

Add helpful comments if you have already any related knowledge

3. Save the Issue/Bug (and inform the customer about his Issue Number in case of any further questions)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Issue-Benchmarks.md - Chunk 0
Hasch built a pipeline, with which all current 14 benchmarks can be run at the same time. We think, we should run this at least with every new release and check, if issues were resolved with the new version. For V1.18.6 this is already done, find the set for these benchmarks here:

And there one can find at the benchmark sets the 'Cloud_IssueBenchmarks_Set'. New one is tagged with Issue V.18.6

Since in V1.18.6 typhon header details are included for the first time InvoiceId, InvoiceDate and GrandTotalAmount changed quite to the better.

A problem Hasch noticed: in ReceiverOrderId Issues are a lot of Ordernumbers, actually SenderOrderId Issues. We should check these together and discuss, what to do. Hasch thinks, we should create a SenderOrderId Benchmark. But we still gotta discuss how to work with the filenames in these cases.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Known-Issues-and-How-to.md - Chunk 0
[[TOC]]

Known Issues

Http 504 from API DetectInvoiceResponse?

Processing time of BLU DELTA API takes too long and thus, the gateway cuts off the connection to the client with a http 504 status response. Many responses of type 504 indicates a load and/or performance problem. Resolution: Inform 2nd and 3rd level!

API response DocType "OTHER", empty predictions and InvoiceStatus=0?

This is a valid response and means that the BLU DELTA API could not detect the type of the document and could not find any values but response is valid and was returned with https status 200. However, we have seen cases where we get a pdf with embedded cmap (specific fonts for this doc) which our OCR can not interpret! Resolution: create an entry in the pdf-json filter config.

Customer does not get line items anymore

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Known-Issues-and-How-to.md - Chunk 1
Customer does not get line items anymore

Check, if deployment was not long ago since the line item container might not have been reactivated since then. Try processing with an invoice but with the customers api key. If it also doesnt work contact contact Gü for checking the line item container.

Customer gets blank empty white document as a response, but the AI finds information on it.

Do the following steps: * Try it out on our test page * Try it out via phoenix action (with different keys maybe?) https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/879/Predict-documents - \phoenix.exe evaluation predict -i PATH_TO_FILE -w -p -o D:\tmp -r -t 1 -c https://api.bludelta.ai/v1-18 -a -l -d -u

How-to

How-to Import Batch Data

Automated-Document-Batch-Import-v1_0-userguide.docx

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Known-Issues-and-How-to.md - Chunk 2
How-to

How-to Import Batch Data

Automated-Document-Batch-Import-v1_0-userguide.docx

SAS URL: https://bminvoicestore.file.core.windows.net/import?st=2021-11-11T13%3A56%3A29Z&se=2025-12-08T13%3A56%3A00Z&sp=rcwl&sv=2018-03-28&sr=s&sig=9jgSH85Q0qWn2lzQYzd8nUSkyDxImacgtrC7uJR%2FK0Q%3D

How to get access to BDS line item Typhon model in V1.18?

See https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Capture%20SDK/256/Capture-SDK-Endpoints

BLU DELTA Databases - access urls

Server DB Name Description ReadOnly User tcp:bcdbserver.database.windows.net,1433 bcsdb-bi Includes Telemetry data (component logging) like exec time, exceptions raised, etc. bcs_rd

Telemetry SQL Queries from Repo: Telemetry_Average_Per_Day.sql

Telemetry: Enum ValueType for Telemetry entries

Telemetry: Query: Item -> Containter -> Usages Join

set dateformat dmy

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Known-Issues-and-How-to.md - Chunk 3
Telemetry SQL Queries from Repo: Telemetry_Average_Per_Day.sql

Telemetry: Enum ValueType for Telemetry entries

Telemetry: Query: Item -> Containter -> Usages Join

set dateformat dmy

SELECT [dbo].[TelemetryItem].[Id] ,[dbo].[TelemetryItem].[Key] ,[dbo].[TelemetryItem].[Value] ,[dbo].[TelemetryItem].[ValueTypeStored] ,[dbo].[TelemetryItem].[TimeStamp] ,[dbo].[TelemetryItem].[TelemetryItemContainerId] ,[dbo].[TelemetryItem].[Version] ,[dbo].[TelemetryItemContainer].[UsageId]

FROM [dbo].[TelemetryItem] Inner Join [dbo].[TelemetryItemContainer] on [dbo].[TelemetryItemContainer].Id = [dbo].[TelemetryItem].TelemetryItemContainerId Inner Join [dbo].[Usages] on [dbo].[Usages].Id = [dbo].[TelemetryItemContainer].UsageId

where CustomerId = 46 and [dbo].[Usages].[Timestamp] >= '11.11.2021' and [dbo].[Usages].[Timestamp] < '12.11.2021'

Telemetry: Query: Only Pages

set dateformat dmy

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Known-Issues-and-How-to.md - Chunk 4
where CustomerId = 46 and [dbo].[Usages].[Timestamp] >= '11.11.2021' and [dbo].[Usages].[Timestamp] < '12.11.2021'

Telemetry: Query: Only Pages

set dateformat dmy

SELECT [dbo].[TelemetryItem].[Id] ,[dbo].[TelemetryItem].[Key] ,[dbo].[TelemetryItem].[Value] ,[dbo].[TelemetryItem].[ValueTypeStored] ,[dbo].[TelemetryItem].[TimeStamp] ,[dbo].[TelemetryItem].[TelemetryItemContainerId] ,[dbo].[TelemetryItem].[Version] ,[dbo].[TelemetryItemContainer].[UsageId]

FROM [dbo].[TelemetryItem] Inner Join [dbo].[TelemetryItemContainer] on [dbo].[TelemetryItemContainer].Id = [dbo].[TelemetryItem].TelemetryItemContainerId Inner Join [dbo].[Usages] on [dbo].[Usages].Id = [dbo].[TelemetryItemContainer].UsageId

where CustomerId = 46 and [dbo].[Usages].[Timestamp] >= '01.11.2021' and [dbo].[Usages].[Timestamp] < '01.12.2021' and TelemetryItem.[Key] = 'Pages'

Telemetry: Query: How many pages

First check the current customer settings in the Dyn.Config, search for:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Known-Issues-and-How-to.md - Chunk 5
Telemetry: Query: How many pages

First check the current customer settings in the Dyn.Config, search for:

"Ocr": { "Enabled": true, "OcrMaxPageConfigs": [ { "MaxPages": 16, "Enabled": true, "CustomerNames": [

SQL Query:

``` set dateformat dmy

DECLARE @LocalTableVariable TABLE ( ContainerId uniqueidentifier ); INSERT INTO @LocalTableVariable (ContainerId) select Id from TelemetryItemContainer where UsageId in (select Id from Usages where CustomerId = 162 and [Timestamp] > '01.04.2023')

select convert(int,[Value]) as [Pages], COUNT(*) as DocCount from TelemetryItem where TelemetryItemContainerId in (select ContainerId from @LocalTableVariable) and [Key] = 'Pages' group by [Value] order by Pages ASC

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Known-Issues-and-How-to.md - Chunk 6
```

Result:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Monthly-Support-Review.md - Chunk 0
[[TOSP]]

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Plugins-Overview.md - Chunk 0
Plugin Overview

There exist four different types of plugins: - Json-Plugins: Plugins in CaptureSDK that consist of .json files - WhiteList-Plugins: Plugins in CaptureSDK that call the WhiteList-Service, also consist of .json files - Assembly Plugins: Plugins in CaptureSDK that consist of code and are loaded as .dll files - Plugins in ExternalPostprocessing: Plugins defined in the config of the external PostProcessing service - Different Plugin Types: Plugins - Repos

Lookup of what runs for whom

There is a wiki page, where all plugins should be written to (might not be up to date, if someone forgets to document it): https://blumatix.visualstudio.com/DefaultCollection/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/312/Bludelta-PlugIn-Overview

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Plugins-Overview.md - Chunk 1
The best and safest way to see all deployed json, whitelist and assembly plugins is to look into the bludelta_cloud_plugins file, this list defines which plugins are deployed during the deployment process: https://blumatix.visualstudio.com/DefaultCollection/Rechnungserkennung/_git/Blumatix%20Capture?path=/Deployment/bludelta_cloud_plugins.json

For the ExternalPostProcessing Plugins, they are defined in the config of the PostProcessing service and can be seen and edited here: https://blumatix.visualstudio.com/DefaultCollection/Rechnungserkennung/_git/PostProcessing?path=/src/Blumatix.PostProcessing.Api/appsettings.json => Also check in dynamic config, if the customers get the OCRRawText or OCRRegions: https://blumatix.visualstudio.com/Rechnungserkennung/_git/DynamicConfig?path=/CaptureSdk/dynamic_config.json&version=GBmain&line=310&lineEnd=310&lineStartColumn=3&lineEndColumn=28&lineStyle=plain&_a=contents => Get DetailTypes here: InvoiceDetailType.cs - Repos

Edit Plugins

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Plugins-Overview.md - Chunk 2
Edit Plugins

Json and WhiteList-Plugins are normally stored here, if you want to edit them: https://blumatix.visualstudio.com/DefaultCollection/Rechnungserkennung/_git/Blumatix%20Capture?path=/Blumatix.Capture.Webservice.Client.Selfhosted/Blumatix.Capture.Webservice.Client.Selfhosted/Plugins

Assembly Plugins can be edited via c# Code in the Blumatix Capture Complete Solution in the directory "CustomSmartFilters"

For the ExternalPostProcessing Plugins, they are defined in the config of the PostProcessing service and can be seen and edited here, for most you will also need to add the customer name to the dynamic config: https://blumatix.visualstudio.com/DefaultCollection/Rechnungserkennung/_git/PostProcessing?path=/src/Blumatix.PostProcessing.Api/appsettings.json

Other Documentation

How to write Json Plugins: https://blumatix.visualstudio.com/DefaultCollection/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/539/Json-Plugins-Mechanics-and-Rules

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Plugins-Overview.md - Chunk 3
Other Documentation

How to write Json Plugins: https://blumatix.visualstudio.com/DefaultCollection/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/539/Json-Plugins-Mechanics-and-Rules

How to write WhiteList Plugins: https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/WhiteListSearch/670/WhiteListSearch

Architecture Overview: https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/541/SmartLib-Plugin-Solution

PostProcssor Docu: https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/PostProcessing/860/PostProcessing

How to update dynamic config: Dynamic Config - Overview

Write the MOP here: MOPs - Overview

How to deploy Capture SDK Json-Plugins: Json-Plugin-Deployment - Overview

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Programm--&-Kenntnissübersicht.md - Chunk 0
Welche Programme und Kenntnisse Mitarbeitende unbedingt brauchen, um einen reibungslosen Ablauf zu gewährleisten:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Programm--&-Kenntnissübersicht.md - Chunk 1
Kategorien Jeder Support Rufbereitschaft 2nd & 3rd Level Support Account/Projekt Manager Programme (Mindest-Anwendungen) Adobe Acrobat oder Vergleichbares (Ebenen von PDFs) x Keeper x Outlook x Outlook Listener Postfach x x x Visual Studio Code x phönix x garuda x Microsoft SQL Server Studio Postman WinMerge Zendesk (da sind Mailadressen drin) Zugriff Repos (manifest, translations) Rechte DevOps (Issue verschieben)  Files LabelNrs (für Zuweisung der Merkmale in RIPEye) PostmanRequest Beispiele Standard Customer Config  Kenntnisse (Aufgabenbereiche wenn 1st Level nicht da ist) Issues in DevOps aufnehmen, antworten mit Issue Nr und erste Priorisierung vornehmen x x Issues richtig labeln und dann auf resolved setzen Release Mails an Kunden schicken (besonders wenn Unterbrechungen vorkommen können) Kontrollieren ob Listener e läuft im Postfach x x JSON responses interpretieren (z.B. mit OCR result, text vs. value, score, bounding box) PDF (responses) kontrollieren, analysieren,

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Programm--&-Kenntnissübersicht.md - Chunk 2
können) Kontrollieren ob Listener e läuft im Postfach x x JSON responses interpretieren (z.B. mit OCR result, text vs. value, score, bounding box) PDF (responses) kontrollieren, analysieren, inspizieren, Ebenen ansehen phoenix für Analyse verwenden (versch. Responses requesten und interpretieren) mit phönix Key ausprobieren Kunden anlegen (meist SME) und in Keeper richtig hinterlegen (garuda und SQL) mit internal User in RIPEye anmelden RIPEye Bugs reproduzieren durch CustomerConfig von z.B. manual_test anpassen Customer Config anpassen, ev. mit WinMerge miteinander vergleichen Neue Details im manifest, translations und Customer hinzufügen Rechnung über Namen oder ID in Datenbank finden und States nachverfolgen Kudu Logs ansehen und interpretieren (z.B. Mandator gibts eig nicht) Requests mit Postman ausprobieren/nachbauen Triage vorbereiten und leiten x Monthly Review vorbereiten und leiten x

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\QRCode-and-BarCode.md - Chunk 0
Documentation

QRCode

BarCode

Important

Bludelta does not return empty predictions for either BarCodes or QRCodes

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Ready4Training-Issue-Process-with-Learn-API-(Swagger).md - Chunk 0
Submit Invoices/Documents for Training

Step 1:

Get Latest Ready4Training Issue(s) -> Open API Training Issue List in new Browser (Tab)

Step 2:

Only issues with an open task named 'Learn API Upload' are processed

Step 3:

Check issue -> find out which details need to be labeled and which Customer is affected

Step 4:

Download all attached documents for labeling and make a zip file out of them

Step 5:

Get the Customer Keys from auth DB

Step 6:

Open the document Uploader Tool -> Link zu Swagger UI 1. Enlarge Package -> POST /v1/Package 2. Click on 'Try it out'

The following fields must be filled in

X-ApiKey = Token

X-ApiIdentifier = ApiIdentifierKey

DocumentType -> If it is an invoice, leave it blank. Otherwise enter a DocType according to the list above it

Package -> all docs as zip file

Tags: Support, #00000 (=Issue Nr), Supplier, Mandant, LabelType according to Blu Doc spelling (eg. SenderReceiver.Id) -> Blu Doc Spelling Link: Invoice Schema - Overview

Execute

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Ready4Training-Issue-Process-with-Learn-API-(Swagger).md - Chunk 1
Tags: Support, #00000 (=Issue Nr), Supplier, Mandant, LabelType according to Blu Doc spelling (eg. SenderReceiver.Id) -> Blu Doc Spelling Link: Invoice Schema - Overview

Execute

After the upload, wait for Code 200 (=Success)

Note the package ID + Tags in the related Issue

Change 'Learn API Upload' Task State from 'New' to 'Closed'

Optional: If more than just the standard details need to be labeled for the documents, please create a Task on the DM Management Board (#21823) and enter details that are not part of the standard, such as LineItems, Contacts, etc. in the title

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Ready4Training-Issue-Process-with-RIPEye.md - Chunk 0
[[TOC]]

Blu Delta Ready4Training Issue Processing via RIPEye

RIPEye offers an internal support user that is able to submit BLU DELTA API training issues

Submit One Invoice/Document for Training

Step 0: Get Latest Ready4Training Issue(s)

Open API Training Issue List in new Browser (Tab)

Download document

Step 1: Login to RIPEye

Go to your security keeper store

Get Key from "BluDeltaSME" -> "Accounts Prod Environment" -> "RIPEye Support" -> ripeye_support

Login at https://validation.bludelta.ai/

Step 2: Manually upload one invoice

Step 3: Provide Training information as Additional Props

CustomerName: from [bcsdb-auth] FROM [dbo].[Customer] (defines DataCollection name)

IssueNr: Azure DevOps Issue number e.g. 12344

Details: comma separated list, e.g. "1,23,32"; Numbers are Label Detail Id out of LabelTypes .xlsx)

Step 4: Refresh Document Overview in RIPEye and Click on Document Thumbnail to open

Step 5: In AzureDevOps

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Ready4Training-Issue-Process-with-RIPEye.md - Chunk 1
Step 4: Refresh Document Overview in RIPEye and Click on Document Thumbnail to open

Step 5: In AzureDevOps

ADD (Child) Task (Template: Task for 'Ready for Trainings' Issues' and complete the missing Infos (ContainerID, Upload Date and LabelType)

Afterwards change Task State from 'Active' to 'Closed'

Afterwards change Issue State from 'New' to 'Active'

OR in case something failed - add a comment with status update

Step 6: Correct Details WITH Bounding Box(!!!)

!!! Bahare and Jana do the labelling. If it is urgent as support, then label it yourself !!! - Use TAB to navigate through the details - Make sure bounding box is copied: -- Click on correct string in document -> value is copied automatically -> paste it into correct detail field -- OR draw a rectangle around a string (group of words) and then copy value into correct detail field -- OR if OCR could not read text then draw a rectangle, paste into detail field and correct string

Submit a Batch Upload

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Ready4Training-Issue-Process-with-RIPEye.md - Chunk 2
Submit a Batch Upload

Alternatively, a single or multiple documents can also be uploaded with Garuda:

The 3 key names are: CustomerName (-c), IssueNr (-n) and Details (-l)

An Example for Internal Support Customer with 1 invoice file: .\garuda.exe upload -u "https://validation.bludelta.ai/api" -k "sme-test-key" -i "sme-test-identifier" -f "C:\invoice\muster_rechnung_de-AT.pdf" -c "Customer Name" -n "929" -l "1,3,55"

An Example for Internal Support Customer with multiple files with defined folder of invoices: .\garuda.exe upload -u "https://validation.bludelta.ai/api" -k "sme-test-key" -i "sme-test-identifier" -d "C:\invoice" -c "Customer Name" -n "929" -l "1"

An Example for Labeling Customer with 1 invoice file: .\garuda.exe upload -u "https://validation.bludelta.ai/api" -k "sme-test-key" -i "sme-test-identifier" -d "C:\invoice" -c "Customer Name"

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Ready4Training-Issue-Process-with-RIPEye.md - Chunk 3
An Example for Labeling Customer with 1 invoice file: .\garuda.exe upload -u "https://validation.bludelta.ai/api" -k "sme-test-key" -i "sme-test-identifier" -d "C:\invoice" -c "Customer Name"

An Example for Labeling Customer with multiple files with defined folder of invoices: .\garuda.exe upload -u "https://validation.bludelta.ai/api" -k "sme-test-key" -i "sme-test-identifier" -d "C:\invoice" -c "Customer Name"

Customer Name = Provider (database table Customer MUST include the exact Customer Name)

You can find the latest version of Garuda here: Garuda

In RIPEye validate the uploaded documents and click on validate. Make sure to provide the necessary bounding box information.

During the night, the documents will be sent to the Data Collection and labels will be created. The error analysis will be started?

Administration of Support Account and user

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Ready4Training-Issue-Process-with-RIPEye.md - Chunk 4
During the night, the documents will be sent to the Data Collection and labels will be created. The error analysis will be started?

Administration of Support Account and user

Make sure that the configuration for the RIPEye Internal Support Customer includes all necessary details as Must Have Details. ! Note, currently the configuration can only be changed once a day before validating the documents. If you change the configuration during the day, documents which do not match the configuration loaded by the Data Collection Sender during the night will throw an error.

Where do I find the Key and Identifier?

A: In the bcsdb-sme-v1.0 -> Tables -> dbo.Customer. If you are lucky, they are also stored in the Keeper PW-Manager.

How to review issues that were imported?

Check in Dashboard

http://ryzen7:7000/Home/Dashboard Invoices - Overview

Check in DB:

serverbmdata.ad.blumatix.com

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Ready4Training-Issue-Process-with-RIPEye.md - Chunk 5
How to review issues that were imported?

Check in Dashboard

http://ryzen7:7000/Home/Dashboard Invoices - Overview

Check in DB:

serverbmdata.ad.blumatix.com

SELECT [Id] ,[FileName] ,[InvoiceDocumentHash] ,[Created] ,[Modified] ,[Version] ,[CreatedBy_Id] ,[ImageDocument_Id] ,[InvoiceDocument_Id] FROM [bcidb].[dbo].[Invoice] where FileName LIKE 'S[_]%'

Submit a batch download

So that the invoices don't linger with us forever, we download and confirm them on the last Thursday of each month (Kathi). You can download and confirm the uploaded documents with the following Garuda action:

Please store the files in the following directory: \\nas-01\CustomerData\Internal_Support_Customer_data\Data_RIPEyeDownloads

``` .\garuda.exe download-and-confirm -o "\nas-01\CustomerData\Internal_Support_Customer_data\Data_RIPEyeDownloads" -u "https://validation.bludelta.ai/api" -i "yourIdentifier" -k "yourApi-key”

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Ready4Training-Issue-Process-with-RIPEye.md - Chunk 6
``` .\garuda.exe download-and-confirm -o "\nas-01\CustomerData\Internal_Support_Customer_data\Data_RIPEyeDownloads" -u "https://validation.bludelta.ai/api" -i "yourIdentifier" -k "yourApi-key”

download-and-confirm Downloads and then confirms all invoices for the provided credentials --SmeWebApiUrl [-u] Url of the sme web api. Default is https://localhost:8060 --ApiKey [-k] The api key of the customer for which to execute the action. --ApiIdentifier [-i] The api identifier of the customer for which to execute the action. --OutputFolderPath [-o] An optional path to an output folder to which the results will be written.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Ready4Training-Issue-Process-with-RIPEye.md - Chunk 7
```

Future Ready4Training Issue Process

Support E-Mail: - Document received in support inbox. - Automatically create a DevOps Issue. - Mail forwarded to RIPEye inbox for processing. - Documents validated in RIPEye. - Sent to data collection. - Documents downloaded on nas and confirmed (Uploader tool). - List of issue documents stored on nas (compare csv file Lisa uses). - Automatic feedback on recognition results by current service in bcidb. - Check PBI Report (joining bcidb recognition results with RIPEye issue list). - Feedback to customer, close issue.

Customer Upload via Learn API - Customer uploads document via learn API (ideally with BLU DOC) - Data Mgt. Value Delivery Process. - ?Fedback to customer?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Receipt-API-Client---Java.md - Chunk 0
HowTo generate and use an openapi java client for our Receipt API

This document describes how to generate and use an openapi client from a openapi spec.

Prerequisites

Docker Docker is required to run the openapi generator. Install it from docker.com

java 8 or higher Install it with chocolatey: choco install jdk8

```powershell PS C:\WINDOWS\system32> choco install jdk8 Chocolatey v0.10.15 Installing the following packages: jdk8 By installing you accept licenses for the packages.

jdk8 v8.0.211 [Approved] jdk8 package files install completed. Performing other installation steps. The package jdk8 wants to run 'chocolateyInstall.ps1'. ... Software installed to 'C:\Program Files\Java\jdk1.8.0_211\'

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Receipt-API-Client---Java.md - Chunk 1
```

maven Install it with chocolatey: choco install maven

```powershell PS C:\WINDOWS\system32> choco install maven Chocolatey v0.10.15 Installing the following packages: maven By installing you accept licenses for the packages. Progress: Downloading maven 3.9.6... 100%

maven v3.9.6 [Approved] maven package files install completed. Performing other installation steps. The package maven wants to run 'chocolateyinstall.ps1'. Note: If you don't run this script, the installation will fail. ... Software installed to 'C:\ProgramData\chocolatey\lib\maven\apache-maven-3.9.6'

Chocolatey installed 1/1 packages. See the log for details (C:\ProgramData\chocolatey\logs\chocolatey.log).

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Receipt-API-Client---Java.md - Chunk 2
```

Download the openapi spec

Please download the openapi spec from the following link: powershell Invoke-WebRequest -Uri "https://capture.bludelta.ai/receipt/specs/receipt/prod/v1/swagger.yaml" -OutFile "receipt-openapi.yaml"

Generate the client with Docker

Download the openapi generator docker image:

powershell docker pull openapitools/openapi-generator-cli

Generate the client on windows with the following command:

powershell docker run --rm -it -v /d/openapi-specs:/local openapitools/openapi-generator-cli generate -i /local/receipt-openapi.yaml -g java -o /local/out/java

Compile the client with maven:

powershell cd openapi-specs/out/java mvn clean install This will generate a jar file 'openapi-java-client-1.0.jar' in the target folder.

Use the client in an example application

```java import java.io.File;

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Receipt-API-Client---Java.md - Chunk 3
Use the client in an example application

```java import java.io.File;

// Import classes: import org.openapitools.client.ApiClient; import org.openapitools.client.ApiException; import org.openapitools.client.Configuration; import org.openapitools.client.model.*; import org.openapitools.client.api.ReceiptApi; import org.openapitools.client.ApiResponse;

public class Example { public static void main(String[] args) { ApiClient defaultClient = Configuration.getDefaultApiClient(); defaultClient.setBasePath("https://capture.bludelta.ai/receipt");

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Receipt-API-Client---Java.md - Chunk 4
ReceiptApi apiInstance = new ReceiptApi(defaultClient);
String xApiKey = "YOUR_API_KEY"; // String | The customer's application key. Required for authentication
String xApiIdentifier = null; // String | The customer's api identifier key. Not required for authentication
File _file = new File("PATH_TO_RECEIPT"); // File | 
try {
  ApiResponse<String> response = apiInstance.v1ReceiptPostWithHttpInfo(xApiKey, xApiIdentifier, _file);
  System.out.println("Response status code: " + response.getStatusCode());
  System.out.println("Response headers: " + response.getHeaders());
  System.out.println("Response body: " + response.getData());
} catch (ApiException e) {
  System.err.println("Exception when calling ReceiptApi#v1ReceiptPost");
  System.err.println("Status code: " + e.getCode());
  System.err.println("Reason: " + e.getResponseBody());
  System.err.println("Response headers: " + e.getResponseHeaders());
  e.printStackTrace();
}

} }

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Receipt-API-Client---Java.md - Chunk 5
```

Compile it

powershell javac -cp "D:\openapi-specs\out\java\target\openapi-java-client-1.0.jar;D:\openapi-specs\out\java\target\lib\*" "D:\openapi-specs\Example.java"

Run it

powershell java -cp "D:\openapi-specs\out\java\target\classes;D:\openapi-specs\out\java\target\openapi-java-client-1.0.jar;D:\openapi-specs\out\java\target\lib\*;D:\openapi-specs\" Example

Output:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Receipt-API-Client---Java.md - Chunk 6
Output:

json Response status code: 200 Response headers: {api-supported-versions=[1.0], connection=[keep-alive], content-length=[83092], content-type=[application/json], date=[Tue, 16 Apr 2024 05:50:36 GMT], server=[Kestrel]} Response body: { "BluDoc.Version": "1.3.0", "Created.DateTime": "2024-04-03T11:29:19.5293973+00:00", "CreatorSoftware.Name": "BluDelta Receipt", "CreatorSoftware.Version": "1.0.0", "DocumentProvider.Name": "partner.css-Receipt", "Document.Languages": [ "de" ], "Document.Type": "Invoice", "DocumentEssentials": [ { "Confidence": 0.1015, "ConfidenceThreshold": -1, "Label": "Invoice.Id", "Location": { "Height": 31, "Left": 676, "Page": 1, "Top": 1222, "Width": 139 }, "Text": "448933", "Value": "448933" }, { "Confidence": 0.9072, "ConfidenceThreshold": -1, "Label": "Invoice.Date", "Location": { "Height": 31, "Left": 2013, "Page": 1, "Top": 871, "Width": 205 }, "Text": "08.08.2023", "Value": "2023-08-08" }, ...

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Reports-(im-Support-Postfach).md - Chunk 0
[[TOC]]

FW: Subscription for ripeye_MonitoringReport_v1 (StateMonitoringByDayCustomer)

Info: Der Power BI Report - dient hauptsächlich zur Übersicht. Wenn sich die Anzahl der Error Doks ohne ersichtlichen Grund erhöht, dann müssen wir dem nachgehen -> Welcher Kunde ist davon betroffen und warum laufen die Doks in den Error State -> Go to report (grüner Button direkt in der Mail) - kommt täglich 3x (~7:00, 12:00 + 16:00 Uhr). - ist tagesaktuell und zeigt die States der verarbeiteten RipEye Dokumente.

Weitere Schritte: IM Power BI Report den betreffenden Kunden suchen und den RipEye Account checken. Dort sieht man gleich welche Art von Dokumente in den Error laufen. Beim Beispiel oben, waren es AGB´s -> Somit alles gut

FW: Subscription for rechnungserkennung_issue_report (IssueCount)

Info: Der Power BI Report - dient als Info. Man muss nicht reagieren. - kommt 1x täglich (~7:00 Uhr). - zeigt die Rechnungserkennungsissues Issues inkl. Prio die im jeweiligen Monat angelegt wurden.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Reports-(im-Support-Postfach).md - Chunk 1
Info: Der Power BI Report - dient als Info. Man muss nicht reagieren. - kommt 1x täglich (~7:00 Uhr). - zeigt die Rechnungserkennungsissues Issues inkl. Prio die im jeweiligen Monat angelegt wurden.

FW: Subscription for rechnungserkennung_issue_report (Summary)

Info: Der Power BI Report - dient als Info. Man muss nicht reagieren. - kommt 1x täglich (~7:00 Uhr). - zeigt die neu angelegten und geschlossenen Issues pro Monat inkl. Type.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\RIPEye-Label-Order.md - Chunk 0
We started labeling via RIPEye with Issues vom 1.3. and will go from there towards todays date. We prioritize Documents/Issues as follows:

1. Date

We generally go by date, when was what Issue raised. We started working off Issue from 1.3.2023 to now. Andrea tried old Documents via the trial page from 1.1.2022 to about May 2022 and tagged them as 'Correct' because sending out 'your old document older than a year works now' is a little embarrassing. If we have to prioritize even more because there are just so many issues, we prioritize even more as follows:

2. What volumes does the customer send us.

If a customer is more important to us, because he is very big, sends us a lot of invoices and we thus make more money from them, we label more frequently and give feedback of now working invoices more frequently.

3. How pissed is the customer

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\RIPEye-Label-Order.md - Chunk 1
3. How pissed is the customer

If the customer is very pissed, we don't just label the document immediately, but also do a analysis (try with their key, look at ocr result in json if a word is interpreted wrong, if an e.g. OrderID gets matched as VatID etc.) and talk to 2nd level about it. We might raise a Bug together with 2nd level.

4. Which details do we even train via model?

Labeling something which we actually already train has more value for us.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Mail-Inbox-Processes.md - Chunk 0
Fundamental Rules:

For every NEW incoming customer issue an AzureDevOps issue must be created If you are not sure whether support has already created an issue/bug for the mail (because the Subject Line contains no Issue Number so far ;-)), you can check all entries here: RE: https://blumatix.visualstudio.com/Rechnungserkennung/_queries/query/226617a7-3bd1-4cb5-9966-a3ed560e2e4c/ SME: https://blumatix.visualstudio.com/BluDeltaSME/_queries/query/d6dd95a7-aca6-45b5-819d-a639a24097f5/

Every customer communication related to issues must be done via the BLU DELTA support email address! Using your dedicated business EMail undermines a decent handover to the next support colleague (besides the customers send their e-mails directly to your account)!

Use default support signature, do not add your direct contact data in the footer

New Incoming Support EMail:

1. Read Mail wisely and creating Issue in Azure Dev Ops

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Mail-Inbox-Processes.md - Chunk 1
Use default support signature, do not add your direct contact data in the footer

New Incoming Support EMail:

1. Read Mail wisely and creating Issue in Azure Dev Ops

Link to "How to create an Issue/Bug": https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/1104/How-to-create-an-Issue-or-a-Bug-at-Azure-Dev-Ops

2. Add the issue number to the inbox email (!Important!)

Open the email so that it is displayed in its own window (double clicking)

Write the Issue number somewhere in the Mail subject Line e.g. Blablabla / Issue #17xxxx

Safe the changes with Ctrl+S or the Safe Button (Top left side)

So now you have marked the incoming (and automatically outgoing) mail with the Issue Number, so that you can find them again later with ease

4. Reply to EMail sender confirming Issue retrieval by:

Reply to incoming emails with a personal message, check out the outging mails or ask ChatGPT

5. Move the Mail in the correct Inbox:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Mail-Inbox-Processes.md - Chunk 2
4. Reply to EMail sender confirming Issue retrieval by:

Reply to incoming emails with a personal message, check out the outging mails or ask ChatGPT

5. Move the Mail in the correct Inbox:

If the Issue does not need any further follow up then set mail status to done and move it to 'Support 2023'

otherwise flag it as open and leave it in the Posteingang

Alerts please move to Alerts (otherwise the support Inboxes are too messy)

Further Items:

How to create a Shortcut (Schnellbaustein): https://support.microsoft.com/de-de/office/schnellbausteine-4ffef7c5-7596-4e95-9faf-41c771847a7b

Standard Mail Texts: ask ChatGPT OR

A collections of mail texts the support people use frequently:

New General Issue:

Vielen Dank für das Feedback. Wir haben den Issue mit der Nr. ..... aufgenommen und werden den Fall im Meeting besprechen.

Wir haben den Issue mit der Nr. ..... aufgenommen und werden das weitere Vorgehen im Meeting besprechen.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Mail-Inbox-Processes.md - Chunk 3
Wir haben den Issue mit der Nr. ..... aufgenommen und werden das weitere Vorgehen im Meeting besprechen.

Vielen Dank für Ihr Feedback. Wir haben dafür den Issue Nr. # 15185 angelegt und werden im Team besprechen, wie wir das Problem beheben können.

New Training Issue:

wir haben den Issue mit der Nr. ..... aufgenommen und werden das/die Dokument/e dem Training hinzufügen.

wir haben den Issue mit der Nr. ..... aufgenommen und haben das/die Dokument/e dem Training bereits hinzugefügt.

New Issue but not Training (e.g. Energieversorger User Story)

wir haben den Issue mit der Nr. ..... aufgenommen und werden das Dokument zur passenden User Story <"gute Bezeichnung"> Nr. ..... hinzufügen.

New Feature Request or similar

wir haben den Issue mit der Nr. ..... aufgenommen und werden das Hinzufügen eines neuen Merkmals/Features... mit dem Projekt Owner besprechen.

Training Issue works after long time:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Mail-Inbox-Processes.md - Chunk 4
wir haben den Issue mit der Nr. ..... aufgenommen und werden das Hinzufügen eines neuen Merkmals/Features... mit dem Projekt Owner besprechen.

Training Issue works after long time:

Sie bekommen diese Mail, da Sie fehlerhaft erkannte Dokumente unserem Support gesendet haben. Wir beginnen nun, nach dem Training erfolgreich funktionierende Support-Dokumente an unsere Kunden und Kundinnen als solche zu verkünden. Folgende Dokumente funktionieren nun, und die korrespondierenden Issues werden auch hiermit geschlossen:

Training Issue works:

Sie bekommen diese Mail, da Sie fehlerhaft erkannte Dokumente unserem Support gesendet haben. Folgende Dokumente funktionieren nun, und die korrespondierenden Issues werden auch hiermit geschlossen:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Phone_-Call-forwarding-setting.md - Chunk 0
Support Phone Number: +43 660 822 9031

It is no longer possible to only forward calls when the line is busy or when there is no answer. With Spusu, all calls are forwarded without exception! When a call is forwarded, an 'Anruf in Abwesenheit' is displayed on the support cell phone.

Briefly settings for call diversion:

There are two different ways: - directly on the phone or - via the Spusu Homepage: https://www.spusu.at/login // Passwort (Keeper)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Process-&-Responsibilites.md - Chunk 0
[[TOC]]

General

Support and on-call duty (Rufbereitschaft) are two separate things.

On-call duty is for availability in case of Service Critical Issues (i.e., P1) outside of business hours. This should occur very rarely, especially considering that there are only 1 customers with premium packages!

Support should NOT occur outside of working hours.

Support must always be covered by the teams during our working hours.

Availability

Support: Monday to Friday, 9am to 5pm [5d x 8h]. On-call duty: Monday to Sunday, 8am to 7pm [7d x 11h].

Reaction Time

P1: Respond immediately (asap). Provide team and customer updates (every 4 hours).

>=P2: within 2 working days.

Inform Customer/Customerlist

If there is a P1/Maintenance/Malfunction here you find the List with e-mail addresses of all customers: BLU DELTA API Cloud: ops_mails_blu_delta_cloud_20240828_1001.csv BLU DELTA API OnPremise: ops_mails_onpremise_20240327_1310.csv BLU DELTA RIPEye: ops_mails_cloud_20240923_0816.csv

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Process-&-Responsibilites.md - Chunk 1
Simply open the CSV file in the text editor. It contains the relevant email addresses, separated by semicolons. You can copy and paste these into Outlook. Ask Kathi or Martin if you have further questions.

BLU DELTA Support Process:

BLUDELTA-SupportProcess-v4

DEPRECATED: BLUDELTA-SupportProcess-v3.docx

DEPRECATED: BLUDELTA-SupportProcess-v2.docx

DEPRECATED: BluDeltaSupportProcess.pptx

P1 Issue handling

If a customer or employee reports a P1 issue please create a P1 Issue in Azure Devops and inform the whole Team, informationsecurity@blumatix.com and if necessary affected customers. Please move the P1 Issue on the Sprint board of the affected Team and find someone who can fix the issue as soon as possible.

The following information has to be provided in the P1 issue description:

Person who detected the incident.

How was the incident noticed (report from outside the company?)?

Detailed description of the incident. What exactly happened. Impact.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Process-&-Responsibilites.md - Chunk 2
Person who detected the incident.

How was the incident noticed (report from outside the company?)?

Detailed description of the incident. What exactly happened. Impact.

Attachements - Gathering all available information about the incident (log files, screenshots, emails, conversation notes, ...).

Location, date, and time of the incident and detection.

Type of affected information.

P1 Root Cause Analysis

For every P1 issue we have to provide a Root Cause Analysis. Review the Root Cause Analysis with Product Owner and Account Management.

For the analysis please provide the following information in the comment section of the respective Issue:

When and where did the incident occur?

Did the issue occur in the past?

What exactly happened?

Who was involved and who is the attacker?

How did the attacker proceed?

Which vulnerability was exploited in which systems?

What damage has occurred so far?

What further damage is threatened?

Is there a monitoring in place?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Process-&-Responsibilites.md - Chunk 3
How did the attacker proceed?

Which vulnerability was exploited in which systems?

What damage has occurred so far?

What further damage is threatened?

Is there a monitoring in place?

Which measure worked to resolve the incident quickly?

Which measure did not work?

What could have been done better?

What needs to be changed?

Where is the documentation incomplete?

Additional P1 Information

P1 Issue Query

ISMS bei Blumatix. A16.1 – Handhabung von Informationssicherheitsvorfällen und Verbesserungen

Responsibilites

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Process-&-Responsibilites.md - Chunk 4
Responsibilities (1st Level) Support On-call duty Team Change the call forwarding from the support mobile phone -> Support Phone: Call forwarding setting . X Answer Support Calls X X Check the Support E-Mail Inbox for potential P1 Issues . Create P1 Issue and inform the whole Team , informationsecurity@blumatix.com and affected customers . Move P1 Issue on Sprint board of affected Team. X X Check the Mails at the Support Inbox . Flag it, if needed put an Issue Number on it and move it to the right (Sub)Folder. Keep the inbox clean and clear so that you can see at a glance what has already been processed and where there is still work to be done. -> Support Mail Inbox Processes X Manage the (RIPEye/Rechnungserkennung) Support Backlog . Discuss in Triage which Team (Support, Rechnungserkennung, RIPEye, Data Mgt.) has to resolve the Issue. X Manage open Issues/Bugs in the Team Backlog (Support, Rechnungserkennung, RIPEye, Data Mgt.). Prioritize Issues/Bugs within the Backlog together with

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Process-&-Responsibilites.md - Chunk 5
RIPEye, Data Mgt.) has to resolve the Issue. X Manage open Issues/Bugs in the Team Backlog (Support, Rechnungserkennung, RIPEye, Data Mgt.). Prioritize Issues/Bugs within the Backlog together with Support. Resolve Issues/Bugs that are still active. Inform Support if an Issue is resolved. X Upload Ready for Training Issues to RIPEye. Since the end of October, Jana and Bahare have taken over the labelling. The upload (incl. additional properties) is still done by the 1st level support. -> Ready4Training Issue Process with RIPEye X Every last Thursday of the month: Download and confirm all RIP Eye documents for the following Labeling Accounts: Internal Support Customer, jbx.label, aptean.label-> https://blumatix.visualstudio.com/BluDeltaSME/_wiki/wikis/BluDeltaSME.wiki/1313/How-to-download-and-confirm-the-Invoices-from-RIPEye X Rechnungserkennung und SME Triage vorbereiten und leiten (jeden Dienstag von 10:00-10:30 Uhr) unter Teams Besprechungs-ID: 364 060 001 889 / Passcode: d8pzWj.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Process-&-Responsibilites.md - Chunk 6
X Rechnungserkennung und SME Triage vorbereiten und leiten (jeden Dienstag von 10:00-10:30 Uhr) unter Teams Besprechungs-ID: 364 060 001 889 / Passcode: d8pzWj. Link zur aktuellen Query: https://blumatix.visualstudio.com/Rechnungserkennung/_queries/query/226617a7-3bd1-4cb5-9966-a3ed560e2e4c/ X Lead Regular Retrospective with Support/On-call duty Team X Support vacation/leave: Organize a stand in familiar with the Support process X

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Process-&-Responsibilites.md - Chunk 7
Customers with Premium Package (On-call duty)

eurodata

Q&A

Wo finde ich, wer Rufbereitschaft hat?

A: Im Outlook Firmenkalender "Blumatix" steht die Einteilung für die Rufbereitschaft. Die Einteilung macht Lisa, da auch die Abrechnung in ihre Verantwortung fällt.

Wer muss die Rufumleitung des Support Telefons machen bzw. was heisst es, wenn das vergessen wird?

A: Derjenige, dessen Rufbereitschafts Periode gerade endet, ist für die Weiterleitung zum Nächsten im Rufbereitschafts Kalender verantwortlich. Geschieht dies nicht bzw. wird dies vergessen, dann bleibt die Rufbereitschaft/Support über das Telefon so lange bei der Person, dessen Nummer aktiv in der Rufnummernumleitung ist. Sprich: Wer Support Anfragen über die Support Nummer erhält hat auch Rufbereitschaft/Support!

Rufumleitung privates Handy: Nachdem ich das Firmenhandy eig noch nie gesehen habe, immer nur Rufumleitung. Wie ist das mit Auslandsanrufen bzw. Rückrufen?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Process-&-Responsibilites.md - Chunk 8
Rufumleitung privates Handy: Nachdem ich das Firmenhandy eig noch nie gesehen habe, immer nur Rufumleitung. Wie ist das mit Auslandsanrufen bzw. Rückrufen?

A: Es gibt 2 Rufbereitschafts Handys, extra deswegen, dass diejenigen die nicht mit dem privaten telefonieren wollen, dieses mitnehmen können. aber wenn es in dieser Frage um die Kosten der Telefonate geht, die können natürlich über Barauslagen eingereicht werden mittels Einzelrufnachweis.

Wann mache ich als "Rufbereitschaft" was?

A: Rufbereitschaft ist 2nd Level Support, wenn 1st Level verfügbar ist (also Kathi im "Amt" ist). In dem anderen Fall ist die Rufbereitschaft 1st und 2nd Level Support in einer Person. Der Prozess gibt dazu eigentlich eine Antwort, da ein Trainingsfall in unserem Fall ein P2 ist und somit von Kathi behandelt wird.

Welche Aufgaben haben die unterschiedlichen Level Supports?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Process-&-Responsibilites.md - Chunk 9
Welche Aufgaben haben die unterschiedlichen Level Supports?

Please reed: Suport Responsibilities A: 1st Level Support (Kathi): Kundenanfragen per EMail oder Telefon entgegennehmen, Issues mit Tasks anlegen, Kunden zurückschreiben, erste Recherche bei den Issues machen

2nd Level Support (Rufbereitschaft): Kundenanfragen per EMail oder Telefon entgegennehmen, Issues mit Tasks anlegen, Kunden zurückschreiben, erste Recherche + vertiefende Analyse und fixen der Issues (je nach Knowledge)

3rd Level Support (Teams): wenn der 2nd Level mit Issue fixen ansteht wird der 3rd Level aktiviert. Analyse sollte der 2nd Level schon gemacht haben.

Training vs. System - wer macht was? Wenn Kathi nicht da ist und es kommt eine Rechnung, mit XY wird nicht erkannt, per Email rein. Kann ich das dann liegen lassen bis Kathi wieder zurück ist oder lege ich da was an?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Process-&-Responsibilites.md - Chunk 10
A: Die Aufgaben des 2nd Levels Support beinhalten auch das Anlegen der Issue und das Retourschreibung dem Kunden samt Issue Nummer. Also ja, die Mail wird beantwortet und der Issue wird richtig angelegt -> 3.2. Trainings Issue

Ist eine Übergabe notwendig?

A: Es war immer Teil des Prozesses, dass es ein Übergabe geben muss. Jeden Montag gibt es das 'Support Übergabe' Meeting zwischen den 2 betroffenen Supportlern. Bei offenen Issues und Tasks muss der Status besprochen werden, die noch aktiven Issues/Tasks müssen übergeben und umassigned werden. Sollte dies durch z.B. Krankheit nicht möglich sein, dann muss der Übernehmende so gut es geht versuchen sich anhand der Taskboards (API und SME) einen Überblick zu verschaffen. Bei Fragen könnt ihr euch auch an Kathi oder Klemens wenden.

Definition der Issue Prioritäten (P1 - P4)?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Process-&-Responsibilites.md - Chunk 11
Definition der Issue Prioritäten (P1 - P4)?

A: P1: Der Kunde (bzw. Kunde des Partners oder Partner) kann aufgrund des Issues mit unserem Services nicht mehr weiterarbeiten oder ist in seiner Produktivität erheblich beeinträchtigt. Ein Stopp der Trainingspipeline ist ab 22.5.2023 ein P1 Issue! P2: Der Kunde kann aufgrund des Issues mit unserem Services beschränkt weiterarbeiten, seine Produktivität ist aber wesentlich beeinträchtigt oder er benötigt zusätzlichen erheblichen Aufwand, um mit unserem System zu arbeiten. P3: Der Kunde kann aufgrund des Issues mit unserem Services weiterarbeiten, seine Produktivität ist leicht beeinträchtigt. Der Kunden hat keinen erheblichen Zusatzaufwand, um mit unserem System zu arbeiten. P4: Ein Fall für die Schönheitschirurgie

Wie lege ich einen Fireline item im aktuellen Sprint an?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Process-&-Responsibilites.md - Chunk 12
Wie lege ich einen Fireline item im aktuellen Sprint an?

A: Ist es aufgrund eines Issues (P1 oder Triage) notwendig im aktuellen Sprint nach dem eigentlichen Planning einen Fireline Item anzulegen dann gehe bitte wie folgt vor: - Erstelle einen Bug oder eine Story mit einem eindeutigen Titel und einer klaren Beschreibung was zu tun ist und bis wann - "Fireline: your Title (wenn notwendig: date dd.mm. EOB)" - Füge den Work Item dem aktuellen Sprint hinzu und definiere die Prio gemeinsam mit dem zuständigen Product Owner. - Informiere das Entwickler-Team über den zusätzlichen Work Item und die Prio.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Schulungen-intern-(inkl.-Links).md - Chunk 0
Regelmäßige Schulungen im Support sind von entscheidender Bedeutung, um sicherzustellen, dass wir, das Supportteam, stets auf dem neuesten Stand ist und effektiv auf die sich ständig verändernden Anforderungen und Technologien reagieren kann. Hier sind einige Gründe, warum regelmäßige Schulungen im Support unerlässlich sind:

Aktualität von Kenntnissen und Fähigkeiten: In der heutigen schnelllebigen technologischen Landschaft ändern sich Tools, Systeme und Plattformen häufig. Regelmäßige Schulungen stellen sicher, dass wir über aktuelle Kenntnisse und Fähigkeiten verfügen, um die neuesten Technologien und Softwarelösungen effizient unterstützen zu können.

Verbesserte Kundenzufriedenheit: Durch regelmäßige Schulungen können wir unsere Fähigkeiten in der Lösung von Problemen und im Umgang mit Kundenanfragen verbessern. Dies trägt dazu bei, eine höhere Kundenzufriedenheit zu erreichen, da Kunden schneller und effizienter betreut werden können.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Schulungen-intern-(inkl.-Links).md - Chunk 1
Effiziente Problemlösung: Neue Tools und Technologien erfordern oft spezifisches Wissen, um Probleme schnell zu diagnostizieren und zu beheben. Regelmäßige Schulungen ermöglichen es dem Supportteam, ihre Problemlösungsfähigkeiten zu schärfen und sicherzustellen, dass sie mit den neuesten Methoden vertraut sind.

Anpassung an sich ändernde Anforderungen: Kundenbedürfnisse und -erwartungen ändern sich im Laufe der Zeit. Durch Schulungen bleiben Supportmitarbeiter auf dem Laufenden über aktuelle Trends und können sich besser an veränderte Anforderungen anpassen, um weiterhin einen hochwertigen Service zu bieten.

Reduzierung von Fehlern: Aktualisierte Schulungen ermöglichen es den Supportmitarbeitern, bewährte Methoden zu erlernen und Fehler zu minimieren. Dies ist besonders wichtig, um mögliche negative Auswirkungen auf Kundenbeziehungen zu vermeiden.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Schulungen-intern-(inkl.-Links).md - Chunk 2
Zusammenfassend ist die kontinuierliche Schulung im Supportbereich unerlässlich, um mit den sich rasch entwickelnden Technologien und Kundenanforderungen Schritt zu halten. Dies gewährleistet nicht nur einen effizienten Supportprozess, sondern stärkt auch die Position des Unternehmens im Wettbewerbsumfeld durch die Bereitstellung eines erstklassigen Kundenservice.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Training-Error-Documents.md - Chunk 0
Training Error Documents

We now have training data error logs. You find them under \\nas-01\TrainingsDataExt4\[model_name]\logs_exceptions model_name: contact, dachser_asia, doc_type, header_details, line_items, order_confirmation, quotation, transport, vat_groups, vat_tax_id There exists one new log file with date per training data generation run. So you always find the up-to-date information in the newest log file. Every document id that is in this exception log file is NOT in the trainingsdata of the model. So if a doc id is in the trainings view and not in the exception log file, then it is used for training.

The exceptions log file has three columns: Document id, Exception, Message

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Under-Construction.md - Chunk 0
As the subpages are very confusing, Kathi checks pages for topicality, correctness and usefulness. After the revision, they are reorganised.

[[TOSP]]

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\XInvoice.md - Chunk 0
With the implementation of user story #22376 customers can send XInvoice to our service. The xInvoice can have one of the following formats:

XML only

PDF with embedded XML

XML with embedded pdf

Api-Endpoint via https://api.bludelta.ai/v1-18

In dynamic config we can enable XInvoice feature for customers under the section Workflows: "Workflows": { "AsiaWorkflow": { .... }, "XInvoiceWorkflow": { "Enabled": true, "CustomerNames": [ "xinvoice.integration"], "SupportedLanguages": [], "ValidXInvoiceErrorRegex": "\\bValid XInvoice\\b", "XInvoiceFormatErrorRegex": "\\bAn error occurred during XInvoice conversion\\b" } }, ValidXInvoiceErrorRegex and XInvoiceFormatErrorRegex should not be changed. Currently we have enabled this feature only for internal use.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\XInvoice.md - Chunk 1
In short if XInvoice is enabled for a customer then we check the invoice if it is PDF file and has embedded XML or it is a XML file only then it is send to our Workflow Server endpoint XInvoice and it delivers a API Response for valid XInvoice. For more exception handling and using default workflow in failure cases or delivering empty response please find the information in link given below.

For more information please see the link: https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/WorkflowServer/2531/XInvoice-Endpoint

XInvoice Visualization

Can be enabled via dynamic_config per customer. For further information please follow the link: https://blumatix.visualstudio.com/DefaultCollection/Rechnungserkennung/_wiki/wikis/WorkflowServer/2576/XInvoice-Visualization

XInvoice Validation

XInvoices are validated against Mustang Library https://www.mustangproject.org/commandline/#validate within the User Story #23334. Please see the table:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\XInvoice.md - Chunk 2
XInvoice Validation

XInvoices are validated against Mustang Library https://www.mustangproject.org/commandline/#validate within the User Story #23334. Please see the table:

When a XInvoice is uploaded, the system sends a detailed error message and corresponding error code to the customer with error HTTP error code 400. The error code is mapped to an overall error description based on the table provided above, but the user himself gets a detailed version like:

400 The provided xml file cannot be interpreted as valid X-Invoice. An error occurred during XInvoice conversion. Error code: 18. Error message: Invalid content was found starting with element 'ram:ActualDeliverySupplyChainEvent'. No child element is expected at this point.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\XInvoice.md - Chunk 3
WITH BODY ``` { "ResponseStatus": { "ErrorCode": "BadRequest", "Message": "The provided xml file cannot be interpreted as valid X-Invoice. An error occurred during XInvoice conversion. Error code: 18. Error message: Invalid content was found starting with element 'ram:ActualDeliverySupplyChainEvent'. No child element is expected at this point.", "Errors": [] } } `

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\XInvoice.md - Chunk 4
```

400 The provided xml file cannot be interpreted as valid X-Invoice. An error occurred during XInvoice conversion. Error code: 18. Error message: Invalid content was found starting with element '{"urn:oasis:names:specification:ubl:schema:xsd:CommonAggregateComponents-2":OriginCountry}'. One of '{"urn:oasis:names:specification:ubl:schema:xsd:CommonAggregateComponents-2":CommodityClassification, "urn:oasis:names:specification:ubl:schema:xsd:CommonAggregateComponents-2":TransactionConditions, "ur

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\XInvoice.md - Chunk 5
WITH BODY { "ResponseStatus": { "ErrorCode": "BadRequest", "Message": "The provided xml file cannot be interpreted as valid X-Invoice. An error occurred during XInvoice conversion. Error code: 18. Error message: Invalid content was found starting with element '{\"urn:oasis:names:specification:ubl:schema:xsd:CommonAggregateComponents-2\":OriginCountry}'. One of '{\"urn:oasis:names:specification:ubl:schema:xsd:CommonAggregateComponents-2\":CommodityClassification, \"urn:oasis:names:specification:ubl:schema:xsd:CommonAggregateComponents-2\":TransactionConditions, \"ur", "Errors": [] } }

IMPORTANT FOR SUPPORT:

The error message for HTTP Error Code 400 for XInvoice is truncated after 512 characters. Unfortunately, this cannot be fixed at the moment as it requires significant effort due to a limitation in the currently used ServiceStack library.

Azure Workbook for Ops (XInvoice HttpStatus Distribution)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\XInvoice.md - Chunk 6
Azure Workbook for Ops (XInvoice HttpStatus Distribution)

You can find the following statistic in the Azure Portal by searching for resource: capturesdk-workbook-otel-prod-weu-01

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Accantum.md - Chunk 0
Important Informations Related Issue tba Partner or Customer Partner API or RIPEye API Name in auth DB Accantum MainKey Nutzungsbeginn tba Paket tba E-Mail Susanne Münzker Consulting & Vertrieb T +43 676 37 04 694 E susanne.muenzker@accantum.at Stefan Melzer Geschäftsführer IT Prozess Manager s.melzer@accantum-digital.at Mobil:+43 664 8456856 Tel: +43 662 873814 Fax:+43 662 873814-90 Customers Specifics Im Falle von gehäuften Recognitionfehler bei einem Lieferanten erstellt Accantum Erfassungsvorlagen für den jeweiligen Supplier (siehe z.B. 22727) -> Erfassungsvorlage bedeutet, dass die Dokumente des Suppliers gänzlich vom KI Vorgang entfernt werden. Die Rechnungen landen nicht mehr bei uns

Alle aktiven Accantum Accounts der auth db:

Produktiv: Accantum MainKey Accantum Digital Productive via Accantum MainKey Printvision Productive via Accantum Main Key SYSco EDV Productive via Accantum Main Key

Demo: Accantum Demo via Accantum MainKey

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Accantum.md - Chunk 1
Demo: Accantum Demo via Accantum MainKey

Test: PraKom Software GmbH Test via Accantum Main Key Printvision Test via Accantum Main Key

Abgelaufen: Act GmbH Test via Accantum MainKey (2021-03-01) Accantum Test via Accantum MainKey (2022-01-01) Kiska Productive via Accantum MainKey (2023-05-01)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\ALD-Autoleasing-GmbH.md - Chunk 0
Important Informations Related Issue tba Partner or Customer tba API or RIPEye API Capture Service no Workflow Service only Quotations Name in auth DB Nutzungsbeginn tba Paket tba E-Mail Anika Grimm - IT Entwicklerin - anika.grimm@aldautomotive.com - T +49 40 47104 7301 Carsten Voss - Chef? - carsten.voss@aldautomotive.com Marco Jeffrey Pansa - marcojeffrey.pansa@aldautomotive.com  -Data Scientist, Business Intelligence Competence Center Tina Bialucha - ?? - tina.bialucha@aldautomotive.com Customers Specifics

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Amt-der-Vorarlberger-Landesregierung.md - Chunk 0
Important Informations Related Issue tba Partner or Customer Customer API or RIPEye API Name in auth DB vorarlberg vorarlberg.trial Nutzungsbeginn May 2024 Paket Prepaid Kunde (startet klein, wird vermutlich mehr) E-Mail Christian Fischer Abteilung Informatik (PrsI) Amt der Vorarlberger Landesregierung Landhaus,  6901 Bregenz, Österreich T +43 5574 511 20532 F +43 5574 511 920595 christian.fischer@vorarlberg.at Customers Specifics Prepaid Kunde; legt viel Wert auf die DSGVO

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner.md - Chunk 0
[[TOC]]

General

Important Informations Related Issue tba Partner or Customer Partner API or RIPEye RIPEye Name in auth-DB Ramsauer & Stürmer Software GmbH partner.ramsauerstuermer.xxx Nutzungsbeginn tba Paket tba E-Mail tba Customers Specifics tba

[[TOSP]]

Aptean is a bit complex, since there are two of them: - Aptean Austria GmbH, former Ramsauer & Stürmer (Exit in 2022) - Aptean DACH GmbH, including oxaion GmbH, requests for new keys often coming from Holger Ritz

We have a separate contract with each of them, and each of them uses a different product: - Aptean Austria: BLU DELTA RIPEye New Aptean Austria customers need to be added to databases bcsdb-auth, bcsdb-sme-v1.0 and smedb-v1.0, belonging to productive Key called "Ramsauer & Stürmer Software GmbH", ID = 103 in bcsdb-auth - Aptean DACH: BLU DELTA API New Aptean DACH customers only need to be added as new ApiIdentifierKey to database bcsdb-auth, belonging to productive Key called "Aptean DACH Productive", ID = 348

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner.md - Chunk 1
Aptean Austria GmbH - BLU DELTA RIPEye Integration

Add a new Aptean Austria Customer to RIPEye

[[TOC]]

Necessary information provided by R&S (Aptean)

Please inform Martin about the new Customer!

In order to add a new customer we need some basic information's from R&S (Consultants). 1. Customer Name 2. Ein Csv mit den benötigten Mandanteninformationen: Mandant XXX: Name Straße, Nummer PLZ, Ort UID

ClientId Name ReceiverVatId Street ZipCode City ClientEmail FeedbackEmail ContactEmail 100 TestMandant DE11111111 Hauptstraße 1 54824 Hamburg invoice.testMandant@company.com feedback@company.com max.mustermann@company.com 101 TestMandant DE11111111 Hauptstraße 1 54824 Hamburg invoice.testMandant@company.com feedback@company.com simone.musterfrau@company.com 3. Customer Mail Address from which documents will be sent to bludelta@blumatix.com 4. Feedback Mail Address to inform Customers in case an E-Mail could not be processed

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner.md - Chunk 2
R&S logs into the UI via accesstoken - thus no user management needs to be done on our side.

Internal Users are created so we can log into a customer account when a new support case opens up. R&S only need the Token and the Api-Identifier.

The Mandator number must be the same as the one in the DB, on the end of the APIIdentifierKey after a dot!

We will then use the configuration of an existing R&S customer such as SSK as default to add the new customer. In case additional details or other configurations are necessary please discuss the requirements with the R&S Consultant.

~~Add the new customer in the file \\192.168.137.12\BluDeltaSupport\Kundenliste.xlsx - Sheet Companies and Contacts. If no other contact is defined then R&S will be our contact.~~

Default fields for new Aptean customers / mandators

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner.md - Chunk 3
Default fields for new Aptean customers / mandators

Please store the default order of the fields in the order in which they are listed below. Very few users will change that. Plus sign next to the field means it can occur more than once.

Mandatory

DocumentType InvoiceCurrency InvoiceId InvoiceDate SenderVatId GrandTotalAmount VatGroup (+)

Nice to Have

Iban (+) ReceiverOrderId (+) DeliveryDate

Default Aptean Customer Configuration

see default Customer Configuration: [CustomerConfiguration](/Support/CustomerConfiguration)

Aptean Handout

Verantwortung von BLU DELTA

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner.md - Chunk 4
Default Aptean Customer Configuration

see default Customer Configuration: [CustomerConfiguration](/Support/CustomerConfiguration)

Aptean Handout

Verantwortung von BLU DELTA

BLU DELTA extrahiert relevante Informationen aus semistrukturierten Dokumenten (z.B. Rechnungen) und gibt diese in einem strukturiertes JSON Format zurück. Die Browser-Oberfläche RIPEye ermöglicht die Validierung (Kontrolle und Korrektur) der Ergebnisse. BLU DELTA führt keinen Abgleich mit Stammdaten durch. Im Anhang findet ihr ein Excel-File mit den erforderlichen Feldern zur Anlage eines neuen Kunden. Wir benötigen ein File pro Kunde, dieses enthält eine Zeile pro Mandant. Customer.xlsx

Neukundenanlage

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner.md - Chunk 5
Neukundenanlage

Für die Anlage von Neukunden in BLU DELTA schicken sie bitte die folgenden Information an bludelta-support@blumatix.com: - ClientId: Die Mandantennummer, so wie sie im Request mitgegeben wird (meistens 3 Buchstaben oder Ziffern bei euch) - Name: Der Name des Madnanten, wird so in der Weboberfläche angezeigt - ReceiverVatId: Die UstId des Mandanten - Street: Straße + Hausnummer - ZipCode: Postleitzahl - City: Stadt - ClientEmail: Optional, nur wenn Email als Eingangskanal genutzt wird. EMail Adresse des Mandanten, von der aus Dokumente an bludelta@blumatix.com gesendet werden. - FeedbackEmail: Optional, nur wenn Email als Eingangskanal genutzt wird. EMail-Adresse um den Kunden zu informieren falls eine Nachricht nicht verarbeitet werden konnte. - ContactEmail: Optional, wird verwendet um Informationen über BLU DELTA Wartungsfenster zu senden.[ACHTUNG: Das muss eigentlich über den Aptean Support geschehen!]*

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner.md - Chunk 6
ClientId Name ReceiverVatId Street ZipCode City ClientEmail FeedbackEmail ContactEmail 101 TestMandant1 DE11111111 Hauptstraße 1 54824 Hamburg invoice.testMandant@company.com feedback@company.com max.mustermann@company.com 102 TestMandant2 DE11111122 Hauptstraße 2 54824 Hamburg invoice2.testMandant@company.com feedback@company.com simone.musterfrau@company.com Sobald der BLU DELTA Support die Anlage bestätigt, kann BLU DELTA für ihren Kunden freigeschaltet werden.

Darüber hinaus benötigen wir das Go Live Datum für diesen Kunden, da ab diesem Tag die Verrechnung startet. Informationen anderer Art, z.B. aus Screenshots aus der RS2 Maske, können wir leider zukünftig nicht mehr annehmen. Wir legen standardmäßig keinen Kunden auf dem Testsystem an. R&S (Aptean) kann bis zum Go Live den produktiven Account kostenfrei zum Testen verwenden. (siehe Mail von Martin an Apte4an vom 07.02.2024)

Support

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner.md - Chunk 7
Support

Der 1st level Support wird von Aptean übernommen. Aptean filtert welche Supportfälle Aptean betreffen und welche nur durch Blumatix gelöst werden können. Die Kundenkommunikation findet ausschließlich über den Support von Aptean statt.

Weiterführende Informationen

Umfangreiche Informationen zu BLU DELTA finden sie in unserem Dev Center unter https://www.bludelta.de/de/ressourcen/dev-center-for-invoice-and-document-capture/

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-DACH.md - Chunk 0
Important Informations Related Issue #18683 Partner or Customer Partner mit 25+ Customer API or RIPEye API Name in auth DB Aptean DACH Productive Nutzungsbeginn tba Paket tba E-Mail Holger.Ritz@aptean.com Customers Specifics QR Code und Barcode wird automatisch für jeden neuen Aptean DACH Kunden freigeschaltet, wenn man sich an die Naming Convention hält (partner.aptean.*) Kunde hat Labelkey -> Labelt Rechnungen via RipEye unter folgendem Key-> partner.aptean.label Kunde hat Testkey für potentielle Neukunden -> partner.aptean.trial

Aptean is a bit complex, since there are two of them: - Aptean Austria GmbH, former Ramsauer & Stürmer (Exit in 2022) - Aptean DACH GmbH, including oxaion GmbH, requests for new keys often coming from Holger Ritz

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-DACH.md - Chunk 1
We have a separate contract with each of them, and each of them uses a different product: - Aptean Austria: BLU DELTA RIPEye New Aptean Austria customers need to be added to databases bcsdb-auth, bcsdb-sme-v1.0 and smedb-v1.0, belonging to productive Key called "Ramsauer & Stürmer Software GmbH", ID = 103 in bcsdb-auth - Aptean DACH: BLU DELTA API New Aptean DACH customers only need to be added as new ApiIdentifierKey to database bcsdb-auth, belonging to productive Key called "Aptean DACH Productive", ID = 348

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-DACH.md - Chunk 2
Aptean DE Customer; Stand 12.09.2024 Aptean DACH Internal via Aptean DACH Productive partner.aptean.bernstein partner.aptean.besecke partner.aptean.bueterhebetechnik partner.aptean.carlberberich partner.aptean.deltamessdwwf (gekündigt mit 07.02.2024) partner.aptean.dillingerfabrikgelochterblechegmbh partner.aptean.dwthandel partner.aptean.examion partner.aptean.gfaelektromaten partner.aptean.haenslermedical partner.aptean.hik partner.aptean.kerndeudiam partner.aptean.KGRZKoblenz partner.aptean.kienzler partner.aptean.ltslicht partner.aptean.lvgdienstlayer partner.aptean.motometer partner.aptean.nussbaumautomotive partner.aptean.pantecengineering partner.aptean.rodriguez partner.aptean.selectricnachrichtensystemegmbH partner.aptean.trial partner.aptean.trioptics partner.aptean.vetterkabel partner.aptean.zuther

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Arineo.md - Chunk 0
Important Informations Related Issue tba Partner or Customer tba API or RIPEye tba Name in auth DB tba Nutzungsbeginn tba Paket tba E-Mail tba Customers Specifics nothing known

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\ARS-Electronica.md - Chunk 0
Important Informations Related Issue #22297 Partner or Customer Customer Name in auth DB ars-electronica API or RIPEye API Services Invoice Service only Name in auth DB tba Nutzungsbeginn August 2024 Paket 1k prepaid E-Mail Corinna Löcker, ERP Inhouse Consultant, T: +43-732-7272, Mobil: +43 699 177 815 57, E-Mail: corinna.loecker@ars.electronica.art Customers Specifics tba

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Artaker.md - Chunk 0
Important Informations Related Issue tba Partner or Customer tba API or RIPEye tba Name in auth DB tba Nutzungsbeginn tba Paket tba E-Mail tba Customers Specifics tba

Custom Detail

WhiteListPlugin: RealEstateObjectId - finds object ids via whitelist resource in azure storage

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Avvaneo.md - Chunk 0
Important Informations Related Issue tba Partner or Customer Partner API or RIPEye API Name in auth DB tba Nutzungsbeginn tba Paket tba E-Mail tba Customers Specifics Elastic Search Plugin -> appsettings.json - Repos

Custom Detail

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\BDS.md - Chunk 0
Important Informations Related Issue #20080 Partner or Customer Partner API or RIPEye API Name in auth DB BDS GmbH & Co KG Produktiv Nutzungsbeginn 2021 Paket 1-2k/Monat pro Kunde Kontakt Robert Strach - rstrach@bds.at oder robert.strach@bds.at - T: +43 5574 45338 Customers Specifics max. Pages lt. Dyn Config: 16 (US #12340)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\BDS.md - Chunk 1
Customers lt. auth DB: BDS GmbH & Co KG Test BDS GmbH & Co KG Produktiv AT Thurner Bau GmbH via BDS Produktiv Johann Huter & Söhne via BDS Produktiv Ing. Hans Lang GmbH via BDS Produktiv Kostmann GmbH via BDS Produktiv Hefel Immobiliengruppe GmbH via BDS Produktiv Fröschl AG & Co KG via BDS Produktiv Alfred Trepka GmbH via BDS Produktiv Empl Bau GmbH via BDS Produktiv Hartl Bau GmbH via BDS Produktiv Felbermayr Holding GmbH via BDS Produktiv SSB Sanierung Straße Brücke Bau GmbH via BDS Produktiv Gebrüder Haider Bauunternehmung GmbH via BDS Produktiv Herzog Bau GmbH via BDS Produktiv Winkler & Co GmbH via BDS Produktiv Oberhauser & Schedler Bau GmbH via BDS Produktiv Mayr Bau GmbH via BDS Produktiv Bodner Test via BDS Test Rhomberg Fahrleitungsbau GmbH via BDS Produktiv Haberl Baugesellschaft m.b.H. via BDS Produktiv Anton Pletzer GmbH via BDS Produktiv Wiesinger Bau GmbH via BDS Produktiv GTB Bau GmbH via BDS Produktiv Hitthaller + Trixl Bau GmbH via BDS Produktiv partner.bds.dreihans

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\BDS.md - Chunk 2
m.b.H. via BDS Produktiv Anton Pletzer GmbH via BDS Produktiv Wiesinger Bau GmbH via BDS Produktiv GTB Bau GmbH via BDS Produktiv Hitthaller + Trixl Bau GmbH via BDS Produktiv partner.bds.dreihans partner.bds.bodner partner.bds.schueller partner.bds.rhzbau partner.bds.gerstl partner.bds.bemotunnelling partner.bds.spiluttini partner.bds.schmiedholding

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Because-Software.md - Chunk 0
Important Informations Related Issue #18590 Partner or Customer Partner API or RIPEye BLU DELTA API Name in auth DB partner.because Nutzungsbeginn 01.01.2024 Paket 1k monatlich (Abrechnung im Nachhinein mit Auswahl des passenden Paketes und reporting der Transaktionszahlen pro Kunde) E-Mail office@because-software.com  lmrkos@because-software.com Customers Specifics nothing known

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Bechtel-(Naabtaler-Milchwerke).md - Chunk 0
Important Informations Related Issue tba Partner or Customer Customer API or RIPEye API Name in auth DB bechtel bechtel.trial Nutzungsbeginn tba Paket tba E-Mail Melanie Zechmann T  +49 9435/308-6035 F  +49 9435/308-0 Melanie.Zechmann@Privatmolkerei-Bechtel.de Fabian Eisermann Mitarbeiter Prozesse Organisation IT T  +49 9435/308- F  +49 9435/308- Fabian.Eisermann@Privatmolkerei-Bechtel.de Customers Specifics nothing known

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Blumatix-Accounting-(Lisa).md - Chunk 0
[[TOC]]

Important Informations Related Issue tba Partner or Customer Partner und Customer API or RIPEye RipEye mit Maileingang Name in smedbtest Blumatix Accounting Customer Test Blumatix Accounting Partner Test Nutzungsbeginn tba Paket tba E-Mail tba Customers Specifics Lisa arbeitet ausschließlich im Testsystem -> Alle Rechnungsmails die auf invoices@blumatix.com ankommen, werden automatisch an ein Test-Postfach weitergeleitet (bludelta-test@blumatix.com) -> von diesem Test Postfach kommen die Rechnungen dann ins Test RipEye (https://validation-test.bludelta.ai); Postfach wurde von Julian eingerichtet

Blumatix Accounting

Blumatix uses the RIPEye test environment for incoming invoices (E-Mail forward). As friendly customer they can report issues before the release on production.

Uploader tool

The uploader tool (developed and maintained by @<2AC19029-9DF1-6308-B6D1-F217206843B6>) is used to regularly download and store the documents and results (csv file) on the nas.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Blumatix-Accounting-(Lisa).md - Chunk 1
Uploader tool

The uploader tool (developed and maintained by @<2AC19029-9DF1-6308-B6D1-F217206843B6>) is used to regularly download and store the documents and results (csv file) on the nas.

Path: \\nas-01\DataCollection\BlumatixAccounting

The uploader tool currently runs on machine 192.168.137.70. For more information regarding this tool please see the following link https://blumatix.visualstudio.com/BluDeltaExternalTools/_wiki/wikis/Bludelta%20Uploader-Tool/314/README.

Configuration of App Config: File content of BludeltaInvoiceCapture.exe.config is in Keeper under "Uploader Tool Internal Config"

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Blumatix-Accounting-(Lisa).md - Chunk 2
Configuration of App Config: File content of BludeltaInvoiceCapture.exe.config is in Keeper under "Uploader Tool Internal Config"

Docker commands: - To navigate into the application (path is mounted so that we can store the data to NAS): docker run -it -v H:\BlumatixAccounting\:C:\BlumatixAccounting blumatixdevregistry.azurecr.io/invoice-uploader-client:3.0.15 - Run the application directly: docker run -it -v H:\BlumatixAccounting\:C:\BlumatixAccounting blumatixdevregistry.azurecr.io/invoice-uploader-client:3.0.15 .\BludeltaInvoiceCapture.exe

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Blumatix-Accounting-(Lisa).md - Chunk 3
Application runs as task daily with version 3.0.15: - The application is added to run daily on 192.168.137.70: .\scheduled_task.ps1 -Action NewTask -Executable docker.exe -Argument "run -v H:\BlumatixAccounting\:C:\BlumatixAccounting blumatixdevregistry.azurecr.io/invoice-uploader-client:3.0.15 .\BludeltaInvoiceCapture.exe" -AtTime "00:00 AM" -User SYSTEM -TaskName "InvoiceUploaderClient" - scheduled_task.ps1 exists on D drive of 192.168.137.70

Uploader tool trouble shooting

Please contact @<2AC19029-9DF1-6308-B6D1-F217206843B6> or TBA for immediate help.

20612

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Compacer.md - Chunk 0
Important Informations Related Issue tba Partner or Customer Partner API or RIPEye API Name in auth DB Compacer Produktiv Compacer Test Trace4Com via Compacer Produktiv Trade4Com via Compacer Test Nutzungsbeginn tba Nutzungsende 31.12.2024 Paket tba E-Mail tba Customers Specifics nothing known

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Dachser.md - Chunk 0
Important Informations Related Issue tba Partner or Customer tba API or RIPEye tba Eigener Labelaccount tba Name in auth DB tba Nutzungsbeginn tba Paket tba Support Paket Premium Support 11x 7 von Mo-Fr 08:00 - 19:00 Uhr E-Mail kta-info.kempten@dachser.com  (Die Mail erhalten dann alle 7 relevanten Personen beim KTA Dachser Team); das KTA Team ist so weit ich nicht weiss nicht direkt in der Firma; im KTA Team sind Mike Hoffmann (Teamleiter), Oliver Lass, Nikol Martin, Oliver Lass, Simon Hügel,?? olga.schoenhardt@dachser.com (Frau Olga Schönhardt // DevOps Engineer, Financial Digitalization & Development, Corporate Financial Systems & Processes); sie ist bei der Dachser Group SE und Co Kg / Head Office ezgi.senyuecel@dachser.com (Frau Ezgi Gülcem Senyücel // Financial Digitalization & Development, Corporate Financial Systems & Processes); sie ist bei der Dachser Group SE und Co Kg / Head Office Customers Specifics Mehrere Systeme: Test und Produktion Mehrere Projekte bzw Keys: AI KTA

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Dachser.md - Chunk 1
Corporate Financial Systems & Processes); sie ist bei der Dachser Group SE und Co Kg / Head Office Customers Specifics Mehrere Systeme: Test und Produktion Mehrere Projekte bzw Keys: AI KTA BEST für normale Rechnungen (Test und Prod Key), OC (mind Prod Key), und geplant Klassifizierung und Trennung (mind Prod Key) OCR Performance am 13.03.2024 von 16 Seiten auf 12 Seiten gesenkt (wir sind um ca. 2sek schneller)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Dachser.md - Chunk 2
Additional Properties (Customer specific)

DachserReceiverId --> via Dachser specific Post-Processing (Dachser Post-Processing)

DachserSenderId --> via Dachser specific Post-Processing (Dachser Post-Processing)

HAWBId --> DLL-Plugin (Bludelta PlugIn Overview)

DachserPurchaseOrderId --> JSON-Plugin (Bludelta PlugIn Overview) --> Validation in Dachser Postprocessing that the OrderId is in the customer master data (ExternalPostProcessing)

TransportTourId --> via Dachser specifig Plugin in Post-Processing (Dachser Post-Processing Plugin) that normalizes results from TyphonTransport-model.

-->

If Post-Processing has multiple candidates for the DachserReceiverId and it cannot clearly decide which one to predict, then it checks if an AdditionalProperty with key "Customer.BranchId" was passed. If the value of the passed-in "Customer.BranchId" matches a vendor number of one of the DachserReceiverId-Candidates, then we return this Vendor Number as DachserReceiverId with Score 0.59.

-->

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Dachser.md - Chunk 3
-->

If AdditionalProperty with key "DocumentReceiverCountry" and Value "IN" is passed, then we try for all incoming VatIds if they represent a GSTIN from which we can generate/extract a PAN. If possible, then we search for both (GSTIN and PAN) in VatId- and TaxId-columns of master data.

If we find a DachserSenderId or DachserReceiverId and we are confident that this prediction is correct (Score = 0.99), then we check if we can perform a correction of a possibly invalid corresponding Sender- or ReceiverVatId prediction, because the VatId is part (a column) of the Dachser masterdata which is stored and retrieved from elastic. We only perform a correction of invalid classified VatIds! We do not predict VatIds which were not found by the CaptureSdk (which may not be written onto the Document)!

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Dachser.md - Chunk 4
Currently there are some limitations in the process of changing existing CaptureSdk predictions in the (External-)PostProcessing. Therefor (for VatIds corrected in PostProcessing) it can happen for Dachser that our API-Response delivers a VatId classified as Receiver- or SenderVatId (TypeName: ReceiverVatId | SenderVatId) and the same VatId also as unclassified VatId (TypeName: UId). As discussed with Martin, this should not be a problem for Dachser and we accept this for now.

Dachser has specific RecommendedThresholds which are configured via the dynamic config (Thresholds-Config) You can find the currently configured Thresholds via the following Link: DynamicConfig (as deployed to Production)

VatGroups (Typhon) https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Typhon/792/VatGroups

DocType (Typhon) https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Typhon/829/DocType

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Dachser.md - Chunk 5
DocType (Typhon) https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Typhon/829/DocType

Documents written mainly in korean and chinese characters are supported via a totally different internal Asia-workflow, using EasyOcr and NuanceOcr with parameter TextOnly (value is true or false) as OcrEngine and a seperate Typhon-model. The decision, which workflow is executed (Default vs asia) is done by a DocClassifier-model. If a korean or chinese invoice consists of mostly romanian characters (written in english), then the Default-Workflow will be triggered.

There are two cases, each containing two subcases for sending the requests to Nuance- or EasyOcr.

Chinese invoices:

If invoice is pdf and text only --> NuanceOcr with TextOnly setting

else --> NuanceOcr without TextOnly setting

All other invoices (we only have korean invoices):

If invoice is pdf and text only --> NuanceOcr with TextOnly setting

else --> EasyOcr

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Dachser.md - Chunk 6
else --> NuanceOcr without TextOnly setting

All other invoices (we only have korean invoices):

If invoice is pdf and text only --> NuanceOcr with TextOnly setting

else --> EasyOcr

The Asia Workflow can only be triggered when Dachser send the Additional property "DocumentReceiverCountry" with value "KR" and "CN"

Ocr is done by EasyOcr (not Nuance)

Only 1 specific Typhon model is responsible for all predictions that we deliver, except for DachserSenderId and DachserReceiverId which come from same PostProcessing as in Default workflow

The Api-Response generated via the Asia-workflow is complete, but many predictions will be empty here

GrandTotalAmount

InvoiceDate

InvoiceId

SenderVatId

ReceiverVatId

HAWBId

ReceiverTaxId

SenderTaxId

DeliveryDate

VatGroup

BankGroup

DachserReceiverId --> This is directly mapped to value "0000000456" for all Requests with AdditionalProperty "DocumentReceiverCountry" with value "KR", even when executed by the Default-Workflow

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Dachser.md - Chunk 7
DachserReceiverId --> This is directly mapped to value "0000000456" for all Requests with AdditionalProperty "DocumentReceiverCountry" with value "KR", even when executed by the Default-Workflow

DachserSenderId

Wiki Page

Public Endpoint: https://api.bludelta.ai/doc-splitter/v1/doc-splitter

Misc: Only pdfs are allowed to upload.

When Dachser is using the Learn API the documents are imported to our BCI database and labels are created.

allvendors.csv

receivers.csv

povendors.csv

Release Notes #16467 Der Order Confirmation Service unter folgender URL angesprochen werden: https://capture.bludelta.ai/order-confirmation/v1/order-confirmation

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Diamant.md - Chunk 0
Important Informations Related Issue tba Partner or Customer tba API or RIPEye tba Name in auth DB tba Nutzungsbeginn tba Paket tba E-Mail tba Customers Specifics Infos falscher Doc Type schmerzt Diamant sehr, da die Docs ganz unterschiedliche interne Wege gehen

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Domonda.md - Chunk 0
Important Informations Related Issue tba Partner or Customer tba API or RIPEye API Name in auth DB Domonda Produktiv Nutzungsbeginn tba Paket tba E-Mail CTO  Erik Unger erik@domonda.com CEO  Mathias Kimpl mathias@domonda.com Customers Specifics Anmerkung Martin 14.11.2024; Anm: Domonda ist ein wichtiger und wachsender Partner, bitte bevorzugt behandeln.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\DrCom-and-Zowierucha.md - Chunk 0
Important Informations Related Issue tba Partner or Customer tba API or RIPEye tba Name in auth DB tba Nutzungsbeginn tba Paket tba E-Mail tba Customers Specifics tba

Our contractual partner is the following company: DrCom Net GmbH & Co. KG Helene-Lange-Str. 34 D-60438 Frankfurt am Main

Our contact person is Zenon Zowierucha from zowierucha.de Those two companies are partners, and support requests can potentially come from boths domains.

The trial API-Key belongs to Zowierucha (partner.zowierucha.trial) whereas the production key belongs to DrCom (partner.drcom)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Eurodata---gekündigt-bis-Januar-2025.md - Chunk 0
Important Informations Related Issue tba Partner or Customer tba API or RIPEye tba Name in auth DB tba Nutzungsbeginn tba Paket tba E-Mail tba Customers Specifics nothing known

wir haben jetzt ein neues Linux-Hotix-Package für die OnPremise V1.18.55 (BLU DELTA ONPREMISE LINUX V1.18.55.1-HotFix.zip) zusammengestellt.

Sie können dieses bis inkl. 10.Oktober unter folgender Url herunterladen: https://mlstoragerelease.file.core.windows.net/releases/v1.18.55.1-HotFix/BLU DELTA ONPREMISE LINUX V1.18.55.1-HotFix.zip?sp=r&st=2023-09-26T00:00:00Z&se=2023-10-10T23:59:00Z&spr=https&sv=2022-11-02&sig=lUlBLdX52VvKMdmPZUIpVWZ8JfYgMK7DVtR%2FC%2BLwccc%3D&sr=f

Release Notes V1.18.55.1: - Significant performance improvements for 2 docker containers (bludelta-compose.yaml / typhon_line_item_cpu & typhon_header_details_cpu) - Changed Linux environment configuration file (.env) to configure 4 CPUs by default (for each BLU DELTA docker container)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Eurodata---gekündigt-bis-Januar-2025.md - Chunk 1
Die Dokumente, welche sie uns nach dem letzten Call geschickt haben, waren bei der Fehleranalyse und -behebung sehr hilfreich. Die Perf.-Improvements machen sich vor allem bei Dokumenten mit vielen LineItems deutlich bemerkbar. Ich möchte sie bitten mit der neuen Version nochmal zu testen und uns über die Ergebnisse zu informieren.

Der zusätzliche Metrics-Endpoint zum Auslesen der „Concurrently processing documents“ wird im aktuellen Sprint geschätzt und im kommenden Sprint in die Entwicklung mit aufgenommen. (Geplante Lieferung in der Woche 16-20.10.)

Update 19.04.2024 --> Neues Rate-Limiting feature für OnPremise (speziell für ETL --> Urs Oberdorf bekommt heute noch das Hotfix package)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Eurodata---gekündigt-bis-Januar-2025.md - Chunk 2
Update 19.04.2024 --> Neues Rate-Limiting feature für OnPremise (speziell für ETL --> Urs Oberdorf bekommt heute noch das Hotfix package)

ETL kann damit einstellen wie viele Requests maximal parallel von einer BLU DELTA Service Instanz verarbeitet werden. Zusätzliche requests werden dann sofort mit einem Http 429 (Too many requests) beantwortet. ETL hat einen Nginx-LoadBalancer vor den BLU DELTA Services platziert welcher mit diesem Status-Code umgehen können sollte.

CaptureSdk Rate Limiter Wiki-Beschreibung

Wir hoffen dass ETL unser Service mit diesem Hotfix wieder zu 100% aktiviert (aktuell werden anscheinend nur 3% der Dokumente an unser Service geschickt). Siehe --> #20741

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\IDALABS.md - Chunk 0
Important Informations Related Issue #18506 #22719 Partner or Customer Partner API or RIPEye API (+ RIPEye Label Account) Name in auth DB partner.idalabs Nutzungsbeginn 01.01.2024 Paket 1k monatlich E-Mail thomas.nowak@idalabs.de - für die Integration zuständig lasse.becker@idalabs.de  - Geschäftsführer tobias.guertler@idalabs.de  - ??? info@idalabs.de  - allgemeine Mail Adresse Herr Lennart Leopold lennart.leopold@idalabs.de ; mein Hauptansprechpartner für den RipEye Label Account Customers Specifics Sie labeln für uns via Labeling Tool - PW in serverbdssql01/bcidb/user; User: partner.idalabs Labeling1; Sie müssen zuerst via Learn API die Docs hochladen, damit wir Ihnen dann die InvoiceIds zuweisen können. Oktober 2024: sie haben nun auch einen RipEye Label Account - Name lt auth DB partner.idalabs.label - BN für RipEye idalabs.label PW siehe Keeper

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\jbx.md - Chunk 0
Important Informations Related Issue tba Partner or Customer tba API or RIPEye tba Name in auth DB tba Nutzungsbeginn tba Paket tba E-Mail tba Customers Specifics nothing known

Plugin in ExternalPostprocessing: https://blumatix.visualstudio.com/DefaultCollection/Rechnungserkennung/_git/PostProcessing?path=/src/Blumatix.PostProcessing.Api/appsettings.json

ReceiverOrderId:

"partner.jbx.schoenesleben", "partner.jbx.schoenesleben.trial" Found via Regex SLG + 7 digits=> "\bSLG\s?\d{7}\b"

"partner.jbx.arabelladeutschland", "partner.jbx.arabelladeutschland.trial", "partner.jbx.ariva", "partner.jbx.ariva.trial", "partner.jbx.dieprivathoteliers", "partner.jbx.dieprivathoteliers.trial", "partner.jbx.cooperationmanagement", "partner.jbx.cooperationmanagement.trial" Found via Regex 6 digits => "\b\d{6}\b"

"partner.jbx.arabellaschweiz", "partner.jbx.arabellaschweiz.trial" Found via Regex 7 digits => "\b\d{7}\b"

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\KraussMaffei-(Partner_-Avvaneo).md - Chunk 0
[[TOC]]

Important Informations Related Issue #22927 Partner or Customer Customer+ 2 Mandanten (Extrusion und Burgsmüller) API or RIPEye RIPEye Name in auth DB partner.avvaneo partner.avvaneo.kraussmaffei Nutzungsbeginn tba Paket tba Kontakte thomas.schmid@avvaneo.com Norbert Bast // Consultant ITA Cross Applications der KraussMaffei Extrusion GmbH // Mail: norbert.bast@kraussmaffei.com // Telefon: +49 (0)5102 8608 7147 Andrej.Kemner@kraussmaffei.com Customers Specifics This customer uses RIPEye because of the E-Mail inbox.The customer does not use the RIPEye UI. Processed documents are released automatically and are imediately available to download. Customer Config: Dass alle Details Prio 3 haben ist gewollt, weil Avvaneo / Krauss Maffei RIPEye nur wegen des EMail Eingangskanals nutzt, nicht aber die Oberfläche. Die PO Number/Auftragsnummer (42+8Digits) wird zusätzlich zur SenderOrderId auch als ReceiverOrderId geführt. Sie brauchen die Nummer in ihrem Workflow; siehe Plugin -> #18680

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Mae-Systems.md - Chunk 0
Important Informations Related Issue tba Partner or Customer API or RIPEye API Name in auth DB maesystems maesystems.trial Nutzungsbeginn tba Paket tba E-Mail ralf.petri@mae-systems.de Customers Specifics nothing known

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\OERK-(Österreichisches-Rotes-Kreuz).md - Chunk 0
[[TOC]]

General

Oerk is a RIPEye client. For support we need a VPN account. VPN server address is vpn.st.roteskreuz.at. OERK will provide the account and the link to Cisco client. We have two remote desktop connections (username with domain prefix rkoffice, the username and password will be provided by OERK: - Test server: st40dmst01.rkoffice.st.oerk.at - Productive server: st40dms01.rkoffice.st.oerk.at

Steps for support

Connect via VPN (cisco client) to OERK

Open windows remote desktop program and connect to corresponding server (in support cases it's the productive server)

Open file explorer and navigate to "D:\SAPERION_BLUDELTA" and you will see three folders (Files, Log_Bludelta2Saperion, Tools) :

Files

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\OERK-(Österreichisches-Rotes-Kreuz).md - Chunk 1
Open file explorer and navigate to "D:\SAPERION_BLUDELTA" and you will see three folders (Files, Log_Bludelta2Saperion, Tools) :

Files

Input folder includes the invoices, which will be uploaded to RIPEye and after that the file will be moved to the folder "Uploaded". As soon as the invoice is processed it is downloaded and the invoice in moved to Output folder and a database entry is written. As soon as the invoice is in "Output" folder, it will be moved to folder "Archiviert" -> this is not done by our Uploader Tool. Uploader Tool works from "Input" folder to "Output" folder.

Log_Bludelta2Saperion: Does not concern us!

Tools: The folder includes the Uploader Tool. The important files here are:

Log.txt: The most important file, we can conclude when, for example, the tool was started the last time. If any error has occured and which files are already successfully uploaded and so on.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\OERK-(Österreichisches-Rotes-Kreuz).md - Chunk 2
Log.txt: The most important file, we can conclude when, for example, the tool was started the last time. If any error has occured and which files are already successfully uploaded and so on.

BludeltaInvoiceCapture.exe.config: Folders (Input, Output, ...), API-URL, API-Key, API-Identifier, Database connection, etc.

BludeltaInvoiceCapture.exe: Uploader Tool itself. Do not start it manually during support because it is triggered by Task Scheduler every minute:

Check database entries: Open "Management Studio" and connect to database with defined username and password in file "BludeltaInvoiceCapture.exe.config" and open defined table. Currently it's name is "NT_BludeltaInvoiceCaptureResults" and it contains all processed invoices.

We only support PDF files, even if the file types are configured in the config! Never restart the remote desktop machine and never undergo any setting which will affect the machine!

TODO: How to configure cisco connection name?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\POI-(OnPremise).md - Chunk 0
Important Informations Related Issue tba Partner or Customer tba API or RIPEye tba Name in auth DB tba Nutzungsbeginn tba Paket tba E-Mail tba Customers Specifics POI testet bereits seit Dez 2021 die VehicelRegistration für Zulassungen (Rudi kennt sich aus) -> siehe auch #22942

They run Triton via CPU!!! POI only needs the HeaderDetails, so they can disable some time-consuming models to gain performance

(Default installation path: "C:\Program Files\Blumatix\BLU DELTA Invoice Capture Service V1.18.12\Blumatix.Capture.Webservice.Client.Selfhosted.exe.config")

<appSettings> ... <add key="NERDeliveryPeriodGpuModeEnabled" value="false" /> ... </appSettings>

(Default installation path: "C:\Program Files\Blumatix\BLU DELTA Invoice Capture Service V1.18.12\dynamic_config.json")

"LineItems": { "TyphonLineItems": { "Enabled": false, "CustomerNames": [], "SupportedLanguages": [], "ModelVersion": "1", "ModelName": "typhon_lineitems" } },

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\POI-(OnPremise).md - Chunk 1
"LineItems": { "TyphonLineItems": { "Enabled": false, "CustomerNames": [], "SupportedLanguages": [], "ModelVersion": "1", "ModelName": "typhon_lineitems" } },

(Default installation path: "C:\Program Files\Blumatix\BLU DELTA Invoice Capture Service V1.18.12\dynamic_config.json")

"Contacts": { "TyphonContacts": { "Enabled": false, "CustomerNames": [], "SupportedLanguages": [ "de" ], "ModelVersion": "1", "ModelName": "typhon_contacts" } },

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\RAG.md - Chunk 0
[[TOC]]

Important Informations Related Issue tba Partner or Customer tba API or RIPEye tba Name in auth DB tba Nutzungsbeginn tba Paket tba E-Mail tba Customers Specifics tba

rag is a RIPEye customer. They also use our Ressource API and whitelist service. The rag apikey/identifier are used in the sme dev environment in order to facilitate some rag specific development/testing.

You can find the different CustomerConfigs here: \nas-01\CustomerData\Customer Configs\RAG

RIPEye User Management

Password requirements (discussed with Martin [2023-02.24]): 12 characters, uppercase/lowercase letters, special characters.

Ressource API

Approver Plugin: WhitelistSearch Match with First- and Lastname. (Problem here is, that the search does not differentiate, where the columns are found, so first and lastname of an approver matches even if those two names are not next to each other.)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\RAG.md - Chunk 1
Please note that each prediction group coming from a white list plugin needs an entry in the customer configuration of the SME and that this entry is dependent on the column names as well as the name of the uploaded resource file. If the customer suddenly changes the name of either of these there might be problems.

Custom Detail

RagReceiverOrderId Plugin: Match with two Regexes: 45 + Eight Digits, 20 + Six Digits

RagApprover WhiteListPlugin: (Vorname and Nachname) or Email

RagClient and RagSupplier are run via the ExternalPostprocessing

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\RAPOOL-Ring-GmbH.md - Chunk 0
Important Informations Related Issue tba Partner or Customer Customer API or RIPEye API Name in auth DB rapool Nutzungsbeginn tba Paket tba E-Mail Der Kontakt läuft über Thomas Stichnoth thomas.stichnoth@leine-weber.net – das ist eine Webagentur, die den Deal für ihren Kunden Rapool eingefädelt haben. Customers Specifics nothing known

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Red-Bull.md - Chunk 0
Important Informations Related Issue tba Partner or Customer tba API or RIPEye tba Name in auth DB tba Nutzungsbeginn tba Paket tba E-Mail Elisabeth Leiter • Project Manager Global ERP FI/CO • T: +43 66265827919 • M: +43 66488988156 • elisabeth.leiter@redbull.com Customers Specifics nothing known

Plugin in ExternalPostprocessing:

https://blumatix.visualstudio.com/DefaultCollection/Rechnungserkennung/_git/PostProcessing?path=/src/Blumatix.PostProcessing.Api/appsettings.json

Indian Invoices for YATRA and MRL are detected via Text and then the VatGroups are read out algorithmically through the plugin and only taken if they can be calculated with the GTA (found via QRCode, Text, or through SDK) VatGroup (VatRate, VatAmount, NetAmount), GTA, Receiver-, SenderVatId, InvoiceId, InvoiceDate are read out.

Swedish invoices with PaymentReferenceId (#16085):

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Red-Bull.md - Chunk 1
Swedish invoices with PaymentReferenceId (#16085):

With release of 4th July 2024: For Swedish invoices the OCR number is included in response as PaymentReferenceId number like: { "Type": 2147483648, "TypeName": "PaymentReferenceId", "Text": null, "Value": "3406900292331", "Score": 0.99, "RecommendedThreshold": -1.0, "X": 1705, "Y": 143, "Width": 198, "Height": 21, "Confidence": -1.0 } For that dynamic_config.json has new block and for the first time we call a endpoint (generic-llm-workflow) of workflow server from our API: "LlmWorkflow": { "PaymentReferenceIdConfig": { "Enabled": true, "CustomerNames": [ "Red Bull Test", "Red Bull Produktiv" ], "SupportedLanguages": [], "SupportedCountries": [ "SE" ], "ModelName": "AzureGPT", "MaxPages": 2, "MustHaveTexts": [ "OCR", "Red Bull Sweden"] } }

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\RVS---neu_-Lagerhaus.md - Chunk 0
[[TOC]]

General Information

Mit 1.7.2024 ändert sich der Firmenwortlaut, sogleich auch die UID Nr und die Mailadressen.

Invoice workflow

RIPEye User Management

Update from Michael Hinterhofer (RVS) on January 17th 2023: Password requirements: 12 Stellig, Groß-/Kleinbuchstaben, Sonderzeichen

Information sent by Michael Hinterhofer (RVS):

Ich darf Sie ersuchen Aufträge zur Benutzerverwaltung ausschließlich durch die u.a. Personen zu bearbeiten und andere Personen darauf hinzuweisen, dass Raiffeisen interne Freigabewege einzuhalten sind.

Folgende Personen haben das Recht Ihnen Aufträge zur Benutzerverwaltung zu übermitteln. Mitarbeitende OE SAS: (vorname.nachname@rvs.at) • Martin Bruckmoser • Stefan Schindecker • Georg Hocheder • Monika Neumann • Hermine Wilhelm • Alexandra Befurt

wir werden Ihnen bei der Übermittlung der User folgendes Format (hier als Beispiel) schicken.

UserID Nachname Vorname Rolle Michael.hinterhofer@rvs.at Hinterhofer Michael Validierung Rechnung

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\RVS---neu_-Lagerhaus.md - Chunk 1
wir werden Ihnen bei der Übermittlung der User folgendes Format (hier als Beispiel) schicken.

UserID Nachname Vorname Rolle Michael.hinterhofer@rvs.at Hinterhofer Michael Validierung Rechnung

Die UserID entspricht immer der Email-Adresse des Benutzers.

Können Sie bitte bei Vergabe von Benutzern ein 12-stelliges PW vergeben und im System hinterlegen, sodass der Benutzer das PW bei der nächsten Anmeldung ändern muss? Die Information über UserID und PW bitte direkt an den Benutzer schicken.

In weiterer Folge würden die Angaben um den Betrieb/Mandant ergänzt werden. Derzeit – da nur 1 Mandant – ist dies nicht erforderlich. Rollen: - Validierung Rechnung - Zuordnung Mandant (wenn eine Rechnung keinem Mandanten zuordenbar ist)

Übermittlung der Accounts monatlich auf sas@rvs.at

Master data comparison

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\RVS---neu_-Lagerhaus.md - Chunk 2
Übermittlung der Accounts monatlich auf sas@rvs.at

Master data comparison

In RIPEye the Supplier and Client information is matched against the master data provided by rvs via the deprecated endpoint (see bludelta.dev -> RIPEye integration -> Upload ClientMasterData / SupplierMasterData).

Following, you will find the score calculation for the Master data comparison. If the calculated score is greater than the score in the customer config, the document will be autoprocessed.

``` public List

        // is there a iban match, ugly code -> should be a list of lists
        if (result?.IbanMatches?.Count > 0)
        {
            UpdateScores(list, result.IbanMatches, 1);
        }
        if (result?.UidMatches?.Count > 0)
        {
            UpdateScores(list, result.UidMatches, 1);
        }
        if (result?.EmailMatches?.Count > 0)
        {
            UpdateScores(list, result.EmailMatches, 0.5);
        }

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\RVS---neu_-Lagerhaus.md - Chunk 3
if (result?.SenderEmailMatches.Count > 0)
        {
            UpdateScores(list, result.SenderEmailMatches, 0.25);
        }

        return list;
    }

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\RVS---neu_-Lagerhaus.md - Chunk 4
```

Plugin in ExternalPostprocessing:

https://blumatix.visualstudio.com/DefaultCollection/Rechnungserkennung/_git/PostProcessing?path=/src/Blumatix.PostProcessing.Api/appsettings.json - For "Trocknungsgemeinschaft Zisserdorf" Invoice the delivery note id is corrected.

Client Id as Additional Property

Lagerhaus sends the Client Id as additional property when uploading a document. This feature was meant for independent branches (Lagerhäuser). For the default branches (starting with 35xxxx and 45xxxx) they cannot distinguish these clients and hence by default provide client 35xxxx. According to Lagerhaus the Supplier Master Data Comparison is not affected by this. In a call with Lagerhaus on 2024-08-19 they informed Blumatix, that a specific Client Id Mapping, where the Client Id maps to a specific ReceiverVatId is not necessary.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Stiegl.md - Chunk 0
Important Informations Related Issue tba Partner or Customer tba API or RIPEye tba Name in auth DB tba Nutzungsbeginn tba Paket tba E-Mail tba Customers Specifics nothing known

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Trade4Com.md - Chunk 0
Important Informations Related Issue tba Partner or Customer tba API or RIPEye tba Name in auth DB tba Nutzungsbeginn tba Paket tba E-Mail tba Customers Specifics tba

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Trade4Com.md - Chunk 1
Trade4Com is a new BLU DELTA API customer. He uses the API productive and RIPEye only for labeling purposes. Since the history of Trade4Com and therefore also its configuration in the database is a bit special, I describe the individual Config entries here: - Trade4Com via Compacer Test: Trade4Com is/was a Compacer customer. This is the API-Identifier that we provided to Compacer for Trade4Com, it works only in combination with the "Compacer Test" API-Key. Trade4com does not know this key. - Trace4Com via Compacer Produktiv: Attention - there's a typo in the name, Trace instead of Trade (does not affect the functionality): See above, this is the Trade4Com API-Identifier which works only with the "Compacer Produktiv" API-Key. Trade4com does not know this key. - Trade4Com TestKey: Trade4Com has tested our BLU DELTA API directly, without Compacer as well. (Longer time after Compacer Integration). This is the according API-Key, it is just for testing purposes. - Trade4Com Customer:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Trade4Com.md - Chunk 2
has tested our BLU DELTA API directly, without Compacer as well. (Longer time after Compacer Integration). This is the according API-Key, it is just for testing purposes. - Trade4Com Customer: Trade4Com has also tested BLU DELTA RIPEye, that's why there is this API identifier. It is just for testing purposes. - partner.trade4com: Trade4Com signed a contract for BLU DELTA API on 9.3.2023. This is the API-Key for productive API usage.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Trade4Com.md - Chunk 3
Trade4Com will continue to use RIPEye. However, not for productive purposes, but for labeling activities.

Therefore thy need the following RIPEye configuration: Mandatory fields: - Dokumenttyp - Währung - Rechnungsnummer - Rechnungsdatum - Lieferdatum - Kundennummer - IBAN +BIC (mehrfach) - Kontonummer + BLZ (mehrfach) - Rechnungssender Name - Rechnungssender UST-ID - Rechnungssender Adresse - Rechnungsempfänger Name - Rechnungsempfänger UST-ID - Rechnungsempfänger Adresse - Steuernummer (DE) - Bruttogesamtbetrag - Zahlungskondition - Mehrwertsteuern (mehrfach) - MwSt-Satz - MwSt-Betrag - Nettobetrag - Lieferzeitraum - Mehrwertsteuerbefreiung - Artikelpositionen

In order to support the labeling idea we need to deactivate Autoprocessing.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\XBit.md - Chunk 0
Important Informations Related Issue Partner or Customer Partner mit ca. 2 Kunden (Fa. Boltas + Fa Kohlschein) Name in bcsdb auth xbit Produktiv API or RIPEye API Nutzungsbeginn Paket Kontakte Herr Dieter Schöddert // Geschäftsführer von XBit // Tel: 0049 2232 7011100 // Mail: schoeddert@xbit.de Customers Specifics siehe Plugins X Invoices sind aktiviert -> dynConfig Eintrag -> läuft über normale APIEndpoint mit XBitTestkey

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\XXX---Inactive-Customers.md - Chunk 0
Kiska (Accantum) since 01.05.2023

Compacer ab 31.12.2024

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\Agatex-Feinchemie-GmbH.md - Chunk 0
[[TOC]]

Important Informations Related Issue tba Partner or Customer tba API or RIPEye tba Eigener Labelaccount tba Customer Config Settings https://blumatixconsultinggmbh.sharepoint.com/:x:/s/BLUDELTAWorkflow/Eadwt0FXG99Amu8CG3hsxVEBGqqEAL67tjwSq5FLfFPXMQ?e=ep7PK8&CID=0E99FD5C-8C2C-4373-9728-298D02AB9498&wdLOR=cD0DD88A1-754E-451D-8406-3C18793CA641 Name in auth DB tba Nutzungsbeginn tba Paket tba Support Paket tba E-Mail nb@agatex.at Nikolaus Bauer-Harnoncourt Mobil: +43 699 11661350 Customers Specifics tba

RIPEye Customer

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\Austroflamm-GmbH.md - Chunk 0
Important Informations Related Issue #22155 Partner or Customer Customer und 1 Mandant (Partner: R&S) Name in bcsdb auth/smedb partner.ramsauerstuermer.austroflamm API or RIPEye RIPEye Internal RipEye User austroflamm_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) ja Nutzungsbeginn voraussichtlich November 2024 Paket 1k Kontakte Patrik Öri PS Consultant T: +43 (0)662-63 03 09-0, patrik.oeri@aptean.com Sebastian Schneeberger, Buchhalter, schneeberger@austroflamm.com Customers Specifics

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\Benediktinerstift-Admont.md - Chunk 0
Important Informations Related Issue #21888 Partner or Customer Customer und 8 Mandant (Partner: R&S) Name in bcsdb auth/smedb partner.ramsauerstuermer.benediktinerstiftadmont API or RIPEye RIPEye Internal RipEye User stiftadmont_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) ja, alle 8 Mandanten Nutzungsbeginn 01.09.2024 Paket 1k E-Mail Katrin Obermoser  T: +43 (0)662-63 03 09-0 Katrin.Obermoser@aptean.com Customers Specifics

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\BRM-Recycling-GmbH.md - Chunk 0
Important Informations Related Issue #21625 Partner or Customer Customer und 1 Mandant (Partner: R&S) Name in bcsdb auth/smedb partner.ramsauerstuermer.brmrecycling API or RIPEye RIPEye Internal RipEye User brmrecycling_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) ja Nutzungsbeginn 01.08.2024 Paket 1k E-Mail Katrin Obermoser  T: +43 (0)662-63 03 09-0 Katrin.Obermoser@aptean.com Customers Specifics

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\Bäko-Österreich.md - Chunk 0
Important Informations Related Issue tba Partner or Customer Customer API or RIPEye RIPEye Name in auth DB Baeko Customer Nutzungsbeginn tba Paket tba E-Mail tba Customers Specifics Rechnungen von Fa. Hauzenberger laufen über pdffilter.json, Pattern allerdings 'Bäko-Österreich e.Gen.' -> more Infos Issue #19542

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\Columbus-GmbH-(Account-stillgelegt).md - Chunk 0
Important Informations Related Issue #19779 Partner or Customer Customer und 2 Mandant (Partner: R&S) Name in bcsdb auth/smedb partner.ramsauerstuermer.columbus API or RIPEye RIPEye Internal RipEye User columbus_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) ja Nutzungsbeginn 1. HJ 2024 -> Kunde war nie auf Prod aktiv (hat nicht 1 Rechnung geschickt), da es zw. Aptean und Columbus vertragliche Probleme gab. Wenn sie sich einig werden, können wir den Account wieder aktivieren. Paket 1k E-Mail Patrik Öri T: +43 (0)662-63 03 09-0 patrik.oeri@aptean.com gerda.postenrieder@columbus.at Customers Specifics

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\Dach-und-Wand-Handels-GmbH-Customer.md - Chunk 0
Important Informations Related Issue #13017 Partner or Customer Customer und 1 Mandant (Partner: R&S) Name in bcsdb auth/smedb Dach und Wand Handels Gmbh Customer API or RIPEye RIPEye Rechnungseingang per Mail (zu RipEye) ja Nutzungsbeginn bereits Kunde seit Sept 2022 -> 1. HJ 2024 Paket 1k E-Mail Mathias Hirczi Belinda.Stadlbauer@dachundwand.at Customers Specifics [Plugin](/BLU-DELTA-Support/Customer-specifics/Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner/Dach-und-Wand-Handels-GmbH-Customer/Plugin-in-ExternalPostprocessing)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\Daka-Entsorgung.md - Chunk 0
Important Informations Related Issue #20209 Partner or Customer Customer und 1 Mandant (Partner: R&S) Name in bcsdb auth/smedb partner.ramsauerstuermer.daka API or RIPEye RIPEye Internal RipEye User daka_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) ja Nutzungsbeginn Mitte Mai 2024 Paket 1,2k E-Mail Katrin Obermoser T: +43 (0)662-63 03 09-0 Katrin.Obermoser@aptean.com Customers Specifics

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\EZG-Gut-Streitdorf.md - Chunk 0
Important Informations Related Issue #23415 Partner or Customer Customer und 3 Mandant (Partner: R&S) Name in bcsdb auth/smedb partner.ramsauerstuermer.ezggutstreitdorf API or RIPEye RIPEye Internal RipEye User ezggutstreitdorf_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) Interne Ordnerstruktur vom RS2; Keine Mailadresse hinterlegt Nutzungsbeginn 09.12.2024 Paket 1k jährlich E-Mail Aptean AT Patrik Öri Patrik.Oeri@aptean.com p.unger@gutstreitdorf.at Customers Specifics

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\FH-Oberösterreich-Produktiv.md - Chunk 0
Important Informations Related Issue #22620 Partner or Customer Customer und 6 Mandant (Partner: R&S) Name in bcsdb auth/smedb FH Oberösterreich Produktiv API or RIPEye RIPEye Internal RipEye User fh_ooe_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) ja Nutzungsbeginn ?? Paket ??k E-Mail Customers Specifics

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\Flughafen-Salzburg.md - Chunk 0
Important Informations API or RIPEye RipEye Related Issue #22730 Partner or Customer Customer +3 Mandanten Name in bcsdb auth/smedb ?? Eigener Labelaccount nein Internal RipEye User ??_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) ja, bei allen drei Mandanten Customer Config Settings https://blumatixconsultinggmbh.sharepoint.com/:x:/s/BLUDELTAWorkflow/Eadwt0FXG99Amu8CG3hsxVEBGqqEAL67tjwSq5FLfFPXMQ?e=ep7PK8&CID=0E99FD5C-8C2C-4373-9728-298D02AB9498&wdLOR=cD0DD88A1-754E-451D-8406-3C18793CA641 Nutzungsbeginn November 2024 Paket 1k / Monat Support Paket tba Kontakte Customers Specifics tba

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\Gasteiner-Bergbahnen.md - Chunk 0
Important Informations Related Issue #18780 Partner or Customer Customer und 1 Mandant (Partner: R&S) Name in bcsdb auth/smedb partner.ramsauerstuermer.gasteinerbergbahnen API or RIPEye RIPEye Internal RipEye User gasteinerbb_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) nein Nutzungsbeginn Oktober 2023 Paket ?? k E-Mail Brigitte Webersdorfer T: +43 (0)662-63 03 09-0 Brigitte.Webersdorfer@aptean.com Benjamin.Rogl@skigastein.com Customers Specifics

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\HB-Fiesen.md - Chunk 0
Important Informations Related Issue #23513 Partner or Customer Customer und Mandant (Partner: R&S) Name in bcsdb auth/smedb partner.ramsauerstuermer.hbfliesen API or RIPEye RIPEye Internal RipEye User hbfliesen_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) nein, über RS2 Ordnerstruktur Nutzungsbeginn sind noch in der Testphase -> danach entscheidet sich ob sie überhaupt produktiv gehen (Stand Dezember 2024) Paket E-Mail Friedrich Wolfsjäger friedrich.wolfsjaeger@aptean.com Mobil: +43 (0)664 144 22 99 Customers Specifics

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\Kleinwalsertaler-Bergbahnen.md - Chunk 0
Important Informations Related Issue #15697 Partner or Customer Customer und 5 Mandanten (Partner: R&S) Name in bcsdb auth/smedb partner.ramsauerstuermer.kleinwalsertalbergbahnen API or RIPEye RIPEye Internal RipEye User kleinwalsertalbb_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) nein Nutzungsbeginn Mai 2023 Paket ?? k E-Mail Hubert Traschwandtner  T: +43 (0)662-63 03 09-0 hubert.traschwandtner@aptean.com Customers Specifics

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\Mayrhofner-Bergbahnen-AG.md - Chunk 0
Important Informations Related Issue #21841 Partner or Customer Customer und 1 Mandant (Partner: R&S) Name in bcsdb auth/smedb partner.ramsauerstuermer.mayrhofnerbergbahnen API or RIPEye RIPEye Internal RipEye User mayrhofnerbergbahnen_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) ja Nutzungsbeginn 01.12.2024 Paket 1k/Monat E-Mail Thomas Pongruber  T: +43 (0)662-63 03 09-0 Thomas.Pongrunber@aptean.com Customers Specifics

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\Megatron-GmbH.md - Chunk 0
Important Informations Related Issue #21704 Partner or Customer Customer und 1 Mandant (Partner: R&S) Name in bcsdb auth/smedb partner.ramsauerstuermer.megatron API or RIPEye RIPEye Internal RipEye User megatron_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) Interne Ordnerstruktur vom RS2; Keine Mailadresse hinterlegt Nutzungsbeginn 01.11.2023 Paket Prepaid 1k E-Mail Hubert Traschwandtner Hubert.Traschwandtner@aptean.com Telefon: +43 664 629 36 78 regina.hofmann@megatron.de stefanie.thoma-seeger@megatron.de Customers Specifics

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\Miraplast-GmbH.md - Chunk 0
Important Informations Related Issue #18539 Partner or Customer Customer und 1 Mandant (Partner: R&S) Name in bcsdb auth/smedb partner.ramsauerstuermer.miraplast API or RIPEye RIPEye Internal RipEye User miraplast_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) nein, über Ordnerstruktur in RS2 Nutzungsbeginn Jänner 2024 Paket 400 E-Mail Patrik Öri T: +43 (0)662-63 03 09-0 patrik.oeri@aptean.com Customers Specifics

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\PWV---Parfümeriewarenvertriebs-GmbH.md - Chunk 0
Important Informations Related Issue #21804 Partner or Customer Customer und 1 Mandant (Partner: R&S) Name in bcsdb auth/smedb partner.ramsauerstuermer.pwvparfumerie API or RIPEye RIPEye Internal RipEye User pwvparfumerie_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) nein, über RS2 Ordnerstruktur Nutzungsbeginn 01.09.2024 Paket 2k E-Mail Patrik Öri  T: +43 (0)662-63 03 09-0 patrik.oeri@aptean.com Customers Specifics

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\Schmittenhöhebahn-AG.md - Chunk 0
Important Informations Related Issue #17321 Partner or Customer Customer und 1 Mandant (Partner: R&S) Name in bcsdb auth/smedb partner.ramsauerstuermer.schmittenhoehebahn API or RIPEye RIPEye Internal RipEye User schmittenhoehebahn_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) nein Nutzungsbeginn September 2023 Paket ??k E-Mail Hubert Traschwandtner T: +43 (0)662-63 03 09-0 hubert.traschwandtner@aptean.com Customers Specifics

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\Senecura-Gastro-Services-GmbH.md - Chunk 0
Important Informations Related Issue Partner or Customer Customer und ? Mandant (Partner: R&S) Name in bcsdb auth/smedb SeneCura Gastro Services GmbH Customer API or RIPEye RIPEye Internal RipEye User ??_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) ?? Nutzungsbeginn ?? Paket ??k E-Mail Customers Specifics

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\Skilifte-Sölden.md - Chunk 0
Important Informations Related Issue #22269 Partner or Customer Customer und 4 Mandanten (Partner: R&S) Name in bcsdb auth/smedb partner.ramsauerstuermer.skiliftesölden API or RIPEye RIPEye Internal RipEye User skiliftesölden_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) nein, über RS2 Ordnerstruktur Nutzungsbeginn 03.10.2024 Paket 1k Kontakte Brigitte Webersdorfer, Senior PS Consultant, Professional Services Brigitte.Webersdorfer@aptean.com T: +43 (0)664-8109287 Customers Specifics

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\SSK-GmbH.md - Chunk 0
Important Informations Related Issue Partner or Customer Customer und 46 Mandanten (Partner: R&S) Name in bcsdb auth/smedb Salzburger Sand- u. Kieswerke GmbH Produktiv API or RIPEye RIPEye Internal RipEye User ssk_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) ?? Nutzungsbeginn ?? Paket ??k E-Mail Hubert Traschwandtner Hubert.Traschwandtner@aptean.com Telefon: +43 664 629 36 78 Customers Specifics

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\SSK-GmbH.md - Chunk 1
SSK Mandanten; Stand 12.09.2024: ABF Straßensanierung GmbH Mandator Bau Beton GmbH Mandator BEW-Immobilien GmbH Mandator BT Beton Transport GmbH Mandator Dolomitsandwerk GmbH & Co KG Mandator Eder Elisabeth Eder Elisabeth Immobilien Eder Immobilien OG Eder-Herzog GmbH & Co OG Eigentümergemeinschaft (Anthering) BEW Erd-Trans Erdbewegungs- und Transportgesellschaft m.b.H. & Co KG Mandator EWB-Investitions GmbH Mandator G & B Grund- und Bautenvermietungs GmbH Gebrüder Eder Beteiligungen GmbH Grundstücksgemeinschaft Oberascher BEW Grundstücksgemeinschaft Stegenwald BEW GT Gütertransport GmbH Mandator Gustav Haagen GmbH Mandator H&B Hallen- und Bürovermietungs GmbH HD Baustoffverwertung GmbH Mandator HTS GmbH J. Eder & Co OG J.E. KKW Immobilien GmbH J.E. Kleinkraftwerke GmbH J.Eder & Co OG - M.H. Vermögensverwaltung GmbH J.Eder & Co OG SACH Vermögensverwaltung GmbH Josef Eder Gutsbesitzer LuF Josef Eder Kraftwerk Miedering Josef Eder Liegenschaftsverwertungs GnbR Josef Eder Privatstiftung

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\SSK-GmbH.md - Chunk 2
Vermögensverwaltung GmbH J.Eder & Co OG SACH Vermögensverwaltung GmbH Josef Eder Gutsbesitzer LuF Josef Eder Kraftwerk Miedering Josef Eder Liegenschaftsverwertungs GnbR Josef Eder Privatstiftung Kieswerk Pfaffstätt GmbH Mandator Kieswerk Untersiebenbrunn GmbH Mandator Lungauer Sand- und Kieswerk Lassacher GmbH & Co KG Mandator Mittendorfer Beton GmbH & Co KG MOLDAN Baustoffe GmbH & Co KG Mandator Pinzgau Beton GmbH & Co KG Mandator Salzach Beton GmbH & Co KG Mandator Salzburger Sand- u. Kieswerke GmbH Mandator Scheuch Kies GmbH & Co KG Mandator SEWB-Investitions GmbH Mandator SSK u. Mitbes.(Christoph Seethaler) Steinbruch Lidaun GmbH Mandator TBL Logistik GmbH Mandator Top Hunt GmbH TSK Traunstein Sand- und Kieswerke GmbH Mandator

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\Tieber-GmbH.md - Chunk 0
Important Informations Related Issue #21628 Partner or Customer Customer und 3 Mandanten (Partner: R&S) Name in bcsdb auth/smedb partner.ramsauerstuermer.tieber API or RIPEye RIPEye Internal RipEye User tieber_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) 2 Mandanten nein, 1 Mandant ja Nutzungsbeginn 01.08.2024 Paket 1k E-Mail Katrin Obermoser  T: +43 (0)662-63 03 09-0 Katrin.Obermoser@aptean.com Customers Specifics

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\Tiroler-Landestheater-und-Orchester-GmbH.md - Chunk 0
Important Informations Related Issue #21891 Partner or Customer Customer und 2 Mandanten (Partner: R&S) Name in bcsdb auth/smedb partner.ramsauerstuermer.tirolerlandestheater API or RIPEye RIPEye Internal RipEye User tirolerlandestheater_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) ja Nutzungsbeginn 01.09.2024 Paket 2k E-Mail Katrin Obermoser T: +43 (0)662-63 03 09-0 Katrin.Obermoser@aptean.com Customers Specifics

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\TUI-Holding-Austria-GmbH.md - Chunk 0
Important Informations Related Issue #21923 Partner or Customer Customer und 1 Mandant (Partner: R&S) Name in bcsdb auth/smedb partner.ramsauerstuermer.tuiholdingaustria API or RIPEye RIPEye Internal RipEye User tuiholdingaustria_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) ja Nutzungsbeginn 01.10.2024 Paket 1k E-Mail Thomas Pongruber T: +43 (0)662-63 03 09-0 Thomas.Pongrunber@aptean.com Customers Specifics

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\Tüchler-GmbH.md - Chunk 0
Important Informations Related Issue US #21578 Partner or Customer Customer und Mandant (Partner: R&S) Name in bcsdb auth/smedb partner.ramsauerstuermer.tuechler API or RIPEye RIPEye Internal RipEye User tuechler_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) nein, über RS2 Ordnerstruktur Nutzungsbeginn Anfang Juli 2024 Paket E-Mail Friedrich Wolfsjäger friedrich.wolfsjaeger@aptean.com Mobil: +43 (0)664 144 22 99 Herr Oskar Bauer, Buchhaltung und Controlling, Firma Tüchler, Mobil: 0676 84827161 Customers Specifics

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\Wasserleitungsverband-Nördl.-Burgenland.md - Chunk 0
Important Informations API or RIPEye RipEye Related Issue #22877 Partner or Customer Customer + 2 Mandanten Name in bcsdb auth/smedb partner.ramsauerstuermer.wasserlvburgenland Eigener Labelaccount nein Internal RipEye User wasserlv_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) ja, bei beiden Mandanten Customer Config Settings https://blumatixconsultinggmbh.sharepoint.com/:x:/s/BLUDELTAWorkflow/Eadwt0FXG99Amu8CG3hsxVEBGqqEAL67tjwSq5FLfFPXMQ?e=ep7PK8&CID=0E99FD5C-8C2C-4373-9728-298D02AB9498&wdLOR=cD0DD88A1-754E-451D-8406-3C18793CA641 Nutzungsbeginn 01.11.2024 Paket 1k / Monat Support Paket tba Kontakte Customers Specifics tba

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\ÖBAU-GmbH.md - Chunk 0
Important Informations Related Issue Partner or Customer Customer und 11 Mandanten (Partner: R&S) Name in bcsdb auth/smedb ÖBAU Customer API or RIPEye RIPEye Internal RipEye User oebau_internal -  PW: im Keeper Rechnungseingang per Mail (zu RipEye) ?? Nutzungsbeginn ?? Paket ??k E-Mail Customers Specifics Kunde wollte alle Thresholds auf 0.00 haben -> siehe Customer Config

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\Dach-und-Wand-Handels-GmbH-Customer\Plugin-in-ExternalPostprocessing.md - Chunk 0
DachUndWandReplaceUidAndIbanPredictions: For Bauder invoices the Receiver-/SenderVatId and Iban are manually set receiverVatIdToSet = "ATU64131246"; senderVatIdToSet = "ATU22666103"; ibanToSet = "AT781100003923025500";

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Aptean-AT-(former-Ramsauer-und-Stürmer)-Partner\ÖBAU-GmbH\Etzi-GmbH.md - Chunk 0
Etzi hat keinen automatischen Retry wenn von uns eine Feedback-Email kommt. Beim Kunde läuft das wie folgt: sie haben 1 großes Postfach für sämtliche Rechnungen (rechnungen@etzi-haus.com). Von da aus werden sie manuell auf die einzelnen Eingangsrechnungspostfächer aufgeteilt. Von den ER-Postfächern werden die Mails zwar automatisch an uns geschickt, unsere Feedback Email geht dann aber wieder ans 'große' Postfach (rechnungen@etzi-haus.com) retour.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Avvaneo\Flughafen-München.md - Chunk 0
Important Informations Related Issue tba Partner or Customer Customer API or RIPEye API Name in auth DB tba Nutzungsbeginn tba Paket 100k / Jahr E-Mail tba Customers Specifics tba

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Avvaneo\SMS.md - Chunk 0
Important Informations Related Issue tba Partner or Customer Customer API or RIPEye API Name in auth DB tba Nutzungsbeginn tba Paket 160k / Jahr E-Mail tba Customers Specifics tba

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Dachser\BluDelta-Support-Workshop-Dachser.md - Chunk 0
BluDelta_SupportWorkshop_Dachser_2024-12-14.pptx

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Dachser\Dachser-OrderConfirmation.md - Chunk 0
Launch Planned for End of November.

Dachser Order Confirmation can be tested: - Open Bennu: http://192.168.137.80:8511/ - Select: BLU DELTA Workflows - Correct URL: https://capture.bludelta.ai/order-confirmation/v1/order-confirmation

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Dachser\DocType-Classification.md - Chunk 0
DocType Classification

Public Endpoint

Https Endpoint: https://classification.bludelta.ai/doc-classifier/v1/doc-classifier

Request: The request is the document provided in the body mulitpart-form request.

Response: A BluDoc. Here is an example: json { "BluDoc.Version": "1.4.0", "Created.DateTime": "2024-08-01T15:25:40.26458+00:00", "CreatorSoftware.Name": "Bludelta DocumentType Classification", "CreatorSoftware.Version": "1.0.0", "Document.Languages": [ "en" ], "Document.Type": "TransitNoteT1", "DocumentEssentials": [ { "Confidence": 0.9999998807907104, "ConfidenceThreshold": -1, "Label": "Document.Type", "Text": "", "Value": "TransitNoteT1" } ], "DocumentProvider.Name": "blumatix" }

Http Codes:

Http 200: on success

Http 400: on failure, e.g. if there is an error during OCR processing

Supported DocType Classes

CollectionOrder

TransitNoteT1

ExportAccompanyingDocument

ProformaInvoice

BillOfLading

DangerousGoodsNote

CMRConsignmentNote

ForwardingOrder

TransitNoteT2

Other

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Dachser\DocType-Classification.md - Chunk 1
Supported DocType Classes

CollectionOrder

TransitNoteT1

ExportAccompanyingDocument

ProformaInvoice

BillOfLading

DangerousGoodsNote

CMRConsignmentNote

ForwardingOrder

TransitNoteT2

Other

Bennu

You can try it by yourself with Bennu. - set the the URL: https://classification.bludelta.ai/doc-classifier/v1/doc-classifier - upload the document to be classified.

Local workflow measurements of http://localhost:8090/doc-classifier

User Story #22201 - Task: #22185 I have changed the value of MaxPages to 1 and 11 (appsettings.json from Blumatix.WorkflowServer.Api): "DocTypeClassificationWorkflowConfig": { "Ocr": { "OcrEngine": "Nuance", "MaxPages": 1 } } Milliseconds value are the average values of 5 executions.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Dachser\DocType-Classification.md - Chunk 2
Filename Größe 1 MaxPage OCR Time [ms] 11 MaxPage OCR Time [ms] Diff [ms] Improvement [%] 1Page_CODCO_003_08ad62fa-436e-4455-8437-50297f6473dc_CollectionOrder.pdf 138 kb 5848 5996 148 2,47 1Page_CDTD1_660_c97c0f48-900e-4ec8-b5e8-0b67a871ba4a_TransitNoteT1.pdf 86 kb 7894 8264 370 4,48 1Page_CDPIN_018_325429ab-cad0-4b36-bf36-be3931e08ef8_ProformaInvoice.pdf 59,3 kb 8914 9560 646 6,76 1Page_TRCMR_001a_0136330f-5551-4abf-ae6b-130212170fa5_CMRConsignmentNote.pdf 499 kb 19771 21168 1397 6,60 2Pages_CDPIN_002_09b58d11-9798-4737-829b-22c1234cb864_ProformaInvoice.pdf 209 kb 6312 9960 3648 36,63 2Pages_CDABD_001_079c974c-5fae-418f-a2ed-87f6bc799aaa_ExportAccompanyingDocument.pdf 59,9 kb 6159 14020 7861 56,07 2Pages_CDPIN_001_083a7088-2df5-427a-82aa-1c85303ca51d_ProformaInvoice.pdf 644 kb 8982 14020 5038 35,93 2Pages_FDSPE_003_02dcff4b-f95a-4e90-9bfe-b85d606b1938_ForwardingOrder.pdf 959 kb 8232 12204 3972 32,55 3Pages_c1c565fe-898e-43ed-8043-1c75ed15a8cc.pdf 977 kb 8841 18024 9183 50,95

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Dachser\DocType-Classification.md - Chunk 3
14020 5038 35,93 2Pages_FDSPE_003_02dcff4b-f95a-4e90-9bfe-b85d606b1938_ForwardingOrder.pdf 959 kb 8232 12204 3972 32,55 3Pages_c1c565fe-898e-43ed-8043-1c75ed15a8cc.pdf 977 kb 8841 18024 9183 50,95 3Pages_64b8bc23-2ceb-4dea-85af-70ec94d8d468.pdf 984 kb 9055 17881 8826 49,36 6Pages_TRCMR_001b_0136330f-5551-4abf-ae6b-130212170fa5_CMRConsignmentNote.pdf 575 kb 20123 21331 1208 5,66 6Pages_225966b4-4396-44a9-89df-26951ef7c08c.pdf 3,72 MB 13789 34993 21204 60,59 12Pages_79dc5f62-04f1-48af-9ff8-f66ffa773eb1.pdf 3,83 MB 8852 69701 60849 87,30 13Pages_MIXED_019_1a4efdf9-5b36-4066-b18d-94fe1b8aaf37_marked.pdf 5,05 MB 8976 46370 37394 80,64

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Customer-specifics\Dachser\DocType-Classification.md - Chunk 4
As a result we do save time by sending limited MaxPages to OCR. We can ignore the improvements for 1 pagers that must be coincidence.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Known-Issues-and-How-to\CMAP-optional-in-PdfFilter.json.md - Chunk 0
Tools:

Regex Tester http://regexstorm.net/tester

Regex Syntax https://learn.microsoft.com/en-us/dotnet/api/system.text.regularexpressions.regex?view=net-7.0

PdfFilter.json https://blumatix.visualstudio.com/Rechnungserkennung/_git/Blumatix%20Capture?path=/Blumatix.Capture.Webservice.Client.Selfhosted/Blumatix.Capture.Webservice.Client.Selfhosted/Plugins/PdfFilter.json

Test-Process:

1.) Find a phrase, word or sentence on the original document which deals as an anker on the document (e.g. sender)

2.) Tell the Dev-Team that you are testing with the Dev-Environment - in Teams Machine Learning General

3.) Open Kudu page of Development-CaptureSdk --> Azure Resource name: app-bludelta-capture-sdk-dev-weu-01 Edit file: advanced tools --> site --> wwwroot --> bin --> Plugins ---> PdfFilter.json Before add window.localStorage['maxViewItems'] = 1500 to the console of your local storage (F12) and press enter. Then reload the website

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Known-Issues-and-How-to\CMAP-optional-in-PdfFilter.json.md - Chunk 1
4.) Add new regex for your anker for the corresponding customer --> For testing in dev Environment use "JsonPlugin Test (FOR INTEGRATION TESTS)" as customer name and set "CheckOnlyRegex" to true so that CMAP check is ignored and only regex is matched for a quick test!!! "Options" can be left to "0". If "CheckOnlyRegex" is false or not declared at all then regex is matched and also checked if the page contains CMAP!

Example text block for Pdffilter.json: "JsonPlugin Test (FOR INTEGRATION TESTS)": [ { "Pattern": "Fischer Austria G.m.b.H.", "Options": 0, "CheckOnlyRegex": "true" } ]

5.) Save and test if this solves your issue --> send invoice with JsonPluginTesterToken to https://app-bludelta-capture-sdk-dev-weu-01.azurewebsites.net Postman example can be found here: https://blumatix.visualstudio.com/Rechnungserkennung/_git/Postman?path=/collections/MOP%20BUG18151%20Image%20conversion%20only%20effective%20when%20CMAP%20included.postman_collection.json

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Known-Issues-and-How-to\CMAP-optional-in-PdfFilter.json.md - Chunk 2
6.) Tell the Dev-Team that you finished testing

7.) If this solved the Issue, write a MOP for the OpsTeam, which exactly describes what needs to be done to get this live! (Add your new config-entry) https://dev.azure.com/blumatix/Rechnungserkennung/_wiki/wikis/BludeltaDeployment/652/Open-MOPs

8.) If this solved the Issue, attend deployment meeting :-)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Known-Issues-and-How-to\Collection-of-SQL-tables-&-queries.md - Chunk 0
Collection and description of the most used database tables for support purposes (so far API and SME)

First, choose of these three servers, then choose the database, then choose the right table:

serverbmdata.ad.blumatix.com

bcidb -- Invoice Ids and Labeling Users

bcdbserver.database.windows.net

bcsdb -- must add newly written lines from smedb-1.0 when creating customer, see Copy into DB

bcsdb-auth -- authentication database, must add newly written lines from smedb-1.0 when creating customer see link above

bcsdb-bi -- Includes als Telemetry Items where data like Total request time, Pages, Language are stored.

smedb-v1.0 -- SME database, e.g. Customer, CustomerAttribute (ReceiverVatId), CustomerConfiguration, DocumentState (in what state is the document currently?), Invoice, Page (needed as connection for several queries), SmeUserSmeCustomers (Connection of RIPEye Users to Customers), User

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Known-Issues-and-How-to\Collection-of-SQL-tables-&-queries.md - Chunk 1
Previous document states: select * FROM [Page] JOIN Invoice ON Invoice.Id = [Page].InvoiceId JOIN DocumentState ON DocumentState.Id = Invoice.DocumentStateId JOIN DocumentState P1 ON P1.Id = DocumentState.PreviousStateId Join DocumentState p2 on p2.Id = p1.PreviousStateId WHERE [Page].InvoiceContainerId LIKE '%5DFA6BCC-88FC-4E2A%' AND [Page].PageNumber = 1

bcdbserverdev.database.windows.net

databases with test are test environments for customers; customers testing via this must also use the test link!!: https://validation-test.bludelta.ai/

databases with dev are used by our developers

smedbdev_current - where our Manual Test Customer is

smedbtest - test users from customers and their CustomerConfiguration

Tip: if unsure on how tables are connected with each other, create a database diagram: right mouse click on Database Diagrams folder, New Database Diagram, add fields that might have a relation with the tables you wanna connect.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Known-Issues-and-How-to\Configuration-and-Info-of-Dynamic-Config.md - Chunk 0
Dynamic Config defines: - what models are called per customer - if responses are cached - number of ocr pager per customer processed

Here is the latest file checked in: https://blumatix.visualstudio.com/DefaultCollection/Rechnungserkennung/_git/DynamicConfig?path=/CaptureSdk

Here you find info regarding latest version and how to change it: https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/BludeltaDeployment/662/Dynamic-Config

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Known-Issues-and-How-to\DevOps-Repo-for-e.g.-language-ressources.md - Chunk 0
https://blumatix.visualstudio.com/Rechnungserkennung/_git/BlumatixI18N?path=/ResourceService/src/Blumatix.Capture.Resources/Resources/languages/cs.json

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Known-Issues-and-How-to\New-API-Key-or-API-Identifier.md - Chunk 0
How to add a new API-Key or API-Identifier

e.g. bitte vergeben Sie für die Aptean DACH und den Endkunden „DWT Handelsgesellschaft für Druckluft-Werkzeug-Technik mbH“ einen neuen API-Identifier unter unserem bestehenden API-Key.

Create API-Key and API-Identifier via phoenix action: .\phoenix.exe customer create-api-key-and-identifier

Check if this already exists for a customer, otherwise create again a new one.

Then write the new partner/customer via slq insert into the db customer:

``` USE [bcsdb-auth] GO

INSERT INTO [dbo].[Customer] ([Name] ,[Token] ,[Limit] ,[ExpirationDate] ,[InvoiceDetailTypes] ,[Email] ,[IsRefused] ,[Version] ,[ApiIdentifierKey] ,[CustomerId]) VALUES (

3.1. Example Partner:

Naming Convention check here -> https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/799/Customer-and-Partners

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Known-Issues-and-How-to\New-API-Key-or-API-Identifier.md - Chunk 1
3.1. Example Partner:

Naming Convention check here -> https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/799/Customer-and-Partners

Values (Limit, InvoiceDetailTypes, IsRefused, Version) check here -> https://blumatix.visualstudio.com/BluDeltaSME/_wiki/wikis/BluDeltaSME.wiki/455/Add-Partner-Customer-Mandator-User-and-their-Configuration ```` USE [bcsdb-auth] GO

INSERT INTO [dbo].[Customer] ([Name] ,[Token] ,[Limit] ,[ExpirationDate] ,[InvoiceDetailTypes] ,[Email] ,[IsRefused] ,[Version] ,[ApiIdentifierKey] ,[CustomerId]) VALUES ( 'partner.blumatix' ,'cxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx=' ,5000 ,'2099-12-31 00:00:00.000' ,-2 ,'blumatix.beispiel@blumatix.com' ,0 ,0 ,NULL ,NULL ) GO `

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Known-Issues-and-How-to\New-API-Key-or-API-Identifier.md - Chunk 2
```

3.2. Example Customer:

Naming Convention check here -> https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/799/Customer-and-Partners

Values (Limit, InvoiceDetailTypes, IsRefused, Version) check here -> https://blumatix.visualstudio.com/BluDeltaSME/_wiki/wikis/BluDeltaSME.wiki/455/Add-Partner-Customer-Mandator-User-and-their-Configuration

```` USE [bcsdb-auth] GO

INSERT INTO [dbo].[Customer] ([Name] ,[Token] ,[Limit] ,[ExpirationDate] ,[InvoiceDetailTypes] ,[Email] ,[IsRefused] ,[Version] ,[ApiIdentifierKey] ,[CustomerId]) VALUES ( 'partner.blumatix.integration' ,NULL ,5000 ,'2099-12-31 00:00:00.000' ,-2 ,'blumatix.beispiel@blumatix.com' ,0 ,0 ,'Qhxxxxxxxxxxxxx==' ,348 ) GO ````

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Known-Issues-and-How-to\Strabag_-Upscale-Support-Requests.md - Chunk 0
[[TOC]]

What is Strabag Upscale?

Strabag uses the BLU DELTA System for RefCode detection on a daily basis and (NEW) as a backup system for their existing invocie capture solution. When Strabags current system is down they trigger an email to bludelta support and we are obliged to scale up our system to be able to handle 15.000 incremental invoices daily.

Below you see the defined processes:

Strabag Upscale Start Process

Strabag Upscale Stop Process

Information for Invoicing:

Once the Upscaling was accomplished Please inform Lisa about: - Start Date - End Date - #Transactions

Original Docs: Strabag-SupportScaleUp-Process-V1-draft.docx

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Monthly-Support-Review\2023.md - Chunk 0
[[TOSP]]

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Monthly-Support-Review\2024.md - Chunk 0
[[TOSP]]

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Monthly-Support-Review\2023\April-2023-Monthly-Support-Review.md - Chunk 0
27.04.2023

Zusammenarbeit 1st und 2nd Level besprochen

Support Posteingang: Mails markieren und Issue Nummer hinzufügen (wie bearbeite ich eine Mail)

Issue anlegen, alle wichtigen Infos rein

Signaturen

Schnellbausteine für Support Anfragen

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Monthly-Support-Review\2023\August-2023-Monthly-Support-Review.md - Chunk 0
Discuss responsability from 2nd Level Support, like in #16747

Discuss new Area Rechnungserkennung/Data Management

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Monthly-Support-Review\2023\December-2023-Monthly-Support-Meeting.md - Chunk 0
Neu Wiki Page von Amrit: https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/1571/CMAP-optional-in-PdfFilter.json

Prozess für Alerts definieren!

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Monthly-Support-Review\2023\February-2023-Monthly-Support-Review.md - Chunk 0
23.02.2023

Issues des letzten Monats: Problem und Lösung (am besten gleich gruppiert nach Themen).

Ripeye - #14811 #14628 - use mandators, that we dont have, see R&S Issues Kudu ressource - Look at Azure Logs (of Requests) - #14810 - upcoming release, if still appears, configure detail to 3 not showing - #14700 - peer review before sending credentials to customer (optional: set-customer-attribute) Task erstellen und email anhängen

Rechnungserkennung - #14793 - how to make a new regex for a e.g. order id (Bludelta Json PlugIn Overview, Json Plugins Mechanics and Rules, Json Plugin Deployment ) - #14731 - customers should take type name for identifying, not just type, since CustomInvoiceDetails have the same type identifier - #14702 - line item container off since deployment - (wiki page known issues)

Neuerungen/Ergänzungen im Support Wiki.

Support Wiki in SME updated, questions?

Rechnungserkennung: Support Process from Mail

and RIPEye updated

QA: Fragen und Anmerkungen

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Monthly-Support-Review\2023\July-2023-Monthly-Support-Review.md - Chunk 0
Neuerungen/Ergänzungen

Rudi geht, Michael und Marcus kommen -> Einschulung gibt's nächste Woche Es kommt ein zweites Handy (MultiSIM)

Neuerungen/Ergänzungen im Wiki

Wie lege ich einen Kunden direkt in der auth an: https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/1145/New-API-Key-or-API-Identifier

Unterschied zw. Aptean und Ramsauer und Stürmer https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/1147/Aptean

BUG Template

DoR - Bug Fix:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Monthly-Support-Review\2023\July-2023-Monthly-Support-Review.md - Chunk 1
Unterschied zw. Aptean und Ramsauer und Stürmer https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/1147/Aptean

BUG Template

DoR - Bug Fix:

Clear bug description • Context -- Environment where bug occured -- User-Agent used -- URL • Reproduction Steps -- List all steps required to reproduce detected bug -- Expected result information -- Actual result information • Visual Proof -- If possible, provide screenshot or a short video of bug being reporoduced in a browser, so it can be easier for developer to spot and reproduce it • Action Points -- What should be done with the bug • Additional Info (optional) -- Any eventual additional information which could be useful for reproducing the bug or fixing it

Github Template

Describe the bug A clear and concise description of what the bug is.

To Reproduce Steps to reproduce the behavior:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Monthly-Support-Review\2023\July-2023-Monthly-Support-Review.md - Chunk 2
Github Template

Describe the bug A clear and concise description of what the bug is.

To Reproduce Steps to reproduce the behavior:

Go to '...' Click on '....' Scroll down to '....' See error Expected behavior A clear and concise description of what you expected to happen.

Screenshots If applicable, add screenshots to help explain your problem.

Desktop (please complete the following information):

OS: [e.g. iOS] Browser [e.g. chrome, safari] Version [e.g. 22] Smartphone (please complete the following information):

Device: [e.g. iPhone6] OS: [e.g. iOS8.1] Browser [e.g. stock browser, safari] Version [e.g. 22] Additional context Add any other context about the problem here.

Optional additional items Issue default title: Assignees: Labels:

Von uns: Version: V.1.18 Umgebung: Prod, Dev oder Test Kunde: muss drop down menü sein

Kunden dort abholen wo sie stehen :-)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Monthly-Support-Review\2023\July-2023-Monthly-Support-Review.md - Chunk 3
Optional additional items Issue default title: Assignees: Labels:

Von uns: Version: V.1.18 Umgebung: Prod, Dev oder Test Kunde: muss drop down menü sein

Kunden dort abholen wo sie stehen :-)

Hallo Frau Schmidthaler, bitte versuche Sie den Local Storage zu löschen. Das sollte das Problem beheben. Beste Grüße, Amrit Bhogal

Ich habe es – trotz Google-Suche – nicht gefunden, wie man das in diesem Tool macht.

Danke für Ihre Bemühungen. Es scheitert aber schon daran, dass meine Benutzeroberfläche DEUTSCH ist und ich die Entsprechung für „Local Storage“ und viele andere Begriffe nicht weiß. Es ist mir klar, dass für EDV-Spezialisten Ihrer Generation Englisch wesentlich vertrauter ist als Deutsch. Meine Englischkenntnisse reichen, um Small Talk zu führen, aber nicht für EDV-Anwendungen. SORRY. Es ist nicht so schlimm, ich behalte die vielen Empfängerfelder.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Monthly-Support-Review\2023\June-2023-Monthly-Support-Review.md - Chunk 0
Wegen Urlaub vom 29.06. auf 13.07. verschoben

Mail Klemens / 21.06.2023

Hi Kathi, kannst du in eurem nächsten Support-Meeting bitte diskutieren, ob die folgende Bug DoR (Definition of Ready) ein brauchbares Template für unsere Bugs liefert.

DoR - Bug Fix: • Clear bug description • Context -- Environment where bug occured -- User-Agent used -- URL • Reproduction Steps -- List all steps required to reproduce detected bug -- Expected result information -- Actual result information • Visual Proof -- If possible, provide screenshot or a short video of bug being reporoduced in a browser, so it can be easier for developer to spot and reproduce it • Action Points -- What should be done with the bug • Additional Info (optional) -- Any eventual additional information which could be useful for reproducing the bug or fixing it Danke! cu

Github Template

Describe the bug A clear and concise description of what the bug is.

To Reproduce Steps to reproduce the behavior:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Monthly-Support-Review\2023\June-2023-Monthly-Support-Review.md - Chunk 1
Github Template

Describe the bug A clear and concise description of what the bug is.

To Reproduce Steps to reproduce the behavior:

Go to '...' Click on '....' Scroll down to '....' See error Expected behavior A clear and concise description of what you expected to happen.

Screenshots If applicable, add screenshots to help explain your problem.

Desktop (please complete the following information):

OS: [e.g. iOS] Browser [e.g. chrome, safari] Version [e.g. 22] Smartphone (please complete the following information):

Device: [e.g. iPhone6] OS: [e.g. iOS8.1] Browser [e.g. stock browser, safari] Version [e.g. 22] Additional context Add any other context about the problem here.

Optional additional items Issue default title: Assignees: Labels:

Von uns:

Version: V.1.18 Umgebung: Prod, Dev oder Test Kunde: muss drop down menü sein

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Monthly-Support-Review\2023\March-2023-Monthly-Support-Review.md - Chunk 0
28.03.2023

Issues des letzten Monats: Problem und Lösung (am besten gleich gruppiert nach Themen).

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Monthly-Support-Review\2023\March-2023-Monthly-Support-Review.md - Chunk 1
Ripeye - #15237 - Invoices stuck in released acc. to RIPEye. TO DO: Analyse if we even get the invoices (log into ripeye, search logs), and search in DB what the state of the docs are. Since the release of the doc, we basically have nothing to do anymore but wait for their download, and when they downloaded it they have to confirm it. What was the solution? R&S started a service again -.- MH: Anscheinend musste nur der Dienst neu gestartet werden – auf den ersten Blick sind jetzt alle Belege da LG MH - #15238 - first important indicator: There is no SME Customer with API Identifier: B.................==.100! TO DO: Ask customer for their request. Check APIKey and Identifier in DB, if the ones they sent are the correct ones. If it still doesn't work on their side build a postman request with their keys and try creating an accesstoken with those credentials. Then also another request should work. (How about a Postman Wiki Page or Summary of most important example requests?)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Monthly-Support-Review\2023\March-2023-Monthly-Support-Review.md - Chunk 2
15239 - troubles using the resource upload

TO DO: Ask customer for their request and response they got. Interpret the error message, build an example postman request and send it to customer, if they want a fiddler recording.

Rechnungserkennung - #15186 - wanted to know, if we can predict PurchaseOrder as LineItem, otherwise they would loose a customer TO DO: Look at example invoices, ask whether it has to be a line item (it was urgent so via phone). What was really annoying is that he wanted estimates about how long the dev time will take. Like, whether its reasonable/economically reasonable. Martin then called them back since he was on a fair or something. And both contacts stated in the mail were also not reachable per mail or phone...

14990 - wanted it corrected via training

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Monthly-Support-Review\2023\March-2023-Monthly-Support-Review.md - Chunk 3
14990 - wanted it corrected via training

TO DO: Look at invoices and see that they are advance payments (Abschlagszahlungen/Schlußrechnungen), where we do find the GTA correctly, but customer wants the remaining claim? "Restforderung" as amount. Contacted Martin about that an he wrote a Mail to their support and they will talk/talked about it in a meeting regarding Schlussrechnungen. Is the case with several issues:

11752

INFO: Collection of several VatID problems. Issues, where several VatIDs are found. Lets collect all these cases via this Bug and/or VatID tag.

Neuerungen/Ergänzungen im Support Wiki.

Postman examples? Repo mit Link hier drauf (Bernhard)

Fiddler setup wo noch gratis, einen Ort mit allen Setups

neuestes Garuda/Phönix (technische Story für Pipeline)

QA: Fragen und Anmerkungen

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Monthly-Support-Review\2023\May-2023-Monthly-Support-Review.md - Chunk 0
was cancelled due to too much work

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Monthly-Support-Review\2023\November-2023-Monthly-Support-Meeting.md - Chunk 0
Issue anlegen

Prozessweg einhalten > siehe Issue #18387 (Area: RE statt SME); Anleitung hier: How to create an Issue

Zeitaufteilung Team vs Support/Rufbereitschaft:

Ab Montag, 02.12. kann der Support täglich 2h für die Support Issues reservieren.

Timebutler eintragen: Arbeitszeit für den Support unter 'BLU DELTA Support' (keine Kategorie) eintragen

To-Dos während Supportzeiten (Mo-Fr 8-19 Uhr)

ausserhalb eurer Arbeitszeit: - E-Mails beantworten und Anrufe entgegennehmen - Issues anlegen - Wenn P1, Team aktivieren und Koordination übernehmen

Kommunikation 1st, 2nd und 3rd Level

keine direkte Anweisung an 3rd Level ohne 2nd Level Check vorher. 3rd Level wird nur aktiviert wenn der 2nd Level nicht mehr weiterkommen und nicht direkt nachdem der Issue angelegt wurde.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Monthly-Support-Review\2023\November-2023-Monthly-Support-Meeting.md - Chunk 1
keine direkte Anweisung an 3rd Level ohne 2nd Level Check vorher. 3rd Level wird nur aktiviert wenn der 2nd Level nicht mehr weiterkommen und nicht direkt nachdem der Issue angelegt wurde.

Arbeitsanweisung an 3rd Level kommt bei - Fireliner oder P1 von 1st bzw. 2nd Level - bei "normalen" Bugs, Issue vom PO (2nd Level meldet sich beim PO. Der priorisiert den Bug/Issue entsprechen in den Sprint ein) Die normalen Issues/Bugs werden nicht direkt vom 1st und 2nd Level an den 3rd Level weitergegeben!!

Neue Wiki Page (SME):

https://blumatix.visualstudio.com/BluDeltaSME/_wiki/wikis/BluDeltaSME.wiki?wikiVersion=GBwikiMaster&pagePath=/Support/GET%20download%20invoice%20next%20returns%20429&pageId=1540&_a=edit

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Monthly-Support-Review\2023\October-2023-Monthly-Support-Review.md - Chunk 0
P1 Issues/Bug durchgehen Issues 17673-17677

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Monthly-Support-Review\2024\February-2024.md - Chunk 0
Naming Convention beachten:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Monthly-Support-Review\2024\January-2024-Monthly-Support-Meeting.md - Chunk 0
Nochmal betonen: Postfach so frei wie möglich machen. Alerts verschieben, Data Coillection Reports verschieben (wenn alles passt), Mails die bereits als Issue angelegt sind oder schon abgearbeitet sind auch verschieben (zuerst noch richtig markieren). So wird das Risiko minimiert, dass eine Mail übersehen wird, wie z.B. im Issue 19027. Mail kam am 21.12.2023 rein, wir haben erst am 03.01.2024 einen Issue angelegt und retour geschrieben.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Process-&-Responsibilites\Support-Process-&-Responsibilites.md - Chunk 0
[[TOC]]

General

Support and on-call duty (Rufbereitschaft) are two separate things.

On-call duty is for availability in case of Service Critical Issues (i.e., P1) outside of business hours. This should occur very rarely, especially considering that there are only 1 customers with premium packages!

Support should NOT occur outside of working hours.

Support must always be covered by the teams during our working hours.

Availability

Support: Monday to Friday, 9am to 5pm [5d x 8h]. On-call duty: Monday to Sunday, 8am to 7pm [7d x 11h].

Reaction Time

P1: Respond immediately (asap). Provide team and customer updates (every 4 hours).

>=P2: within 2 working days.

Inform Customer/Customerlist

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Process-&-Responsibilites\Support-Process-&-Responsibilites.md - Chunk 1
Reaction Time

P1: Respond immediately (asap). Provide team and customer updates (every 4 hours).

>=P2: within 2 working days.

Inform Customer/Customerlist

If there is a P1/Maintenance/Malfunction here you find the List with e-mail addresses of all customers -> Stand 27.03.2024: BLU DELTA API Cloud: ops_mails_blu_delta_cloud_20240524_1409.csv BLU DELTA API OnPremise: ops_mails_onpremise_20240327_1310.csv BLU DELTA RIPEye: ops_mails_ripeye_20240327_1310.csv

Simply open the CSV file in the text editor. It contains the relevant email addresses, separated by semicolons. You can copy and paste these into Outlook. Ask Kathi or Martin if you have further questions.

BLU DELTA Support Process:

TBD: BLUDELTA-SupportProcess-v3.docx

DEPRECATED: BLUDELTA-SupportProcess-v2.docx

DEPRECATED: BluDeltaSupportProcess.pptx

P1 Issue handling

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Process-&-Responsibilites\Support-Process-&-Responsibilites.md - Chunk 2
BLU DELTA Support Process:

TBD: BLUDELTA-SupportProcess-v3.docx

DEPRECATED: BLUDELTA-SupportProcess-v2.docx

DEPRECATED: BluDeltaSupportProcess.pptx

P1 Issue handling

If a customer or employee reports a P1 issue please create a P1 Issue in Azure Devops and inform the whole Team, informationsecurity@blumatix.com and if necessary affected customers. Please move the P1 Issue on the Sprint board of the affected Team and find someone who can fix the issue as soon as possible.

The following information has to be provided in the P1 issue description:

Person who detected the incident.

How was the incident noticed (report from outside the company?)?

Detailed description of the incident. What exactly happened. Impact.

Attachements - Gathering all available information about the incident (log files, screenshots, emails, conversation notes, ...).

Location, date, and time of the incident and detection.

Type of affected information.

P1 Root Cause Analysis

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Process-&-Responsibilites\Support-Process-&-Responsibilites.md - Chunk 3
Location, date, and time of the incident and detection.

Type of affected information.

P1 Root Cause Analysis

For every P1 issue we have to provide a Root Cause Analysis. Review the Root Cause Analysis with Product Owner and Account Management.

For the analysis please provide the following information in the comment section of the respective Issue:

When and where did the incident occur?

Did the issue occur in the past?

What exactly happened?

Who was involved and who is the attacker?

How did the attacker proceed?

Which vulnerability was exploited in which systems?

What damage has occurred so far?

What further damage is threatened?

Is there a monitoring in place?

Which measure worked to resolve the incident quickly?

Which measure did not work?

What could have been done better?

What needs to be changed?

Where is the documentation incomplete?

Additional P1 Information

P1 Issue Query

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Process-&-Responsibilites\Support-Process-&-Responsibilites.md - Chunk 4
Which measure did not work?

What could have been done better?

What needs to be changed?

Where is the documentation incomplete?

Additional P1 Information

P1 Issue Query

ISMS bei Blumatix. A16.1 – Handhabung von Informationssicherheitsvorfällen und Verbesserungen

Responsibilites

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Process-&-Responsibilites\Support-Process-&-Responsibilites.md - Chunk 5
Responsibilities (1st Level) Support On-call duty (SCRUM) Team Change the call forwarding from the support mobile phone -> Support Phone: Call forwarding setting . X Answer Support Calls X X Check the Support E-Mail Inbox for potential P1 Issues . Create P1 Issue and inform the whole Team , informationsecurity@blumatix.com and affected customers . Move P1 Issue on Sprint board of affected Team. X X Check the Mails at the Support Inbox. Flag it, if needed put an Issue Number on it and move it to the right (Sub)Folder. Keep the inbox clean and clear so that you can see at a glance what has already been processed and where there is still work to be done. -> Support Mail Inbox Processes X Manage the (RIPEye/Rechnungserkennung) Support Backlog. Discuss in Triage which Team (Support, Rechnungserkennung, RIPEye, Data Mgt.) has to resolve the Issue. X Manage open Issues/Bugs in the Team Backlog (Support, Rechnungserkennung, RIPEye, Data Mgt.). Priortize Issues/Bugs within the Backlog together

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Process-&-Responsibilites\Support-Process-&-Responsibilites.md - Chunk 6
RIPEye, Data Mgt.) has to resolve the Issue. X Manage open Issues/Bugs in the Team Backlog (Support, Rechnungserkennung, RIPEye, Data Mgt.). Priortize Issues/Bugs within the Backlog together with Support. Resolve Issues/Bugs that are still active. Inform Support if an Issue is resolved. X Upload 'Ready for Training' Issues to RIPEye. Since the end of October, Jana and Bahare have taken over the labelling. The upload (incl. additional properties) is still done by the 1st level support. -> Ready4Training Issue Process with RIPEye X Every last Thursday of the month: Download and confirm all RIP Eye documents for the following Labeling Accounts: Internal Support Customer, jbx.label, aptean.label-> https://blumatix.visualstudio.com/BluDeltaSME/_wiki/wikis/BluDeltaSME.wiki/1313/How-to-download-and-confirm-the-Invoices-from-RIPEye X Prepare and lead the Rechnungserkennung Triage (every Tuesday from 10:00-10:30 AM) with Teams Meeting-ID: 364 060 001 889 / Passcode: d8pzWj. Link to the current

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Process-&-Responsibilites\Support-Process-&-Responsibilites.md - Chunk 7
X Prepare and lead the Rechnungserkennung Triage (every Tuesday from 10:00-10:30 AM) with Teams Meeting-ID: 364 060 001 889 / Passcode: d8pzWj. Link to the current query: https://blumatix.visualstudio.com/Rechnungserkennung/_queries/query/226617a7-3bd1-4cb5-9966-a3ed560e2e4c/ X Prepare and lead the SME Triage (every Thursday from 11:30-12:00 AM) with Teams Meeting-ID: 391 224 254 386 Passcode C6jUTn. Link to the current Query:  https://blumatix.visualstudio.com/BluDeltaSME/_queries/query/05db55e8-19f1-41bd-8e53-173be3096c2e/ X Lead Regular Retrospective with Support/On-call duty Team X Support vacation/leave: Organize a stand in familiar with the Support process X

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Process-&-Responsibilites\Support-Process-&-Responsibilites.md - Chunk 8
Customers with Premium Package (On-call duty)

eurodata

Support Responsibilities

1st Level Support (Kathi)

Handle customer inquiries via email or phone.

Create tasks for issues.

Respond to customers.

Conduct initial research on issues.

2nd Level Support (On-call)

Handle customer inquiries via email or phone.

Create tasks for issues.

Respond to customers.

Conduct initial research and in-depth analysis on issues.

Fix issues depending on knowledge level.

3rd Level Support (Teams)

Activated when 2nd Level Support cannot fix the issue.

The 2nd Level should have already conducted the analysis before escalating to 3rd Level.

Definition of Issue Priorities (P0 - P4)

P0 - Outages

P1 - The customer (or the partner's customer or partner) cannot continue working due to the issue with our services or their productivity is significantly impaired. - A stoppage of the training pipeline is considered a P1 issue from 22.5.2023 onwards.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Process-&-Responsibilites\Support-Process-&-Responsibilites.md - Chunk 9
P2 - The customer can continue working in a limited capacity due to the issue with our services, but their productivity is significantly impaired. - The customer requires substantial additional effort to work with our system.

P3 - The customer can continue working despite the issue with our services, but their productivity is slightly impaired. - The customer does not require significant additional effort to work with our system.

P4 - Minor or non-critical issues.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLU-DELTA-Support\Support-Schulungen-intern-(inkl.-Links)\Support-Training.md - Chunk 0
BLU DELTA Tech Training 20231004.pptx

Video: https://blumatixconsultinggmbh-my.sharepoint.com/:v:/g/personal/b_wimmer_blumatix_at/EbPGFj74HFlLvC4RhOBn4Z8BlM9qTJvoipPRGwQmMnBRCw

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 0
About arc42

arc42, the template for documentation of software and system architecture.

Template Version 8.2 EN. (based upon AsciiDoc version), January 2023

Created, maintained and © by Dr. Peter Hruschka, Dr. Gernot Starke and contributors. See https://arc42.org.

::: note This version of the template contains some help and explanations. It is used for familiarization with arc42 and the understanding of the concepts. For documentation of your own system you use better the plain version. :::

Introduction and Goals {#section-introduction-and-goals}

Describes the relevant requirements and the driving forces that software architects and development team must consider. These include

underlying business goals,

essential features,

essential functional requirements,

quality goals for the architecture and

relevant stakeholders and their expectations

Requirements Overview {#_requirements_overview}

::: formalpara-title Contents :::

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 1
quality goals for the architecture and

relevant stakeholders and their expectations

Requirements Overview {#_requirements_overview}

::: formalpara-title Contents :::

Short description of the functional requirements, driving forces, extract (or abstract) of requirements. Link to (hopefully existing) requirements documents (with version number and information where to find it).

::: formalpara-title Motivation :::

From the point of view of the end users a system is created or modified to improve support of a business activity and/or improve the quality.

::: formalpara-title Form :::

Short textual description, probably in tabular use-case format. If requirements documents exist this overview should refer to these documents.

Keep these excerpts as short as possible. Balance readability of this document with potential redundancy w.r.t to requirements documents.

See Introduction and Goals in the arc42 documentation.

Quality Goals {#_quality_goals}

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 2
See Introduction and Goals in the arc42 documentation.

Quality Goals {#_quality_goals}

::: formalpara-title Contents :::

The top three (max five) quality goals for the architecture whose fulfillment is of highest importance to the major stakeholders. We really mean quality goals for the architecture. Don't confuse them with project goals. They are not necessarily identical.

Consider this overview of potential topics (based upon the ISO 25010 standard):

::: formalpara-title Motivation :::

You should know the quality goals of your most important stakeholders, since they will influence fundamental architectural decisions. Make sure to be very concrete about these qualities, avoid buzzwords. If you as an architect do not know how the quality of your work will be judged...

::: formalpara-title Form :::

A table with quality goals and concrete scenarios, ordered by priorities

Stakeholders {#_stakeholders}

::: formalpara-title Contents :::

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 3
::: formalpara-title Form :::

A table with quality goals and concrete scenarios, ordered by priorities

Stakeholders {#_stakeholders}

::: formalpara-title Contents :::

Explicit overview of stakeholders of the system, i.e. all person, roles or organizations that

should know the architecture

have to be convinced of the architecture

have to work with the architecture or with code

need the documentation of the architecture for their work

have to come up with decisions about the system or its development

::: formalpara-title Motivation :::

You should know all parties involved in development of the system or affected by the system. Otherwise, you may get nasty surprises later in the development process. These stakeholders determine the extent and the level of detail of your work and its results.

::: formalpara-title Form :::

Table with role names, person names, and their expectations with respect to the architecture and its documentation.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 4
::: formalpara-title Form :::

Table with role names, person names, and their expectations with respect to the architecture and its documentation.

+-------------+---------------------------+---------------------------+ | Role/Name | Contact | Expectations | +=============+===========================+===========================+ | \ | \ | \ | +-------------+---------------------------+---------------------------+ | \ | \ | \ | +-------------+---------------------------+---------------------------+

Architecture Constraints {#section-architecture-constraints}

::: formalpara-title Contents :::

Any requirement that constraints software architects in their freedom of design and implementation decisions or decision about the development process. These constraints sometimes go beyond individual systems and are valid for whole organizations and companies.

::: formalpara-title Motivation :::

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 5
::: formalpara-title Motivation :::

Architects should know exactly where they are free in their design decisions and where they must adhere to constraints. Constraints must always be dealt with; they may be negotiable, though.

::: formalpara-title Form :::

Simple tables of constraints with explanations. If needed you can subdivide them into technical constraints, organizational and political constraints and conventions (e.g. programming or versioning guidelines, documentation or naming conventions)

See Architecture Constraints in the arc42 documentation.

System Scope and Context {#section-system-scope-and-context}

::: formalpara-title Contents :::

System scope and context - as the name suggests - delimits your system (i.e. your scope) from all its communication partners (neighboring systems and users, i.e. the context of your system). It thereby specifies the external interfaces.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 6
If necessary, differentiate the business context (domain specific inputs and outputs) from the technical context (channels, protocols, hardware).

::: formalpara-title Motivation :::

The domain interfaces and technical interfaces to communication partners are among your system's most critical aspects. Make sure that you completely understand them.

::: formalpara-title Form :::

Various options:

Context diagrams

Lists of communication partners and their interfaces.

See Context and Scope in the arc42 documentation.

Business Context {#_business_context}

::: formalpara-title Contents :::

Specification of all communication partners (users, IT-systems, ...) with explanations of domain specific inputs and outputs or interfaces. Optionally you can add domain specific formats or communication protocols.

::: formalpara-title Motivation :::

All stakeholders should understand which data are exchanged with the environment of the system.

::: formalpara-title Form :::

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 7
::: formalpara-title Motivation :::

All stakeholders should understand which data are exchanged with the environment of the system.

::: formalpara-title Form :::

All kinds of diagrams that show the system as a black box and specify the domain interfaces to communication partners.

Alternatively (or additionally) you can use a table. The title of the table is the name of your system, the three columns contain the name of the communication partner, the inputs, and the outputs.

Technical Context {#_technical_context}

::: formalpara-title Contents :::

Technical interfaces (channels and transmission media) linking your system to its environment. In addition a mapping of domain specific input/output to the channels, i.e. an explanation which I/O uses which channel.

::: formalpara-title Motivation :::

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 8
::: formalpara-title Motivation :::

Many stakeholders make architectural decision based on the technical interfaces between the system and its context. Especially infrastructure or hardware designers decide these technical interfaces.

::: formalpara-title Form :::

E.g. UML deployment diagram describing channels to neighboring systems, together with a mapping table showing the relationships between channels and input/output.

Solution Strategy {#section-solution-strategy}

::: formalpara-title Contents :::

A short summary and explanation of the fundamental decisions and solution strategies, that shape system architecture. It includes

technology decisions

decisions about the top-level decomposition of the system, e.g. usage of an architectural pattern or design pattern

decisions on how to achieve key quality goals

relevant organizational decisions, e.g. selecting a development process or delegating certain tasks to third parties.

::: formalpara-title Motivation :::

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 9
relevant organizational decisions, e.g. selecting a development process or delegating certain tasks to third parties.

::: formalpara-title Motivation :::

These decisions form the cornerstones for your architecture. They are the foundation for many other detailed decisions or implementation rules.

::: formalpara-title Form :::

Keep the explanations of such key decisions short.

Motivate what was decided and why it was decided that way, based upon problem statement, quality goals and key constraints. Refer to details in the following sections.

See Solution Strategy in the arc42 documentation.

Building Block View {#section-building-block-view}

::: formalpara-title Content :::

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 10
See Solution Strategy in the arc42 documentation.

Building Block View {#section-building-block-view}

::: formalpara-title Content :::

The building block view shows the static decomposition of the system into building blocks (modules, components, subsystems, classes, interfaces, packages, libraries, frameworks, layers, partitions, tiers, functions, macros, operations, data structures, ...) as well as their dependencies (relationships, associations, ...)

This view is mandatory for every architecture documentation. In analogy to a house this is the floor plan.

::: formalpara-title Motivation :::

Maintain an overview of your source code by making its structure understandable through abstraction.

This allows you to communicate with your stakeholder on an abstract level without disclosing implementation details.

::: formalpara-title Form :::

The building block view is a hierarchical collection of black boxes and white boxes (see figure below) and their descriptions.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 11
::: formalpara-title Form :::

The building block view is a hierarchical collection of black boxes and white boxes (see figure below) and their descriptions.

Level 1 is the white box description of the overall system together with black box descriptions of all contained building blocks.

Level 2 zooms into some building blocks of level 1. Thus it contains the white box description of selected building blocks of level 1, together with black box descriptions of their internal building blocks.

Level 3 zooms into selected building blocks of level 2, and so on.

See Building Block View in the arc42 documentation.

Whitebox Overall System {#_whitebox_overall_system}

Here you describe the decomposition of the overall system using the following white box template. It contains

an overview diagram

a motivation for the decomposition

black box descriptions of the contained building blocks. For these we offer you alternatives:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 12
an overview diagram

a motivation for the decomposition

black box descriptions of the contained building blocks. For these we offer you alternatives:

use one table for a short and pragmatic overview of all contained building blocks and their interfaces

use a list of black box descriptions of the building blocks according to the black box template (see below). Depending on your choice of tool this list could be sub-chapters (in text files), sub-pages (in a Wiki) or nested elements (in a modeling tool).

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 13
(optional:) important interfaces, that are not explained in the black box templates of a building block, but are very important for understanding the white box. Since there are so many ways to specify interfaces why do not provide a specific template for them. In the worst case you have to specify and describe syntax, semantics, protocols, error handling, restrictions, versions, qualities, necessary compatibilities and many things more. In the best case you will get away with examples or simple signatures.

Motivation

: \

Contained Building Blocks

: \

Important Interfaces

: \

Insert your explanations of black boxes from level 1:

If you use tabular form you will only describe your black boxes with name and responsibility according to the following schema:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 14
: \

Insert your explanations of black boxes from level 1:

If you use tabular form you will only describe your black boxes with name and responsibility according to the following schema:

+-----------------------+-----------------------------------------------+ | Name | Responsibility | +=======================+===============================================+ | \ | \ | +-----------------------+-----------------------------------------------+ | \ | \ | +-----------------------+-----------------------------------------------+

If you use a list of black box descriptions then you fill in a separate black box template for every important building block . Its headline is the name of the black box.

\

Here you describe \

Purpose/Responsibility

Interface(s), when they are not extracted as separate paragraphs. This interfaces may include qualities and performance characteristics.

(Optional) Quality-/Performance characteristics of the black box, e.g.availability, run time behavior, ....

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 15
(Optional) Quality-/Performance characteristics of the black box, e.g.availability, run time behavior, ....

(Optional) directory/file location

(Optional) Fulfilled requirements (if you need traceability to requirements).

(Optional) Open issues/problems/risks

\<(Optional) Quality/Performance Characteristics>

\<(Optional) Directory/File Location>

\<(Optional) Fulfilled Requirements>

\<(optional) Open Issues/Problems/Risks>

\

\

\

...

\

Level 2 {#_level_2}

Here you can specify the inner structure of (some) building blocks from level 1 as white boxes.

You have to decide which building blocks of your system are important enough to justify such a detailed description. Please prefer relevance over completeness. Specify important, surprising, risky, complex or volatile building blocks. Leave out normal, simple, boring or standardized parts of your system

White Box \ {#_white_box_emphasis_building_block_1_emphasis}

...describes the internal structure of building block 1.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 16
White Box \ {#_white_box_emphasis_building_block_1_emphasis}

...describes the internal structure of building block 1.

White Box \ {#_white_box_emphasis_building_block_2_emphasis}

...

White Box \ {#_white_box_emphasis_building_block_m_emphasis}

Level 3 {#_level_3}

Here you can specify the inner structure of (some) building blocks from level 2 as white boxes.

When you need more detailed levels of your architecture please copy this part of arc42 for additional levels.

White Box \<_building block x.1_> {#_white_box_building_block_x_1}

Specifies the internal structure of building block x.1.

White Box \<_building block x.2_> {#_white_box_building_block_x_2}

White Box \<_building block y.1_> {#_white_box_building_block_y_1}

Runtime View {#section-runtime-view}

::: formalpara-title Contents :::

The runtime view describes concrete behavior and interactions of the system's building blocks in form of scenarios from the following areas:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 17
::: formalpara-title Contents :::

The runtime view describes concrete behavior and interactions of the system's building blocks in form of scenarios from the following areas:

important use cases or features: how do building blocks execute them?

interactions at critical external interfaces: how do building blocks cooperate with users and neighboring systems?

operation and administration: launch, start-up, stop

error and exception scenarios

Remark: The main criterion for the choice of possible scenarios (sequences, workflows) is their architectural relevance. It is not important to describe a large number of scenarios. You should rather document a representative selection.

::: formalpara-title Motivation :::

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 18
::: formalpara-title Motivation :::

You should understand how (instances of) building blocks of your system perform their job and communicate at runtime. You will mainly capture scenarios in your documentation to communicate your architecture to stakeholders that are less willing or able to read and understand the static models (building block view, deployment view).

::: formalpara-title Form :::

There are many notations for describing scenarios, e.g.

numbered list of steps (in natural language)

activity diagrams or flow charts

sequence diagrams

BPMN or EPCs (event process chains)

state machines

...

See Runtime View in the arc42 documentation.

\

\<insert description of the notable aspects of the interactions between the building block instances depicted in this diagram.>

\

... {#_}

\

Deployment View {#section-deployment-view}

::: formalpara-title Content :::

The deployment view describes:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 19
\

... {#_}

\

Deployment View {#section-deployment-view}

::: formalpara-title Content :::

The deployment view describes:

technical infrastructure used to execute your system, with infrastructure elements like geographical locations, environments, computers, processors, channels and net topologies as well as other infrastructure elements and

mapping of (software) building blocks to that infrastructure elements.

Often systems are executed in different environments, e.g. development environment, test environment, production environment. In such cases you should document all relevant environments.

Especially document a deployment view if your software is executed as distributed system with more than one computer, processor, server or container or when you design and construct your own hardware processors and chips.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 20
From a software perspective it is sufficient to capture only those elements of an infrastructure that are needed to show a deployment of your building blocks. Hardware architects can go beyond that and describe an infrastructure to any level of detail they need to capture.

::: formalpara-title Motivation :::

Software does not run without hardware. This underlying infrastructure can and will influence a system and/or some cross-cutting concepts. Therefore, there is a need to know the infrastructure.

Maybe a highest level deployment diagram is already contained in section 3.2. as technical context with your own infrastructure as ONE black box. In this section one can zoom into this black box using additional deployment diagrams:

UML offers deployment diagrams to express that view. Use it, probably with nested diagrams, when your infrastructure is more complex.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 21
UML offers deployment diagrams to express that view. Use it, probably with nested diagrams, when your infrastructure is more complex.

When your (hardware) stakeholders prefer other kinds of diagrams rather than a deployment diagram, let them use any kind that is able to show nodes and channels of the infrastructure.

See Deployment View in the arc42 documentation.

Infrastructure Level 1 {#_infrastructure_level_1}

Describe (usually in a combination of diagrams, tables, and text):

distribution of a system to multiple locations, environments, computers, processors, .., as well as physical connections between them

important justifications or motivations for this deployment structure

quality and/or performance features of this infrastructure

mapping of software artifacts to elements of this infrastructure

For multiple environments or alternative deployments please copy and adapt this section of arc42 for all relevant environments.

Motivation

: \

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 22
For multiple environments or alternative deployments please copy and adapt this section of arc42 for all relevant environments.

Motivation

: \

Quality and/or Performance Features

: \

Mapping of Building Blocks to Infrastructure

: \

Infrastructure Level 2 {#_infrastructure_level_2}

Here you can include the internal structure of (some) infrastructure elements from level 1.

Please copy the structure from level 1 for each selected element.

\ {#__emphasis_infrastructure_element_1_emphasis}

\ {#__emphasis_infrastructure_element_2_emphasis}

...

\ {#__emphasis_infrastructure_element_n_emphasis}

Cross-cutting Concepts {#section-concepts}

::: formalpara-title Content :::

This section describes overall, principal regulations and solution ideas that are relevant in multiple parts (= cross-cutting) of your system. Such concepts are often related to multiple building blocks. They can include many different topics, such as

models, especially domain models

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 23
models, especially domain models

architecture or design patterns

rules for using specific technology

principal, often technical decisions of an overarching (= cross-cutting) nature

implementation rules

::: formalpara-title Motivation :::

Concepts form the basis for conceptual integrity (consistency, homogeneity) of the architecture. Thus, they are an important contribution to achieve inner qualities of your system.

Some of these concepts cannot be assigned to individual building blocks, e.g. security or safety.

::: formalpara-title Form :::

The form can be varied:

concept papers with any kind of structure

cross-cutting model excerpts or scenarios using notations of the architecture views

sample implementations, especially for technical concepts

reference to typical usage of standard frameworks (e.g. using Hibernate for object/relational mapping)

::: formalpara-title Structure :::

A potential (but not mandatory) structure for this section could be:

Domain concepts

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 24
::: formalpara-title Structure :::

A potential (but not mandatory) structure for this section could be:

Domain concepts

User Experience concepts (UX)

Safety and security concepts

Architecture and design patterns

\"Under-the-hood\"

development concepts

operational concepts

Note: it might be difficult to assign individual concepts to one specific topic on this list.

See Concepts in the arc42 documentation.

\ {#__emphasis_concept_1_emphasis}

\ {#__emphasis_concept_2_emphasis}

...

\ {#__emphasis_concept_n_emphasis}

Architecture Decisions {#section-design-decisions}

::: formalpara-title Contents :::

Important, expensive, large scale or risky architecture decisions including rationales. With \"decisions\" we mean selecting one alternative based on given criteria.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 25
Important, expensive, large scale or risky architecture decisions including rationales. With \"decisions\" we mean selecting one alternative based on given criteria.

Please use your judgement to decide whether an architectural decision should be documented here in this central section or whether you better document it locally (e.g. within the white box template of one building block).

Avoid redundancy. Refer to section 4, where you already captured the most important decisions of your architecture.

::: formalpara-title Motivation :::

Stakeholders of your system should be able to comprehend and retrace your decisions.

::: formalpara-title Form :::

Various options:

ADR (Documenting Architecture Decisions) for every important decision

List or table, ordered by importance and consequences or:

more detailed in form of separate sections per decision

See Architecture Decisions in the arc42 documentation. There you will find links and examples about ADR.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 26
more detailed in form of separate sections per decision

See Architecture Decisions in the arc42 documentation. There you will find links and examples about ADR.

Quality Requirements {#section-quality-scenarios}

::: formalpara-title Content :::

This section contains all quality requirements as quality tree with scenarios. The most important ones have already been described in section 1.2. (quality goals)

Here you can also capture quality requirements with lesser priority, which will not create high risks when they are not fully achieved.

::: formalpara-title Motivation :::

Since quality requirements will have a lot of influence on architectural decisions you should know for every stakeholder what is really important to them, concrete and measurable.

See Quality Requirements in the arc42 documentation.

Quality Tree {#_quality_tree}

::: formalpara-title Content :::

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 27
See Quality Requirements in the arc42 documentation.

Quality Tree {#_quality_tree}

::: formalpara-title Content :::

The quality tree (as defined in ATAM -- Architecture Tradeoff Analysis Method) with quality/evaluation scenarios as leafs.

::: formalpara-title Motivation :::

The tree structure with priorities provides an overview for a sometimes large number of quality requirements.

::: formalpara-title Form :::

The quality tree is a high-level overview of the quality goals and requirements:

tree-like refinement of the term \"quality\". Use \"quality\" or \"usefulness\" as a root

a mind map with quality categories as main branches

In any case the tree should include links to the scenarios of the following section.

Quality Scenarios {#_quality_scenarios}

::: formalpara-title Contents :::

Concretization of (sometimes vague or implicit) quality requirements using (quality) scenarios.

These scenarios describe what should happen when a stimulus arrives at the system.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 28
Concretization of (sometimes vague or implicit) quality requirements using (quality) scenarios.

These scenarios describe what should happen when a stimulus arrives at the system.

For architects, two kinds of scenarios are important:

Usage scenarios (also called application scenarios or use case scenarios) describe the system's runtime reaction to a certain stimulus. This also includes scenarios that describe the system's efficiency or performance. Example: The system reacts to a user's request within one second.

Change scenarios describe a modification of the system or of its immediate environment. Example: Additional functionality is implemented or requirements for a quality attribute change.

::: formalpara-title Motivation :::

Scenarios make quality requirements concrete and allow to more easily measure or decide whether they are fulfilled.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 29
::: formalpara-title Motivation :::

Scenarios make quality requirements concrete and allow to more easily measure or decide whether they are fulfilled.

Especially when you want to assess your architecture using methods like ATAM you need to describe your quality goals (from section 1.2) more precisely down to a level of scenarios that can be discussed and evaluated.

::: formalpara-title Form :::

Tabular or free form text.

Risks and Technical Debts {#section-technical-risks}

::: formalpara-title Contents :::

A list of identified technical risks or technical debts, ordered by priority

::: formalpara-title Motivation :::

"Risk management is project management for grown-ups" (Tim Lister, Atlantic Systems Guild.)

This should be your motto for systematic detection and evaluation of risks and technical debts in the architecture, which will be needed by management stakeholders (e.g. project managers, product owners) as part of the overall risk analysis and measurement planning.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 30
::: formalpara-title Form :::

List of risks and/or technical debts, probably including suggested measures to minimize, mitigate or avoid risks or reduce technical debts.

See Risks and Technical Debt in the arc42 documentation.

Glossary {#section-glossary}

::: formalpara-title Contents :::

The most important domain and technical terms that your stakeholders use when discussing the system.

You can also see the glossary as source for translations if you work in multi-language teams.

::: formalpara-title Motivation :::

You should clearly define your terms, so that all stakeholders

have an identical understanding of these terms

do not use synonyms and homonyms

A table with columns \

Potentially more columns in case you need translations.

See Glossary in the arc42 documentation.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Arc42---Template.md - Chunk 31
do not use synonyms and homonyms

A table with columns \

Potentially more columns in case you need translations.

See Glossary in the arc42 documentation.

+-----------------------+-----------------------------------------------+ | Term | Definition | +=======================+===============================================+ | \ | \ | +-----------------------+-----------------------------------------------+ | \ | \ | +-----------------------+-----------------------------------------------+

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting.md - Chunk 0
TODO: must be translated into english

Einführung

Regelmäßige Architektur-Alignment Meeting werden gemacht, um unser Team bei der Entwicklung und Pflege unserer Softwarearchitektur besser zu unterstützen. Diese Meetings bieten uns die Gelegenheit, gemeinsam über aktuelle Herausforderungen, technische Schulden und Verbesserungsmöglichkeiten zu diskutieren. Sie sind entscheidend, um sicherzustellen, dass alle Teammitglieder – von SW Architekten, DevOps und Entwicklern bis hin zum PO – auf dem gleichen Stand sind und effektiv zusammenarbeiten. Unser Ziel ist es, durch diese regelmäßigen Treffen unsere BLU DELTA (alle SW Teile die dazugehören) stärker an den Geschäftszielen auszurichten und gleichzeitig die technische Qualität zu sichern.

Aufbau des Meetings

Häufigkeit und Dauer

Alle zwei Wochen und vor dem Product Planning Meeting, alos mehr oder weniger wie gehabt :-)

Maximal 60-90 Minuten

Teilnehmer

Lead Architekt

Softwarearchitekt(en)

DevOps Lead

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting.md - Chunk 1
Alle zwei Wochen und vor dem Product Planning Meeting, alos mehr oder weniger wie gehabt :-)

Maximal 60-90 Minuten

Teilnehmer

Lead Architekt

Softwarearchitekt(en)

DevOps Lead

PO für bestimmte Abschnitte - wenn nötig. Ansonsten wir PO (Chris) immer via Meetings Notes (Protokoll) am laufenden gehalten

Agenda

Agenda wird vorab definiert und mindestens einen Tag im Voraus an alle verteilt. Input sollte von uns allen kommen.

Schlüsselthemen werden besprochen:

aktuelle Architekturprobleme

technische Schulden

Operative Probleme

mögliche Verbesserungen und Updates zu techn. Stories.

ISMS relevante Themen

Aufteilung des Meetings: über die Dauer der einzelnen Punkte kann man diskutieren, hab ich einfach mal so aus dem Bauch heraus definiert :-)

Überprüfung des aktuellen Zustands (15-20 Minuten):

Kurze Updates zu laufenden Aktivitäten und Informationen über kritische Probleme seit dem letzten Meeting.

Diskussion von Problemen (20-30 Minuten):

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting.md - Chunk 2
Kurze Updates zu laufenden Aktivitäten und Informationen über kritische Probleme seit dem letzten Meeting.

Diskussion von Problemen (20-30 Minuten):

Welche Probleme bezüglich Architektur gibt es aktuell - wie kann man die lösen.

Für die Diskussion von Architekturthemen möchte ich bestimmte Abschnitte aus dem Arc42 Template (das hab ich Kurs gelernt bzw. kennengelernt) heranziehen (Component View, Runtime View, Deployment View, Quality Requirements etc.). Dazu wirds von mir noch nähere Informationen geben.

Technische Schulden und Verbesserungen (15-20 Minuten):

Überprüfen und Priorisieren von technischen Schulden.

Diskussion über mögliche architektonische Verbesserungen, refactorings.

Integration des PO (10-15 Minuten), das ist optional und könnte auch im Product Planning gemacht werden:

Update zu relevanten technischen Stories, Refactorings etc.

Auswirkungen aufs Business

Action Points und Abschluss (5-10 Minuten):

Zusammenfassung der Schlüsselentscheidungen

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting.md - Chunk 3
Update zu relevanten technischen Stories, Refactorings etc.

Auswirkungen aufs Business

Action Points und Abschluss (5-10 Minuten):

Zusammenfassung der Schlüsselentscheidungen

Zuweisung von Verantwortlichkeiten und Festlegung von Zielen bis zum nächsten Meeting.

Dokumentation und Nachverfolgung

Wichtigste Punkte werden protokolliert, z.B. Entscheidungen und Action Points während des Meetings.

Protokoll wird an alle Teilnehmer und relevante Personen verteit.

Zuständigkeiten, also wer was macht, für die Action Points werden definiert

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Documentation-Guidelines---C4-Model.md - Chunk 0
Why Software Architecture Visualization and Description

Having a common understanding of how a Software System works

A basis for discussions with various stakeholders

Fast onboarding of new employees (Management, Development, etc)

Abstractions

A common set of abstractions is needed to create a ubiquitous and unambiguous language that we can use to describe the static structure of a software system. With the C4 Model a software system can be described in terms of containers, components and code as well as people who use the software systems that we build.

Elements

Person: A person represents one of the human users of your software system (e.g. actors, roles, personas, etc).

Software System: A software system is the highest level of abstraction and describes something that delivers value to its users, whether they are human or not – Bludelta or RipEye can be considered as a Software System.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Documentation-Guidelines---C4-Model.md - Chunk 1
Container: Container represents an application or a data store. Container != DockerContainer. Examples ares:

Server-side web application

Serverless function

Console Application

Database

Blob Storage

Filesystem

ShellScript

Any application which runs in a docker container

etc

Component: A component is a grouping of related functionality encapsulated behind a well-defined interface. In dotnet it could be an assembly, dll. In java it could be a jar file. In Python it could be a pip package or a python module. An important point to note here is that all components inside a container typically execute in the same process space. In the C4 model, components are not separately deployable units.

Code

References

C4Model

structurizr

structurizr-github

Simon Brown C4 YouTube

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Bludelta---DocumentCapture-Architecture.md - Chunk 0
Architecture

This is a first draft how our DocumentCapture System might be implemented in the future

Services - Containers

Bludelta consists of several key containers:

Bludelta API: Entry point. Accepts documents from our customers. Starts workflows, does authentication etc.

Workflow Engine: Executes workflows

Workflow: A specific workflow which consists of several activities. Each customer may have one or more custom or default workflows

Activity: An activity is a certain task that is execute by a workflow. An activity might for example be a request to an OCR-Service, or a request to our typhon service or an email notification or whatever.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Documentation---Bludelta-Software-Systems.md - Chunk 0
Introduction

This page shall acts as a starting point for the exploration of our Bludelta Software Systems, namely the "Bludelta.Api", "Bludelta.Data" and the "Bludelta.Ai", various guidelines, best practices and more. From here you can dig deeper into the Bludelta rabbit hole.

Bludelta 1.0 - Visio Diagram

Bludelta 1.0

Bludelta.Ai

Architecture Documentation

Training pipeline

Bludelta.Api

Architecture Documentation

Bludelta.Data

Architecture Documentation

DataCollection

Best Practices

Best Practices - Development

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Elsa-Workflow-Engine.md - Chunk 0
Using Elsa as a Workflow Engine

BludeltaWorkflow Repo Bludelta 2.0

1. Introduction to Elsa

What is Elsa?

Elsa is an open-source workflow engine tailored for ease of use and extensibility. It enables developers to design, manage, and automate business processes within applications seamlessly.

The significance of workflow engines

Workflow engines play a pivotal role in modern software architectures. They standardize processes, boost productivity, and ensure consistency in operations. By integrating a workflow engine, businesses can make processes transparent, efficient, and adaptive to change.

2. Elsa’s Architecture

Core Components

Elsa's design centers on four primary components: Workflows, Activities, Workflow Context, and Outcomes. Each has a distinct role in orchestrating and executing tasks.

Importance of Modular Design

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Elsa-Workflow-Engine.md - Chunk 1
Elsa's design centers on four primary components: Workflows, Activities, Workflow Context, and Outcomes. Each has a distinct role in orchestrating and executing tasks.

Importance of Modular Design

A modular approach ensures scalability, maintainability, and flexibility. By isolating functionalities into distinct components, developers can modify, test, and extend features with minimal disruption.

3. Activity Types in Elsa

Overview of Built-in Activities

Elsa comes packed with a diverse set of activities, from Control Flow Activities like If, Fork, and Join to Timer Activities, Event Activities, and HTTP Activities. These predefined activities cover a broad spectrum of common workflow tasks.

Designing Custom Activities

For unique business requirements, Elsa empowers developers to craft custom activities. By harnessing Elsa's extensible architecture, developers can incorporate specialized operations seamlessly.

Bludelta Activities:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Elsa-Workflow-Engine.md - Chunk 2
Bludelta Activities:

ProxyService and Service Activities: ProxyService Activities are those parts which are really called during worklow execution. These activities will then communicate, most of the time via message passing, with Bludelta Services. Some current examples:

OcrBoxProxyActivity and OcrBox Service

EntityRecognitionProxyActivity and EntityRecognition

TyphonServiceProxyActivity and any TyphonService

Naming convention for Activity Classes:

ProxyActivity:

Service Activity: NameOfYourService

RPC-Based-Communication: Proxy Services class shall inherit from the RequestReplayBaseActivity class which provides all the necessary functionality and properties needed for RPC-Message-Based Communication.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Elsa-Workflow-Engine.md - Chunk 3
Async for IO Operations: Proxy Activities have to override and implement the following method. Csharp protected override async ValueTask<IActivityExecutionResult> OnExecuteAsync(ActivityExecutionContext context) { try { // Your Code comes here ... var result = await base.OnExecuteAsync(context); .... return Outcome(OutcomeNames.Done); } catch (Exception ex) { _logger.Error(ex.Message, ex); return Fault(BlumatixOutcomes.Fault); } }

4. Developing with Elsa

Setting up Elsa

Elsa 3 Documentation

Visual Designer vs. Code-based Definitions

While the Visual Designer offers a drag-and-drop interface ideal for rapid prototyping, code-based definitions provide granular control, particularly beneficial for complex workflows.

Workflow Context & State Management

Every Elsa workflow operates within a Workflow Context, an environment that stores runtime data. This stateful approach ensures workflows can pause, resume, and maintain data consistency across tasks.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Elsa-Workflow-Engine.md - Chunk 4
Persistence: SQLite, MSSQL, MongoDB and others. We have to select the right storage solution!!!

Elsa is configured to use MSSQL and update the database schema automatically

Database connection is provided via "ConnectionStrings" in appsettings.json

Testing and Debugging Workflows

???

5. Integration & Extensibility

Connecting to External Services

Elsa can interface with external systems, whether through HTTP activities or custom-built integrations like the RabbitMQ-based OcrActivity.

Developing Custom Activities

With Elsa's adaptable architecture, introducing bespoke activities tailored to specific tasks becomes an achievable feat, ensuring that the workflow engine can evolve with the organization's needs.

6. Best Practices with Elsa

Workflow Design Recommendations

Design workflows to be modular, maintainable, and idempotent. Ensure a single responsibility per activity and leverage versioning to manage evolving business processes.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Elsa-Workflow-Engine.md - Chunk 5
Design workflows to be modular, maintainable, and idempotent. Ensure a single responsibility per activity and leverage versioning to manage evolving business processes.

Performance, Security, and Scalability Tips

Optimize workflows for performance. Always prioritize security, especially in integrations. As demands grow, ensure that the workflows and infrastructure can scale to meet the increased load.

8. Versioning

How to version Workflows

TBD

How to version Activities

TBD

9. Workflow Correlation

How can we identifiy a certain workflow. Workflow identification is especially important when we introduce asynchronous endppoints.

Workflows

OrderConfirmation Quotation Receipt

TODOS:

Authentication

Add authentication

BluDoc

Add real version to CreatorSoftwareVersion: The version can or should be taken from an environment variable

REST Interface

Async public endpoint

Packet tracing: correlation id

State Tracking

OcrBox

OCRBox Exception Handling - convert to image

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Elsa-Workflow-Engine.md - Chunk 6
REST Interface

Async public endpoint

Packet tracing: correlation id

State Tracking

OcrBox

OCRBox Exception Handling - convert to image

OCRBox parameters

RabbitMQ:

Health probing einbauen:

Http Ping Endpoint einbauen: das würde ich bevorzugen, weil wir diesen mechanismus schon verwenden. Hat halt einen gewissen overhead.

Eine eigene health queue einrichten. Die Services schicken periodisch eine message mit einer eindeutigen ID hin. Die messages müssen dann ausgewertet werden. Hab ich gelesen, dass man das so machen kann. Find ich irgendwie kompliziert.

RabbitMQ scalable und ausfallsicher machen. Sehr wichtig!

Retry Mechnismus in den Clients einbauen.

Workflow: do not add real content to a rabbitmq message. Data shall be stored in a cache or blobstorage. Message shall only contain path/link to the data/content.

ACtivities should use our RabbitMQ library

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Elsa-Workflow-Engine.md - Chunk 7
ACtivities should use our RabbitMQ library

Messages shall be slim. Documents etc. shall not be transported via messages. Messages shall only contain links/paths to document etc.

ELSA WorkflowEngine

Check and fix memory issues

Performance Tests

Exception handling

How do we test our workflows - integration tests

Parallel Fork Activity

sql Server issure

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\OnPremise-(2.0).md - Chunk 0
OnPremise_General_Architecture_Future.pptx

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Process-Archtitecture-2.0.md - Chunk 0
BLU DELTA Process Architecture 2.0

Goal:

individual models to be applied per customer and/or document type fast and easy

How-to: Decoupling of process execution and tasks (=services)

Decoupled services enable individual models to be applied per customer and/or document type Models and services can be added to the process on the fly based on configuration Service components are indpendent and can be scaled via Azure individually

Basic principle with 4 generic elements:

4 generic base elements:

Individual process definition:

Defines the process workflow (what models are called for what customer/document)

Orchestrator:

Service Responsibility:

Executes Enrichment of incoming documents according to process definition

Generic Doc Definition

Document Meta-Information

Services (Enrichment)

Service Responsibility:

can process generic document information processes document and enriches meta-information

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Scaling-Endpoint-(Strabag-Concept).md - Chunk 0
The scaling service can be used to scale any Cloud Resources. This means: - no special implementation for BLU DELTA - Could be used to Scale SME-Resources too - This generic approach does not really add additional implementation-complexity

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\SmartLib-Plugin-Solution.md - Chunk 0
Requirements

It should be possible to handle multiple SmartLibs from different customers in the cloud.

It should be possible to handle multiple SmartLibs from a single customer.

A SmartLib for a certain customer should only be accessible by this customer

It should also support non-custom InvoiceDetails and Filters, see Contact class

It should be possible to update custom resources which are only available and needed in the custom smart lib.

SmartLibs shall be signed

It should be possible to use a CustomSmartLib locally.

Plugins can be created in two ways:

Assembly plugins - .dll files from our internal assemblies

Json plugins - a .json file containing the definition of the plugin

Json plugins only need to support smart patterns for now

How To

The assembly name must end with SmartFilters.dll or SmartFilters.json

For assembly plugins: Add the AssemblyPlugin attribute with the customer's APIKey to the the AssemblyInfo.cs file.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\SmartLib-Plugin-Solution.md - Chunk 1
How To

The assembly name must end with SmartFilters.dll or SmartFilters.json

For assembly plugins: Add the AssemblyPlugin attribute with the customer's APIKey to the the AssemblyInfo.cs file.

SmartLib Plugins must be copied into the Blumatix.Capture.Webservice.Client.Selhosted/bin/x64/debug(release)/plugins or Hosted/bin/Plugins folder

Architecture

SmartLib Class Diagram

The image below shows the class diagram of our SmartLib system.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\SmartLib-Plugin-Solution.md - Chunk 2
Architecture

SmartLib Class Diagram

The image below shows the class diagram of our SmartLib system.

The SmartLib system consists of mainly of these parts: - SmartFilter: A SmartFilter must implement the ISmartFilter interface. Filters find certain InvoiceDetails on certain invoice types with pattern matching algorithms like RegularExpressions. - CustomInvoiceDetail: CustomInvoiceDetails must be derived from the abstract class CustomInvoiceDetailBase. We use custom invoice details for situations where a SmartFilter implementation can't be used, e.g. when a custom ML model shall be used for a certain customer. - Plugin: A Plugin encapsualtes SmartFilters and CustomInvoiceDetails of one customer. - PluginManager: The PluginManager is responsible for loading SmartLib assemblies into the capturesdk process. - Customer Specific: In the AssemblyInfo you put the APIKeys of the customer for which the plugin should be activated.

REST Endpoints

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\SmartLib-Plugin-Solution.md - Chunk 3
REST Endpoints

The BlumatixCaptureSdk service provides endpoints for listing plugins that are currently in use and for uploading a new plugin.

Upload new plugin: Provide capturesdk url, plugin file and plugin name.

phoenix.exe capturesdk plugin -u -c http://blumatixcapturesdk-v1-8.azurewebsites.net -s "D:\Source\Repos\Blumatix Capture\OerkSmartFilters\bin\Release\OerkSmartFilters.dll" -n oerkstmk

List all plugins: PS> phoenix.exe capturesdk plugin -c http://blumatixcapturesdk-v1-8.azurewebsites.net -i Plugin: Plugin info: CustomerName: AssemblyName: OerkSmartFilters AssemblyVersion: 1.0.0.0 ApiKeys: Egs+JbcnCn6T8YWdT3Fps8h1yqDIfiIX9XUobV3EUpxqJLyAOWQnxyHEjdzC0hZVraVx8z0fAH96WmsrmwK5MA==, ndDyEMeqh0IRw45pbdwmpUWYP54geTKu2xQZwhaAFP1hvNjp/rVw4FLaOIN3LK6ZMool2tK+DpY8ToJB7XIXTQ== ResourceUpdateName: CustomInvoiceDetail Type: CustomInvoiceDetail Name: OerkBezirksstelle

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\SmartLib-Plugin-Solution.md - Chunk 4
Plugin: Plugin info: CustomerName: Strabag AssemblyName: StrabagSmartFilters AssemblyVersion: 1.7.0.0 ApiKeys: Egs+JbcnCn6T8YWdT3Fps8h1yqDIfiIX9XUobV3EUpxqJLyAOWQnxyHEjdzC0hZVraVx8z0fAH96WmsrmwK5MA==, +ui/D3F2kJMi7IQzZz2XykdgnlTZJjeKqvin1y7iy4I72WGRgApWhuU+AT32hk0k8j3u5Dd8v9OxNGV5z7hkQA==, kyrI7hQ70xEyn0Hd9JuFggIMwGT2gAQkxrPaf320KN7meE3OgDIdgYAhpIIyxtrVB1UhLtEMwRIlpCdgYFOTfg== ResourceUpdateName: RefcodeTable CustomInvoiceDetail Type: CustomInvoiceDetail Name: StrabagRefCode

Json Plugins

https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/539/Json-Plugins-Mechanics-and-Rules

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Tech-Stack.md - Chunk 0
Technology Stack Overview Template

Frontend

Supported Client Browsers

Browser Version Google Chrome 91 and above Microsoft Edge 91 and above

Programming Languages

Language Version JavaScript ES6 and above TypeScript 4.3.2

Frameworks and Libraries

Framework/Library Version React 17.0.2

Platforms/OS

Platform/OS Version Windows 10 and above Linux Ubuntu 20.04 LTS

Backend

Programming Languages

Language Version C# 9.0 Node.js 14.17.0 Python 3.9.5

Frameworks

Framework Version .NET Framework 4.6.1 .NET Core 3.1 .NET 6.0 Flask (Python) 2.0.1

Platforms/OS

Platform/OS Version Windows Server 2019 Linux Ubuntu 20.04 LTS Docker 20.10.7

Databases and MemCaches

Database Version Redis 6.2.4 Azure SQL Database Managed Service

Cloud Services (Azure)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Tech-Stack.md - Chunk 1
Platform/OS Version Windows Server 2019 Linux Ubuntu 20.04 LTS Docker 20.10.7

Databases and MemCaches

Database Version Redis 6.2.4 Azure SQL Database Managed Service

Cloud Services (Azure)

Service Description Web Apps Hosting web applications (Windows-based) Azure Functions Serverless computing service Azure SQL Database Managed relational SQL database Container Instances Container deployment and management AKS (Azure Kubernetes Service) Managed Kubernetes orchestration Azure Queues Messaging service for communication between WebApp and Azure Functions

Development and Deployment

Platform

Platform Description Azure DevOps CI/CD and project management Git Version control system

CI/CD

Service Description Azure Pipeline Continuous integration and deployment

Infrastructure as Code

Tool Description Terraform Infrastructure provisioning

On-Premise Solutions

Tool/Service Description Docker Compose Container orchestration

Additional Tools

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Tech-Stack.md - Chunk 2
Infrastructure as Code

Tool Description Terraform Infrastructure provisioning

On-Premise Solutions

Tool/Service Description Docker Compose Container orchestration

Additional Tools

Tool Description PowerShell Scripting and automation Azure CLI (az) Command-line interface for managing Azure resources

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Transition-Architecture-1.0-_2.0.md - Chunk 0
Architecture Transition

To be discussed: How can we do this seamlessly and reuse as much as we have

Should we process both or execute 1.x OR 2.x Or is CaptureSDK one service of 2.0? Make or buy decision on Process orchestration Can I use Capture SDK in a way that it just returns certain details?

Transition Options

Smooth transition: integration of orchestrator into 1.x

implement the DocEnchrichment Ochestrator and integrate it into Bludelta 1.x

replace the PredictionController with the Orchestrator in a first step

all Enchrichers should provide the same interface so that they can be treated in a uniform way.

Implement 2.x from the ground

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\XRechnung.md - Chunk 0
Requirements: General EU: https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/1921/e-Invoicing-EU-and-EU-Factsheet

22069

Timeline:

A high level timeline forsees a delivery beginning of October (6 weeks) to handover the system for testing to our customers.

Architecture

X-Invoice vs Invoice - Decision-Making Process

The diagram above is a flowchart that outlines a process for handling invoice documents based on their format and content. Here's a

Invoice Document: The process starts with an "Invoice Document."

Is Standard Invoice (no XML included)?:

Yes: If the invoice is a standard one without XML, it proceeds to the "Invoice" step, which then leads to the "Standard/Asia Workflow."

No: If the invoice is not standard and includes XML, the process moves forward.

Is XML only?

Yes: If the invoice is XML only, it goes into the "Xinvoice Workflow."

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\XRechnung.md - Chunk 1
No: If the invoice is not standard and includes XML, the process moves forward.

Is XML only?

Yes: If the invoice is XML only, it goes into the "Xinvoice Workflow."

No: If the invoice is not XML only (it includes a PDF), it moves to the "PDF Invoice with XML Invoice" step.

PDF Invoice with XML Invoice: This step checks if a PDF is available.

No and PDF Available: If a PDF is available, it proceeds to "ResponseBuilder," which eventually generates a "Json Result."

No and XML only: If there is no PDF and only XML, it checks if the "IsOK (http 200)" condition is met:

Yes: If it's OK, the process moves back to the "Xinvoice Workflow."

No: If it's not OK, the process ends with an "HTTP 400 Error Invalid XML Xinvoice."

ResponseBuilder: This step prepares the response based on the available information.

Json Result: The final output of the process, produced by the "ResponseBuilder," is a JSON result.

X-Invoice Workflow

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\XRechnung.md - Chunk 2
Json Result: The final output of the process, produced by the "ResponseBuilder," is a JSON result.

X-Invoice Workflow

HttpRequestPreparationActivity: Extracts pdf and xml from the multipart form body and stores the pdf and xml part in the HTTPRequestContext

OcrActivity: Does the OCR

XInvoiceProxyActivity: Reads the xml from the HttpRequestContext and sends it to the XInvoiceService. Communication shall be message based via RabbitMQ

XInvoiceService: Processes the XInvoice xml documment. Is able to handle different standards. Returns a simplified BluDoc without any locations. Currently V2 is used because there is no need for XInvoiceService yet and the code lines for converting XML into XInvoice class InvoiceDescriptor with nuget package s2industries.ZUGFeRD are few. The conversion is currently done in custom nuget package Blumatix.BluDocConverter.Business.XInvoice.

XInvoiceResultBuiderActivity: Adds Locations of OcrResult is available. Returns BluDoc with the OcrResult

V1: V2:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\XRechnung.md - Chunk 3
XInvoiceResultBuiderActivity: Adds Locations of OcrResult is available. Returns BluDoc with the OcrResult

V1: V2:

XML Visualizer

XML shall be visualized.

X-Invoice HTTP Request/Response Format

Request

multipart-form

may contain one or more parts:

xml part (x-invoice in xml representation)

pdf part (invoice pdf with xml x-invoice)

Response

On Success: - An Invoice BluDoc is returned either with locations or without - OcrResult

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\XRechnung.md - Chunk 4
xml part (x-invoice in xml representation)

pdf part (invoice pdf with xml x-invoice)

Response

On Success: - An Invoice BluDoc is returned either with locations or without - OcrResult

On Failure We have the following cases mainly for failure: - PDF with embedded XML: - Workflow delivers 'Bad Request' with error message containing "... an error occurred during XInvoice conversion ..." - This error message text/regex is also defined under XInvoiceWorfklow section XInvoiceFormatErrorRegex in dynamic_config of API. - For API the error message indicates that at least the root element of XInvoice in XML did exist but there is another format error - Customer receives HTTP 400 with message "Invalid X-Invoice. The provided xml file cannot be interpreted as valid X-Invoice."

Workflow delivers 'Internal Server Error' with error message containing "Valid XInvoice but error occurred ..."

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\XRechnung.md - Chunk 5
Workflow delivers 'Internal Server Error' with error message containing "Valid XInvoice but error occurred ..."

This error message text/regex is also defined under XInvoiceWorfklow section ValidXInvoiceErrorRegex in dynamic_config of API.

BlumatixCaptureException is thrown and customer gets empty prediction because this exception is thrown to global handler (if no specific error handling or policy changed).

Workflow delivers 'Internal Server Error', or 'Bad Request' without the error messages described above

Default workflow will handle the pdf.

Workflow server cannot be reached:

Customer gets empty prediction because the internal error is thrown to global handler (if no specific error handling or policy changed)

Only XML:

Workflow delivers 'Bad Request' with or without error message containing "... an error occurred during XInvoice conversion ..."

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\XRechnung.md - Chunk 6
Only XML:

Workflow delivers 'Bad Request' with or without error message containing "... an error occurred during XInvoice conversion ..."

This error message text/regex is also defined under XInvoiceWorfklow section XInvoiceFormatErrorRegex in dynamic_config of API, so that API knows to send Bad Request to customer or send the invoice to default workflow

For API the error message indicates that at least the root element of XInvoice in XML did exist but there is another format error

Customer receives HTTP 400 with message "Invalid X-Invoice. The provided xml file cannot be interpreted as valid X-Invoice."

Workflow delivers 'Internal Server Error' with error message containing "Valid XInvoice but error occurred ..." or any other exception occured

This error message text/regex is also defined under XInvoiceWorfklow section ValidXInvoiceErrorRegex in dynamic_config of API.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\XRechnung.md - Chunk 7
This error message text/regex is also defined under XInvoiceWorfklow section ValidXInvoiceErrorRegex in dynamic_config of API.

BlumatixCaptureException is thrown and customer gets empty prediction because this exception is thrown to global handler (if no specific error handling or policy changed).

Workflow server cannot be reached:

Customer gets empty prediction because the internal error is thrown to global handler (if no specific error handling or policy changed)

Workflow Server for XInvoice sends HTPP error 400 for invalid XML or if XML is not included. Workflow Server for XInvoice sends HTTP error 500 for valid XML but any other error occurred afterwards or before.

Libraries

ZUGFeRD-csharp

ZUGFeRD-csharp-nuget

LLM-Based Solution

Testing

We need thorough testing of the 3 formats and appropriate samples.

Samples Links:

https://github.com/ConnectingEurope/eInvoicing-EN16931?tab=readme-ov-file UBL, CII directories you can find samples

Samples for UBL, CII

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\XRechnung.md - Chunk 8
Samples Links:

https://github.com/ConnectingEurope/eInvoicing-EN16931?tab=readme-ov-file UBL, CII directories you can find samples

Samples for UBL, CII

Musterrechnung-CII--data.pdf XRechnung-3.0.1-ubl.xml 069

Brain Storming

Ansatz Vorteile Nachteile Library-basierter Ansatz - Standardisierte Implementierung - Eingeschränkte Flexibilität - Zuverlässigkeit durch getestete Funktionen - Abhängigkeit von externer Software - Höhere Performance - Wartung und Support durch die Community - Keine zusätzlichen laufenden Kosten LLM-basierter Ansatz - Hohe Flexibilität - Hohe Kosten - Adaptive Fähigkeiten, reagiert auf neue Formate - Risiko von „Halluzinationen“ (Fehlerhafte Daten) - Geringere Performance, hohe Rechenleistung erforderlich

Library approach:

Deterministic

Fast

Cheap

Inflexibel

LLM approach

Flexible

Halluzination prone: how do we overcome this problem

„Expensive“

How shall we test/bm this approach

LLM result must be converted into prediction result

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\XRechnung.md - Chunk 9
Cheap

Inflexibel

LLM approach

Flexible

Halluzination prone: how do we overcome this problem

„Expensive“

How shall we test/bm this approach

LLM result must be converted into prediction result

Separate prompts for each Standard?`

Where do we store these prompts. Prompt Versioning, Prompt improvement

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting\Meeting-Minutes.md - Chunk 0
13.09.2023

Agenda für heutiges concept meeting:

Feature Branch Testing - wie testen wir unsere FeatureBranches, welche Möglichkeiten gibt es Service/Container in einem FeatureBranch testen und zwar mit Dev Environment in unserer Cloud Richtiges Tool finden: DevSpace: Bernhard etc... So einfach wie möglich!!!!!!!!!!!!!!!!!!!!!!!!!! PR Pipeline Referenz Architektur Resourcen??? DynamicService Routing via CaptureSDK endpoint additional request property: provide local url for current feature branch service. https://learn.microsoft.com/en-us/visualstudio/bridge/overview-bridge-to-kubernetes https://learn.microsoft.com/en-us/azure/aks/hybrid/overview Techn. Story: How could we implement this. Gü ´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting\Meeting-Minutes.md - Chunk 1
Feature Request Dashboard: Kopieren von Kommentaren, evntl. auch modifizieren? Hasch und andere fragen, was im Dashboar benötigt wird: Rudi Techn. Story schreiben ´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´

Logging Strategie: TETA Wiki page für diverse Tasks die zum Mitmachen sind wenn man ein Service/Code angreift: Bernhard

kein ping als info log bzw gar nicht loggen einheitliches loggingformat auch in the python services Serilog für CaptureSDK und CaptureService

Konzept für:

Customer tracking over all services Track request with AppGateway tracking-id ´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´

Workshop: ELSA und neue Architektur Bludelta 2.0

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting\Meeting-Minutes.md - Chunk 2
Workshop: ELSA und neue Architektur Bludelta 2.0

Termin: Montag, den 2.Okt. 2023 All sollen teilnehmen Theorie: Einführung in ELSA: Bludelta 2.0 - Architektur RabbitMQ Deployment von Workflows etc., Pipelines Praxis Teil: - Workflow implemntieren: Aufteilung in 2 - 3 Gruppen - Beispiel sollte praxisnahe Techn. Story: Workshop Vorbereitung

´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´

Techn Stories:

OnPremise TODOs See: https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/BludeltaDeployment/676/OnPremise-Automation-(CICD) TETO Wiki

ResourceService: Bernhard

2 Instanzen Neuer Key basierend auf ResourceFiles ins TETA wiki eintragen Triton mit mehreren Intanzen hinter load-balancer funkt nicht im explicit modus!!!!!!!!!

Techn. Story: Rudi ISMS: ab nächstes Mal

´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting\Meeting-Minutes.md - Chunk 3
Techn. Story: Rudi ISMS: ab nächstes Mal

´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´

Review aller existierenden T. Stories: Ausmisten was wir nicht mehr brauchen

13.11.2023

SuxessIT (k8s consulting)

Disaster Recovery / ArgoCD / QA-Env möglichst schnell aufbauen

(highest prio) Monitoring & Alerting

Erzeugen neuer Services / Trainingspipelines, etc.. (Repo bis Deployment)

1.) Abklärung Geschäftsführung 2.) Wenn Zusage --> NDA klären

Blumatix-Capture Build Pipeline machen

Step1) OP Pipeline macht upload von phoenix in einen daily-phoenix folder

Step2) BM-Pipelines repoless (download phoenix from folder)

22.01.2024

Participants - Chris Weiler - Bernhard Wimmer - Rudi Dittrich

Actions Undertaken

Reviewed, discussed, and reprioritized the first 7 Technical Stories. Prioritization:

17233: FSOD Benchmark. Bernhard to initiate a "Planned Task".

16525: Generic Typhon Service implementation.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting\Meeting-Minutes.md - Chunk 4
Reviewed, discussed, and reprioritized the first 7 Technical Stories. Prioritization:

17233: FSOD Benchmark. Bernhard to initiate a "Planned Task".

16525: Generic Typhon Service implementation.

17033: Development of OCR Cache.

17766: Asynchronous Endpoint creation.

16429: Engage with Werner to assess the feasibility of auto-generating alerts for critical vulnerabilities detected by the vulnerability scan.

16507: Wait for the outcome of #18397 and re-prioritize of necessary

The rationale ("Why") behind each Technical Story should align with and be explained based on the following quality metrics: Why Criteria

Team Efficiency

Model Deployment

Customer Onboarding

etc.

Performance Enhancement

Scalability Improvement

Cost Optimization

05.02.2024

Participants - Chris Weiler - Bernhard Wimmer - Günther Schwaiger - Rudi Dittrich

Actions Undertaken

Reviewed, discussed, and reprioritized the first 7 Technical Stories. Prioritization:

13859 Do we really need this story?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting\Meeting-Minutes.md - Chunk 5
Actions Undertaken

Reviewed, discussed, and reprioritized the first 7 Technical Stories. Prioritization:

13859 Do we really need this story?

11564 Parametrization, Error handling is still missing. Shall be used by the CaptureSDK too.

A new disaster recovery story is needed: Shall take capturesdk etc. into account

Tasks until next meeting: - Rudi does a pre-sorting and prepares the technical stories so that they can be prioritized

19.02.2024

Participants - Hasch - Bernhard - Günther - Rudi - Dominique

Actions Undertaken

Presented technical Epics

Discussed current operational Problems:

Resource Service might cause performance problems:

Bernhard is already debugging and profiling it.

Junk Detection: disabled junk detection. In general performance is improved but could lead to timeouts in delivery period.

Further investigations are needed.

CaptureService: difference between dev and pro version leads to different results.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting\Meeting-Minutes.md - Chunk 6
Further investigations are needed.

CaptureService: difference between dev and pro version leads to different results.

Solution: Combine capture service and sdk into a single service. A Tech. Story must be written. Shall replace #13861

Label Enums:

It is currently not possible to define new labels without adapting our code.

Labels are currently defined as enums in the code and are also saved as enum or int in the database.

Before we write a technical story, we should first clarify whether we want to continue working with our labeling tool in the future or use an existing solution

Ocr Problems:

Easy Ocr produces OCR error: could be mitigated with training of a custom easy ocr model

Discrepancy text and image/mixed pdfs: Has already been investigated and is probably fixed.

Our OCR is accessed in different ways and is therefore difficult to maintain and prone to errors. Single entry point is preferrable.

No image deskewing in easy ocr

Dominique will provide further details!

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting\Meeting-Minutes.md - Chunk 7
No image deskewing in easy ocr

Dominique will provide further details!

02.04.2024

Meetings Minutes:

Participants: - Bernhard - Gü - Chris - Rudi

Billings Service: - Events für request und response werden im API Gateway getriggered - DB Schema wird innerhab der Story definiert - Story schreibt Rudi

ELSA 3.1: - Upgrade auf ELSA 3.1 - Im ersten Schritt nur den aktuellen Code hochheben, aber nicht refactorn (Request-Reply Pattern) - Story schreibt Rudi

Telemtrie Datenbank: - Story schreibt Bernhard

Logging Concept: - Bernhard schreibt was zusammen - Gü sammelt weiterhin exceptions etc. und gibt diese ans Team weiter

Steady and Faster Learning: - Typhon Architektur muss angepasst werden - Integration von AzureGPT

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting\Multiliagual-Bludelta---Concept-Two.md - Chunk 0
Bludelta as a Multilingual Document Capturing System

Introduction

This concept document outlines the approach and architecture for a multilingual document capture system that can handle invoices and other documents in any language. The existing system consists of an API, a data collection workflow, and training pipelines for machine learning models. This document will provide a high-level overview of the proposed changes and enhancements to the existing system to enable multilingual capabilities.

Approach

The approach to making the document capture system multilingual can be divided into the following steps:

2.1 Language Identification 2.2 Data Preprocessing and Normalization 2.3 Multilingual OCR and Text Extraction 2.4 Language-Specific Data Collection and Labeling 2.5 Multilingual Model Training and Evaluation 2.6 API Enhancements for Language Support

Detailed Architecture

3.1 Language Identification

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting\Multiliagual-Bludelta---Concept-Two.md - Chunk 1
Detailed Architecture

3.1 Language Identification

The first step is to identify the language of the document. This can be achieved by incorporating a language identification model at the beginning of the processing pipeline. The model can be based on pre-trained language identification models, such as langid.py, fastText, or Google Cloud Natural Language API.

3.2 Data Preprocessing and Normalization

Before extracting information from the documents, it's essential to perform preprocessing and normalization, including cleaning and standardizing date formats, currency symbols, and address formats. This step may involve language-specific rules and regular expressions to handle unique cases in different languages.

3.3 Multilingual OCR and Text Extraction

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting\Multiliagual-Bludelta---Concept-Two.md - Chunk 2
3.3 Multilingual OCR and Text Extraction

To extract text from the documents, the system needs to implement multilingual OCR support. This can be achieved by integrating an OCR engine like Nuance, EasyOCR or Paddle OCR, which already support multiple languages. Additionally, the OCR engine should be trained on domain-specific data to improve the recognition of e.g invoice-specific terms and symbols.

3.4 Language-Specific Data Collection and Labeling

To train the system for each language, it is crucial to collect and label language-specific data. This data can be sourced from publicly available datasets or by partnering with clients who can provide multilingual invoices. The labeled data will be stored in the BCI database for model training.

3.5 Multilingual Model Training and Evaluation

Once the language-specific data is collected and labeled, the machine learning models can be trained and evaluated.

Typhon

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting\Multiliagual-Bludelta---Concept-Two.md - Chunk 3
3.5 Multilingual Model Training and Evaluation

Once the language-specific data is collected and labeled, the machine learning models can be trained and evaluated.

Typhon

A multilingual FastText model has to be trainend - we probably would need more than 30 dims to get reliable word embeddings. The remaining process wouldn't change. Training as usual.

Alternative

Instead of typhon the system could incorporate state-of-the-art NLP models, like LayoutLM, multilingual BERT, XLM-R, or mT5, that have been pretrained on a large corpus of multilingual text. Fine-tuning these models on the domain-specific data will allow for accurate extraction of invoice details in multiple languages.

3.6 API Enhancements for Language Support

To enable multilingual support in the API, it should be enhanced to accept the detected language as an input parameter, along with the document. The API should also return the extracted information in a standardized JSON format, including language metadata.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting\Multiliagual-Bludelta---Concept-Two.md - Chunk 4
Conclusion

By implementing the above architecture, the document capture system will be able to handle invoices and other documents in any language. The system will leverage language identification, multilingual OCR, and state-of-the-art NLP models to deliver accurate results. With these enhancements, the document capture system will be a comprehensive, multilingual solution for customers worldwide.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting\Multilingual-BluDelta---Concept-One.md - Chunk 0
Multilingual Document Capture System Concept Using Translation

Introduction

An alternative approach to developing a multilingual document capture system is to translate the documents into a single language (perferrable, German or English) before processing them. This document outlines the architecture and components of a document capture system that uses translation as a preprocessing step.

Approach

The approach for this alternative solution can be divided into the following steps:

2.1 Language Identification 2.2 Document Translation 2.3 Data Preprocessing and Normalization 2.4 OCR and Text Extraction 2.5 Data Collection and Labeling 2.6 Model Training and Evaluation 2.7 API Enhancements for Language Support

Detailed Architecture

New Bludelta architecture after our discussion in our API Refinment meeting (3.5.2023):

NOTE: The DocTransformation layer could also be used in the DataCollection.

3.1 Language Identification

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting\Multilingual-BluDelta---Concept-One.md - Chunk 1
New Bludelta architecture after our discussion in our API Refinment meeting (3.5.2023):

NOTE: The DocTransformation layer could also be used in the DataCollection.

3.1 Language Identification

Similar to the first approach, the system needs to identify the language of the document. This can be achieved using pre-trained language identification models, such as Nuance OCR, fastText, or Google Cloud Natural Language API. I think in our case we should try to identify the language with FastText

3.2 Document Translation

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting\Multilingual-BluDelta---Concept-One.md - Chunk 2
3.2 Document Translation

Once the language has been identified, the document can be translated into the target language (German or). This can be achieved using machine translation APIs, like Google Cloud Translation API - we have already implemented a translation service based on google's translation API. The translation should focus on the relevant regions of the document containing the required information, such as dates, amounts, and addresses. Proper region extraction is definitely a necessary pre-processing step as the layout plays an import role in semi-structured documents.

3.3 Data Preprocessing and Normalization

After translation, preprocessing and normalization should be performed on the translated document. This includes cleaning and standardizing date formats, currency symbols, and address formats. Since the document is now in a single language, this step becomes simpler as it doesn't require language-specific rules.

3.4 OCR and Text Extraction

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting\Multilingual-BluDelta---Concept-One.md - Chunk 3
3.4 OCR and Text Extraction

With the translated document, the system can use an OCR engine, like Nuance, EasyOcr or PaddleOCR, to extract text. The OCR engine should be trained on domain-specific data to improve the recognition of invoice-specific terms and symbols.

3.5 Data Collection and Labeling

Since the documents will be translated, data collection and labeling efforts can focus on the target language (German or English). This data can be sourced from publicly available datasets or through partnerships with clients who can provide invoices in the target language. The labeled data will be stored in the BCI database for model training.

3.6 Model Training and Evaluation

The machine learning models can be trained and evaluated using the translated and labeled data.

Typon

Use original image pages but take the translated text as input for our FastText embeddings. Training as fasttext model could be reduced to german and english text.

Alternative

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting\Multilingual-BluDelta---Concept-One.md - Chunk 4
Typon

Use original image pages but take the translated text as input for our FastText embeddings. Training as fasttext model could be reduced to german and english text.

Alternative

State-of-the-art NLP models, like BERT or GPT, can be fine-tuned on this domain-specific data to accurately extract invoice details.

3.7 API Enhancements for Language Support

The API should be enhanced to accept the detected language as an input parameter, along with the document. The API will use this information to perform translation and extraction. The extracted information should be returned in a standardized JSON format, including language metadata.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting\Multilingual-BluDelta---Concept-One.md - Chunk 5
Conclusion By implementing the above architecture, the document capture system will translate documents into a single language before processing. This approach simplifies data collection, labeling, and model training by focusing on a single target language. However, it relies on accurate machine translation, which may introduce errors or inconsistencies. Additionally, the translation step may add latency to the overall processing time. Despite these potential drawbacks, this alternative solution provides a viable option for creating a multilingual document capture system.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting\Workshop-ELSA.md - Chunk 0
Agenda:

Elsa Github

Elsa 2.0

Elsa 3.0

Introduction and Objectives

Brief overview of the workshop’s objectives. Why do we need a workflow engine. Benefits, etc...

Theoretical Part: Understanding Elsa Workflow

What is Elsa Workflow?

Background and evolution.

Elsa's Architecture

Overview of the architecture.

Core components and their roles.

Deep Dive into Elsa Components

Activities: What they are, how they're used

Workflow Context: Importance, use cases, and best practices, Context Variables etc.

Other essential components: Triggers, Outcomes, and more.

Best Practices and Use Cases Common patterns and anti-patterns.

Break

Practical Part: Building a Workflow with Elsa

Setting up the Development Environment

Necessary tools and resources.

Initial project setup.

Hands-On: Implementing a Simple Workflow Walk through the process of creating a workflow step-by-step. Integrate an OCR activity, deep learning models, and a result builder. Test and debug the workflow.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Architecture-Alignment-Meeting\Workshop-ELSA.md - Chunk 1
Group Exercise:

Enhance and Customize the Workflow

Teams work on adding additional features or optimizing the workflow.

Wrap-up and Q&A

Discuss the day's learning.

Address any questions or concerns.

Feedback and Closing

What else?

Shall we also talk about DevOps stuff like pipelines, deployements etc.???

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Bludelta---DocumentCapture-Architecture\CaptureSDK---Async-Sync-Endpoint.md - Chunk 0
Bludelta Async/Sync Endpoint

Client Request: The client sends a request to process a document to the /invoicedetail/detect endpoint through the Azure App Gateway.

Authentication: The API Gateway interacts with our Authentication Service to authenticate the customer.

Queue Message: Upon successful authentication, the request is forwared to the Bludelta Workflow, where the document is written into an Azure BlobStorage and request is converted into a message and sent to the bludelta-in-queue

Processing: The CaptureSDK Service processes the message, and upon completion, the result is pushed to the bludelta-out-queue.

Caching Result: Simultaneously, the processed document is written into the Document Cache (Redis).

Client Response

If the response is ready within the expected timeframe, the API Gateway retrieves the response message from the bludelta-out-queue and sends it back to the client as a JSON response.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Bludelta---DocumentCapture-Architecture\CaptureSDK---Async-Sync-Endpoint.md - Chunk 1
If the response is ready within the expected timeframe, the API Gateway retrieves the response message from the bludelta-out-queue and sends it back to the client as a JSON response.

If there is a timeout (e.g., the processing takes longer than the client's HTTP timeout setting), the client can retry. Upon retry, the CaptureSDK will first check the Document Cache for the result before processing the request. If the result is in the cache, it is returned to the client immediately, preventing the need to reprocess the document.

Cache Expiration: Each entry in the Redis cache has a set expiration time, after which it will be removed to prevent the cache from indefinitely growing in size.

Bludelta Message

Contains the request

A unique id needed to map each message to the corresponding request

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Elsa-Workflow-Engine\Performance-Tests.md - Chunk 0
Performance Tests were executed with and without database against https://capture-dev.bludelta.ai/quotation/v1/quotation.

Tests with database - Green diagram One API response with database took around 1 minute to 30 seconds and which is a very long time. The requests were sent sequentially and not in parallel! The timeline is from 9:30 to 10:00. The memory usage was under 954 MB.

Tests without database - Purple diagram (max. memory usage 2,5 GB): 64 invoices/requests were sent simultaneously (parallel), and this process was repeated three times sequentially. So it seems that the memory usage doubles with every repeated process. - Green diagram (average. memory usage around 1,9 to 2 GB): 4 invoices/requests were sent simultaneously (parallel), and this process was repeated sequentially until 300 requests has been processed.

Decisions made as of 25. October 2023 - Turn of database - max. parallel usage of requests is 4 - max. memory usage is set to 3 GB of workflow server

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Elsa-Workflow-Engine\Performance-Tests.md - Chunk 1
Decisions made as of 25. October 2023 - Turn of database - max. parallel usage of requests is 4 - max. memory usage is set to 3 GB of workflow server

Note: for time evaluation per response please find more information in quotationEvaluation.txt

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Elsa-Workflow-Engine\RabbitMQ.md - Chunk 0
Request-Reply Pattern Implementation Using RabbitMQ

Overview

Our system uses the Request-Reply (RPC) pattern to enable synchronous communication between our workflow engine and various services. This communication is mediated through RabbitMQ, a robust message-broker that facilitates message queuing and delivery.

Key Components

RpcClient: Manages the sending of request messages and the receiving of replies. It is responsible for setting up and maintaining a connection to RabbitMQ and handling timeouts and message correlation.

RabbitMqConnection: Provides and manages RabbitMQ connections and channels, ensuring efficient and thread-safe communication.

ModelWrapper: Abstracts the RabbitMQ channel operations, encapsulating the logic for publishing messages, setting up consumers, and handling model shutdowns.

Communication Flow

Connection Establishment:

RpcClient initializes a connection with RabbitMQ using RabbitMqConnection.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Elsa-Workflow-Engine\RabbitMQ.md - Chunk 1
Communication Flow

Connection Establishment:

RpcClient initializes a connection with RabbitMQ using RabbitMqConnection.

A single channel and a unique reply queue are set up for all incoming responses to ensure that replies can be correlated with their corresponding requests.

Message Handling:

Requests are sent as byte arrays with appropriate message properties, including a unique correlation ID and a reply-to queue.

The RpcClient awaits replies on the dedicated reply queue. Each reply correlates back to the request via the correlation ID.

Asynchronous Consumer:

ModelWrapper sets up an asynchronous consumer that listens for messages on the reply queue.

When a message is received, it resolves the corresponding TaskCompletionSource, allowing the RpcClient to complete the request task with the received message payload.

Error Handling and Reconnection:

The system is designed to handle connection and channel interruptions gracefully.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Elsa-Workflow-Engine\RabbitMQ.md - Chunk 2
Error Handling and Reconnection:

The system is designed to handle connection and channel interruptions gracefully.

RpcClient and ModelWrapper include mechanisms to detect shutdowns and automatically reinitialize the connection and channel.

Timeout Management:

Each request includes a timeout. If a reply is not received within the specified timeout period, the request is considered failed, and the system logs an error.

Implementation Highlights

Concurrency: Uses ConcurrentDictionary to manage pending messages, ensuring thread-safety.

Resilience: Implements retry mechanisms and error handling in connection and channel setups to handle transient failures effectively.

Efficiency: Manages a single reply queue and a single channel for all replies, reducing resource usage and simplifying the correlation of replies to requests.

Conclusion

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\BLUDELTA-Architecture\Elsa-Workflow-Engine\RabbitMQ.md - Chunk 3
Efficiency: Manages a single reply queue and a single channel for all replies, reducing resource usage and simplifying the correlation of replies to requests.

Conclusion

The Request-Reply pattern implemented using RabbitMQ provides a robust framework for synchronous communication within our workflow system. This setup ensures high availability, fault tolerance, and efficient message handling.

UML

Preliminary Load Tests

Processes Workflow Servers OCR Workers Entity Recognitions Total Minutes Total Seconds Total Milliseconds 1 1 4 2 13.453 807.19 807194.71 2 1 4 2 7.423 445.37 445366.26 4 1 4 2 3.992 239.54 239538.93 8 1 4 2 2.677 160.63 160629.94 16 1 4 2 2.477 148.64 148642.05 16 1 8 2 2.573 154.37 154373.51 16 2 8 2 2.489 149.33 149327.11

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BCI-Database---BciDb.md - Chunk 0
MetaInfo Table

Type Description when set Values 0 Document Format last: 2020-02-03 Default Receipt 1 Labeler Comment set by labeler free text 2 Provider when document is imported provider name 3 Document Quality last: 2019-09-23 Default Bad 4 Error Classes last: 2020-10-14 MoreThanInvoice NoInvoice NoOcr Other Redundant Rotated 4 ? 5 ? last: 2019-12-17 refcode_ok refcode_wrong fails_dec_2019 6 Language last: 2022-03-15 2 letter language code 7 Single Document SingleDocument ToBeSplit

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Benchmark-QA-Report.md - Chunk 0
We are going to summarize our finding from checking benchmarks here. [[TOC]]

hik_DeliveryNote_CustomerSample

Benchmark run Id - 1735266 - Stamps contain a date. Some wrong predictions that predict the stamp date as DeliveryNote.Date instead of the date that is written in the document. - Some wrong predictions that predict the hand-written number in stamp as DeliveryNote.Id (invoice id: 400124) - According to our wiki (HIK Delivery notes - Overview) CustomsTariff.Id should be 6 - 8 digits. While in benchmark a 10 digit number is predicted as Line.Item | CustomsTariff.Id (invoice id: 400311). Maybe we need to check to update our prompt or ask customer about it. - There is no prediction for Line.Item | Order.Id. - Details are not part of benchmark set: - Sender.Contact.Item (optional) - Receiver.Contact.Item - Sender.Id - Wrong predictions for Line.Item | Charge.String that are position.id, Menge and etc, not charge string.

dachser_TW_#22547_CustSample benchmark

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Benchmark-QA-Report.md - Chunk 1
dachser_TW_#22547_CustSample benchmark

Documents that should be unreleased or relabeled are written in the following link. Although Olga responded, there are some problems in document types. So, we need to discuss with customer. dachser_TW_#22547_CustSample benchmark checking

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc.md - Chunk 0
[[TOC]]

Definition

BluDoc is a simple and human-readable format to describe any business document.

Aim

BluDoc simplifies and unifies document data exchange between services.

Design Principles

One BluDoc for one Document

One BluDoc defines one document only. BluDoc is not a description of a file that may contain many documents. Hint: if a file contains multiple documents which belong together (e.g. invoice and delivery note), those additional documents could be handled as "attachments" in future.

Generic

BluDoc defines basic structure and generic elements to describe any document.

Supports General Business Document Types

Additionally it provides pre-defined document detail schemas for general business documents to ease data exchange between companies (e.g. universal schema for invoice).

Easy to read

BluDoc content and structure is easy to understand.

Most information is optional

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc.md - Chunk 1
Easy to read

BluDoc content and structure is easy to understand.

Most information is optional

There are many different use cases for using BluDoc. Every use case might have a different aspect and concern and therefore different information needed. Therefore most information is optional.

Examples: A BluDoc created by DocGenerator does not need scores A BluDoc created for providing ground truth may not need OCR Result A BluDoc created as API Response includes just one InvoiceId, created for label creation includes all occurrences of the InvoiceId

Redundancy is accepted

For human readability and easy process different aspects redundancy of information is accepted.

BluDoc should become OpenSource

Goals:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc.md - Chunk 2
Redundancy is accepted

For human readability and easy process different aspects redundancy of information is accepted.

BluDoc should become OpenSource

Goals:

BLUDOC is a multi-layer document description format enabling information exchange between businesses but with AI in mind - BLUDOC describes context, format and contents of a single document - BLUDOC includes attributes facilitating AI model outputs and trainings - BLUDOC is easy to read - BLUDOC provides a schema defining a default content for all common business docs - BLUDOC can be extended and customized as needed - BLUDOC defines basic types and normalization of related values

High Level Structure:

Document Meta Information including DocumentType

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc.md - Chunk 3
High Level Structure:

Document Meta Information including DocumentType

DocumentEssentials: Includes essential information for this Document Type -- General DocumentType context (see basic schema) -- Country-context DocumentEssentials: should start with Country letter: NOKId = KId for Norway -- Industry-context DocumentEssentials: should start with industry name e.g. "LogisticsHawbId" -- Customer-context DocumentEssentials: should start with Customer name

DocumentEntities: First semantic layer with basic word entity information (doc-type agnostic)

DocumentTexts: Character, Word, Lines of this document (doc-type agnostic)

DocumentBinaries: Binary Representation of this document (doc-type embedded or linked)

Common Rules

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc.md - Chunk 4
DocumentTexts: Character, Word, Lines of this document (doc-type agnostic)

DocumentBinaries: Binary Representation of this document (doc-type embedded or linked)

Common Rules

Empty Value in DocumentEssentials items: - An empty Value (Value: "") indicates that this element is NOT on the document -- E.g. there is no DeliveryDate on your DeliveryNote, then your json includes an Item under DocumentEssential with the "Label": "DeliveryDate" and a "Value": "" - Leave out what you do not know: -- E.g. if you do not know the Page structure of a document then leave out the "Pages" array -- E.g. if you do not know the Location of a DocumentEssential then leave out the "Location" element - Null: -- In some cases generic attributes like Location, Text, etc. are not applicable for certain items; in these cases these attributes must be set to null

Versioning:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc.md - Chunk 5
Versioning:

A BLU DOC version defines the basic structure and the predefined elements of DocumentEssentials for a fixed set of document types. x.y.z x ... denotes a breaking of fundamental change y ... denotes an addition of fields z ... denotes a minor change

Most Simple Form of a BLU DOC:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc.md - Chunk 6
Most Simple Form of a BLU DOC:

{ "BluDoc.Version": "1.2.0", "DocumentProvider.Name": "customer x", "Created.DateTime": "2023-03-21T21:54:29.123Z", "CreatorSoftware.Name": "BluDoc Creator", "CreatorSoftware.Version": "1.0.0", "Document.Type": "Invoice", "Document.Languages": [ "de", "en" ], "Pages": [ { "Id": 1, "Width": 827, "Height": 1169, "Dpi": 300, "Orientation": "Portrait" } ], "DocumentEssentials": [ { "Label": "Invoice.Type", "Value": "CreditMemo", "Text": null, "Location": null, "Confidence": 1.0, "ConfidenceThreshold": 0.8123 }, { "Label": "Invoice.Id", "Value": "2000008238", "Text": "2000008238", "Location": { "Page": 1, "Left": 414, "Top": 155, "Width": 91, "Height": 18 }, "Confidence": 1.0, "ConfidenceThreshold": 0.8123 } ] }

DocumentEssentials:

Can be one simple essential or document detail like that:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc.md - Chunk 7
DocumentEssentials:

Can be one simple essential or document detail like that:

{ "Label": "Invoice.Id", // the name of a label is defined as: "Value": "3453445-45", // Value holds a normalized value "Text": ""345 3445 - 45", // Text equals characters printed on invoice (not normalized) "Location": { // page-based location of the coordinates "Page": 1, "Left": 752, "Top": 443, "Width": 33, "Height": 13 }, "Confidence": 1.0000, // Confidence has 4 decimals, model confidence < 1.0, Ground Truth confidence=1.0000 "ConfidenceThreshold": 0.8123 // Confidence values above this threshold can be assumed to be safe, if no threshold available then =-1.0000 }

Essential Naming policy is like:

_<[Country][Industry][Customer][DocType][DetailDescription]>.<Datatype>_

is a must notation [abc] is a optional notation and denotes validity domain (e.g. detail is only valid for certain customer or in a certain country)

Pascal Case: e.g. PurchaseOrder.Id (always capital letter for new word)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc.md - Chunk 8
Pascal Case: e.g. PurchaseOrder.Id (always capital letter for new word)

Or can be a group of Essentials (aka Item) or a group of Item(s) and Essential

{ "Label": "Vat.Item", // Changed group to Item "Value": null, "Location": null, "Items": [ { "Label": "Vat.Rate", "Value": "", // empty value // no location available "Text": "", "Confidence": 1.0, "ConfidenceThreshold": 0.8123 }, { "Label": "Net.Amount", "Value": "640.00", "Text": "640.00", "Location": { "Page": 1, "Left": 752, "Top": 443, "Width": 33, "Height": 13 }, "Confidence": 1.0, "ConfidenceThreshold": 0.8123 }, { "Label": "Vat.Amount", "Value": "0.00", "Text": "0.00", "Location": { "Page": 1, "Left": 759, "Top": 460, "Width": 27, "Height": 13 }, "Confidence": 1.0, "ConfidenceThreshold": 0.8123 } ] }

Basic Datatypes and their Normalization

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc.md - Chunk 9
Type Sample Value Spec Version "x.y.z" UTF-8 String Id Invoice.Id UTF-8 String Date Invoice.Date YYYY-MM-DD (ISO 8601) Timestamp Created.Timestamp yyyy-MM-dd'T'HH:mm:ss.SSSZ (ISO 8601) Decimal decimal number Int integer SmallAmount Unit.SmallAmount decimal separator '.', no group separator, four(!) decimal digits, e.g. 9.0009, 2314.5066, -12.9988 Amount GrandTotal.Amount decimal separator '.', no group separator, two decimal digits, e.g. 9.00, 2314.50, -12.99 Rate Vat.Rate decimal separator '.'; one decimal digits, e.g. 20.0, 19.0, 10.0; value less or equal 100.0 Currency Invoice.Currency ISO-4217 Name Name UTF-8 String Type Document.Type categorical values, specific list of possible values VatId Value-added Tax Id Following IBAN standard Iban Iban Standardized account identifier Bic Bic Standardized bank identifier Duration Due.Duration days, int Period Is only implicitly defined within an Itam by means of a PeriodStart.Date and PeriodEnd.Date Item that consists of start and end date

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc.md - Chunk 10
bank identifier Duration Due.Duration days, int Period Is only implicitly defined within an Itam by means of a PeriodStart.Date and PeriodEnd.Date Item that consists of start and end date Email Email @ .__ ITU E.123 Street Street in contact incl. street num To be normalized Zip Zip in Contact.Item UTF-8 String, To be normalized City City in Contact.Item UTF-8 String, To be normalized Phone Phone in Contact.Iteam UTF-8 String, To be normalized Country Country in Contact.Item ISO 3166-1 Alpha 2 Languages array of Language(s) ISO 639-1 Region region in Contact.Iteam Website e.g. www.example.top-level-domain ITU E.123 Item Vat.Item or Line.Item a group of details or again items Text Free Text Continuous Text (Fließtext) Bytes Byte Content e.g. images, etc.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc.md - Chunk 11
Category: Predefined categories

Type Sample Value Spec VatExemption.Type e.g. in Invoice describes essentials of value added tax exemption;Can have 4 values: "Reverse Charge","Intra-community supply", "Export outside the EU", "VATExemption", "" means no Exemption Unit.Type e.g. in Line Items describes units like meters, tons, pcs, etc. - OPEN - NEW Version? Article.Type in Line Items describes article categories with a "." notation; from left to right type becomes more specific: Main Types: Material, Service, Surcharge, Discount; With SubTypes for Surcharge.Service, Surcharge.Shipping, Surcharge.Payment, Surcharge.Environment, Surcharge.Fuel

Item(s): Available Predefined Grouped Essentials (invoice schema)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc.md - Chunk 12
Type Sample Value Spec Vat.Item e.g. in Invoice describes essentials of value added tax Line.Item e.g. in Invoice describes essentials of an e.g. article line including amounts, decriptiosn, ids, etc. Discount.Item e.g. in Invoice describes discount essentials incl. due dates BankAccount.Item Sender.Contact.Item Item that consists of contact info like address, email, website, phone, etc. Contact.Item Sender.Contact.Item Item that consists of contact info like address, email, website, phone, etc. DeliveryDate.Item in Line Items or Invoice denotes period and date Discount.Item in Line Items denotes discount as rate or amount Due.Item in Line Items denotes discount as rate or amount Payment.Due.Item e.g. in Invoice describes due dates as due.item and discount amounts as discount.item Surcharge.Item as header field denotes surcharges denotes surcharges as rates or amounts and the type Contact.Item Sender.Contact.Item Item that consists of contact info like address, email, website, phone,

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc.md - Chunk 13
as header field denotes surcharges denotes surcharges as rates or amounts and the type Contact.Item Sender.Contact.Item Item that consists of contact info like address, email, website, phone, etc. QrCode.Item QrCode Item that outlines basic qr code value and if available essentials as defined per qrcode specification

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc.md - Chunk 14
Versions

BLU DOC V7 --> OFFICIAL Release 1.0.0

Supported Document.Types: "Invoice", "OrderConfirmation", "Quotation"

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc.md - Chunk 15
Suggested Changes: - CHECK WITH HASCH: Created.Date becomes a Created.DateTime - CHANGED to Timestamp as this is more common for CreatedTime and in ISO standard DONE in V7 Sample - Renamed Category datatype to Type ... makes much more sense! Now we have e.g. Document.Type or Invoice.Type or VatExemption.Type - DONE in V7 Sample - DeliveryNote.Id not part of Delivery.Item - DONE in V7 Sample - Delivery Item becomes DeliveryDate.Item - DONE in V7 Sample CHECK with Hasch: COntact - changed from e.g. Street to Contact.Street (I see street as a data type - will be normalized one dey?, same for country, etc) - to be discussed, DONE in V7 Sample - Line Items: Item.Id -> Article.Id; Quantity -> Quantity.Double; Unit.Amount -> Unit.SmallAmount; Unit -> Item.Unit; Delivery.Date -> DeliveryDate.Item; Discount.Rate -> Discount.Item; CHECK with Hasch: Double became Decimal; Unit becaome Unit.Type since it is a categorical value, ; rest done as discussed - CHECK with Hasch: Added also Surcharges -

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc.md - Chunk 16
Discount.Rate -> Discount.Item; CHECK with Hasch: Double became Decimal; Unit becaome Unit.Type since it is a categorical value, ; rest done as discussed - CHECK with Hasch: Added also Surcharges - Change Iban to Account.Iban and Bic to Bank.Bic - makes it consistent to Bank.Id and Account.Id - Done ins Sample V7 - When is invoice in the name? - No change - Orientation should be added - DONE in V7 Sample - CHECK with Hasch DocumentType became Document.Type - CHECK: PaymentCondition.Item became a Payment.Due.Item which defines standard due dates; and I added a PaymentDiscount.Item for Skonto which defines due dates and values based on Due.Item and Discount.Item - CHECK: Added Article.Type as Label in Line Items to denote following types: Material, Service, Surcharge and Discount as line item incl. Subtypes denoted via "."; removed the Surcharge Item out of Line Items; removed the type information out of discounts which was a copy&paste error - and defined in the Type section the

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc.md - Chunk 17
item incl. Subtypes denoted via "."; removed the Surcharge Item out of Line Items; removed the type information out of discounts which was a copy&paste error - and defined in the Type section the subtypes - OPEN: Mapping - not part of V7

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc.md - Chunk 18
Samples:

Invoice: BLUDOC-Sample-V7.json

OrderConfirmation: -- BLUDOC-OrderConfirmation_V1.0.0_Sample.json -- Auftrag_2000170003.pdf

Schemas:

General: BluDoc_Schema_V1.0.0.json

BLU DOC V6

Basic Intro

BluDoc-Basic-Intro-V6-2023-05.pptx

Known Issues

Organize Versioning Remove Document where not necessary Orientation should be added Validation should be part of the implementation Label Mapping still not fixed for some situations

Changes:

Alignment with Hasch

Changed Product.Item to Line.Item

Added InvoiceType.Category

Schema

This is the first version of the schema. The layers of the document are not defined yet. BluDoc-schema-V6.json

Sample

BLUDOC-Sample-a4781ae9-edd9-4161-b54c-006762c28c79-v2-27f5e31d-800e-40e6-8797-78e5620d7c2f-V6.json

BLU DOC V5

Changes:

"." are now a part of naming convention

Introduced a context mapping section; it denotes the mapping from document essentials or texts to context information like master data

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc.md - Chunk 19
BLU DOC V5

Changes:

"." are now a part of naming convention

Introduced a context mapping section; it denotes the mapping from document essentials or texts to context information like master data

Search for "open" in json to find open points BLUDOC-Sample-a4781ae9-edd9-4161-b54c-006762c28c79-v2-27f5e31d-800e-40e6-8797-78e5620d7c2f-V5.json

BLU DOC V2

Incorporated Hasch comments Sample-BLU-DOC-a4781ae9-edd9-4161-b54c-006762c28c79-v2.json

BLU DOC V1

BLUDELTA-BLUDOC-V1-Sample.zip 0004AC1E5729A9D1AECB30909E002C38-BLUDOCV1.json

Resources

Presentation BluDoc.pptx

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Dachser-Typhon-Heads-and-Labels.md - Chunk 0
Models for all details needed for Dachser

Dachser Models Data.xlsx

New Typhon Headers for Header Details

Typhon Header Dates

InvoiceDate 6 DeliveryDate 5 SenderOrderDate 46 DiscountDate 47 ReceiverOrderDate 86 DueDateDate 81 DeliveryPeriodKey 117 DeliveryPeriodValue 118

Typhon Header Ids

InvoiceId 8 SenderVatId 23 ReceiverVatId 32 ReceiverOrderId 44 SenderOrderId 45 CustomerId 9 SenderTaxNo 24 CompanyRegistrationNumber 92 CostCenterId 111 CostCenterKey 112

Typhon Header Amounts

GrandTotalAmount 10 NetAmount 11 VatRate 12 VatAmount 13 TotalNetAmount 48 TotalVatAmount 49

Typhon Header Bank

Iban 33 Bic 34 BankAccount 78 BankCode 77

Analysis of released labels:

[Dachser Typhon Header.xlsx](/.attachments/Dachser%20Typhon%20Header-c29d37bd-745f-4a1e-8438-55d9e5381bd6.xlsx)` Dachser Typhon Header.xlsx 17.11.2022

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Dachser-Typhon-Heads-and-Labels.md - Chunk 1
Analysis of released labels:

[Dachser Typhon Header.xlsx](/.attachments/Dachser%20Typhon%20Header-c29d37bd-745f-4a1e-8438-55d9e5381bd6.xlsx)` Dachser Typhon Header.xlsx 17.11.2022

Summary: Typhon Header Dates: 443 DeliveryPeriods have to be labeled to get 500 Typhon Header Ids: without CompanyRegistrationNumber and CostCenter we have already 2362 Typhon Header Amounts: we have already 2099 Typhon Header Bank: we have already 2957

Values: number of fully labeled documents

Procedure

Label missing labels to have at least 500 documents with all labels released

Train first model

Use Active Learning to identify best 100 documents to label

Label those 100 documents with RIPEye -- predictions of old models are validated / corrected -> faster, cheaper (just one labeler)

Retrain model and repeat procedure

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Collection---Data-Lake.md - Chunk 0
Tags: Data Lake, BCIDB, Storage, NAS

This wiki page summarizes requirements and ideas for a refactored and sustainable data storage solution.

[[TOC]]

Requirements

Follows the Data Mgt. Process: Dataset Creation and Curation.

Uses Elastic Search for full-text search.

Vector DB 4 Learning without forgetting, ...

Store Blu Docs in Elastic?

Plan

Build a data lake with minio, hive and trino: https://chat.openai.com/share/4603771b-1a6c-45ab-832d-ecdf0cfa0c93

Stories

12660

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-labeling-process.md - Chunk 0
This page discusses the data labeling process defined by the Data Management Team.

[[TOC]]

Goal

Our goal is to provide fully labeled documents in a short amount of time, with the needed quality and value to train AI models at a minimal cost.

Definition: A fully labeled document is a document where each detail supported at time t by the Blu Delta service has been labeled. This includes all occurrences of a detail on all pages.

Goal set in February 2023: In a first step we want to provide 10k fully labeled documents (max 5 documents for each Type 0 (global) cluster)

Manual labeling: - Ops: 100 line item tables / month; ~€220/month - Ops: 800 documents (header data ~7 details/document) / month; ~€800/month - Project dependent labeling (e.g. Benchmarks, New detail types) ~ 400 documents; ~€500/month

Selection of Documents

There are three different aspects to be considered for document selection - represent customer distribution #14558 - value for training - ownership

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-labeling-process.md - Chunk 1
Selection of Documents

There are three different aspects to be considered for document selection - represent customer distribution #14558 - value for training - ownership

Since we lack the information for Point 1 we suggest to focus on point 2 under the constraint of Point 3

Represent customer distribution

To predict results of our service for a customer it is essential to have a realistic sample of documents.

Value for training

To provide best value for training, there are different aspects to consider: - provide at least ~10% of data points (not NA) for details that are rare such as "KID" - provide "difficult" situation (edge cases) more often than in reality please DEFINE "more often" - provide maximum on diversity - active learning to provide the most valuable training data for our models

Ownership

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-labeling-process.md - Chunk 2
Ownership

We have to consider ownership for document selection. To be less vulnerable and dependend on few customers. Hence, if a customer requests to delete his data our risk is minimized.

Sources to label documents

There are different sources to provide labels for documents: - Blu Delta Service (including various models for a single detail) - Structured data provided by customers - Validated documents provided by customers (e.g. via RIPEye) - Manually labeled documents (e.g. via RIPEye, Label Studio, Blumatix label tool)

Label process

If a new document is uploaded via the Blu Delta learn API labels will be created instantly, 1. by the current version of the Blu Delta Service #12070 2. from structured data provided by a customer - if available #14566, #14544 3. from the validation provided by RIPEye - if available

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-labeling-process.md - Chunk 3
In addition, it is necessary to fill gaps, add new details and improve the quality of the created data manually, 1. using RIPEye, Label Studio (#11046, #14544) or the Blumatix label tool a. if it was not possible to create labels from the sources above b. if the quality assessment shows that the labels are of poor quality c. ~~if the active learning container suggests a document for labeling~~ d. if the label is not yet supported by Blu Delta

Add labels to existing documents (fully labeled)

TBD: Speed vs. Quality: Do we need this 10k fully labeled documents asap or do we need to represent the document population of our customers?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-labeling-process.md - Chunk 4
Add labels to existing documents (fully labeled)

TBD: Speed vs. Quality: Do we need this 10k fully labeled documents asap or do we need to represent the document population of our customers?

Speed: - Choose 10k documents under the conditions that each (global) cluster is represented with max 5 documents and that the number of available labels of Prio 1 details is maximized. - If possible use predictions and structured data to create the required labels - Fill manually where needed (manual release, correction) + manual labeling (Goal: 800 documents/month; estimated cost = €800) - Repeat for labels with Prio 2 to n until all documents are fully labeled

Quality: It would be beneficial to understand which documents are important for our customers. Therefore, we need to understand the population of documents we process better:

14558

See also: #9285 Or: Analyze the cluster distribution in our DB (+ CustomerData files?)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-labeling-process.md - Chunk 5
14558

See also: #9285 Or: Analyze the cluster distribution in our DB (+ CustomerData files?)

To be able to... - Suggest doc from DB for labeling - Suggest document from our customers if we dont have that cluster in our DB - Also, do we need to train with this doc or is the quality of our predictions good enough

Then, apply the steps above to the suggested dataset.

Detail priority

Not all details are equally important. Below you will find a list stating the priority of the details supported by BLU DELTA.

Prio 1: (Dachser-AT-vollständig): DocumentType, InvoiceCurrency, InvoiceId, InvoiceDate, GTA, VATGroup, VATExemption Prio 2: SenderVatIds, ReceiverVatIds, IBAN, BIC, BankCode, BankAccount Prio 3: TBD ...

~~What about VatExemption?~~

Details .xlsx ~~Details .xlsx (deprecated)~~

Release already created labels

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-labeling-process.md - Chunk 6
~~What about VatExemption?~~

Details .xlsx ~~Details .xlsx (deprecated)~~

Release already created labels

In the current situation there is a huge amount of labels already created (~600k), but not released. There is a lot of potential to find strategies to release them efficiently. 1. Add predictions for auto release 2. Manual release 3. Analyse and fix automatically

Quality assurance

Release strategies

Our release strategies are one-time releases that express that the quality meets the requirements.

Current release strategies

Auto Release

Structured data:

labels created from the provided structured data are released and available for training if they align with the predictions provided by the Blu Delta service.

Manually labeled data:

If two annotators agree on a label it will be released. If they disagree, an additional step is necessary where an employee needs to manually release them.

Manually labeled line item data:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-labeling-process.md - Chunk 7
If two annotators agree on a label it will be released. If they disagree, an additional step is necessary where an employee needs to manually release them.

Manually labeled line item data:

Only one annotator labels documents and there is no release.

Future strategy: Continuous quality assessment

TBD: Label Quality based on Source and SourceVersion

Every Label gets its own Quality, mainly derived from the source and source version. #14064

Quality flag "best label" and "Quality score"

Different labels (1 to n) from various sources (1 to m) at time t available -> flag "best label" provides information which label n at time t is best suited for training

All labels n get a "Quality score" resulting from the quality process (former Auto Release; new quality process TBD).

Whenever a label is added for a data point the "Quality score" and the quality flag "best label" (based on all available labels n) is recalculated.

Quality process

TBD

Quality control of production

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-labeling-process.md - Chunk 8
Quality process

TBD

Quality control of production

Take a 10% random sample of documents for which labels have been created in the past month

Manually label the Prio 1 details (done by selected employees)

Calculate quality measures (bootstrapping?)

Please add your ideas:

TBD

Document Generator

Next steps? Learnings from Philipps evaluation?

13200

Priortized Stories

12070

12380

14230

11899

14064

14558

(or: #9285)

14566

14544

11046

Tooling

manual release in label studio? own validation view in label studio? validation view for RIPEye, and label studio and stand alone? bootstraping for benchmarks random labeling of benchmark

Labeln

Create a data package for labeling

Allocate a package to a labeler or to all labeler

Manual release

As Data Mgt. I want to manage my data packages for labeling in a GUI (e.g. label studio) -> add labeler to a package, specify details, specify random labeln or not,

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-labeling-process.md - Chunk 9
Manual release

As Data Mgt. I want to manage my data packages for labeling in a GUI (e.g. label studio) -> add labeler to a package, specify details, specify random labeln or not,

As Data Mgt. I want the active learning component to add new documents to the continous label packages -> I only want to set the amount of invoices per month or week

As Data Mgt. I need a service to construct Benchmarks and add them to a package -> Input: Size, Data plus population distribution -> Output = representative customer benchmark

Benchmark

Benchmark bootstraping

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Goals.md - Chunk 0
[[TOC]]

Goals: Data Management - H1 2024

AGENDA

Align on how data management can support following business goals in 2024 / H1 1) All customers perceive a steady and faster learning of existing BLU DELTA Doc recognitions 2) Easier, faster onboarding of new “other docs” for existing or new customers 3) Easier and faster addition of new data fields for existing BLU DELTA Doc recognitions

The goal for this meeting is: a) Establish a process where we continuously define, review and measure your goals b) Come up with a first list of goals and actions that support above business goals a. Come up with a list of obstacles that might risk or limit your capability to reach these goals

Prerequisite: - Chris to prep a process proposal for goal definition and tracking - Klemens, Hasch to come up with a proposal of dm goals for H1 2024

Update [2023-12-20]: Goal Definition: Based on company goals the team(s) define their contribution (sub-goals)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Goals.md - Chunk 1
Update [2023-12-20]: Goal Definition: Based on company goals the team(s) define their contribution (sub-goals)

Measurement: For each sub-goal define: How will we and the outside world recognize that the goal was reached and/or the situation has improved?

Reporting: Monthly: A written, informal report in the WIKI for each goal including the actions accomplished to reach the goal Quarterly: A meeting to review the status and validity of the goals

Plan - H1 2024

RED - All customers perceive a steady and faster learning of existing BLU DELTA Doc recognition

18991

Goal: - #18379

19000

Measure Service Improvement - Measure TotalValueDeliveryDocs/TotalProdDocs by Customer and DocumentType (month/day). - Autoprocessed docs (compare RIPEye measure) - Score > RecommendedThreshold for defined set of LabelTypes.

Measure Label Quality - Label Quality: Max. Correct&Verified/Verified

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Goals.md - Chunk 2
Measure Label Quality - Label Quality: Max. Correct&Verified/Verified

Measure Label Creation - Labels Correct&Verified - Labels created total (absolut) - Labels verified/total - Labels verified&correct/total - Labels released/total

by CreatedBy and LabelType

Goal: Max. Labels released/total = Labels verified&correct/total

Actions:

19179

19180

19951

20399

20400

20401

19167

20019

19164

19013

17215

19590

19165

17379

20311

18372

19412

18817

19811

20332

18790

20309

Obstacles: - DevTeam power (currently ~0.5 FTE). - OCR Errors. - Poor Customer ground truth data. - Not labeled according to our label policies (e.g. RIPEye, BLU DELTA prediction). - Not corrected at all (e.g. RIPEye). - Incomplete BLU DOC (e.g. Dachser). - Efficient Quality Control/Improvement process and tooling. - Training set construction (e.g. Documents where VatGroup = NA not included). - Typhon head construction (set of labelTypes in typhon head). - Fireline items.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Goals.md - Chunk 3
GREEN - Easier, faster onboarding of new “other docs” for existing or new customers

Goal: - #19004

Actions:

19170

17184

Front end 4 customer document upload.

19169

17187

21243

21177

Obstacles: - DevTeam power (currently ~0.5 FTE). - Make Data Collection stable. - Fireline items.

RED - Easier and faster addition of new data fields for existing BLU DELTA Doc recognitions

Goal: - #19061

Actions:

19376

19003

19938

Obstacles: - DevTeam power (currently ~0.5 FTE). - Impact on other components.

TBD: - #19003 - #19035

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes.md - Chunk 0
This wiki page describes the Data Management processes.

[[TOC]]

[[TOSP]]

Dataset Creation and Curation

Data Management - Future_process [2023-07-29]

Manual labelling, label package creation

Data Management - manualLabelling [2023-09-18]

Our current process regarding manual labeling and label package creation for manual labeling.

Data Request

Data Management - DataRequest [2023-11-09]

Benchmark Creation

Data Management - Benchmarks_current [2023-07-29]

On-board Human Labeller

Data Management - Human Labeller [2023-08-02]

see also: - Labeler Aquisition - Labeln

Customer off-boarding

Risks

Off-boarding PPP Template

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research.md - Chunk 0
[[TOC]]

Datasets

This is a dataset comprising 813 images of invoices and receipts of a private company in the Portuguese language

my personal receipts collected all over the world

Rossum flying rectangles

ICDAR 2013 Table Competition from https://studylib.net/doc/18677041/icdar-2013-table-competition

The RVL-CDIP Dataset also RVL-CDIP consists of 400,000 grayscale images in 16 classes (e.g. invoices), with 25,000 images per class. Licence information

SROIE 1000 whole scanned receipt images.

Dataset for table recognition

Marmot Dataset: https://www.icst.pku.edu.cn/cpdp/sjzy/index.htm

Synthetic Image Data for Table Detection: https://www.kaggle.com/champ333999/synthetic-image-data-for-table-detection

Google Scholar "table recognition dataset" https://scholar.google.at/scholar?q=table+recognition+dataset&hl=en&as_sdt=0&as_vis=1&oi=scholart

Microsoft: microsoft/table-transformer

Metadata management and data catalogue tools:

Open source

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research.md - Chunk 1
Microsoft: microsoft/table-transformer

Metadata management and data catalogue tools:

Open source

Open Source Data Catalog Software: 5 Popular Tools to Consider in 2022 Amundsen vs. Atlas

Apache Atlas

Apache Atlas | An architecture for federated data discovery & lineage with Apache Atlas | Atlas GitHub

Amundson by lyft

Amundson | Amundson YouTube Channel | Amundson GitHub

DataHub

DataHub | Demo | DataHub GitHub

Tensorflow ML Metadata

Tensorflow ML Metadata | https://www.tensorflow.org/tfx/guide/mlmd#data_model

Other

Alation | https://www.alation.com/ Alex | https://alexsolutions.com.au/ Azure Purview | https://azure.microsoft.com/en-us/services/purview/#overview | https://www.youtube.com/watch?v=J2T_2tXjAkA Collibra | https://www.collibra.com/us/en Informatica | https://www.informatica.com/

Data Catalog:

Azure Data Catalog (https://azure.microsoft.com/en-us/services/data-catalog/#overview)

OvalEdge (https://www.ovaledge.com/)

Data Versioning:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research.md - Chunk 2
Data Catalog:

Azure Data Catalog (https://azure.microsoft.com/en-us/services/data-catalog/#overview)

OvalEdge (https://www.ovaledge.com/)

Data Versioning:

Git Large File Storage (https://git-lfs.github.com/) Open-source Version Control System for Machine Learning Projects (https://dvc.org/)

Annotation tools

https://ubiai.tools/

https://docs.microsoft.com/en-us/azure/applied-ai-services/form-recognizer/quickstarts/try-sample-label-tool

https://labelstud.io/

https://prodi.gy/

"C:\Data\OneDrive\OneDrive - Blumatix Intelligence GmbH\Labeling\Gamification Labelling.docx"

https://github.com/doccano/doccano#:~:text=doccano%20is%20an%20open%20source,text%20summarization%20and%20so%20on.

V7

Supervisely

iMerit

Quality assurance

Variance estimates in k-fold cross-validation

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Deployment-instructions.md - Chunk 0
Deployment of data management tools

Description found in sub folders

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Detail-Priority.md - Chunk 0
This page gives the detail priority as discussed with our PO [confirmed on June 1st 2023].

Current Label Types

[[TOC]]

Document Types

Invoice

Prio 1: (Must-complete): DocumentType, InvoiceCurrency, InvoiceId, InvoiceDate, GrandTotalAmount, VATGroup, VATExemption, SenderVatId, ReceiverVatId, IBAN, ReceiverTaxId, SenderTaxId

Note (Dachser-AT-complete): DocumentType, InvoiceCurrency, InvoiceId, InvoiceDate, GrandTotalAmount, VATGroup, VATExemption

Prio 2: BIC, BankCode, BankAccount Prio 3: TBD - DeliveryDate, ReceiverOrderId, SenderOrderId, DueDate, DeliveryPeriodKey, DeliveryPeriodValue,

Default LabelTypes

Default LabelTypes for each new label task: - 1,2,5,6,8,9,10,11,12,13,23,32,33,34,44,45,46,47,48,49,50,77,78,117,118,123,124

Line Items:

51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,93,94,95,96,97,98,99,100,101,102,103,104

Contacts:

105,106,107,108,109,110,139,140

...

Order Confirmation

Prio 1:

Default LabelTypes

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Detail-Priority.md - Chunk 1
51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,93,94,95,96,97,98,99,100,101,102,103,104

Contacts:

105,106,107,108,109,110,139,140

...

Order Confirmation

Prio 1:

Default LabelTypes

Default LabelTypes for each new label task: - 1,2,5,9,10,11,12,13,23,32,33,34,44,45,46,47,48,49,77,78,123,124,126,127,128,129,130,133

Delivery Note

Prio 1:

Default LabelTypes

Default LabelTypes for each new label task:

Quotation

Prio 1:

Default LabelTypes

Default LabelTypes for each new label task: - 1,2,5,9,10,11,12,13,23,32,33,34,44,45,46,47,48,49,77,78,123,124,134,135

ALD

136,137,138,205

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Document-Generator.md - Chunk 0
Goal

Create synthetic data - Documents that are of value for training and belong to Blumatix.

Key Ideas

Start with white paper - content is new -> Ownership Generic, simple structure - composed by DocumentDetails and DocumentDetailGroups -> build any document, Generic -> composed by unknown DocumentDetails

Implementation

C# .NET Core use 3rd party components where possible (Render- Engine,...)

Main Components

Structure Builder

Content Provider

Layouter

Render Engine

Main Tasks

Document Structure

Composite Pattern All elements have a Tags attribute for label definition (multiple labels possible) All elements have a Bounding Box attribute All leafs have a Content attribute

Document Generator

gets a construction plan and builds Document Structure (logic structure only)

enriches Document Structure step by step: --add Content --add Position --add Style

finally render and save document file and document structure

Structure Builder

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Document-Generator.md - Chunk 1
enriches Document Structure step by step: --add Content --add Position --add Style

finally render and save document file and document structure

Structure Builder

Input: Construction Plan that can include definitions of variants Output: List

Structure Builder creates logic structure by composing just DocumentDetails and DocumentDetailGroups objects. Tags are used for type information of the objects (e.g. LineItemTable, LineItemDescription, Amount, Integer); there might be more than one tag for a DocumentDetail.

Content Provider

Input: Document Structure as DocumentDetailGroup with Tags set Output: Document Structure is enriched: all DocumentDetailLeafs include Content

different Sources of Content

Interface for all different Content Providers

Mapping: Tag - Content Provider

Context to pass settings through hierarchy

Layouter

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Document-Generator.md - Chunk 2
different Sources of Content

Interface for all different Content Providers

Mapping: Tag - Content Provider

Context to pass settings through hierarchy

Layouter

Input: Document Structure as DocumentDetailGroup with Tags and Content set Output: Document Structure is enriched: all DocumentDetails include BoundingBoxes

Still in discussion: Render engine might align elements and it is not just the Layouter that sets bounding boxes. - some definition about horizontal and vertical alignment

Render Engine

Input: Document Structure as DocumentDetailGroup with Tags, Contents and Position set Output: Word Document

First try: use Office Interop to create Word Documents

Style to pass settings through hierarchy

Construction Plan

To create many variants of documents it must be possible to define fixed and variable (random distributions) structures, eg. (random number of positions or line item details based on distributions about specific type and position).

Format to be defined!

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Document-Generator.md - Chunk 3
Format to be defined!

Samples

Resources

BASIC CONCEPT FOR DISCUSSION by Chris DocGenerator - first simple Implemenation by Hasch

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Guidelines-and-Policies.md - Chunk 0
In this Wiki you will find Guidelines and Policies from the Data Management Team regarding our data and other responsibilities such as the acquisition of new labeller.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Tools.md - Chunk 0
[[TOC]]

Label tools

RIPEye

Credentials see Keeper "RIPEye Labelling Tool" - https://validation.bludelta.ai/ - Doku: https://www.bludelta.de/de/web-ui-for-invoice-and-document-capture/

Label tool

http://bludelta-labelingtool.azurewebsites.net/Login?ReturnUrl=%2FInvoice

Label Studio

Open Label Studio: http://192.168.137.80:11000/user/signup/?token=1d2f67962482b771

Blutils

Blutils Wiki

PyBlutils in Azure DevOps

Text PDF crawler

C:\source\PyBlutils\Blutils\tools\text_pdf_crawler.py

Label Quality

Cleanlab

APIs

Learn API

https://www.bludelta.de/de/learn-api-invoice-and-document-capture/

SQL Queries

Select Training Data - Query

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Tools.md - Chunk 1
Label Quality

Cleanlab

APIs

Learn API

https://www.bludelta.de/de/learn-api-invoice-and-document-capture/

SQL Queries

Select Training Data - Query

``` -- Set the parameters for the query DECLARE @Provider NVARCHAR(100) = 'Dachser,RedBull'; -- replace with your desired provider value DECLARE @Language NVARCHAR(100) = 'en,de'; -- replace with your language value DECLARE @LabelFilters NVARCHAR(100) = '2|EUR,6,8,10'; -- replace with your desired label types and filter values separated by '|' DECLARE @MaxPerCluster NVARCHAR(100) = '5'; -- replace with your desired max number of invoices per cluster DECLARE @MaxPages NVARCHAR(100) = '1'; -- replace with your desired max number of pages per invoice

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Tools.md - Chunk 2
-- This CTE gets the master ID, invoice ID, provider value, and cluster size for each invoice in the specified provider and language WITH cluster_master AS ( SELECT c.Master_Id, c.Invoice_Id, mi.Value AS Provider, o.Language, o.NumberOfPages, c.ClusterSize FROM ClusterTable AS c JOIN MetaInfo AS mi ON c.Invoice_Id = mi.InvoiceEntity_Id JOIN OcrResult AS o ON c.Invoice_Id = o.InvoiceEntity_Id WHERE c.Type = 0 AND mi.Type = 2 AND mi.Value IN (SELECT VALUE FROM string_split(@Provider, ',')) AND o.Language IN (SELECT VALUE FROM string_split(@Language, ',')) AND o.NumberOfPages <= @MaxPages ),

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Tools.md - Chunk 3
-- This CTE gets the count of labels for each invoice in the specified label types that have been released invoice_label_counts AS ( SELECT i.Id, l.Type, l.Value, COUNT(l.Id) AS LabelCount FROM Invoice AS i LEFT JOIN Label AS l ON i.Id = l.InvoiceEntity_Id WHERE i.Id IN (SELECT cm.Invoice_Id FROM cluster_master AS cm) AND l.Released = 1 AND l.Type IN (SELECT CAST(VALUE AS INT) FROM string_split(@LabelFilters, ',')) GROUP BY i.Id, l.Type, l.Value ),

-- This CTE assigns a rank to each invoice based on the label count within its cluster, and selects the top invoices per cluster up to the specified max invoice_rank AS ( SELECT cm.Invoice_Id, cm.Master_Id, cm.ClusterSize, COALESCE(ilc.LabelCount, 0) AS LabelCount, ROW_NUMBER() OVER (PARTITION BY cm.Master_Id ORDER BY ilc.LabelCount DESC, cm.Invoice_Id) AS RowNum FROM cluster_master AS cm LEFT JOIN invoice_label_counts AS ilc ON cm.Invoice_Id = ilc.Id ),

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Tools.md - Chunk 4
-- This CTE selects the top invoices per cluster up to the specified max rank_and_cluster AS ( SELECT Invoice_Id, Master_Id, ClusterSize, LabelCount, COUNT(*) OVER (PARTITION BY Master_Id) AS InvoicesInCluster FROM invoice_rank WHERE RowNum <= @MaxPerCluster )

-- This is the final SELECT statement that returns the desired columns, sorted by cluster size, label count, and invoice ID SELECT rac.Invoice_Id, rac.Master_Id, rac.InvoicesInCluster, rac.ClusterSize, rac.LabelCount, cm.Provider, cm.Language, cm.NumberOfPages FROM rank_and_cluster AS rac JOIN cluster_master AS cm ON rac.Invoice_Id = cm.Invoice_Id ORDER BY rac.InvoicesInCluster DESC, rac.LabelCount DESC, rac.ClusterSize DESC, rac.Invoice_Id;

```

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BLU-DOC-Addresses.md - Chunk 0
How BLU DELTA receives and returns addresses:

BLU DELTA receives and returns following address information

Normalized:

Name | company name Unit, Attn: Name -> OPEN: check how libpostal maps "z.Hd." Street name AND house number/staircase/floor/entrance | post office box number City | town name Province and/or state and/or region name and/or island Postal code or zip code Country name Category (Sender, Receiver, Other)

The BLU DELTA address definition follows:

1 - ISO11180 and UPU:

In general there exist 2 global standards: ISO11180 and UPU (United Nations)

They both recommend a very similar structure like this:

Recipient's name or company name Street name and number or post office box number City or town name Province, state or region name Postal code or zip code Country name (in uppercase letters)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BLU-DOC-Addresses.md - Chunk 1
Recipient's name or company name Street name and number or post office box number City or town name Province, state or region name Postal code or zip code Country name (in uppercase letters)

ISO 11180 also provides guidelines for formatting each field, such as using a consistent font size and style, separating each line with a comma or new line, and using uppercase letters for the country name.

2 - libpostal library

Additionally there exist software libraries to normalize addresses. Most known open source library is: https://github.com/openvenues/libpostal

libpostal normalizes worldwide addresses based on any common format into following schema:

house: venue name e.g. "Brooklyn Academy of Music", and building names e.g. "Empire State Building"

category: for category queries like "restaurants", etc.

near: phrases like "in", "near", etc. used after a category phrase to help with parsing queries like "restaurants in Brooklyn"

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BLU-DOC-Addresses.md - Chunk 2
category: for category queries like "restaurants", etc.

near: phrases like "in", "near", etc. used after a category phrase to help with parsing queries like "restaurants in Brooklyn"

house_number: usually refers to the external (street-facing) building number. In some countries this may be a compount, hyphenated number which also includes an apartment number, or a block number (a la Japan), but libpostal will just call it the house_number for simplicity.

road: street name(s)

unit: an apartment, unit, office, lot, or other secondary unit designator

level: expressions indicating a floor number e.g. "3rd Floor", "Ground Floor", etc.

staircase: numbered/lettered staircase

entrance: numbered/lettered entrance

po_box: post office box: typically found in non-physical (mail-only) addresses

postcode: postal codes used for mail sorting

suburb: usually an unofficial neighborhood name like "Harlem", "South Bronx", or "Crown Heights"

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BLU-DOC-Addresses.md - Chunk 3
postcode: postal codes used for mail sorting

suburb: usually an unofficial neighborhood name like "Harlem", "South Bronx", or "Crown Heights"

city_district: these are usually boroughs or districts within a city that serve some official purpose e.g. "Brooklyn" or "Hackney" or "Bratislava IV"

city: any human settlement including cities, towns, villages, hamlets, localities, etc.

island: named islands e.g. "Maui"

state_district: usually a second-level administrative division or county.

state: a first-level administrative division. Scotland, Northern Ireland, Wales, and England in the UK are mapped to "state" as well (convention used in OSM, GeoPlanet, etc.)

country_region: informal subdivision of a country without any political status

country: sovereign nations and their dependent territories, anything with an ISO-3166 code.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BLU-DOC-Addresses.md - Chunk 4
country_region: informal subdivision of a country without any political status

country: sovereign nations and their dependent territories, anything with an ISO-3166 code.

world_region: currently only used for appending “West Indies” after the country name, a pattern frequently used in the English-speaking Caribbean e.g. “Jamaica, West Indies”

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-Benchmarks.md - Chunk 0
The Name of the BenchmarkDefinition must contain the Word: "OrderConf"

DETAILS

The Name of the BenchmarkDefinition must contain the Word: "quotation"

DETAILS

The Name of the BenchmarkDefinition must contain the Word: "receipt". Before and after the word "receipt" there has to be either a space or "-" or "_".

DETAILS

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-Format.md - Chunk 0
Design Decisions

Separate information that is independent from document type

Information like Creation Date, Sources, or Pages is together in a separate section.

BluDoc is organized in abstraction layers

Binaries -> Pixels (might be a reference to the original document)

Texts -> OCR result

Entities / Datatypes -> ER result

DocumentEssentials -> document details

Items in different layers are referenced by position only. All layers are optional.

Page information is separeted from document structure

In the document type independend section there is a list of pages. Document details have a page reference (number).

Just one Label

Each document detail has just one label. For most use case this is fine and it reduces complexity.

Use Case Labels GrandTotalAmount, Amount: is covered by additional ER layer Use Case Label InvoiceDate, DeliveryDate: is covered by two document details Use Case Label as Tag like Receiver or Sender: is covered by additional child

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-Format.md - Chunk 1
BluDoc structure is organized as tree; root is document

There is one tree that includes document details hierarchy. This is fine for processing and reading.

Common Rules

"Not there" -> Empty property

An empty Value (Value: "") indicates that this element is NOT on the document (not available, N/A). E.g. there is no DeliveryDate on your DeliveryNote, then your json includes an Item in the DocumentEssentials section with the "Label": "DeliveryDate" and a "Value": ""

"Unknown" -> No property

Leave out what you do not know: E.g. if you do not know the Page structure of a document then skip the "Pages" array E.g. if you do not know the Location of a DocumentEssential then skip the "Location" element

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-Format.md - Chunk 2
~~## "Not applicable" -> Null property - ! only before BluDoc 1.2.0 ! In some cases properties like Location, Text, etc. are not applicable for certain items; in these cases these attributes must be set to null. E.g. for Label "InvoiceCurrency" the Text and Location property are set to null.~~

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-OCR.md - Chunk 0
Introduction

From the very beginning, OCR information was planned to be one of the "layers" of document information in BluDoc.

Requests

there might be more than one OCR result (e.g. Nuance and Easy OCR)

current Nuance OCR can be represented without information loss

First design

Have a DocumentTexts layer on the same level as DocumentEssentials

Text (OCR Result) is organized in our old format

Sample:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-OCR.md - Chunk 1
// Document Text Layer Descriptions
// Various Document Text Descriptions can be attached
"DocumentTexts": [
    {
        "TextFormat": "BLU DOC Text",
        "TextFormatVersion": "1.0.0",
        "CreatorSoftware": "Omnipage",
        "CreatorSoftwareVersion": "3.0.0",
        "Text": { // from here it represents OCRResult from old format
            "Width": 2484,
            "Height": 3509,
            "NumberOfPages": 1,
            "Pages": [
                {
                    "Index": 0,
                    "DpiX": 300,
                    "DpiY": 300,
                    "Width": 2484,
                    "Height": 3509,
                    "Orientation": "0",
                    "Regions": [
                        {
                            "Lines": [
                                {
                                    "Words": [
                                        {
                                            "Text": "BRIGH1",

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-OCR.md - Chunk 2
{
                                    "Words": [
                                        {
                                            "Text": "BRIGH1",
                                            "BoundingBox": {
                                                "Rectangle": "295, 49, 340, 89"
                                            },
                                            "Languages": [
                                                "en"
                                            ],
                                            "CapHeight": 88,
                                            "BaseLine": 137,
                                            "FontSize": 29,
                                            "Bold": true,
                                            "Italic": false,
                                            "Underlined": false,
                                            "Proportional": true

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-OCR.md - Chunk 3
"Italic": false,
                                            "Underlined": false,
                                            "Proportional": true
                                        }
                                    ],
                                    "BoundingBox": {
                                        "Rectangle": "295, 49, 340, 89"
                                    }
                                },

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-OCR.md - Chunk 4
Problems with first design

Pages are already defined in BluDoc and should be reused

BoundingBox and Rectangle should be Location as used in DocumentEssentials (including reference to their page and relative coordinates)

for OCR System specific Metainfo like Languages, CapHeight, Font, etc. there should be a common, extendable mechanism (like key/value pairs)

do we really need a separate format version for DocumentTexts or is it just the BluDoc schema?

Additional features to discuss

Confidence field

Additional Character level

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-Schema-Change-Checklist.md - Chunk 0
Update Schema Release Notes

BluDoc Implementation

Implement new Schema in C# - Add new Schema file as Embbedded Resource - Generate new BluDoc class (see ) - Copy new BluDoc code to BluDoc.cs and check differences - Clean multiple Locations: Remove WordLocation Remove LineLocation Rename LocationLocation to Location Rename all types of location references to Location - Increase Current Version number and reference to schema file in BluDocExtension - Implement new extension classes if necessary - Implement unit test for schema validation, if necessary

Update BluDoc Schemas in Wiki

New BluDoc NuGet Package

Upload new BluDoc NuGet Package

Update BluDoc Nuget Package Release notes and email

Update Learn API

Update BluDocConverter in BluDocConverter project in Normalizer component

Update Learn API Release Notes

Deploy Learn API

Update BluDoc Website

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-Schema-Change-Requests.md - Chunk 0
Schema request

add element for OCR to schema

add element for Document file reference to schema

normalize Unit

Schema 1.2.0 Change requests

Confidence threshold should get additional properties: -1, 0-1

Add element for Document File reference

Add element for Context

Page.Id no good name

Add Type property to DocumentEssential

Improve description: Created.DateTime should be RFC 3339 (update samples!)

object instead of array (no order of DocumentEssentials)

Schema 1.0.0 Change requests

Severe Issues

Confidence type must be changed from integer to number - Schema adaptation, new schema - APPROVED

Dpi type should be changed from string to integer - APPROVED, new schema and spec

Dpi format should be removed

Improvements

Confidence should get additional properties: "Minimum": 0, "Maximum": 1

Confidence threshold should get additional properties: -1, 0-1

Naming

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-Schema-Change-Requests.md - Chunk 1
Dpi format should be removed

Improvements

Confidence should get additional properties: "Minimum": 0, "Maximum": 1

Confidence threshold should get additional properties: -1, 0-1

Naming

Page name in Page should be changed it should be Page.Id oder Page.Number or just Id or Number ? Type is integer -> Id instead of Page - APPROVED

Contact.Zip -> Contact.ZipCode (nice to have)

Payment.Discount.Item because Payment.Due.Item? - APPROVED

SenderOrder.Id because Sender.Contact.Item - NO CHANGE

Warum .Item und nicht .Items - NO CHNAGE

Dachser.Sender.Id ?

Dachser.Receiver.Id ?

Dachser.DachserToDachser -> IntraCompany.Flag?

Dachser.PurchaseOrder.Id? -> NO CHANGE

UId -> VatId (missing in Invoice sample - NO CHANGE -ADDRESS?

Type

Contact.Fax : is fax a separate Type or is it Phone? -> CHANGE: DELETE

Format

Confidence and ConfidenceThreshold should get format that shows just 4 digits after decimal point - APPROVED

Structure

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-Schema-Change-Requests.md - Chunk 2
Format

Confidence and ConfidenceThreshold should get format that shows just 4 digits after decimal point - APPROVED

Structure

Rule for schema: Null setting means: not applicable (like Location for InvoiceCurrency) - it would be much easier if Null property is same as missing property -> APPROVED - only spec change, schema change

Provider mandatory?

Add element for Document File reference

Add element for Context

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-Schema-Release-Notes.md - Chunk 0
BluDoc JSON Schema Release Notes

Version 1.4.0 - Release Date: 2024-04-26

Overview

This release enables to add binaries or references to binaries

New BluDoc Element

DocumentBinaries has been added on the first level. It is organized in Base64 encoded Embeddings and/or References to binaries (Uri)

Version 1.3.1 - Release Date: 2024-04-17

Overview

Fix "required" bug within DocumentTexts

Key Changes and Additions

DocumentTexts Line required moved from DocumentTexts to DocumentTexts array item definition.

Version 1.3.0 - Release Date: 2024-04-03

Overview

This release enables OCR Text within BluDoc

New BluDoc Element

DocumentTexts has been added on the first level. It is organized in Lines and their Words. Line and Word include a Text and a Location property; Line additionaly has a collection of Words.

Key Changes and Additions

DocumentEssentials required changed to not required (removed required attribute)

Version 1.2.1 - Release Date: 2023-11-07

Overview

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-Schema-Release-Notes.md - Chunk 1
Key Changes and Additions

DocumentEssentials required changed to not required (removed required attribute)

Version 1.2.1 - Release Date: 2023-11-07

Overview

This release introduces enhancements to the JSON schema.

Names of Document Essentials

Changed:

Currency Invoice.Currency has been changed to Currency because currency is used not only in invoices.

Document Types

OrderConfirmation: Currency has been added to OrderConfirmation

Version 1.2.0 - Release Date: 2023-10-03

Overview

This release introduces enhancements, bug fixes, and improvements to the JSON schema.

Key Changes and Additions

DocumentEssential/Confidence type: integer changed to number to be able to handle double values.

Page/Dpi type: string changed to integer and formatremoved to handle Dpi values as integer.

Page/Page property: Page changed to Id to be more clear and consistent in naming.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-Schema-Release-Notes.md - Chunk 2
Page/Dpi type: string changed to integer and formatremoved to handle Dpi values as integer.

Page/Page property: Page changed to Id to be more clear and consistent in naming.

Policy to make a difference between "element is missing" and "element is null" has been skipped. This makes the schema much cleaner and code generation is more easy.

Improvements

DocumentEssential/Confidence New keyword minimum: 0 and maximum: 1 added to limit the range of values.

Names of Document Essentials

Added: - Contact Attention.Name has been added to the contact properties to provide information of a unit or person

Removed: - Contact Contact.Fax has been removed because there is no longer need (hopefully)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-Schema-Release-Notes.md - Chunk 3
Removed: - Contact Contact.Fax has been removed because there is no longer need (hopefully)

Changed: - Contact Zip has been changed to ZipCode - PaymentDiscount PaymentDiscount.Item has been changed to Payment.Discount.Item because Discount is a Type itself and therefore separated by "." - LineItem Article.Description.String has been changed to ArticleDescription.String because the "." is just wrong.

Thank you for using our JSON schema and helping us improve it!

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-Schemas-and-Samples.md - Chunk 0
BluDoc schema version 1.4.0

2024-04-30

Schema

BluDoc_Schema_V1.4.0.json

BluDoc schema version 1.3.1

2024-04-04

Schema

BluDoc_Schema_V1.3.1.json

BluDoc schema version 1.3.0

2024-04-03

Schema

BluDoc_Schema_V1.3.0.json

Classification Sample

Classification_sample.json

OCR Sample

CSS Invoice OCR Sample

Invoice.pdf Invoice_OCR_sample.json

BluDoc schema version 1.2.1

Schema

BluDoc_Schema_V1.2.0.json

Invoice Sample

Invoice_Sample.json

Dachser Invoice Sample

920a6543-7b29-4348-a831-b0c10080efef.pdf 920a6543-7b29-4348-a831-b0c10080efef.json

OrderConfirmation Sample

Auftrag_2000170003.pdf OrderConfirmation_Sample.json OrderConfirmation_GroundTruth_Sample.json

Quotation Sample

a4820ec2-ef14-4101-9c54-2e96546d9777.pdf Quotation_Sample.json Quotation_GroundTruth_Sample.json

BluDoc schema version 1.2.0

Schema

BluDoc_Schema_V1.2.0.json

Invoice Sample

Invoice_Sample.json

OrderConfirmation Sample

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-Schemas-and-Samples.md - Chunk 1
BluDoc schema version 1.2.0

Schema

BluDoc_Schema_V1.2.0.json

Invoice Sample

Invoice_Sample.json

OrderConfirmation Sample

Auftrag_2000170003.pdf OrderConfirmation_Sample.json OrderConfirmation_GroundTruth_Sample.json

Quotation Sample

a4820ec2-ef14-4101-9c54-2e96546d9777.pdf Quotation_Sample.json Quotation_GroundTruth_Sample.json

BluDoc schema version 1.1.0

Schema

BluDoc_Schema_V1.1.0.json

Invoice Sample

Invoice_Sample.json

OrderConfirmation Sample

Auftrag_2000170003.pdf OrderConfirmation_Sample.json OrderConfirmation_GroundTruth_Sample.json

Quotation Sample

a4820ec2-ef14-4101-9c54-2e96546d9777.pdf Quotation_Sample.json Quotation_GroundTruth_Sample.json

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-Validators.md - Chunk 0
Introduction

BluDoc provides a set of validators that check BluDocs for plausibility and/or consistence. There are a lot of assumptions about "valid" BluDocs that are not part of the schema.

Some of the validators just give a hint what might be wrong.

How to use

Validators

Schema Validation

Line Item - Calculate Price

Line Item - One Position only

Line Item - Position is left

Line Item - Compare to Total Amount

Vat - Calculate Vat

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-_Dachser_.md - Chunk 0
Why

We had to present Dachser a ground truth definition for the Learn API and since the final BluDoc definition was not ready we gave Dachser a simplified format to start with.

Format Samples

Dachser

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-_Dachser_.md - Chunk 1
{ "BluDocVersion": "1.0.0", "Created": "2023-06-22 09:33:30", "CreatorSoftware": "Dachser Ground Truth Exporter", "CreatorSoftwareVersion": "1.0.0", "DocumentType": "Invoice", "DocumentEssentials": [ { "Label": "InvoiceDate", "Value": "2023-04-07", "Confidence": 1.0 }, { "Label": "InvoiceId", "Value": "151431", "Confidence": 1.0 }, { "Label": "DachserReceiverId", "Value": "0322", "Confidence": 1.0 }, { "Label": "DachserSenderId", "Value": "0041049019", "Confidence": 1.0 }, { "Label": "VatGroup", "Value": null, "Items": [ { "Label": "NetAmount", "Value": "590.5", "Confidence": 1.0 }, { "Label": "VatRate", "Value": "0.0", "Confidence": 1.0 }, { "Label": "VatAmount", "Value": "0.00", "Confidence": 1.0 } ] }, { "Label": "VatExemption", "Value": "Vat Exemption", "Confidence": 1.0 }, { "Label": "GrandTotalAmount", "Value": "590.50", "Confidence": 1.0 }, { "Label": "InvoiceCurrency", "Value": "EUR", "Confidence": 1.0 }, { "Label": "SenderVatId", "Value": "SI88311732", "Confidence": 1.0 }, {

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-_Dachser_.md - Chunk 2
"GrandTotalAmount", "Value": "590.50", "Confidence": 1.0 }, { "Label": "InvoiceCurrency", "Value": "EUR", "Confidence": 1.0 }, { "Label": "SenderVatId", "Value": "SI88311732", "Confidence": 1.0 }, { "Label": "ReceiverVatId", "Value": "ATU47239901", "Confidence": 1.0 } ] }

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-_Dachser_.md - Chunk 3
Update for VatGroup/VatExemption

Update for DeliveryDate

Update for TransportTourId

Value for Tour Id is normalized (filled with leading zeros)

{ "Label": "TransportTourId", "Value": "08/0000123", "Confidence": 1.0 },

Update for Countries

Values for Countries are two-letter country codes defined in ISO 3166-1.

{
  "Label": "SenderCountry",
  "Value": "DE",
  "Confidence": 1.0
},
{
  "Label": "ReceiverCountry",
  "Value": "FR",
  "Confidence": 1.0
},

General

Musterrechnung.pdf Musterrechnung.json BluDoc Ground Truth Format.docx

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\Delivery-Note-Schema.md - Chunk 0
Delivery Note (HIK)

DocumentType: DeliveryNote

Delivery Note Schema 1.0.0

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\Delivery-Note-Schema.md - Chunk 1
Key Parent Detail Description Format Additional information DeliveryNote.Id Delivery Note Id Unique identifier of the document identifier DeliveryNote.Date Delivery Note Date Issue date of the document date Sender.VatId Sender VAT Id Unique tax identification number of the sender for Value Added Tax (VAT) vatid Sender.Id Sender Id Supplier Id maintained by the receiver identifier 5 to 7 digits, often with leading zeros ReceiverOrder.Id Receiver Order Id Unique identifier of a purchase or receiving order identifier 11 digits, starts with "BE" or "AR" or "BK" BankAccount.Item Bank Account Group Structure of Bank Account Group Structure multiple occurrences possible, create new BankAccount.Item for each Bank.Iban BankAccount.Item IBAN International Bank Account Number Iban Bank.Bic BankAccount.Item BIC Bank Identifier Code (SWIFT) Bic Bank.Id BankAccount.Item Bank Id Unique identifier assigned to a bank identifier Account.Id BankAccount.Item Bank Account Id Unique identifier of a bank

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\Delivery-Note-Schema.md - Chunk 2
BIC Bank Identifier Code (SWIFT) Bic Bank.Id BankAccount.Item Bank Id Unique identifier assigned to a bank identifier Account.Id BankAccount.Item Bank Account Id Unique identifier of a bank account identifier Line.Item Line Item Structure of Single line of goods or services purchased Structure multiple occurrences possible, create new Line.Item for each Article.Id Line.Item Article Id Identifier of the article identifier ArticleDescription.String Line.Item Article Description Description of the article string might include line feeds ReceiverArticle.Id Line.Item Article Id of Receiver Receiver identifier of the article identifier 6 digits, starting with 7 Quantity.Decimal Line.Item Quantity Quantity Decimal Unit.Type Line.Item Unit Type Unit type of quantity Type Charge.String Line.Item Charge Batch of goods delivered together String Origin.Country Line.Item Origin Country Country of production Country CustomsTariff.Id Line.Item Customs Tariff Id Code used to classify goods for

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\Delivery-Note-Schema.md - Chunk 3
Charge Batch of goods delivered together String Origin.Country Line.Item Origin Country Country of production Country CustomsTariff.Id Line.Item Customs Tariff Id Code used to classify goods for import/export identifier 6-8 digits Contact.Item Contact Group Structure of Contact Information Structure Contact.Name Contact.Item Contact Name Full name of the contact Name Attention.Name Contact.Item Contact Attentiom Name Name of a specific person or department Name Contact.Street Contact.Item Contact Street Street address of the contact String Contact.ZipCode Contact.Item Contact Zip Code Postal/Zip code of the contact String Contact.City Contact.Item Contact City City of the contact String Contact.Region Contact.Item Contact Region State, province, or administrative division, within a country String Contact.Country Contact.Item Contact Country Country of the contact Country Contact.Website Contact.Item Contact Website Website URL of the contact URL Contact.Email Contact.Item Contact

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\Delivery-Note-Schema.md - Chunk 4
String Contact.Country Contact.Item Contact Country Country of the contact Country Contact.Website Contact.Item Contact Website Website URL of the contact URL Contact.Email Contact.Item Contact Email Email address of the contact Email Contact.Phone Contact.Item Contact Phone Phone number of the contact String Sender.Contact.Item Sender Contact Contact details for the sender Structure Receiver.Contact.Item Receiver Contact Contact details for the receiver Structure

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\Generic-Detail-Naming-Convention.md - Chunk 0
Generic Detail Naming Convention

Camel-based

TBD: How to handle one vs. many - do we need to distinguish this somewhere??

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\Generic-Detail-Naming-Convention.md - Chunk 1
Type Sample Detail Value Spec Sample Value Id Invoice.Id UTF-8 String 1234ABX Date Invoice.Date YYYY-MM-DD (ISO 8601) 2023-10-03 DateTime Created.DateTime RFC 3339 2023-10-10T13:23:27.7242467+02:00 Amount GrandTotal.Amount decimal separator '.', no group separator, two decimal digits 9.00, 2314.50, -12.99 SmallAmount Unit.SmallAmount decimal separator '.', no group separator, fouredecimal digits .0011, 2314.5000, -12.1234 Rate Vat.Rate decimal separator '.'; one decimal digits;  value less or equal 100.0 20.0, 19.0, 10.0 Currency Invoice.Currency ISO-4217 EUR Name Contact.Name UTF-8 String Blumatix GmbH Duration DueDate.Duration days, int Email Email in contact @ .__ ITU E.123 ZipCode ZipCode in address Normalized??? Phone Phone in contact Normalized??? ITU E.123? Country Country in address ISO 3166-1 Alpha 2 URL e.g. www.example.top-level-domain ITU E.123 Period DeliveryPeriod Group that consists of start and end date Iban IBAN standardized VatId Company value-added tax id

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\Generic-Detail-Naming-Convention.md - Chunk 2
in address ISO 3166-1 Alpha 2 URL e.g. www.example.top-level-domain ITU E.123 Period DeliveryPeriod Group that consists of start and end date Iban IBAN standardized VatId Company value-added tax id standardized String ArticleDesciption.String Continuous Text (Fließtext) Content Byte Content e.g. images, etc. Flag IntraCompany 0 (false) or 1 (true)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\Invoice-Schema.md - Chunk 0
Invoice

DocumentType: Invoice

Invoice Schema 1.2.2

Invoice.Type Currency Invoice.Id Invoice.Date GrandTotal.Amount Vat.Item - Vat.Rate - Net.Amount - Vat.Amount

VatExemption.Type

Due.Item - Due.Date - Due.Duration

Discount.Item - Discount.Amount - Discount.Rate

Payment.Discount.Item - Due.Item - Discount.Item

DeliveryDate.Item - Delivery.Date - DeliveryPeriodStart.Date - DeliveryPeriodEnd.Date

DeliveryNote.Id CostCenter.Id Customer.Id ReceiverOrder.Id ReceiverOrder.Date SenderOrder.Id SenderOrder.Date CompanyRegistration.Id

BankAccount.Item - Bank.Iban - Bank.Bic - Bank.Id - Account.Id

VatId Sender.VatId Receiver.VatId TaxId Sender.TaxId Receiver.TaxId Sender.Country Receiver.Country Sender.Id Receiver.Id IntraCompany.Flag

Contact.Item - Contact.Name - Attention.Name - Contact.Street - Contact.ZipCode - Contact.City - Contact.Region - Contact.Country - Contact.Website - Contact.Email - Contact.Phone

Sender.Contact.Item Receiver.Contact.Item

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\Invoice-Schema.md - Chunk 1
Sender.Contact.Item Receiver.Contact.Item

Line.Item - Position.Id - Article.Id - ArticleDescription.String - Quantity.Decimal - Unit.SmallAmount - Total.Amount - Order.Id - DeliveryNote.Id - Unit.Type - Vat.Rate - DeliveryDate.Item - Discount.Item - Article.Type

QrCode.Item CH.Swiss.QrCode.Item - Version - Amount - Currency - Account - ReferenceType - Reference - UnstructuredMessage - Creditor - Creditor.AddressLine1 - Creditor.AddressLine2 - Creditor.CountryCode - Creditor.HouseNo - Creditor.PostalCode - Creditor.Street - Creditor.Town - Debitor - Debtor.AddressLine1 - Debtor.AddressLine2 - Debtor.CountryCode - Debtor.HouseNo - Debtor.PostalCode - Debtor.Street - Debtor.Town

NO.K.Id CH.IsrReference CH.IsrSubscriber

Transport.Hawb.Id Transport.Tour.Id

Dachser.PurchaseOrder.Id PaymentReference.Id

Invoice Schema 1.2.1

Invoice.Type Currency Invoice.Id Invoice.Date GrandTotal.Amount Vat.Item - Vat.Rate - Net.Amount - Vat.Amount VatExemption.Type

Due.Item - Due.Date - Due.Duration

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\Invoice-Schema.md - Chunk 2
Invoice Schema 1.2.1

Invoice.Type Currency Invoice.Id Invoice.Date GrandTotal.Amount Vat.Item - Vat.Rate - Net.Amount - Vat.Amount VatExemption.Type

Due.Item - Due.Date - Due.Duration

Discount.Item - Discount.Amount - Discount.Rate

Payment.Discount.Item - Due.Item - Discount.Item

DeliveryDate.Item - Delivery.Date - DeliveryPeriodStart.Date - DeliveryPeriodEnd.Date

DeliveryNote.Id CostCenter.Id Customer.Id ReceiverOrder.Id ReceiverOrder.Date SenderOrder.Id SenderOrder.Date CompanyRegistration.Id

BankAccount.Item - Bank.Iban - Bank.Bic - Bank.Id - Account.Id

VatId Sender.VatId Receiver.VatId TaxId Sender.TaxId Receiver.TaxId Sender.Country Receiver.Country Sender.Id Receiver.Id IntraCompany.Flag

Contact.Item - Contact.Name - Attention.Name - Contact.Street - Contact.ZipCode - Contact.City - Contact.Region - Contact.Country - Contact.Website - Contact.Email - Contact.Phone

Sender.Contact.Item Receiver.Contact.Item

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\Invoice-Schema.md - Chunk 3
Sender.Contact.Item Receiver.Contact.Item

Line.Item - Position.Id - Article.Id - ArticleDescription.String - Quantity.Decimal - Unit.SmallAmount - Total.Amount - Order.Id - DeliveryNote.Id - Unit.Type - Vat.Rate - DeliveryDate.Item - Discount.Item - Article.Type

QrCode.Item CH.Swiss.QrCode.Item - Version - Amount - Currency - Account - ReferenceType - Reference - UnstructuredMessage - Creditor - Creditor.AddressLine1 - Creditor.AddressLine2 - Creditor.CountryCode - Creditor.HouseNo - Creditor.PostalCode - Creditor.Street - Creditor.Town - Debitor - Debtor.AddressLine1 - Debtor.AddressLine2 - Debtor.CountryCode - Debtor.HouseNo - Debtor.PostalCode - Debtor.Street - Debtor.Town

NO.K.Id CH.IsrReference CH.IsrSubscriber

Transport.Hawb.Id Transport.Tour.Id

Dachser.PurchaseOrder.Id

Invoice Schema 1.2.0

Invoice.Type Invoice.Currency Invoice.Id Invoice.Date GrandTotal.Amount Vat.Item - Vat.Rate - Net.Amount - Vat.Amount VatExemption.Type

Due.Item - Due.Date - Due.Duration

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\Invoice-Schema.md - Chunk 4
Invoice Schema 1.2.0

Invoice.Type Invoice.Currency Invoice.Id Invoice.Date GrandTotal.Amount Vat.Item - Vat.Rate - Net.Amount - Vat.Amount VatExemption.Type

Due.Item - Due.Date - Due.Duration

Discount.Item - Discount.Amount - Discount.Rate

Payment.Discount.Item - Due.Item - Discount.Item

DeliveryDate.Item - Delivery.Date - DeliveryPeriodStart.Date - DeliveryPeriodEnd.Date

DeliveryNote.Id CostCenter.Id Customer.Id ReceiverOrder.Id ReceiverOrder.Date SenderOrder.Id SenderOrder.Date CompanyRegistration.Id

BankAccount.Item - Bank.Iban - Bank.Bic - Bank.Id - Account.Id

VatId Sender.VatId Receiver.VatId TaxId Sender.TaxId Receiver.TaxId Sender.Country Receiver.Country Sender.Id Receiver.Id IntraCompany.Flag

Contact.Item - Contact.Name - Attention.Name - Contact.Street - Contact.ZipCode - Contact.City - Contact.Region - Contact.Country - Contact.Website - Contact.Email - Contact.Phone

Sender.Contact.Item Receiver.Contact.Item

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\Invoice-Schema.md - Chunk 5
Sender.Contact.Item Receiver.Contact.Item

Line.Item - Position.Id - Article.Id - ArticleDescription.String - Quantity.Decimal - Unit.SmallAmount - Total.Amount - Order.Id - DeliveryNote.Id - Unit.Type - Vat.Rate - DeliveryDate.Item - Discount.Item - Article.Type

QrCode.Item CH.Swiss.QrCode.Item - Version - Amount - Currency - Account - ReferenceType - Reference - UnstructuredMessage - Creditor - Creditor.AddressLine1 - Creditor.AddressLine2 - Creditor.CountryCode - Creditor.HouseNo - Creditor.PostalCode - Creditor.Street - Creditor.Town - Debitor - Debtor.AddressLine1 - Debtor.AddressLine2 - Debtor.CountryCode - Debtor.HouseNo - Debtor.PostalCode - Debtor.Street - Debtor.Town

NO.K.Id CH.IsrReference CH.IsrSubscriber

Transport.Hawb.Id Transport.Tour.Id

Dachser.PurchaseOrder.Id

Invoice Schema 1.1.0

Invoice.Type Invoice.Currency Invoice.Id Invoice.Date GrandTotal.Amount Vat.Item - Vat.Rate - Net.Amount - Vat.Amount VatExemption.Type

Due.Item - Due.Date - Due.Duration

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\Invoice-Schema.md - Chunk 6
Invoice Schema 1.1.0

Invoice.Type Invoice.Currency Invoice.Id Invoice.Date GrandTotal.Amount Vat.Item - Vat.Rate - Net.Amount - Vat.Amount VatExemption.Type

Due.Item - Due.Date - Due.Duration

Discount.Item - Discount.Amount - Discount.Rate

PaymentDiscount.Item - Due.Item - Discount.Item

DeliveryDate.Item - DeliveryDate - DeliveryPeriodStart.Date - DeliveryPeriodEnd.Date

DeliveryNote.Id CostCenter.Id Customer.Id ReceiverOrder.Id ReceiverOrder.Date SenderOrder.Id SenderOrder.Date CompanyRegistration.Id

BankAccount.Item - Bank.Iban - Bank.Bic - Bank.Id - Account.Id

VatId Sender.VatId Receiver.VatId TaxId Sender.TaxId Receiver.TaxId

Contact.Item - Contact.Name - ContactAttention.Name - Contact.Street - Contact.ZipCode - Contact.City - Contact.Region - Contact.Country - Contact.Website - Contact.Email - Contact.Phone

Sender.Contact.Item Receiver.Contact.Item

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\Invoice-Schema.md - Chunk 7
Sender.Contact.Item Receiver.Contact.Item

Line.Item - Position.Id - Article.Id - Article.Description.String - Quantity.Decimal - Unit.SmallAmount - Total.Amount - Order.Id - DeliveryNote.Id - Unit.Type - Vat.Rate - DeliveryDate.Item - Discount.Item - Article.Type

QrCode.Item CH.Swiss.QrCode.Item - Version - Amount - Currency - Account - ReferenceType - Reference - UnstructuredMessage - Creditor - Creditor.AddressLine1 - Creditor.AddressLine2 - Creditor.CountryCode - Creditor.HouseNo - Creditor.PostalCode - Creditor.Street - Creditor.Town - Debitor - Debtor.AddressLine1 - Debtor.AddressLine2 - Debtor.CountryCode - Debtor.HouseNo - Debtor.PostalCode - Debtor.Street - Debtor.Town

NO.K.Id CH.IsrReference CH.IsrSubscriber

Transport.Hawb.Id

DachserSender.Id DachserReceiver.Id DachserPurchaseOrder.Id DachserToDachser

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\Json-Schema-Tooling.md - Chunk 0
Online Schema Validation

Check, if schema definition is correct

Open https://www.jsonschemavalidator.net/

Select Schema: Schema Draft 2019-09 on the left

Copy current BluDoc Schema file to the right

Online Document Validation

Check, if document is valid for given schema

Open https://json-everything.net/json-schema/

Copy current BluDoc Schema file to the editor on the left

Copy BluDoc file to the editor on the right

Chose Evaluate JSON

Press Run button

Online Code Generation

Open https://app.quicktype.io/

Write BluDoc to Name and JSON Schema to Source Type in the left pane and copy latest schema to the area below - Set Namespace to Blumatix.BluDoc (not just Blumatix as in screenshot) - Set creation properties in the right pane

Update BluDoc Class

Copy Code to BluDoc class unfortunately there is some manual change necessary

fix Location just one class Location, so rename LocationLocation and delete WordLocation and LineLocation

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\Order-Confirmation-Schema.md - Chunk 0
Order Confirmation

DocumentType: OrderConfirmation

DocumentEssentials Schema 1.2.0

GitHub: orderconfirmation-documentessentials.md

DocumentEssentials Schema 1.1.0

OrderConfirmation.Id OrderConfirmation.Date ReceiverOrder.Id

DeliveryDate.Item - Delivery.Date - DeliveryPeriodStart.Date - DeliveryPeriodEnd.Date

Surcharge.Item - Surcharge.Type - Surcharge.Rate - Surcharge.Amount

Contact.Item - Contact.Name - Contact.Street - Contact.Zip - Contact.City - Contact.Region - Contact.Country - Contact.Website - Contact.Email - Contact.Phone - Contact.Fax

Sender.Contact.Item Receiver.Contact.Item Delivery.Contact.Item Invoice.Contact.Item

Discount.Item - Discount.Amount - Discount.Rate

Line.Item - Position.Id - Article.Id - Article.Description.String - Quantity.Decimal - Unit.SmallAmount - Total.Amount - Order.Id - DeliveryNote.Id - Unit.Type - Vat.Rate - DeliveryDate.Item - Discount.Item - Article.Type

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\Quotation-Schema.md - Chunk 0
Quotation

DocumentType: Quotation

DocumentEssentials Schema 1.4.1

GitHub: quotation-documentessentials.md

DocumentEssentials Schema 1.4.0

Quotation.Id Quotation.Date ReceiverOrder.Id GrandTotal.Amount

VatId Sender.VatId Receiver.VatId

Vat.Item - Vat.Rate - Net.Amount - Vat.Amount

BankAccount.Item - Bank.Iban - Bank.Bic - Bank.Id - Account.Id Sender.Contact.Item Receiver.Contact.Item

Contact.Item - Contact.Name - Attention.Name - Contact.Street - Contact.ZipCode - Contact.City - Contact.Region - Contact.Country - Contact.Website - Contact.Email - Contact.Phone

Sender.Contact.Item Receiver.Contact.Item Delivery.Contact.Item Invoice.Contact.Item

DeliveryDate.Item - Delivery.Date - DeliveryPeriodStart.Date - DeliveryPeriodEnd.Date

Discount.Item - Discount.Amount - Discount.Rate

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\Quotation-Schema.md - Chunk 1
DeliveryDate.Item - Delivery.Date - DeliveryPeriodStart.Date - DeliveryPeriodEnd.Date

Discount.Item - Discount.Amount - Discount.Rate

Line.Item - Position.Id - Article.Id - ArticleDescription.String - Quantity.Decimal - Unit.SmallAmount - Total.Amount - Order.Id - DeliveryNote.Id - Unit.Type - Vat.Rate - DeliveryDate.Item - Discount.Item - Article.Type

Automotive.Plate.Id Automotive.Vin.Id Automative.Mileage Automotive.FirstRegistration.Date

DocumentEssentials Schema 1.2.0

Quotation.Id Quotation.Date ReceiverOrder.Id GrandTotal.Amount

VatId Sender.VatId Receiver.VatId

Vat.Item - Vat.Rate - Net.Amount - Vat.Amount

BankAccount.Item - Bank.Iban - Bank.Bic - Bank.Id - Account.Id Sender.Contact.Item Receiver.Contact.Item

Contact.Item - Contact.Name - Attention.Name - Contact.Street - Contact.ZipCode - Contact.City - Contact.Region - Contact.Country - Contact.Website - Contact.Email - Contact.Phone

Sender.Contact.Item Receiver.Contact.Item

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\Quotation-Schema.md - Chunk 2
Sender.Contact.Item Receiver.Contact.Item

DeliveryDate.Item - Delivery.Date - DeliveryPeriodStart.Date - DeliveryPeriodEnd.Date

Discount.Item - Discount.Amount - Discount.Rate

Line.Item - Position.Id - Article.Id - ArticleDescription.String - Quantity.Decimal - Unit.SmallAmount - Total.Amount - Order.Id - DeliveryNote.Id - Unit.Type - Vat.Rate - DeliveryDate.Item - Discount.Item - Article.Type

Automotive.Plate.Id Automotive.Vin.Id Automative.Mileage Automotive.FirstRegistration.Date

DocumentEssentials Schema 1.1.0

Quotation.Id Quotation.Date ReceiverOrder.Id GrandTotal.Amount

VatId Sender.VatId Receiver.VatId

Vat.Item - Vat.Rate - Net.Amount - Vat.Amount

BankAccount.Item - Bank.Iban - Bank.Bic - Bank.Id - Account.Id

Contact.Item - Contact.Name - Attention.Name - Contact.Street - Contact.ZipCode - Contact.City - Contact.Region - Contact.Country - Contact.Website - Contact.Email - Contact.Phone - Contact.Fax

Sender.Contact.Item Receiver.Contact.Item

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\Quotation-Schema.md - Chunk 3
Sender.Contact.Item Receiver.Contact.Item

DeliveryDate.Item - DeliveryDate - DeliveryPeriodStart.Date - DeliveryPeriodEnd.Date

Discount.Item - Discount.Amount - Discount.Rate

Line.Item - Position.Id - Article.Id - Article.Description.String - Quantity.Decimal - Unit.SmallAmount - Total.Amount - Order.Id - DeliveryNote.Id - Unit.Type - Vat.Rate - DeliveryDate.Item - Discount.Item - Article.Type

Automotive.Plate.Id Automotive.Vin.Id Automative.Mileage Automotive.FirstRegistration.Date

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-Schema-Release-Notes\Schema-Release-Notes-Template.md - Chunk 0
BluDoc JSON Schema Release Notes

Version 1.2.0 - Release Date: 2023-10-02

Overview

This release introduces enhancements, bug fixes, and improvements to the JSON schema.

Key Changes and Additions

DocumentEssential/Confidence type: integer changed to number to be able to handle double values.

Page/Dpi type: string changed to integer and formatremoved to handle Dpi values as integer.

Page/Page property: Page changed to Id to be more clear and consistent in naming.

Policy to make a difference between "element is missing" and "element is null" has been skipped. This makes the schema much cleaner and code generation is more easy.

Improvements

DocumentEssential/Confidence New keyword minimum: 0 and `maximum: 1 added to limit the range of values.

Names of Document Essentials

Added: - Contact Attention.Name has been added to the contact properties to provide information of a unit or person

Removed: - Contact Contact.Fax has been removed because there is no longer need (hopefully)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-Schema-Release-Notes\Schema-Release-Notes-Template.md - Chunk 1
Removed: - Contact Contact.Fax has been removed because there is no longer need (hopefully)

Changed: - Contact Zip has been changed to ZipCode - PaymentDiscount PaymentDiscount.Item has been changed to Payment.Discount.Item because Discount is a Type itself and therefore separated by "." - LineItem Article.Description.String has been changed to ArticleDescription.String because the "." is just wrong.

New keyword: new_keyword added to provide [explanation of new_keyword].

Deprecated keyword: deprecated_keyword has been marked as deprecated and will be removed in [future_version].

Improved validation rule for existing_keyword to [describe improvement].

Impact on Users

Users using the deprecated keyword deprecated_keyword are encouraged to migrate to alternative_keyword for continued compatibility.

Schemas using the existing_keyword might need minor adjustments to adhere to the updated validation rule.

Bug Fixes and Improvements

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-Schema-Release-Notes\Schema-Release-Notes-Template.md - Chunk 2
Schemas using the existing_keyword might need minor adjustments to adhere to the updated validation rule.

Bug Fixes and Improvements

Fixed [issue_number]: [Brief description of the fix].

Improved performance in [specific scenario] by [explanation of improvement].

Migration Guide

If you're upgrading from the previous version, follow these steps to migrate your existing schemas: 1. Update occurrences of deprecated_keyword to use alternative_keyword. 2. Review and adjust any schemas that utilize existing_keyword to meet the updated validation rule.

Compatibility and Upgrading

JSON schemas designed for the previous version [version_number] remain compatible with this version.

Please review the migration guide for details on any necessary adjustments.

Documentation Updates

Refer to the updated [documentation link] for detailed information on the new keywords, improved validation rules, and migration instructions.

Getting Help

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\BluDoc\BluDoc-Schema-Release-Notes\Schema-Release-Notes-Template.md - Chunk 3
Documentation Updates

Refer to the updated [documentation link] for detailed information on the new keywords, improved validation rules, and migration instructions.

Getting Help

If you encounter any issues or have questions regarding this release, feel free to ask on our community forum or reach out to our support team at [support_email].

Acknowledgments

We'd like to extend our gratitude to the contributors and community members who provided valuable feedback and insights for this release.

Thank you for using our JSON schema and helping us improve it!

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-labeling-process\Label-creation.md - Chunk 0
This wiki page discusses the initial label creation process as discussed in the BLU DELTA API refinement on June 1st 2023.

[[TOC]]

Process

For suited details such as HAWB: Create a plugin which uses e.g. regex to create predictions

Import your documents which need to be labeled via the learn API

During the import the predictions will be created and stored as label

Create a benchmark (and label manually) to assess the quality of the created labels

If the benchmark results are ok continue with training a typhon head

If the bechnmark results are not ok manually label more documents and provide training data for a typhon head

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-labeling-process\Label-Quality-Assurance.md - Chunk 0
14064

[[TOC]]

In the future we want to implement a permanent quality assurance process for Label Quality instead of the current auto release process. This will result in a continous quality value (0 - 1) at every time instead of a binary classification (released - non released).

Source Quality

Each label has its own quality that is derived from the source of the label, e.g. Labeler A oder Model Version 1.3 or Structured Data from customer X. The source quality is part of each label and it is never changed. The quality of a source might change. The next Model version improves or the Labeler gets more experienced. So new labels from "improved" sources get a higher quality, but old labels don't change.

Label Quality

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-labeling-process\Label-Quality-Assurance.md - Chunk 1
Label Quality

Whenever there are more than one label for a single data point, there are two options: the labels have the same value and promote that value, or the labels have different values. In the first case (same values) the quality of the labels will be higher than the Source Quality of each single label. In the second case (different values) the quality of the labels will be lower than the Source Quality of each single label. So Label Quality can be calculated from Source Quality considering all labels.

In the following examples "same" and "different" labels are reduced to consider "Value" for ease. In reality, position might be an additional criteria.

Hint: It is important to notice that the final Label Quality calculation is not defined yet. So the values are just relative, higher or lower than other values.

Example 1:

Step 1: first label added

Label Id Value Source Source Quality Label Quality Best Label 1 12345 Labeler A 0.8 0.8 x

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-labeling-process\Label-Quality-Assurance.md - Chunk 2
Example 1:

Step 1: first label added

Label Id Value Source Source Quality Label Quality Best Label 1 12345 Labeler A 0.8 0.8 x

Source Quality is defined by Source "Labeler A".

Label Quality is calculated: same as Source Quality.

Step 2: second label with same value is added

Label Id Value Source Source Quality Label Quality Best Label 1 12345 Labeler A 0.8 0.94 2 12345 Labeler B 0.9 0.94 x

A new label has been added and the calculation of the Label Quality is executed again: - Since both labels have the same value, the Label Quality is higher than the highest single Source Quality. - The flag of the best label has moved to the label with the higher Source Quality. (may be this is not necessary, because value is the same

Step 3: third label with same value is added

Label Id Value Source Source Quality Label Quality Best Label 1 12345 Labeler A 0.8 0.95 2 12345 Labeler B 0.9 0.95 x 3 12345 Model V3 0.7 0.95

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-labeling-process\Label-Quality-Assurance.md - Chunk 3
Step 3: third label with same value is added

Label Id Value Source Source Quality Label Quality Best Label 1 12345 Labeler A 0.8 0.95 2 12345 Labeler B 0.9 0.95 x 3 12345 Model V3 0.7 0.95

A new label has been added and the calculation of the Label Quality is executed again: - All labels have the same value and although the new labels has the lowest Source Quality, the Label Quality is increased again. The new label is another confirmation of correctness.

Step 4: label with different value is added

Label Id Value Source Source Quality Label Quality Best Label 1 12345 Labeler A 0.8 0.8 2 12345 Labeler B 0.9 0.8 x 3 12345 Model V3 0.7 0.8 4 54321 Model V5 0.8 0.2

A new label has been added and the calculation of the Label Quality is executed again: - a different label value changes a lot: the best label is not changed, but Label Quality drops significantly. - the "wrong" value gets the Label Quality 1 - Label Quality of correct values

Example 2:

Step 1: first label added

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-labeling-process\Label-Quality-Assurance.md - Chunk 4
Example 2:

Step 1: first label added

Label Id Value Source Source Quality Label Quality Best Label 1 12345 Labeler A 0.8 0.8 x

Source Quality is defined by Source "Labeler A".

Label Quality is calculated: same as Source Quality.

Step 2: label with different value is added

Label Id Value Source Source Quality Label Quality Best Label 1 12345 Labeler A 0.8 0.4 2 54321 Labeler B 0.9 0.6 x

A new label has been added and the calculation of the Label Quality is executed again: - a situation with few confidence - Label quality is low - best label flag moves to highest Label quality

Step 3: label with different value is added

Label Id Value Source Source Quality Label Quality Best Label 1 12345 Labeler A 0.8 0.2 2 54321 Labeler B 0.9 0.3 3 22222 Model V2 0.95 0.5 x

A new label has been added and the calculation of the Label Quality is executed again: - a situation with few confidence - Label quality is low - best label flag moves to highest Label quality

TBD

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-labeling-process\Label-Quality-Assurance.md - Chunk 5
A new label has been added and the calculation of the Label Quality is executed again: - a situation with few confidence - Label quality is low - best label flag moves to highest Label quality

TBD

~~Naming: Label Quality = Source Quality Datapoint Quality = Label Quality Flag Best = Best Label~~

How do we derive the Source Quality? Why cant the Source Quality change? ~~How do we derive the Datapoint Quality?~~ Why do we need both? For both values I can imagine that there are various features to calculate the quality: experience (value: manual labels > structured data > model predictions), intersection, shapley value?, etc.44

Quality Assurance

Various Aspects to be checked

Benchmark Compare contains label checks

[ ] no mix of N/A and other labels, both released

[ ] exception of VatRate parse on released

Compare with any model

BoundingBox

[ ] most of available labels must have bounding box (except Invoice.Currency, DocumentType, etc.)

Validation of values

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-labeling-process\Label-Quality-Assurance.md - Chunk 6
Compare with any model

BoundingBox

[ ] most of available labels must have bounding box (except Invoice.Currency, DocumentType, etc.)

Validation of values

[ ] VatId should not end with '.' or ','

[x] Amount no currency

[ ] 104 LineItemCount must be integer

Validation of groups

[x] calculate vatgroup

[x] calculate single line item

[x] calculate amounts of line item table

[ ] compare number of Line Items and Count

[ ] multiple pages - multiple line item tables

[ ] Position.Id follow given format

[ ] line Items details >= 13

[x] vat group details = 3

[ ] just one sender and one receiver (fuzzy equal)

Validation automated

In BluDoc we have implemented a concept of Validation, where all kinds of quality issues can be checked based on BluDoc documents (see)

In the Validation component (part of DataCollection) we can validate labels by - read all labels for a document from BciDb - convert labels to BluDoc - execute validation(s) - create a report

Validation results

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-labeling-process\Label-Quality-Assurance.md - Chunk 7
Validation results

Vat.Item for ALD (607 documents) Jän. 2024

Validation Description Error status VatCalculation calculation wrong 2,3% fixed VatCalculation pass error 2,4% not fixed VatCalculation pass error % 0.6% not fixed VatStructure 0.4% fixed VatCalcultaion VatRate N/A 4.4%

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Benchmark-Creation.md - Chunk 0
[[TOC]]

Value Creation: Project or Poc

Customer sends data: Sharepoint or Email

Data Preparation and Upload Learn API

Cluster Analysis

Allocate Label Task to Human Labeller

Create Benchmark

Process/Task

Go to the Dashboard

Add

Enter Name and import ids list file

Save

Insert line into BlumatixCaptureAutomation.dbo.BenchmarkDefinitionName and add the desired DetailTypes Name has to be the same as in the dashboard

1 document / cluster

set weights?

Control Label Progress

Purpose/Objective

The "Control Label Progress" component aims to assess the completeness of a benchmark set to be able to measure remaining effort and significance of current benchmark results.

Input

Benchmark Task (stored in BlumatixCaptureAutomation database in dbo.BenchmarkTask table) it includes information about the benchmark definition (all documents) and document details

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Benchmark-Creation.md - Chunk 1
Input

Benchmark Task (stored in BlumatixCaptureAutomation database in dbo.BenchmarkTask table) it includes information about the benchmark definition (all documents) and document details

Benchmark Execution it includes the benchmark runs (one for each document detail). Each benchmark run contains the labels and predictions for each document and the comparision result

Process/Task

release anything possible check if there is anything left for manual release. If so, check if autorelease would help, because since last autorelease some labels have been created. If so, start Phönix Action "Autorelease" with a list of Ids for this benchmark: .\phoenix.exe invoice autorelease -i "C:\Temp\ALD_Random_500.txt" Then manual release anything left

check benchmark for document details with missing results Goto benchmark runs view and check the "All" column for missing results (marked red, e.g. 99/100)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Benchmark-Creation.md - Chunk 2
check benchmark for document details with missing results Goto benchmark runs view and check the "All" column for missing results (marked red, e.g. 99/100)

get ids missing documents for each document detail Open Benchmark Run Detail View by clicking the symbol in the Details column for each run with missing results. In this view on the right you see an indicator for missing results: Click on it and you will download a list with the Ids of the missing results.

check possible reasons why missing Open Label Edit for each Id and check: --If there are two labels it should have been manual released. But you can release them here as well (be aware you have to set the correct state (Released, Verified, Correct) for all labels involved. -- If there is just one label you can release just this one if you know that it is correct or add the correct one and set the correct state -- If you can't open the manual release no label has been created so far. You have to create labels.

QA Benchmark

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Benchmark-Creation.md - Chunk 3
QA Benchmark

Purpose/Objective

The "QA Benchmark" component aims to assess the accuracy of a benchmark set. It ensures that the benchmark reflects the intended document details and identifies obvious label errors and fix them.

Input

Benchmark Task (stored in BlumatixCaptureAutomation database in dbo.BenchmarkTask table) it includes information about the benchmark definition (all documents) and document details

Benchmark Execution it includes the benchmark runs (one for each document detail). Each benchmark run contains the labels and predictions for each document and the comparision result

Process/Task

check that all document details are part of the benchmark set possible reason: missing labels

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Benchmark-Creation.md - Chunk 4
Process/Task

check that all document details are part of the benchmark set possible reason: missing labels

check empty labels when there is a prediction but an empty label, we check if the prediction is correct and we have to fix the label. Be aware: there a benchmarks where we don't use any threshold ("best match"), so there are also predictions with low score -> you don't have to check them.

multible predictions - check missing labels for document details where more than one label is possible we check if we have more predictions than labels and if predictions are correct we add them as labels

negative amounts sometimes the labels miss the '-' character for negative amounts

check typos in labels sometimes prediction value and label value are very similar. We check if the label is wrong and fix it

rerun benchmark set (may be there ar many iterations)

Tools/Resources

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Benchmark-Creation.md - Chunk 5
check typos in labels sometimes prediction value and label value are very similar. We check if the label is wrong and fix it

rerun benchmark set (may be there ar many iterations)

Tools/Resources

BluDelta Dashboard: Benchmark Execution view, Runs for Benchmark Execution view, Benchmark Run Detail view BlumatixCaptureAutomation database

Output

The output of the "Analyze Benchmark" component is a refined and accurate benchmark execution that includes complete and aligned labels and predictions. This output is suitable for subsequent analysis, presentation, or further use.

The output is identified with the name of the benchmark execution like B_Dachser_Wave3_570_20230811 09.32.14

Dependencies

Interactions

Quality Checks/Validation

The validation process involves cross-referencing labels and predictions to ensure that they align accurately. Quality checks focus on identifying missing labels, addressing common labeling errors, and validating the overall benchmark outcome.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Benchmark-Creation.md - Chunk 6
Roles/Responsibilities

DataMangement is responsible to finish this component before publishing benchmark results.

Exceptions/Errors

This process will not find any possible label error. If labels and predictions for a document are both wrong, we don't find them.

Optimizations/Improvements

Probably there should also be a minimal number of labels to provide a meaningful benchmark result, e.g. 10% for each document detail

Often we have high recognition rates because of many empty labels. We should report that information as well, e.g. confusion matrix

Sometimes the normalization of the label fails and prediction is correct but reported as failure. We should count them and report it

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Data-Request.md - Chunk 0
Labeling Kick-Off

Introduction

The primary objective of our Labeling Kick-Off Meeting is to enhance the quality of labels generated by our labelers. Especially when dealing with new document types, new countries, or new document details we aim to provide all the necessary information upfront before the start of the labeling process.

Who should attend

All members of the DataManagement team attend. We invite all involved parties (product team, Rechnungserkennung-Team). The discussion about new situations and the way to label them will help all of us. Therefore, we encourage participation.

Prerequisite

Datamanagement team has provided - Benchmark Definition (documents are imported and set of documents and details defined) - Basic language/region specific information for new country - optional: issues and/or insights that we have encountered so far

Agenda of the Meeting

Explain Topic (e.g. which country)

Present Benchmark

Present current information

Label three samples together

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Data-Request.md - Chunk 1
Agenda of the Meeting

Explain Topic (e.g. which country)

Present Benchmark

Present current information

Label three samples together

Discuss resulting label policies

Make decicions

Update Labeler Wiki

Datamanagement team updates our Labeler Wiki to ensure labelers can consistently execute the new tasks in line with recent decisions. Updated Wiki is visible for everyone.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Label-Quality-Assurance.md - Chunk 0
This page describes the process of Label Quality Assurance.

[[TOC]]

Label Quality Assurance

Purpose/Objective

The Label Quality Assurance component aims to guarantee a defined level of label quality for each detail.

Input

Labels stored in BCIDB in Table Label.

Release mechanism.

Process/Task

Label KickOff:

Data Management does a Label-KickOff (including Members of Data Mgt., Product-Team, Rechnungserkennung-Team) for new DocumentTypes, Countries, Details. Add new information to labeling.bludelta.dev.

Align Label Policy:

For each detail define the label policy in the labeling.bludelta.dev wiki and update if necessary. Communicate new policies.

Four-Eye Labeling:

label documents with two independent sources (four-eye principle - current exception: LineItems).

Release Anything Possible:

Check if there is anything left for manual release.

If so, check if autorelease would help, because since last autorelease some labels have been created.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Label-Quality-Assurance.md - Chunk 1
Release Anything Possible:

Check if there is anything left for manual release.

If so, check if autorelease would help, because since last autorelease some labels have been created.

If so, start Phönix Action "Autorelease" with a list of Ids for this benchmark: .\phoenix.exe invoice autorelease -i "C:\Temp\ALD_Random_500.txt"

Then manual release anything left - ATTENTION:

A labeler is not permitted to release their own labels. Please skip such documents and report (e.g., in our Data Mgt. daily) that there are documents remaining for manual release.

Complex details, such as LineItems and VatGroups must undergo a pairwise release, adhering to the 4-eye principle.

Tools/Resources

LabelTool, RIPEye - Validation Tool, Label Manual Wiki, Label Edit - Description, Manual Release, Line Item Release - Description, Phoenix - release, create, store labels, PowerBI - Provides an indicator for the label quality by source.

Output

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Label-Quality-Assurance.md - Chunk 2
Output

Provides labels which have been created and approved by at least two different informed sources.

Dependencies

Identify any dependencies that this component might have on other components or factors within the workflow. Are there certain conditions that need to be met before this component can start?

Interactions

If relevant, explain how this component interacts with other components in the process. Does it communicate with other parts of the workflow, and if so, how?

Quality Checks/Validation

Discuss any quality control or validation measures that are applied to the output of this component. How is the accuracy or correctness of the output ensured?

Roles/Responsibilities

Data Mangement is responsible for this component to guarantee label quality.

Exceptions/Errors

Address any potential exceptions, errors, or issues that might arise during the execution of this component. How are these handled?

Optimizations/Improvements

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Label-Quality-Assurance.md - Chunk 3
Exceptions/Errors

Address any potential exceptions, errors, or issues that might arise during the execution of this component. How are these handled?

Optimizations/Improvements

Optionally, mention any suggestions for optimizing or improving this component's efficiency, effectiveness, or overall performance.

Component Name 2

# Component Name 3

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Label-Release.md - Chunk 0
Definition

"Releasing" a label indicates marking it as correct and ready for use in benchmarking or training, serving as an indicator of label quality. This process is represented by a binary flag.

Automation

An automated release task has been implemented as a Phoenix action, which can be run manually or scheduled. This task executes nightly on the Ryzen7Virt. Initially, a "four eyes" strategy was used for automated label release: when two or more identical labels from different sources were available, one label was automatically marked as released, while the others were marked as correct. Over time, additional strategies have been incorporated to enhance this automated release process. Further details are available here: Auto Release Documentation

Label Release in the Database

There are two distinct mechanisms for handling the release status of Label and LabelGroup entities.

LabelGroup

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Label-Release.md - Chunk 1
Label Release in the Database

There are two distinct mechanisms for handling the release status of Label and LabelGroup entities.

LabelGroup

A LabelGroup represents a hierarchical structure that may include multiple levels, with each level potentially containing other LabelGroups or individual Labels. The release status for a LabelGroup is set at the top level, indicating that the entire hierarchy is released. This release indicator is a references to a specific ReleaseItem.

Label

For individual Labels that are part of a hierarchy, the release mechanism of the parent LabelGroup applies. However, if a Label is not part of any hierarchy (it does not reference a LabelGroup), it contains its own Released column to indicate its release status.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Label-Release.md - Chunk 2
Note: For the initial LabelGroup implementation (VatGroup), this concept was not fully applied. As a result, the VatGroup labels do not reference a ReleaseItem; instead, all three Labels within the VatGroup are directly marked as released in their own Released columns. This inconsistency requires special handling across multiple areas.

Release Indicator

Abb.: Table Diagram

Release Table

The Release table records information about one release task that may include many documents.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Label-Release.md - Chunk 3
Release Indicator

Abb.: Table Diagram

Release Table

The Release table records information about one release task that may include many documents.

Column Data Type Description Id bigint Primary key, unique identifier for each release record, auto-incremented with an identity constraint. Type int Indicates the type of release: 0 ... Unknown, 1 ... Automatic, 2 ... Manual DurationSeconds int Duration in seconds that the release task Created datetime Timestamp indicating when the release record was created. Modified datetime Timestamp indicating the last modification of the release record. Version int Used for version control CreatedBy_Id bigint Foreign key referencing User.Id , specifying the user who created the release. Filter nvarchar(max) Optional field storing filter criteria associated with the release, e.g. provider or list of Ids

ReleaseItem Table

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Label-Release.md - Chunk 4
ReleaseItem Table

The ReleaseItem table stores individual items related to releases, including their release status. It also includes Label Type (SpecificType) and Label Id or Label Group Id (Item_Id) and so it is prepared for detailed reports.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Label-Release.md - Chunk 5
Column Data Type Description Id bigint Primary key, unique identifier for each release item, auto-incremented with an identity constraint. Released bit Indicates if the item is marked as released ( 1 for true, 0 for false). Verified bit Indicates if the item has been verified ( 1 for true, 0 for false). BaseType int Represents the base type: 0 ... Label, 1 ... LabelGroup, 2 ... LabelTable SpecificType int Represents the LabelType oder LabelGroupType (depending on BaseType), e.g. 8 is Invoice.Id for BaseType 0, but Contact for BaseType 1 Item_Id bigint Foreign key reference to the label released Created datetime Timestamp indicating when the release item was created. Modified datetime Timestamp for the last modification to the release item. Version int Used for version control CreatedBy_Id bigint Foreign key referencing User.Id , specifying the user who created this release item. Release_Id bigint Foreign key referencing Release.Id , linking this item to its associated release task.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Label-Release.md - Chunk 6
bigint Foreign key referencing User.Id , specifying the user who created this release item. Release_Id bigint Foreign key referencing Release.Id , linking this item to its associated release task. Invoice_Id bigint Foreign key referencing Invoice.Id , linking this item to a specific invoice

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Label-Release.md - Chunk 7
Stored Procedure ReleaseLabelGroup

Releases all LabelGroups of the given LabelGroupType for all given documents.

Beware: Each label group is released independently, regardless of other, potentially identical label groups.

Parameters: - @InvoiceIds NVARCHAR(MAX), -- Comma-separated list of Invoice IDs - @LabelGroupType INT, -- The LabelGroup Type to release - @CreatedById BIGINT, -- User who is creating the release - @ReleaseType INT -- Release type: 0 ... Unknown, 1 ... Automatic, 2 ... Manual

Algorithm: - Create a single Release entry - Create ReleaseItem entries if the LabelGroup has no ReleaseItem yet, create one and set released if the LabelGroupalready has a ReleaseItem, check if is set to Released. If so, nothing else to do; if not Released, create a new ReleaseItem - Update the reference to ReleaseItem in each LabelGroup that has a new ReleaseItem - Calculate duration and update Release table.

Vision

Continous Label Quality

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Label-Release.md - Chunk 8
Vision

Continous Label Quality

A continuous quality score (ranging from 0 to 1) for labels could replace the current binary release system. This approach would offer greater flexibility for benchmarking and training, allowing initial results to be gathered even from lower-quality data. An in-depth discussion on this approach can be found here: Label Quality

Automatic Release based on label source quality only

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Label-Release.md - Chunk 9
Automatic Release based on label source quality only

Label source quality refers to the quality associated with the origin or creator of a label—whether a human labeler, model, or ground truth provided by a customer. This label source quality might change over time. Currently, most automatic release strategies rely, to some extent, on implicit assumptions about the quality of the label source (e.g., 'ground truth provided by a customer after correction is assumed to be high quality'). Moving forward, a single, unified strategy should be applied: label quality (whether binary or continuous) should be determined solely based on the quality of the label source.

Enable Automatic Release for LabelGroups

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Label-Release.md - Chunk 10
Enable Automatic Release for LabelGroups

Currently some LabelGroup Types are blacklisted. This is due to label hierarchy to be handled, ReleaseItems and missing AreEqual for Label Groups. Some main ideas to implement it in a generic way: - Remove Table Handling (not used any longer, makes it more complex) - Remove blacklist (it is difficult to maintain, it is based on Label level, other criteria are needed) - To handle LabelGroups you have to identify the root elements (no LabelGroup is referenced) - How to handle correct? There is no such status in ReleaseItem. May be because it is not clear what "correct" means , is it really identical in all hierarchy levels - How to exclude all Labels belonging to a Label Group from Automatic Release (already existing programm)?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Template-for-Process-Component-descriptions.md - Chunk 0
By covering the topics of this template you'll be able to provide a concise yet comprehensive explanation of each component in your process workflow. This approach ensures that the reader gets a clear understanding of what each component does.

Some of the topics are a must in every component description.

[[TOC]]

Component Name

Purpose/Objective

Clearly state the purpose or objective of the component within the overall process. What is this component supposed to achieve or contribute to the workflow? MUST

Input

Describe the inputs required for this component to function. What information, materials, or data does this component rely on to perform its task? MUST

Process/Task

Detail the specific actions or steps involved in this component. Explain what happens during the execution of this component within the workflow. MUST

Tools/Resources

If applicable, mention any tools, software, equipment, or resources that are utilized in this component to complete the task.

Output

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Template-for-Process-Component-descriptions.md - Chunk 1
Tools/Resources

If applicable, mention any tools, software, equipment, or resources that are utilized in this component to complete the task.

Output

Highlight the expected or desired outcome of this component. What does this component produce or provide as a result of its execution? MUST

Dependencies

Identify any dependencies that this component might have on other components or factors within the workflow. Are there certain conditions that need to be met before this component can start?

Interactions

If relevant, explain how this component interacts with other components in the process. Does it communicate with other parts of the workflow, and if so, how?

Quality Checks/Validation

Discuss any quality control or validation measures that are applied to the output of this component. How is the accuracy or correctness of the output ensured?

Roles/Responsibilities

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Processes\Template-for-Process-Component-descriptions.md - Chunk 2
Discuss any quality control or validation measures that are applied to the output of this component. How is the accuracy or correctness of the output ensured?

Roles/Responsibilities

Clarify who is responsible for executing this component. Are there specific roles or individuals assigned to this task? MUST

Exceptions/Errors

Address any potential exceptions, errors, or issues that might arise during the execution of this component. How are these handled?

Optimizations/Improvements

Optionally, mention any suggestions for optimizing or improving this component's efficiency, effectiveness, or overall performance.

Component Name 2

# Component Name 3

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\Data-Labeling-Tool_-Label-Studio.md - Chunk 0
Label Studio

Ergebnisse einer begrenzten Recherche (Juli 2022)

https://labelstud.io/

Marketing

OCR Put an Image and Text right next to each other (Multi Domain applications)

Document Classification Classify document into one or multiple categories. Use taxonomies of up to 10000 classes

Named Entity Extract and put relevant bits of information into pre-defined categories

Image Classification Put images into categories

Object Detection Detect objects on image, bboxes, polygons, circular, and keypoints supported

Semantic Segmentation Partition image into multiple segments. Use ML models to pre-label and optimize the process

Open Source - Enterprise

Es gibt die Open Source Community Version und eine Enterprise Version, die von Heartex vertrieben wird. Price gibt es nur "custom"

Wesentliche Eigenschaft der Enterprise Version - Collaboration - QA - Secure - Label Queue Managment (Label Stream) - Monitor, Review and Verify annotations

Integration von Modellen

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\Data-Labeling-Tool_-Label-Studio.md - Chunk 1
Wesentliche Eigenschaft der Enterprise Version - Collaboration - QA - Secure - Label Queue Managment (Label Stream) - Monitor, Review and Verify annotations

Integration von Modellen

Integrate with machine learning models -> supply predictions (pre-labels) -> perform continous active learning

Download und erster Eindruck

GUI wird selber aufgebaut. Es gibt viele Templates, aber man stoppelt sich Tool je Anwendungsfall (Projekt) individuell zusammen. Integration mit Predictions aus Modellen wird selber gemacht.

ausserdem

Es gibt Standards zu Label-Definitionen!

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 0
[[TOC]]

Q: Can I test the quality of my classifier with a binomial test?

A: Yes, you can use a binomial test to assess the quality of a classifier. A binomial test is a statistical test that is used to determine whether the probability of a certain event occurring is different from a hypothesized probability. In the context of evaluating a classifier, the event of interest would be the classifier correctly predicting the class label of a given input.

To perform a binomial test, you would need to generate a sample of data and use your classifier to make predictions on this sample. You would then compare the observed proportion of correct predictions to the hypothesized probability of correct predictions, which is usually set to the classifier's overall accuracy on the training data. If the observed proportion of correct predictions is significantly different from the hypothesized probability, you can conclude that the classifier is not performing as expected.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 1
It's important to note that the binomial test is only one way to evaluate the performance of a classifier, and there are other methods that may be more suitable depending on the specific characteristics of your data and the goals of your analysis. For example, you may also want to consider other evaluation metrics such as precision, recall, and F1 score, or consider using techniques like cross-validation to get a more robust estimate of the classifier's performance.

Q: what about the sample size for such a test?

A: The sample size for a binomial test can have a significant impact on the power of the test and the ability to detect differences between the observed and hypothesized probabilities. In general, a larger sample size will result in a more powerful test, as there is more data available to make inferences about the classifier's performance.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 2
There are several factors that can influence the appropriate sample size for a binomial test, including the desired level of power, the magnitude of the difference between the observed and hypothesized probabilities, and the variability of the data. In some cases, it may be necessary to use a sample size calculator or perform a sample size estimation to determine the appropriate sample size for your test.

It's also worth noting that the sample size should be chosen carefully to ensure that it is representative of the population of interest. If the sample is not representative, the results of the binomial test may not accurately reflect the performance of the classifier on the larger population.

Q: can you give me the formula to calculate the sample size for a given level?

A: Sure! The sample size required for a binomial test can be calculated using the following formula:

n = (Z^2 * p * (1 - p)) / (d^2)

where:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 3
n = (Z^2 * p * (1 - p)) / (d^2)

where:

n is the sample size Z is the z-score corresponding to the desired level of confidence (e.g., 1.96 for a 95% confidence interval) p is the hypothesized probability of success (i.e., the classifier's overall accuracy on the training data) d is the desired precision or margin of error for the estimate of the success probability This formula can be used to calculate the minimum sample size required to detect a difference between the observed and hypothesized probabilities at a certain level of confidence. For example, if you want to detect a difference between the observed and hypothesized probabilities with a 95% confidence interval and a margin of error of 0.1, you would set Z to 1.96, p to the hypothesized probability, and d to 0.1. Plugging these values into the formula would give you the minimum sample size required to detect the desired difference.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 4
It's important to note that this formula assumes that the sample is drawn from a binomial distribution, which is the case when evaluating a classifier that makes binary predictions (i.e., predicting one of two classes). If you are evaluating a classifier that makes multi-class predictions, you may need to use a different formula or approach to calculate the sample size.

Q: if the classifier makes mulit-class predictions what would you suggest?

A: If the classifier you are evaluating makes multi-class predictions (i.e., predicts one of more than two classes), you may need to use a different approach to calculate the sample size for a binomial test. One option is to consider each class separately and perform a separate binomial test for each class. This would allow you to assess the classifier's performance on each class individually, which can be useful for identifying any class-specific issues or biases.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 5
Another option is to use a different statistical test that is better suited to multi-class classification. One example of such a test is the chi-square test, which can be used to compare the observed and expected frequencies of each class in the sample. The chi-square test can be used to determine whether the classifier's predictions are significantly different from what would be expected by chance.

It's worth noting that the binomial test and chi-square test are just two of many statistical tests that can be used to evaluate the performance of a classifier. The appropriate test to use will depend on the specific characteristics of your data and the goals of your analysis. It may be helpful to consult with a statistician or review relevant literature to determine the most appropriate test for your needs.

Q: Sure, but maybe you can point me in one direction. Now, what if my sample data is not independent and

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 6
Q: Sure, but maybe you can point me in one direction. Now, what if my sample data is not independent and

A: identically distributed. Can I still use a binomial test and calculate the sample size as proposed? If your sample data is not independent and identically distributed (i.i.d.), it may not be appropriate to use a binomial test to evaluate the performance of your classifier. This is because the assumptions underlying the binomial test rely on the data being drawn from an i.i.d. population. If the data are not i.i.d., the results of the test may not be reliable.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 7
If your data are not i.i.d., you may need to use a different statistical test or approach to evaluate the performance of your classifier. For example, you may want to consider using a test that is specifically designed to handle non-i.i.d. data, such as a permutation test or a bootstrap test. These tests can be used to estimate the statistical significance of the observed differences in classifier performance and can be more robust to deviations from the i.i.d. assumption.

It's also worth noting that the sample size calculation formula that I provided earlier assumes that the data are i.i.d. If your data are not i.i.d., you may need to use a different formula or approach to calculate the sample size for your test. It may be helpful to consult with a statistician or review relevant literature to determine the most appropriate approach for your needs.

Q: can you suggest a formula to calculate the sample size if the data is not i.i.d?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 8
Q: can you suggest a formula to calculate the sample size if the data is not i.i.d?

A: Calculating the sample size for a statistical test when the data are not independent and identically distributed (i.i.d.) can be more challenging, as the assumptions underlying many standard sample size formulas may not hold. In general, it may be necessary to use more specialized techniques or approaches to calculate the sample size in these cases.

One option is to use a permutation test or a bootstrap test to estimate the sample size required to achieve a certain level of power. These tests can be used to estimate the statistical significance of the observed differences in classifier performance and can be more robust to deviations from the i.i.d. assumption.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 9
Alternatively, you can use simulation-based approaches to estimate the sample size required to achieve a certain level of power. These approaches involve simulating data from a model that reflects the characteristics of your data (e.g., the correlations between variables, the distribution of the data, etc.) and using these simulated data to estimate the sample size required to detect a difference between the observed and hypothesized probabilities.

It's worth noting that these approaches can be quite complex and may require specialized software or expertise. It may be helpful to consult with a statistician or review relevant literature to determine the most appropriate approach for your needs.

Q: Can you please provide some python code for a bootstrap test to estimate the sample size to assess the quality of my classifier

A: Sure! Here is an example of how you can use a bootstrap test to estimate the sample size required to assess the quality of a classifier in Python:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 10
A: Sure! Here is an example of how you can use a bootstrap test to estimate the sample size required to assess the quality of a classifier in Python:

` import numpy as np

def bootstrap_sample_size(classifier, X, y, p_null, alpha, n_iter=1000): """ Estimate the sample size required to detect a difference between the observed and hypothesized success probabilities using a bootstrap test.

Parameters
----------
classifier : object
    A classifier object with a fit and predict method.
X : array-like, shape (n_samples, n_features)
    The feature matrix.
y : array-like, shape (n_samples,)
    The target vector.
p_null : float
    The hypothesized success probability.
alpha : float
    The significance level of the test.
n_iter : int, optional, default: 1000
    The number of iterations to use in the bootstrap test.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 11
Returns
-------
sample_size : int
    The estimated sample size required to detect a difference between the observed and hypothesized 
    success probabilities at the specified significance level.
"""
# Compute the classifier's accuracy on the training data
accuracy = classifier.score(X, y)

# Compute the observed success probability
p_obs = accuracy

# Compute the observed difference between the success probabilities
diff = p_obs - p_null

# Initialize an array to store the bootstrapped differences
bootstrapped_diffs = np.empty(n_iter)

# Perform the bootstrap test
for i in range(n_iter):
    # Generate a bootstrapped sample of the data
    indices = np.random.choice(len(X), len(X), replace=True)
    X_bootstrapped = X[indices]
    y_bootstrapped = y[indices]

    # Fit the classifier to the bootstrapped sample and compute the accuracy
    classifier.fit(X_bootstrapped, y_bootstrapped)
    accuracy_bootstrapped = classifier.score(X_bootstrapped, y_bootstrapped)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 12
# Compute the bootstrapped difference between the success probabilities
    p_bootstrapped = accuracy_bootstrapped
    bootstrapped_diffs[i] = p_bootstrapped - p_null

# Compute the p-value of the observed difference
p_value = np.mean(bootstrapped_diffs >= diff)

# If the p-value is less than the significance level, increase the sample size and repeat the test
sample_size = len(X)
while p_value < alpha:
    sample_size += 1

    # Generate a bootstrapped sample of the data with the increased sample size
    indices = np.random.choice(len(X), sample_size, replace=True)
    X_bootstrapped = X[indices]
    y_bootstrapped = y[indices]

    # Fit the classifier to the bootstrapped sample and compute the accuracy
    classifier.fit(X_bootstrapped, y_bootstrapped)

Q: can you please give me some literature for bootstrapping on small sample sizes

A: Sure! Here are a few papers and books that discuss bootstrapping with small sample sizes:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 13
Q: can you please give me some literature for bootstrapping on small sample sizes

A: Sure! Here are a few papers and books that discuss bootstrapping with small sample sizes:

"Bootstrap Methods: A Guide for Practitioners and Researchers" by Bradley Efron and R.J. Tibshirani "Bootstrap Methods: Another Look at the Jackknife" by Bradley Efron "The small sample performance of the bootstrap" by Andrew Davison "Bootstrap Methods: Accuracy and Reliability" by David S. Moore You may also find these references helpful:

"Boostrapping in small samples" by Richard A. Lockhart, John J. McArdle "Small Sample Performance of Bootstrap Methods: A Simulation Study" by Tze Leung Lai and S. X. Mao In addition, it's worth noting that there are some variations of bootstrapping methods specifically designed for small samples, such as the balanced bootstrap and the percentile bootstrap. These methods can be useful alternatives to consider when working with small samples.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 14
Please note that many journal articles are behind paywall and might require institutional access or individual purchase to be accessible.

Q: when does bootstrapping fail and what are remedies of failure

A: Bootstrapping can fail when the underlying data generating process is not approximately exchangeable, or when the sample size is too small. When the data generating process is not approximately exchangeable, the bootstrap may not accurately capture the uncertainty in the estimator, which can lead to inaccurate confidence intervals or hypothesis testing results. This is because the bootstrap relies on the assumption that the sample is representative of the population from which it was drawn. When this assumption is not met, the bootstrap may not be a good choice for quantifying uncertainty.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 15
Another situation in which bootstrapping can fail is when the sample size is too small. In small samples, the bootstrap may not accurately capture the uncertainty in the estimator due to the limited amount of information available. This is because the bootstrap relies on the central limit theorem, which states that the distribution of the sample mean will be approximately normal if the sample size is large enough.

Remedies for these failure:

Modifying the bootstrap method: For example, using a variation of the bootstrap such as the balanced bootstrap or the percentile bootstrap, which are specifically designed for small samples.

Collect more data: Increasing the sample size can help to ensure that the bootstrap accurately captures the uncertainty in the estimator, since the central limit theorem holds for larger samples.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 16
Collect more data: Increasing the sample size can help to ensure that the bootstrap accurately captures the uncertainty in the estimator, since the central limit theorem holds for larger samples.

Using alternative method: When the data generating process is not exchangeable, alternative methods such as the jackknife or the delta method may be more appropriate for quantifying uncertainty.

Check for assumptions: Make sure assumptions are valid and pay attention to data distribution, outliers and extreme values.

Please note that this is not an exhaustive list, and other remedies may also exist depending on the specific scenario.

Q: what do you mean by approximately exchangeable

A: "Approximately exchangeable" refers to a property of a dataset, where the observations within the dataset are similar to one another, and can be "exchanged" or "permuted" among themselves to produce other datasets that are also similar to the original dataset.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 17
In the context of bootstrapping, "approximately exchangeable" means that the observations in the sample are similar enough to one another that we can randomly sample with replacement from the sample to create new samples that are also similar to the original sample. If the data-generating process is approximately exchangeable, it means that the sample is likely to be representative of the population from which it was drawn, and the bootstrap can be used to estimate the sampling distribution of an estimator.

For example, if you have a sample of 100 people, each person has a certain height, and the sample is approximately exchangeable, you can create a new sample by randomly selecting 100 people from the sample and use that new sample as a proxy for the population of the heights.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 18
Please note that "approximately exchangeable" does not mean that the sample must be exactly exchangeable, rather the bootstrap method performs well even when the data-generating process is not exactly exchangeable, but the exchangeability holds to a certain extent.

Q: if I use bootstrapping what is the minimum sample size I should use?

A: The minimum sample size for bootstrapping depends on the specific estimator being used and the desired level of precision. The general rule of thumb is that the larger the sample size, the more accurate the bootstrap estimate of the sampling distribution of the estimator will be. However, the bootstrap is a robust method and can still be used with small samples, but the results may not be as precise.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 19
The rule of thumb is that the sample size should be at least 30, it is because the central limit theorem states that the sampling distribution of the mean becomes more normal as the sample size increases, and the bootstrap relies on this normality to produce accurate results. However, in some cases such as when the data generating process is not exchangeable or the data distribution is heavy-tailed or skewed the sample size of 30 may not be sufficient. In such cases, a larger sample size is usually needed to achieve a desired level of precision.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 20
It's also important to note that sample size is not the only factor that affects the precision of the bootstrap. The quality of the data, the specific estimator being used, and the underlying assumptions also play important roles. It's always best to consult with experts, or if possible, perform simulation studies to evaluate the performance of the bootstrap in a specific scenario, with respect to the sample size, estimator and the assumptions.

Q: what are the main assumption I have to met when I use the bootstrapping method?

A: The main assumption of the bootstrap method is that the sample is drawn from an approximately exchangeable population, meaning that the observations in the sample are similar enough to one another that we can randomly sample with replacement from the sample to create new samples that are also similar to the original sample. If this assumption is not met, the bootstrap may not accurately capture the uncertainty in the estimator.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 21
There are also other assumptions that need to be met when using the bootstrap method:

Independence: The observations in the sample should be independent of each other, this means they shouldn't be clustered or time-series data, as the assumption of independence is not met in these cases.

Randomness: The sample should be random, if the sample is not random, the bootstrap may not accurately capture the sampling distribution of the estimator.

Normality: If the sample size is large enough, the central limit theorem states that the sampling distribution of the mean becomes more normal, this assumption is critical for some inferential statistics such as t-test or confidence intervals.

Stationarity: For time series data, it's necessary that the underlying process generating the data is stationary.

No outliers: The bootstrap may be sensitive to outliers, and extreme values may affect the results.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 22
No outliers: The bootstrap may be sensitive to outliers, and extreme values may affect the results.

It's important to keep in mind that these assumptions are not always met in practice and can affect the accuracy of the bootstrap. Checking assumptions, and if necessary, using appropriate modifications or alternative methods, can help to ensure that the bootstrap results are as accurate as possible.

Q: what can I do if the assumption of independence is not met?

A: If the assumption of independence is not met, it means that the observations in the sample are not independent of one another, and traditional bootstrapping methods may not be appropriate. There are a few alternative methods that can be used in these situations:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 23
Cluster-corrected standard errors: When observations are clustered in some way, such as individuals within a group, or repeated measures on the same subject, it's common to use cluster-corrected standard errors. The idea is to adjust the standard errors to account for the non-independence of the observations.

Multi-level or Hierarchical modeling : A multilevel model, also known as a hierarchical model, can be used to account for the non-independence of observations that arise in clustered data. This approach models the variation both within and between groups.

Time-series bootstrap : When dealing with time series data, a variant of the bootstrap known as the time series bootstrap can be used to take into account the temporal dependence in the data. The idea is to resample the original data in a way that preserves the temporal dependence while still allowing the estimation of the sampling distribution of the estimator.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 24
Block bootstrap: if the data is correlated in time, but the correlation is limited to a certain number of lags, a variant of bootstrap called block bootstrap can be used, this method resample with replacement blocks of fixed length, preserving the temporal structure of the data.

It's worth noting that these methods are not mutually exclusive and sometimes they may be used in combination. It's always a good idea to consult with an expert and evaluate the performance of the method with respect to the specific scenario, data and assumptions.

Q: tell me more about cluster-corrected standard errors

A: Cluster-corrected standard errors (CCSE) is a technique used to adjust for the non-independence of observations that occur when observations are grouped or clustered in some way. The goal is to produce more accurate standard errors that take into account the non-independence of observations within a cluster.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 25
When observations are clustered, the standard errors of estimates tend to be underestimated because the observations within a cluster are not independent. By taking into account the clustering, the CCSE method produces standard errors that are larger than the standard errors obtained from a traditional regression analysis, making the results more conservative.

The basic idea of the method is to use the cluster structure to form a new data set by taking one observation per cluster, and then use this reduced data set to compute the standard errors. There are different ways to implement CCSE but some popular options include:

Using a sandwich estimator: A sandwich estimator is used to adjust the variance-covariance matrix of the regression coefficients to account for the clustering. The sandwich estimator is a consistent estimator of the variance-covariance matrix under weak assumptions.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 26
Using bootstrapped standard errors: The bootstrap method can be used to estimate the standard errors of the cluster-mean estimator.

Using the Degrees of Freedom Method (DFM) : It is another popular method to adjust for cluster dependence, it's based on adjusting the denominator of the t-statistic for the number of clusters.

It's worth noting that the choice of method may depend on the specific scenario, data and assumptions and it's always a good idea to consult with an expert and evaluate the performance of the method.

Please note that the cluster-corrected standard errors are an approximation, and do not fully account for the dependence among observations within the same cluster, hence it may not be suitable in some cases, and more complex models such as multi-level models may be needed.

Q: tell me more about bootstrapped standard errors

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 27
Q: tell me more about bootstrapped standard errors

A: Bootstrapped standard errors are a method for estimating the standard errors of an estimator using the bootstrap. The basic idea is to use the bootstrap to create many resampled datasets, and for each resampled dataset, calculate the estimator of interest. The standard error of the estimator is then estimated as the standard deviation of the set of estimates obtained from the resampled datasets.

Here's the general steps to compute bootstrapped standard errors:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 28
Here's the general steps to compute bootstrapped standard errors:

Take a sample of size N from the original data, this will be your original dataset. Draw B samples with replacement from the original dataset, where each sample has the same size of N. For each of the B resampled datasets, calculate the estimator of interest, for example, if it's a mean, you will compute the mean of each resampled dataset. The standard error of the estimator is then estimated as the standard deviation of the set of B estimates. Bootstrapped standard errors are a useful technique when the data generating process is not well understood, and when it is not possible to compute the standard error analytically. This method can also be used to estimate the standard errors of complex estimators or estimators that do not have a closed form expression.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\OpenAI-chatGPT---Discussions.md - Chunk 29
Bootstrapped standard errors can also be used in combination with cluster-corrected standard errors. The idea is to use the bootstrap to generate many resampled datasets within each cluster, and then use these resampled datasets to calculate the cluster-mean estimator and its standard errors.

It's worth noting that the method of bootstrapped standard errors assumes that the data is random and independent, that there are no outliers, and that the sample size is large enough. Also, it's important to have a large number of bootstrap resamples (B) in order to get a good estimate of the standard error. A good rule of thumb is to use at least a thousand bootstrap resamples.

Add your discussion and experiences here

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\Quality-assessment-using-Benchmarks.md - Chunk 0
[[TOC]]

Goal:

We would like to get good estimators (e.g. for accuracy, meanIoU) to assess the quality of our predictions on the population of our customers. In addition we would like to give statistics such as the standard error or a 95 confidence interval to better understand the quality we can deliver.

Note: this is independent to the assessments we have to make to achieve our goal of models which can generalize and are not overfitting.

Issue:

Currently we rely on various benchmarks in various sizes to assess the quality. Furthermore, creating a reliable benchmark can be time and cost expensive. Also, are we sure which distribution we need to assume for our data? Therefore, can we guarantee good estimates regarding the quality of our predictions?

Proposal:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\Quality-assessment-using-Benchmarks.md - Chunk 1
Proposal:

We would like to assess the quality from an early stage even though a benchmark of size 500 or 1000 might take some time until all labels are available. Hence, we propose using bootstrapping to calculate reliable statistics from an early stage (e.g. sample size 50).

For each customer benchmark we would like to get a true random sample of size n from the last 12 months (to get rid of any seasonality). This random sample should of course reflect the true population. Hence, there are no limits such as max 5 documents from vendor y.

Now for the available m results (m < n) in the benchmark we would like to draw a 10k bootstrap sample to calculate our statistics. That means we draw 10k random samples of size m with replacement from our benchmark data.

For the generated distribution we can then calculate the following statistics.

Statistics to consider:

Accuracy for each detail

Mean

Median

Standard Error

95 confidence interval

MeanIoU

Mean

Median

Standard Error

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Data-Management-Research\Quality-assessment-using-Benchmarks.md - Chunk 2
Statistics to consider:

Accuracy for each detail

Mean

Median

Standard Error

95 confidence interval

MeanIoU

Mean

Median

Standard Error

95 confidence interval

TBD:

Optimal sample size

Is the assumption of independence violated?

Bootstrapping assumes independence in the data. Not sure how this has to be interpreted considering documents. Nevertheless, if this assumption is violated, we could use another bootstrap method which does not assume independence to calculate the same statistics. It won´t hurt to calculate and provide both and compare them.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Deployment-instructions\Bludelta-Dashboard-Deployment.md - Chunk 0
Bludelta Dashboard Deployment

Update Assembly Version Increase the AssemblyVersion and AssemblyFileVersion in the AssemblyInfo.cs file in the project.

Publish to staging Right click the Blumatix.Capture.Automation.Dashboard project and choose the Publish... dialog.

Login to ryzen7virt with .\blumatix password

Select Staging profile and press publish - Test staging Use Dashboard Url and change port 7000 to 7001 and test new version e.g. Overview to check if production bci db (number of invoice ids)

Publish to production Select Production profile and press publish

Update Release Notes in

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Deployment-instructions\Bludelta-Labeling-Tool-Deployment.md - Chunk 0
Bludelta Labeling Tool Deployment

Update Labeling Instructions Wiki

Run labeling-tool-cicd-staging pipeline is done automatically when updating the Blumatix.Capture.Website project

Test new version on Staging https://bludelta-labelingtool-staging.azurewebsites.net

Swap staging slot to production Log in to Azure Portal (use Support user (hp.haberlandner@bizsparkblumatixconsulting.onmicrosoft.com)) Goto Resource Group bludelta-tools Open App Service (Slot) staging (bludelta-labelingtool/staging)

Select Deployment slots and press Swap button

Press Swap button

Bludelta Labeling Tool Restart

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Deployment-instructions\DataCollection-Deployment.md - Chunk 0
Create new version of DataCollection in production

Finish development in DataCollection in development

Push changes to master

upload test package with Package Uploader dev e.g. use phönix action: .\phoenix dataset uploadPackage -u "dev", -p "C:\Users\hasch\Downloads\DachserBluDoc.zip" -c "Dachser"

check results

Create new Manifest version

Goto repo DataMining and folder workflows

Copy last scheduled-datacollection-dag-prod_vn.n.n.yml file and rename it and increase version in filename

Update new yml file: increase generateName property in metadata property update all versions of components

Check Pipeline for component version number

OR - Check Repository for component version number

[Azure Repository] (https://portal.azure.com/#@bizsparkblumatixconsulting.onmicrosoft.com/resource/subscriptions/899e7821-330e-44f4-af63-98f78ba776e1/resourceGroups/bludeltaservicedevcontainer/providers/Microsoft.ContainerRegistry/registries/blumatixdevregistry/repository)

Update Argo

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Deployment-instructions\DataCollection-Deployment.md - Chunk 1
Update Argo

Set namespace to argo

Press Create new crown workflow button

Press Upload file button and select new manifest

Press Create button and create new workflow

Test new Workflow

Set History Limits

Select CRON Tab and set both History Limits to 24 and Update

Suspend old productive workflow and Resume new one

Update Learn API Release Notes in eniston

Tag Source Code

git tag -a v0.6.11 -m "normalizer" git push origin v0.6.11

Visual Studio: - Select Manage Branches - Select Commit and Create Tag (New Tag...) - Push Tag (Push all tags to)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Deployment-instructions\Phönix-Deployment.md - Chunk 0
Phönix Deployment

Variant 1: Create new Phönix Version

Update VersionAction In Blumatix.Capture.BluDeltaCli.Actions there is the action VersionAction to provide the Phoenix version. Increase the Version constant and add two lines of release notes, version information and description of changes.

Build (Debug x64) of Phoenix project in BlumaticCaptureComplete solution.

Copy C:\Source\Repos\Blumatix Capture\Blumatix.Capture.BluDeltaCli\bin\x64\Debug folder to Ryzon 7 Virtual (Ryzen7Virt) C:\

Variant 2: Copy Phönix from Built Artefacts

Open Azure Storage Explorer

Download phoenix.zip from build artefact

Unzip to a Debug folder

Copy C:\Source\Repos\Blumatix Capture\Blumatix.Capture.BluDeltaCli\bin\x64\Debug folder to Ryzon 7 Virtual (Ryzen7Virt) C:\

Replace old version on Ryzen 7 Virtual

Delete phoenixOld

Rename phoenix folder to phoenixOld

Rename copied Debug folder to phoenix

Copy ExternalReferences folder from old phoenix folder to new phoenix folder

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Deployment-instructions\Phönix-Service-Deployment.md - Chunk 0
Deployment

Build Service

Build the service in release mode (set Visual Studio to Release instead of Debug)

copy ExternalReferences directory into the local directory - it's located one dir outside

check version in registry

https://portal.azure.com/#view/Microsoft_Azure_ContainerRegistries/RepositoryBlade/id/%2Fsubscriptions%2F899e7821-330e-44f4-af63-98f78ba776e1%2FresourceGroups%2Fbludeltaservicedevcontainer%2Fproviders%2FMicrosoft.ContainerRegistry%2Fregistries%2Fblumatixdevregistry/repository/phoenix_service

build as windows container latest and your version

Go to \BlumatixCapture\Blumatix.Capture.BludeltaCliService

docker build -t blumatixdevregistry.azurecr.io/phoenix_service:latest .

docker push blumatixdevregistry.azurecr.io/phoenix_service:1.26

connect to 70er

cd D:

docker pull blumatixdevregistry.azurecr.io/phoenix_service:latest

change versions in docker compose

change the versions in the docker compose file - notepad D:\docker-compose-winservices.yml

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Deployment-instructions\Phönix-Service-Deployment.md - Chunk 1
docker pull blumatixdevregistry.azurecr.io/phoenix_service:latest

change versions in docker compose

change the versions in the docker compose file - notepad D:\docker-compose-winservices.yml

restart the service: careful with training, check - docker stats - docker-compose.exe -f D:\docker-compose-winservices.yml pull - docker-compose.exe -f D:\docker-compose-winservices.yml down - docker-compose -f D:\docker-compose-winservices.yml up -d

if you only want to restart one single service: - docker-compose.exe -f D:\docker-compose-winservices.yml stop phoenix-training-prod - docker-compose.exe -f D:\docker-compose-winservices.yml rm phoenix-training-prod - docker-compose.exe -f D:\docker-compose-winservices.yml up -d phoenix-training-prod

write release notes

https://blumatix.visualstudio.com/DefaultCollection/Rechnungserkennung/_wiki/wikis/BludeltaDeployment/1709/Phoenix-Service-Release-Notes

send deployment email

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Document-Generator\Content.md - Chunk 0
Introduction

Input: Document Structure as DocumentDetailGroup with Tags set Output: Document Structure is enriched: all DocumentDetailLeafs include Content

different Sources of Content

one Interface for all different Content Providers

Mapping: Tag - Content Provider

Context to pass settings through hierarchy

Content based on Labels

Our labels can be used for some content, e.g. Line Item Header Values. This is text, that is important because the models will use the words to identify the line item details.

Query: SELECT Distinct [Text] FROM [bcidb].[dbo].[Label] where Type = 61 and InvoiceEntity_Id IN ( SELECT [InvoiceEntity_Id] FROM [bcidb].[db_owner].[ManuallyFullyLabelledLineItemsIds])

Problems: - a lot of wrong labels (unknown reason) - different languages, sometimes mixed - manual preparation is necessary - how to store, update, manage?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Document-Generator\Content.md - Chunk 1
Problems: - a lot of wrong labels (unknown reason) - different languages, sometimes mixed - manual preparation is necessary - how to store, update, manage?

Future Requirements: - add metadata to content, eg. language, industry, ... - the content of header items is not independent, like lower/uppercase writing or semantic...

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Document-Generator\Sprint-78.md - Chunk 0
First prototype

new code base (C#, .Net Core)

show main components, their responsibility and their collaboration

first test of Office Interop as Render Engine

completely new documents - Ownership at Blumatix

Next tasks

Implement classes for logical structure (DocumentDetail and DocumentDetailGroup)

Implement Repositories to manage providers (for content, layout, ...)

Implement Context for Style, Layout, Content and Render to pass through hierarchy

Implement Label Creator

Implement Configuration (documented definition of variable structures)

Next Goals

Use Configuration for unknown simple structure (e.g. unknown Key Value Pair) -> enforce that the Document Generator is generic and every component provides a meaningful default behaviour

Use given position and create labels with positions -> verify that Render Engine provides coordinates that are needed

Enable structure variations of line item headers

Define production architecture of Document Generator

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Document-Generator\Sprint-80.md - Chunk 0
Switch to HTML for Rendering

For the first prototype we started with Office Interop API for Rendering. This was fine to create fast results and to be able to create Word documents. But there are many disadvantages: - proprietary, complex, old API - bad documentation - COM integration - Extension to Visual Studio necessary - Installation of Word or PIA needed on System

But the main challenge was to get back the coordinates and positions of all labels from the render engine! We did a lot of investigation, but we could not find a reliable way...

Finally we decided to switch to HTML. This is a standard approach which is supported by many tools (creation of html and stylesheet files, rendering to create pdf or images). Coordinates can be provided in an easy way for HTML.

Documents generated

Document Generator creates three documents for each logical structure: - Pdf Document (.pdf) - Document Description File (.json) - HTML File (file for rendering) (.html)

Label Creation Design

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Document-Generator\Sprint-80.md - Chunk 1
Document Generator creates three documents for each logical structure: - Pdf Document (.pdf) - Document Description File (.json) - HTML File (file for rendering) (.html)

Label Creation Design

Bounding Boxes in Document Description File (.json) match position in Pdf Document (.pdf)

Layout Design

The layout component provides Bounding Boxes before rendering. Like all other components there is a default implementation that can handle unknown tags: divide given area horizontally or vertically equally for all children.

Done: Default and one other Layout Provider is implemented

Style Design

The style design is part of the rendering component. It will be organized like all other components (e.g. Layout).

Done: Marin is working on Default and three special Styles: Margins, Bold and Alignment

DPI

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Document-Generator\Sprint-80.md - Chunk 2
Done: Marin is working on Default and three special Styles: Margins, Bold and Alignment

DPI

Pixel definition without DPI don't have a real meaning when used in documents. This has consequences for our label definitions: can we get it from the document? Is it consistent? How can customers provide the information?

Our current HTML Renderer works internally with 96 DPI. So our bounding boxes are calculated for DIN A4 and 96 DPI. Our OCR is best with 300 DPI. How to handle that?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Document-Generator\Todos.md - Chunk 0
[x] - implement string resource provider class (common in many content providers)

[x] Remove Version, Source, GUID from Tag

[x] Define Version and Source at the root or in Metadata and only if it changes then override

[ ] Make Tag:Value visible for Debugger

[x] DPI 96 right now, should have mechanism to add dpi to metadata, so that labels can be adjusted for 300dpi in OCR.

[x] Make Header Permutations in TableStructureBuilder

[x] Make table from no header and items; Make table from items and no header; Make table from items and header

[ ] Performance: TableStructureBuilder: Save all numRows iterations and just plug them in for all header permuations

[x] Implement LabelCreation

[x] Implement DocDetailGroups as Input Format

[x] Implement Config Class

[x] Adapt TableStructureBuilder for new input format

[x] Hierarchy for Tags in separate class

[x] Use Hierarchy Class in all components

[ ] Context for Providers

[x] Make actual content with the existing content providers

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Document-Generator\Todos.md - Chunk 1
[x] Hierarchy for Tags in separate class

[x] Use Hierarchy Class in all components

[ ] Context for Providers

[x] Make actual content with the existing content providers

[x] Implement Config File instead of Class

[ ] Create Container for Doc Generator (Gü)

[ ] Add structure of Buffer Lines

[x] Create Document from Labels

[x] Tags should be named like already existing Labels

[ ] Use HTLM Table and get positions

[x] implement missing Content providers for LineItemDetails

Open Questions

? How to make Multi-Line-Headers? Header: {HeaderLineItem, HeaderLineItem, ...} or {Header, Header, LineItem, LineItem, ...}

Updated Todos

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Document-Generator\Todos.md - Chunk 2
Open Questions

? How to make Multi-Line-Headers? Header: {HeaderLineItem, HeaderLineItem, ...} or {Header, Header, LineItem, LineItem, ...}

Updated Todos

Prio 1 - [x] Fix Margins for LineItemTable (manage to fill all page) - [x] Fix endless loop in GetRandomColumns - [x] Add Rate of Bufferlines to Config (0 - 1; 0 no bufferline at all, 1 for every line item 1 buffer line - [x] Add Version to Filename - [x] fix Bounding Boxes - [x] Refactor: Store Word vs. _generateDoc; use Classes for extensive calculations and add unit tests; Naming of NumberChild method; use of Aspose / Cut; - [x] larger FontSize

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Document-Generator\Todos.md - Chunk 3
Prio 2 - [ ] more than 1 page - [ ] make more realistic: use same Content Structure for all Buffer Lines (e.g. with GPT2 ?); if Description has more lines -> for all line items; - [ ] use Content Service - [ ] add metadata (Language, Industrie, Source ..., Length ) to Content Repository - [ ] Layout from Labels or Layout Model Provider - [x] Refactor Config - different sections, unique declaration - [ ] Definition of multi line headers (better to take given layout?) - [ ] Doc Generator part of Data Collection

Next big possible steps

Content Service with Metadata filter (Language, Industry, Source, ... )

Content Creation based on a language model (e.g. GPT, OPT, ...)

Layout Model Provider based on a Layout AI model

Take Layout from original documents

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Document-Generator\User-Manual.md - Chunk 0
BluDelta Document Generator

Version: 1.0.13

Description

Create random Documents with Annotation

Features

Line Item Tables

Currently the BluDelta Document Generator is limited to create Line Item Tables.

First Steps

Create your first document

Execute DocGenerator.exe <OutputDirectory>

Upload your documents

Open GeneralConfig.json and change Upload setting to "true". Execute DocGenerator.exe <OutputDirectory>

Configuration

The process of document creation is controlled with settings in the GeneralConfig.json file.

The syntax for all settings are like this: - single,fixed value sample: "5" - range, randomly choose value out of this range (including borders) sample: "5-10"

Unit: Pixel Available Area: DIN A4 Page (for 96 dpi): 793 x 1123

General settings

NumberOfDocs ... number of documents to generate Upload ... "true" upload generated documents and delete locally, "false" don't upload generated documents

Structure settings

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Document-Generator\User-Manual.md - Chunk 1
General settings

NumberOfDocs ... number of documents to generate Upload ... "true" upload generated documents and delete locally, "false" don't upload generated documents

Structure settings

NumberOfLineItems ... number of line items in the line item table MinNumberOfDetails ... minimal number of line item details BufferLine_LineItemRate ... rate of buffer lines / line items: if 0, no buffer lines are created; if 1, for each line item a buffer line is created; else, rate is calculated and buffer lines are randomly distrubuted within line items LineItemDetails ... list of line item details with their probability of occurrence in a line item table. LineItemDetailspartitioning ... every line item detail has an array of probabilities for position. The table is divided into three partitions: left, middle, right and the three values of the array are the probabilities for each partition.

Layout settings

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Document-Generator\User-Manual.md - Chunk 2
Layout settings

LineItemTableMargin ... Margin of the line item table (top, bottom, left, right) from Document LineItemHeight ... Height of a single line item BufferLineHeight ... Height of a single buffer line

Content Settings

MaxLengthOfDescription ... max number of characters for description content

Style settings

LineItemFontSize ... Font size of a single line item LineItemBufferFontSize ... Font size of a single buffer line LineItemHeaderFontSize ... Font size of a header line

RowsBorderProb ... probablity to draw borders for line item rows (top, bottom) ColumnsBorderProb ... probability to draw borders for line item columns (left, right) TableBorderProb ... probability to draw bounding box of line item table

LineItemHeaderLinesProb ... 3 values: prob for two lines for header (top, bottom), prob for one line for header (bottom) and prob for no line for header (together 100 %)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Document-Generator\User-Manual.md - Chunk 3
LineItemHeaderLinesProb ... 3 values: prob for two lines for header (top, bottom), prob for one line for header (bottom) and prob for no line for header (together 100 %)

LineItemAmountTextAlign ... alignment of TotalAmount detail LineItemPositionNumberTextAlign ... alignment of PositionNumber detail LineItemQuantityTextAlign ... alignment of Quantity detail

LineItemHeaderTextAlign ... alignment header text

HeaderVerticalTextAlign ... vertical alignment of header text BufferVerticalTextAlign ... vertical alignment of buffer line text LineVerticalTextAlign ... vertical alignment of line item text

LineItemHeaderFontWeight ... font weight for header text LineItemBufferFontWeight ... font weight for buffer line text LineItemFontWeight ... font weight for line item text

BorderWidth ... width of border lines

Known Issues

"right alignment" and corresponding padding (needed for Amounts) does not work correctly with pdf renderer and might create slightly overlapping content.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Document-Generator\User-Manual.md - Chunk 4
Known Issues

"right alignment" and corresponding padding (needed for Amounts) does not work correctly with pdf renderer and might create slightly overlapping content.

There might occur problems when creating too big font size. The cells might not fit any longer.

Many settings are not independent from others. Not all inconsistent settings are checked.

Limits

only line item tables

only one pagers

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Guidelines-and-Policies\BLU-DELTA-Workflow.md - Chunk 0
Handling of Documents and document related data

BLU DELTA Workflow Handling of Documents and document related data

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Guidelines-and-Policies\Data-Mgt.-Employee-On-Boarding.md - Chunk 0
[[TOC]]

General

Get a Company Notebook -> HR/IT

MS Office is installed -> IT

Grant permissions for Azure DevOps Rechnungserkennung Project and Data Management Team -> IT

Install and grant permission 4 MS SQL Server Management Studio -> IT

Invite to Reetro.io -> Scrum Master

Headset/Microphone 4 Online Meetings -> HR?

Workplace is defined and set up (e.g. second Monitor) -> HR/IT

Set up and Introduction BLU DELTA Dashboard (Manual Release) -> IT/Data Mgt.

Specifics for Devs/Data Scientists

Grant permissions to necessary Azure Storages and provide connection strings -> IT

Specifics for Labeler

Create/Update User to Label Tool Admin Account -> Data Mgt.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Guidelines-and-Policies\Delete-Customer-Data.md - Chunk 0
[[TOC]]

What to do if a customer terminates the contract with Blumatix/Blu Delta

Please collect potential data candidates and risks associated with deleting customer data according to our template.

Customer Off-Boarding Template.pptx

Solution

Not all customer data can be deleted in an automated fashion. Especially emails and sharepoint data can be challenging.

For easy accessible structured data like database data we want a Phoenix Action with two Parameters: report, and delete. Calling the action with the report parameter returns an overview of the customer data in various places (see below). Calling the action with the delete parameter deletes all customer data and returns a report.

Look for Customer Data (documents, invoices, etc.) in:

SQL-Databases

BCA: if a document that is included in a benchmark has to be removed, that benchmark report gets a new baseline!

BCI

Report - execute stored procedure on BCI

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Guidelines-and-Policies\Delete-Customer-Data.md - Chunk 1
SQL-Databases

BCA: if a document that is included in a benchmark has to be removed, that benchmark report gets a new baseline!

BCI

Report - execute stored procedure on BCI

Delete - execute stored procedure (see chapter Delete Documents/Invoices in this page)

\nas-01\CustomerData

\nas-01\DataCollection

\nas-01\TrainingsData

BCS_Auth; Token should be inactive

BCS_BI

RIPEye:

SME Table Storage

Documents in inbox bludelta@blumatix.com

\\serverbmdata\BluDeltaSupport\SME

Dev server: bcdbserverdev.database.windows.net - Dev DB: smedbdev_current - Test DB: smedbtest; Delete the corresponding customer data!

Is customer-data in database-backups a problem?

Sharepoint

Teamwebsite - Deliveries

Teamwebsite - Labels

Teamwebsite - Prediction Errors

Source-Code:

Specific documents could be used for integration tests

Employee:

Check your Email Inbox for documents we have to delete

Check your local disc(s) for documents (Development, Support, Training, Benchmark)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Guidelines-and-Policies\Delete-Customer-Data.md - Chunk 2
Employee:

Check your Email Inbox for documents we have to delete

Check your local disc(s) for documents (Development, Support, Training, Benchmark)

RIPEye Invoice Cleaner - Customer settings

Production Environment

By default Customer data will be deleted after 90 days if not specified otherwise. Please notify the respective Account Manager and Product Owner if this setting was changed for a customer!

Free test customer data will be deleted after 90 days

Data uploaded on any Blumatix Test Customer will be deleted after 90 days

Data uploaded on the Blumatix Demo Customer will be deleted after 365 days (the account is owned by Martin)

Data uploaded for the Blumatix Support Customer will be deleted after 90 days

Data uploaded for the Blumatix Label Customer will be deleted after 90 days

Test Environment

Data uploaded on all Accounts will be deleted after 30 days

Development Environment

Data uploaded on all Accounts will be deleted after 1 day

Delete Document/Invoice

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Guidelines-and-Policies\Delete-Customer-Data.md - Chunk 3
Test Environment

Data uploaded on all Accounts will be deleted after 30 days

Development Environment

Data uploaded on all Accounts will be deleted after 1 day

Delete Document/Invoice

To delete documents / invoices from BCI Db we use the Stored Procedure: spDeleteDocuments

Overview

The spDeleteDocuments stored procedure handles various approaches to delete documents and their dependencies in the database. This procedure allows for the deletion of documents based on a single invoice ID, a range of invoice IDs, a list of invoice IDs, or a Provider name. Note: The parameters work in an additive manner, meaning multiple parameters can be specified to union invoices to be deleted.

Parameters

@SingleInvoiceId BIGINT = NULL Single Invoice ID to be deleted.

@StartInvoiceId BIGINT = NULL Start of the range of Invoice IDs to be deleted.

@EndInvoiceId BIGINT = NULL End of the range of Invoice IDs to be deleted.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Guidelines-and-Policies\Delete-Customer-Data.md - Chunk 4
@StartInvoiceId BIGINT = NULL Start of the range of Invoice IDs to be deleted.

@EndInvoiceId BIGINT = NULL End of the range of Invoice IDs to be deleted.

@InvoiceIdList NVARCHAR(MAX) = NULL Comma-separated list of Invoice IDs to be deleted.

@Provider NVARCHAR(MAX) = NULL Name of the Provider whose invoices are to be deleted.

Behavior

The parameters work in an additive manner. This means you can specify multiple parameters, and the procedure will combine them to determine the set of invoices to delete. For example, specifying both @SingleInvoiceId and @Provider will delete the invoice with the given ID and all invoices from the specified provider.

Tables included in deletion process

OCRResult (CASCADING DELETE)

OCRPage (CASCADING DELETE)

Content

Cluster (Cluster is deleted - this might be

ClusterInfo (CASCADING DELETE)

Metainfo (CASCADING DELETE)

LabelGroup

Label (CASCADING DELETE)

ReleaseItem (CASCADING DELETE)

Tables updated in deletion process

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Guidelines-and-Policies\Delete-Customer-Data.md - Chunk 5
ClusterInfo (CASCADING DELETE)

Metainfo (CASCADING DELETE)

LabelGroup

Label (CASCADING DELETE)

ReleaseItem (CASCADING DELETE)

Tables updated in deletion process

DocumentInfo (InvoiceId and IsNew are set to NULL)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Guidelines-and-Policies\Human-Labeler-On-Boarding.md - Chunk 0
[[TOC]]

From Getting new Labelers to the first Payment

Getting new Labelers

Do you know friends/family members, who would like to make some extra money? Please send them the link to our webpage "Werde Daten-Labeler": https://www.bludelta.de/de/ressourcen/werde-daten-labeler/?doing_wp_cron=1646233027.0739719867706298828125 [Accessed: 2022-03-02]

Since they can label whenever and wherever they want, its a perfect job for students.

Signed Documents, where to put them and what we need to add:

Please control, if they checked the minimum criteria on the signed documents, and then put them in this folder: "C:\Data\OneDrive\Blumatix Intelligence GmbH\Machine Learning - Documents\Labelling\VertraegederNeuenLabeler" On these documents there is already their address, which we will add together with their name and mail adress to the "Labeller Stammdaten.xlsx". ("C:\Data\OneDrive\OneDrive - Blumatix Intelligence GmbH\3_Gutschriften\Tooling\Labeller Stammdaten.xlsx")

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Guidelines-and-Policies\Human-Labeler-On-Boarding.md - Chunk 1
We should also get their bank details (IBAN) when the onboarding process is started, so we don't struggle when we prepare their first payment.

Labeling tool credentials

Username policy! First name 3 letters + last name, e.g. andpauritsch

Training Labelers

Within the first week of being first contacted/getting the documents, we will offer dates for the training over teams. This should happen rather quickly, so they can start working whenever they want. Before inviting them we must check if they have been added to the "Labeller Stammdaten.xlsx" file. If not, please add them.

Q&A

Questions and other comments should be communicated through the teams channel at most times, since other Labelers can learn from it. This way we want to build a better information/data base regarding the labeling webtool and invoices themselves. Please add new labeler to this channel once they are added to the "Labeller Stammdaten.xlsx" file.

Labeler Abrechnung

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Guidelines-and-Policies\Human-Labeler-On-Boarding.md - Chunk 2
Labeler Abrechnung

On the first/second of a month, Andrea will fetch the labeling numbers from the database, and calculate how much money who will get. Gü gets the PDFs for sending the money, and Lisa will also get them for accounting.

Continuous Revisions:

Add what languages who speaks or has already done, or what packages, in this file: "C:\Data\OneDrive\Blumatix Intelligence GmbH\Machine Learning - Documents\Labelling\KommunikationLabeller\zugewiesenePakete.xlsx" This will help improve the labeler satisfaction, happiness, speed and correctness of labels

POLICY: Label Tool Users will not be deleted!

Instead we will rename the user in the Label tool and/or RIPEye and create a new password. This is important to be able to allocate the processed data to a specific User!

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Guidelines-and-Policies\Human-Labeler-On-Boarding.md - Chunk 3
Instead we will rename the user in the Label tool and/or RIPEye and create a new password. This is important to be able to allocate the processed data to a specific User!

Therefore: - Disable a User if he/she was inactive for 6 months - The original LastName e.g.: Doe will be changed to Doe Disabled - Create a new password - Make sure that the user no longer receives documents for labeling

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Guidelines-and-Policies\Label-deletion-in-BCI.md - Chunk 0
Problem description

It should not be possible to unintentionally delete labels from the BCI.

Solution

Implement a recovery bin (Recycle Bin) for each table from which the deleted data can be recovered. The data in the recovery bin will be finally deleted after 14 days.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Guidelines-and-Policies\Receive-and-Store-Customer-Data.md - Chunk 0
TBD:

Customer data should always be received and stored through the Package Uploader and the Data Collection: https://learn.bludelta.ai/swagger/index.html

If you receive data via Email, etc. please upload the data through the Package Uploader and delete it from your local machine. Before uploading the data check if there is a naming convention for this customer.

If you are not able to upload your data via the Package Uploader please contact the Data Management Team.

In case you need to share data please send a link to the file. Never send the file!

Support Data

Data for testing Bugs and Issues

Data (Documents) not stored in a database but used for testing Bugs and Issues or other Code need to be stored on the Share \\nas-01\CustomerData\Testing.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\Guidelines-and-Policies\Receive-and-Store-Customer-Data.md - Chunk 1
Data for testing Bugs and Issues

Data (Documents) not stored in a database but used for testing Bugs and Issues or other Code need to be stored on the Share \\nas-01\CustomerData\Testing.

Please store the files (or folders) and rename them stating the customer name, Azure DevOps ID, if possible a Tag such as "OCR-Error" or "JunkDetection" and if there are several documents a consecutive number: "customerName_DevOpsID_yourTag_consecutiveNumber".

Please do not attach the data to a Work Item in Azure DevOps or share it via MS Teams.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Benchmark.md - Chunk 0
Tags: Create Benchmark, Naming Convention, Remove Document

[[TOC]]

Benchmark Requirements

Before creating a benchmark, please align the requirements with the ML Team, Product Owner, and QA. You can use the following checklist to specify the benchmark requirements.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Benchmark.md - Chunk 1
Benchmark Requirements

Before creating a benchmark, please align the requirements with the ML Team, Product Owner, and QA. You can use the following checklist to specify the benchmark requirements.

Check list - Purpose: Describe in one or two sentences what the Benchmark is used for (e.g. QA, Customer Value, Error Analysis, R&D, etc.) - Naming: Default = Naming Convention. Please specify special requests such as for OrderConf or Quotation. - Related Work Item Ids - Size: Default = 100. - Distribution: Uniform (= Default), Customer Sample, Representative (same distribution as in production), Weighted. - Max. Cluster Size: Default = 1. - Necessary Label Types. - Detail Availability: Always available, Customer Sample (= Default), Representative, etc. - Document Type: Default = Not Relevant. - Countries: Default = Not Relevant. - Language: Default = Not Relevant. - Customer: Default = Not Relevant. - Additional Requests: e.g. exclude handwritten documents, OCR-Errors, etc. - TBC

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Benchmark.md - Chunk 2
Create Benchmark

Naming Convention [TBD]

The naming convention applies to the Benchmark-Task-Name and the Benchmark-Definition-Name. ATTENTION: Due to bug #18676 the max. number of charakters in the Benchmark-Definition-Name is 32!

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Benchmark.md - Chunk 3
Customer Name: The Customer we created the Benchmark for such as "blumatix" or "support". Naming follows our Customer Naming Convention! - Document Type: According to the following list: Wiki - Product - Supported Doc-Types - Description: Either a project name (e.g. wave3), country (e.g. CN), language (e.g. KR) or document type (e.g. OrderConfirmation). - Size: Number of documents in the benchmark - Property: Stating the explanatory power of the benchmark. Values can be: - Uniform: The Benchmarks uses n documents from each cluster. - CustomerSample: The Benchmark follows the cluster distribution provided by the Customer. It is not guaranteed that the sample represents the population observed in production. - Representative: The Benchmark follows the cluster distribution representing the population ovserved in production. - Weighted: The Benchmarks uses n documents from each cluster and is weighted by cluster size. - Quality Approved: - Final: The quality assessment has been completed

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Benchmark.md - Chunk 4
ovserved in production. - Weighted: The Benchmarks uses n documents from each cluster and is weighted by cluster size. - Quality Approved: - Final: The quality assessment has been completed by Data Mgt. - Dev or QA: see also Development - Benchmark-Overview - Dev: benchmark is used in development. - Qa: benchmark is used for qa.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Benchmark.md - Chunk 5
Examples: - Support_Issues_100_Representative - Blumatix_CN_200_Weighted - Blumatix_Wave3_70_Uniform - Blumatix_OrderConfirmation_100_CustomerSample

Create a new benchmark

Video Tutorial

Define a new Benchmark in the Blumatix Capture Dashboard. Select: Benchmarks -> Definitions.

Select Add (top right corner) -> Define a Name and Import a list of comma separated document IDs (e.g. 1, 2, 3). Save your Benchmark definition.

Connect to the DB: ServerBDSql01\BluDeltaDev

Select: BlumatixCaptureAutomation -> Tables -> dbo.BenchmarkTask

Right click -> Script Table as -> INSERT to. -- Name = BenchmarkTaskName -> provide a descriptive name. -- DetailTypes = Details required in the Benchmark. -- BenchmarkDefinitionName as defined in the Blumatix Capture Dashboard.

! Make sure to provide the correct DetailTypes as defined in table InvoiceDetailType

Result: there is a Benchmark Definition with a given name and a set of attached invoices in the BlumatixCaptureAutomation database.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Benchmark.md - Chunk 6
Result: there is a Benchmark Definition with a given name and a set of attached invoices in the BlumatixCaptureAutomation database.

Label Benchmark

Create Labels

There are various options to create labels for a benchmark. - You can assign a benchmark (list of invoice ids) and a set of invoice details to labellers to create labels. - You can create labels from predictions of our service - You can create labels from accounting data

Release Labels

Whenever there is are labels they have to be released to be used for benchmarking. Currently we have the strategy to compare at least two labels from different users for any invoice detail for release. There will be different strategies in future. - Automatic release: if all labels are the same, they can be released automatically - this is done nightly.

Manual Release

Start Label Release in Dashboard

Filter Labels: 1. add all ids of benchmark to Invoice Id Filter 2. Click Invoice Provider

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Benchmark.md - Chunk 7
Manual Release

Start Label Release in Dashboard

Filter Labels: 1. add all ids of benchmark to Invoice Id Filter 2. Click Invoice Provider

The first table shows a status summary of the filtered labels.

The second table shows all labels, that can be manually released.

This table shows, that there is one invoice with Document Types to release, 57 Invoice Ids and 2 Grand Total Amounts. 3. Click on resolve to start with manual release for this invoice detail

Add Benchmark to nightly cloud benchmarks and to reporting in dashboard

tags: benchmark reports, nightly benchmarks, benchmark set

Unfortunately this procedure is a bit tedious. There is a how-to in sharepoint: https://blumatixconsultinggmbh-my.sharepoint.com/:v:/g/personal/p_grafendorfer_blumatix_at/EeNzL_G1NFtFl5xXPSn3P6sBQotquA3scJ6WDONQ5ltm4Q

Check labelling progress

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Benchmark.md - Chunk 8
Check labelling progress

When we have assigned a benchmark to labelers it might be useful to check progress sporadically. This can be done by executing the benchmark. Since the benchmarks show results only for released labels it is a good indicator how many labels are still missing. Reasons for missing labels: - no single label - just one label - more than one label, but not released

Two Options two execute benchmark.

Phönix Action

Start Phönix Action to execute benchmark with current production service: .\phoenix.exe evaluation bm_run -a "Cloud_B_I18N_Denmark" -t 4 -c "Andrea Test" -s "https://api.bludelta.ai/V1-18"

c ... any comment to be able to identify the benchmark run -s ... current productive service

Benchmark Execute Pipeline

Video Tutorial

Select Benchmark Execute (No Tagging) Pipeline(click Pipeline)

Run Pipeline (click Run Pipeline)

Set Parameters Set parameters in dialog window:

startLocalCaptureSdk: false

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Benchmark.md - Chunk 9
Video Tutorial

Select Benchmark Execute (No Tagging) Pipeline(click Pipeline)

Run Pipeline (click Run Pipeline)

Set Parameters Set parameters in dialog window:

startLocalCaptureSdk: false

benchmarks: add your benchmark(s); for two benchmarks add another line starting with "-"

comment: add your comment

Run Pipeline Click Run button

Removing an invoice id in a benchmark

Connect to the DB:

Select Databases -> BlumatixCaptureAutomation -> Tables -> dbo.BenchmarkDefinition (Table of Benchmark Definition)

Right Click -> Select Top 1000 Rows: Find the name of the benchmark (column: Name) and its Id (column: Id)

Select dbo.Invoice (Mapping of Ids)

Right Click -> Select Top 1000 Rows: Execute the following query and find Invoice Id in Automation Database (column: Id) that is related to Invoice Id in BCI database (column: InvoiceId)

Select dbo.InvoiceEntityBenchmarkDefinitionEntities (Table of invoices belonging to benchmark)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Benchmark.md - Chunk 10
Select dbo.InvoiceEntityBenchmarkDefinitionEntities (Table of invoices belonging to benchmark)

Right Click -> Select Top 1000 Rows: Execute the following query and find the row intended to be deleted (! If there are some rows to delete, it is better to delete them one by one)

To delete the selected row -> Select dbo.InvoiceEntityBenchmarkDefinitionEntities -> Right click -> Script Table as -> Delete to -> New Query Editor Window

Delete the query in red box in the below picture

Replace below query

Execute it (The invoice id is deleted).

To check if the invoice deleted from benchmark successfully - Select dbo.InvoiceEntityBenchmarkDefinitionEntities - Right Click -> Select Top 1000 Rows: Execute the following query. The number of rows on the left down should be reduced.

Adding a document to a benchmark:

In this section, we intend to add a document to a benchmark which has already been created in Automation Database. In order to do this, we should go through the following steps:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Benchmark.md - Chunk 11
In this section, we intend to add a document to a benchmark which has already been created in Automation Database. In order to do this, we should go through the following steps:

1. Check if the invoice Id is in Automation Database:

Connect to the Automation database:

Select Databases -> BlumatixCaptureAutomation -> Tables -> dbo.Invoice Right Click -> Select Top 1000 Rows: Execute the following query and find Invoice Id in Automation Database (column: Id) that is related to Invoice Id in BCI database (column: InvoiceId)

If the invoice id is in Automation Database jump into step 4. If not, continue the following steps.

2. Find and copy details of the document from BCI database:

Connect to the BCI database:

Select Databases -> bcidb -> Tables -> dbo.Invoice

Right Click -> Select Top 1000 Rows

Execute the following query to find information of intended invoice.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Benchmark.md - Chunk 12
Connect to the BCI database:

Select Databases -> bcidb -> Tables -> dbo.Invoice

Right Click -> Select Top 1000 Rows

Execute the following query to find information of intended invoice.

The details that we need are in these three columns: 'Id', 'FileName', 'InvoiceDocumentHash'. Click on data in these three columns (which are shown in blue color in the above picture) -> right click -> copy.

3. Insert details to Automation Database:

Connect to the Automation database:

Select Databases -> BlumatixCaptureAutomation -> Tables -> dbo.Invoice

Right click -> Script Table as -> INSERT TO -> New Query Editor Window

To insert details to the opened window, the characters that are in red boxes should be deleted and be replaced with the copied data according to the below picture, and at the end be Executed.

4. Insert details to a benchmark that has been created:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Benchmark.md - Chunk 13
4. Insert details to a benchmark that has been created:

New invoices are created in Automation Database during the previous steps and now, they should be entered to the desired benchmark. - Select Databases -> BlumatixCaptureAutomation -> Tables -> dbo.BenchmarkDefinition - Right Click -> Select Top 1000 Rows: Find the name of the benchmark (column: Name) and its Id (column: Id) - Select dbo.InvoiceEntityBenchmarkDefinitionEntities -> Right click -> Script Table as -> INSERT TO -> New Query Editor Window - To insert invoice into the desired benchmark, the characters that are in red boxes should be deleted and be replaced with the data according to the below picture, and at the end be Executed:

Now, desired document is added to the intended benchmark.

To check if the document is added in benchmark successfully

Select dbo.InvoiceEntityBenchmarkDefinitionEntities

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Benchmark.md - Chunk 14
Now, desired document is added to the intended benchmark.

To check if the document is added in benchmark successfully

Select dbo.InvoiceEntityBenchmarkDefinitionEntities

Right Click -> Select Top 1000 Rows: Execute the following query. The number of rows on the left down should be increased.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Document-Labeling-Manual.md - Chunk 0
Please visit: labeling.bludelta.dev You will find the password to open the wiki in our Keeper password manager.

Update tasks for labeling.bludelta.dev

add table with basic information for each DetailType

Prepare and implement example pictures for Chapter 4.1.1

add SK, CZ DIC policy

update NO country information

format chapters currently part of chapter additional information

add chapters from de version missing in en version

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Labeln.md - Chunk 0
Tags: Allocation, label edit, Release, Available, Correct, Verified.

[[TOC]]

How to allocate a new package to label

AVV Check

Before we can allocate a new package to a Labeler we need to check if he or she is allowed to work on that package. Hence, they need to be accepted by the respective Customer. You can check if this is true in the following file:

Labeler Stammdaten

If you do not have the permission to view this file please contact our HR.

Allocate a new package

Connect with DB

Choose the bcidb

Choose the table dbo.User

Select (right click) "Edit Top 200 Rows"

Select an annotater (row) to allocate a package - Column AssignedLabels: LabelTypes the Annotater should label. - Column AssignedInvoices: Document Ids to label. You can assign a single document e.g. Id 1, or a range of documents Ids 1-10 or comma separated 1, 2, 3, 4, 5.

or use

UPDATE [bcidb].[dbo].[User] SET AssignedLabels = '33,34', AssignedInvoiceIds= '148835-149134' WHERE Id = '540'

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Labeln.md - Chunk 1
or use

UPDATE [bcidb].[dbo].[User] SET AssignedLabels = '33,34', AssignedInvoiceIds= '148835-149134' WHERE Id = '540'

If a new package was assigned to a labeler this information must be noted in the following file:

zugewiesenePakete.xlsx - please contact the Data Mgt. Team if you cant access the file.

Video Tutorial

Where do I find the label ids for the AssignedLabels column?

LabelTypes.xlsx - please contact the Data Mgt. Team if you cant access the file.

Why are invoices skipped?

Method: GetInvoiceIdsToSkip // get invoiceIds which the current user skipped with a comment (MetaInfo type = 1) and where the comment-creation-date is not older than 2 months

Labeln von Positionsdaten (Line Items)

Video Tutorial: https://blumatixconsultinggmbh.sharepoint.com/:v:/g/EeqSAhy_TmNGsUsUvmgv_VYBzUupcP6ks8QaXrchZQULWg?e=nizyKe English PDF: "C:\Data\OneDrive\Blumatix Intelligence GmbH\Machine Learning - Documents\Labelling\Anleitung zum Labeln\Labeling Line Items.pdf"

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Labeln.md - Chunk 2
Auswahl der Dokumente zum Labeln von Positionsdaten

Muss Kriterium:

noch nicht gelabeled (Tabelle LabelGroup: kein Type 4 (LineItemTable), 5 (LineItemHeader), 6 (LineItem), 7 LineItemBuffer)

Mögliche Kriterien:

Cluster: aus dem Cluster des Dokuments ist noch keine Dokument gelabeled (siehe Muss-Kriterum)

Cluster: aus dem Cluster des Dokuments sind erst 1, 2, n Dokumente gelabeled

Provider Auswahl: BDS oder Strabag oder ... (Tabelle Metainfo: Value = 'BDS')

Anzahl Seiten: <=2 oder 1 oder > 5 oder ... (Tabelle OcrResult: NumberOfPages <= 2)

Simple Query (no cluster information):

SELECT [MetaInfo].[Value] ,[InvoiceEntity_Id] ,[MetaInfo].[Created] FROM [bcidb].[dbo].[MetaInfo] LEFT OUTER JOIN [bcidb].[dbo].[LabelGroup] ON [MetaInfo].InvoiceEntity_Id = [LabelGroup].Invoice_Id Where Value = 'BDS' AND [LabelGroup].Id is null

Query with cluster information:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Labeln.md - Chunk 3
Query with cluster information:

SELECT ct.[Cluster_Id] ,ct.[Invoice_Id] ,ct.[InvoiceSource] ,ct.[ClusterSize] FROM [bcidb].[dbo].[ClusterTable] ct LEFT OUTER JOIN [bcidb].[dbo].[LabelGroup] lg ON (ct.[Invoice_Id] = lg.[Invoice_Id]) WHERE lg.[Id] IN (SELECT min(lg2.[Id]) FROM [bcidb].[dbo].[ClusterTable] ct2 INNER JOIN [bcidb].[dbo].[LabelGroup] lg2 ON (ct2.[Invoice_Id] = lg2.[Invoice_Id]) GROUP BY ct2.[Cluster_Id]) AND ct.[InvoiceSource] = 'BDS' AND ct.[Type] = 1 AND ct.[Invoice_Id] NOT IN (SELECT lg3.[Invoice_Id] FROM [bcidb].[dbo].[LabelGroup] lg3 WHERE lg3.[Type] IN (4, 5, 6, 7)) AND lg.[Type] IS NOT NULL ORDER BY ct.ClusterSize desc

Find inconsistent Line Item Tables

In the very beginning we had the strategy to label just 3 Line Items within a Lineitem Table, the first two and the last. Setting the correct number of line items in Label 104 enables to find out all those Line Item Tables, that are not fully labeled.

Query to find inconsistent Line Item Tabels

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Labeln.md - Chunk 4
Query to find inconsistent Line Item Tabels

mismatch of Number of Line Items and Label 104

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Labeln.md - Chunk 5
WITH LineItemCount as ( SELECT Invoice_Id as InvoiceEntity_Id, count(Invoice_Id) as NumberLabels FROM [bcidb].[dbo].[LabelGroup] where Type = 6 --and CreatedVia = 'LabelingTool' group by Invoice_Id --order by InvoiceEntity_Id ), LineItemCountLabel as ( SELECT InvoiceEntity_Id, sum(cast(Text as INT)) as NumberLabels FROM [bcidb].[dbo].[Label] WHERE Type = 104 group by InvoiceEntity_Id --order by InvoiceEntity_Id ), result as ( SELECT distinct LineItemCount.InvoiceEntity_Id, LineItemCount.NumberLabels FROM LineItemCount, LineItemCountLabel Where LineItemCount.NumberLabels != LineItemCountLabel.NumberLabels and LineItemCount.InvoiceEntity_Id=LineItemCountLabel.InvoiceEntity_Id ) SELECT distinct InvoiceEntity_Id FROM result EXCEPT ( -- exclude the bds_100 benchmark from training data SELECT Invoice.InvoiceId as InvoiceEntity_Id FROM [BlumatixCaptureAutomation].[dbo].[InvoiceEntityBenchmarkDefinitionEntities] as bmEnt, [BlumatixCaptureAutomation].[dbo].[Invoice] as Invoice where

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Labeln.md - Chunk 6
SELECT Invoice.InvoiceId as InvoiceEntity_Id FROM [BlumatixCaptureAutomation].[dbo].[InvoiceEntityBenchmarkDefinitionEntities] as bmEnt, [BlumatixCaptureAutomation].[dbo].[Invoice] as Invoice where bmEnt.BenchmarkDefinitionEntity_Id=20175 and Invoice.Id = bmEnt.InvoiceEntity_Id UNION /* don't use Ids that were already generated */ SELECT [InvoiceEntity_Id] FROM [bcidb].[db_owner].[DocumentGeneratedLineItemIds] UNION /* don't use bds accounting generated */ SELECT [InvoiceEntity_Id] FROM [bcidb].[db_owner].[BDSAccountingLineItemTrainingsDataCreatedByScript] )

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Labeln.md - Chunk 7
Delete LabelGroup

To delete a LabelGroup including its child LabelGroups and Labels use this SQL Query:

``` DECLARE @GivenLabelGroupId BIGINT = 357351 -- LabelGroup Id to delete DECLARE @DeletedLabelsCount INT, @DeletedGroupsCount INT

-- Table variable to store the LabelGroup ids in the hierarchy DECLARE @HierarchicalLabelGroups TABLE (Id BIGINT);

-- Populate the table variable with the LabelGroup ids WITH HierarchicalLabelGroups AS ( -- Base case SELECT Id FROM [dbo].[LabelGroup] WHERE Id = @GivenLabelGroupId

UNION ALL

-- Recursive member
SELECT lg.Id
FROM [dbo].[LabelGroup] lg
INNER JOIN HierarchicalLabelGroups hlg ON lg.LabelGroup_Id = hlg.Id

) INSERT INTO @HierarchicalLabelGroups (Id) SELECT Id FROM HierarchicalLabelGroups

-- Delete from Label table DELETE l FROM [dbo].[Label] l INNER JOIN @HierarchicalLabelGroups hlg ON l.LabelGroupEntity_Id = hlg.Id SET @DeletedLabelsCount = @@ROWCOUNT

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Labeln.md - Chunk 8
-- Delete from Label table DELETE l FROM [dbo].[Label] l INNER JOIN @HierarchicalLabelGroups hlg ON l.LabelGroupEntity_Id = hlg.Id SET @DeletedLabelsCount = @@ROWCOUNT

-- Delete from LabelGroup table DELETE FROM [dbo].[LabelGroup] WHERE Id IN (SELECT Id FROM @HierarchicalLabelGroups) SET @DeletedGroupsCount = @@ROWCOUNT

-- Display the count of deleted rows for Labels and LabelGroups SELECT 'Labels' AS EntityType, @DeletedLabelsCount AS DeletedCount UNION SELECT 'LabelGroups' AS EntityType, @DeletedGroupsCount AS DeletedCount

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Labeln.md - Chunk 9
```

Swap Label Types

To swap the label types of two labels use the following:

Verify which labels will be changed and their values SELECT [Id] ,[Type] ,[Text] ,[Left] ,[Top] ,[Width] ,[Height] ,[Available] ,[Created] ,[Modified] ,[Version] ,[CreatedBy_Id] ,[InvoiceEntity_Id] ,[Released] ,[Verified] ,[Correct] ,[CreatedVia] ,[LabelGroupEntity_Id] FROM [bcidb].[dbo].[Label] where (type = 60 or type = 62) and InvoiceEntity_Id in (91494,27084,27590) --example for lineitem posid/article number order by InvoiceEntity_Id, type

Swap the types: ``` USE [bcidb] GO

UPDATE [dbo].[Label] SET [Type] = CASE WHEN [Type] = 60 THEN 62 WHEN [Type] = 62 THEN 60 END, [Modified] = GETDATE() WHERE [Type] IN (60, 62) and InvoiceEntity_Id in (91494,27084,27590) GO

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Labeln.md - Chunk 10
```

Release Line Item Tables

Currently there is no autorelease and manual release mechanism for line items. There is a workaround that can be done for single documents.

Assign line item details and documents to release, just as for labeling

Start Labeling Tool

Enter Url with Id for document to release: https://labelingtool.bludelta.ai/Invoice/Release?Id=147412

Release button is shown

Check labels and press Release button

Update document Id in Url for next document

Label Edit

Using the following URL you can edit a label: http://ryzen7:7000/InvoiceBci/ManualResolve?type=35&delimitedInvoiceIds=%5B1%5D&isLabelEdit=true

type=xx -> specify the label type you would like to edit.

elimitedInvoiceIds=%5Bxx%5D -> specify the document id you would like to edit.

Label States

Available is completely independent and indicates whether this label exists on the document or not.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Labeln.md - Chunk 11
elimitedInvoiceIds=%5Bxx%5D -> specify the document id you would like to edit.

Label States

Available is completely independent and indicates whether this label exists on the document or not.

Released means approval, i.e., a certain quality standard has been met. Released = 1 also means that Correct and Verified are also 1.

Correct is also set for labels that are the same as the Released.

Verified is 1 when it was part of the quality assessment. If only Verified is set out of the three, it means it was incorrect.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\LabelTypes.md - Chunk 0
[[TOC]]

List of Label Types and Label Group Types LabelTypes.xlsx

Create new LabelType

Add to Enum InvoiceLabelType

Add new label type to enum InvoiceLabelType in Blumatix.Capture.InvoiceModel.Structure

There are two sections, the second is for custom labels and id starts with 200.

Check if any of the attributes is needed.

Add to Label Type document

Insert new value into bcidb Database: Insert it to table LabelType and/or table LabelGroupType

INSERT INTO [dbo].[LabelType] ([Id], [Name], [LabelGroupType_Id]) VALUES (125, 'TourId', NULL); or INSERT INTO [dbo].[LabelType] ([Id], [Name], [LabelGroupType_Id]) VALUES (139, 'AttentionName', 8); Refresh Label Types excel (open it in Excel Desktop to refresh): LabelTypesFromDb.xlsx

Update Labeling Tool

Add(copy) new Label Type to Labeling Tool Update InvoiceLabelType.ts in Blumatix.Capture.Website\Scripts\app (to copy the label definition should be refactored)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\LabelTypes.md - Chunk 1
Update Labeling Tool

Add(copy) new Label Type to Labeling Tool Update InvoiceLabelType.ts in Blumatix.Capture.Website\Scripts\app (to copy the label definition should be refactored)

Add new Label to German and English Resources Resources are found in Properties Resources.resx and Resources.en.resx. The key of the new label resources should start with InvoiceLabelType, follwed by label type name, e.g. InvoiceLabelTypeDachserSenderId.

Add GUI component to Labeling Tool Open LabelViewModelSchemaBuilder in Blumatix.Capture.Website.Models and decide where to add the new label. You see the options in BuildDefaultSchema() method. Open the method where the new label should be added and add the control that should be used for the new label.

Update Labeling wiki

Check Labeling Tool Assign a user the new label and start Labeling Tool locally. Create labels and check, if they are stored in Db. Check updated instruction tutorial.

Update Wiki Release Notes

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\LabelTypes.md - Chunk 2
Check Labeling Tool Assign a user the new label and start Labeling Tool locally. Create labels and check, if they are stored in Db. Check updated instruction tutorial.

Update Wiki Release Notes

Deploy labeling Tool (see https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/965/Bludelta-Labeling-Tool-Deployment )

Update Dashboard

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\LabelTypes.md - Chunk 3
Deploy labeling Tool (see https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/965/Bludelta-Labeling-Tool-Deployment )

Update Dashboard

Solution BlumatixCaptureAutomationDashboard, Project Blumatix.Capture.Automation.Dashboard - Add new Label Update enum InvoiceLabelType in Blumatix.Capture.Automation.Dashboard.Shared.Enums - Add new Label to German and English Resources Resources are found in Domain/Language folder. The key of the new label resources should start with Label_ followed by label type name, e.g. Label_DachserSenderId. - Check Dashboard open Dashboard from VS and try Label Edit to see the new LabelType (Menu Invoices/Labels Edit) - Update Wiki Release Notes - Deploy Dashboard ( see https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/967/Bludelta-Dashboard-Deployment )

Update Phönix

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\LabelTypes.md - Chunk 4
Update Phönix

To enable Autorelease with new Label Types you have to Deploy Phönix (see https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/963/Ph%C3%B6nix-Deployment)

Update BluDoc

Add new label type and label group to BluDocConstants.

Update BluDocFactory.

Add new Type if necessary

Update BluDoc schema definitions wiki for each document type.

Update LabelConverter

Label Converter has to be updated with mapping of BluDoc DocumentEssential Label and it InvoiceLabelType. Unfortunately we have currently two LabelConverters, one in the Normalizer (convert from Label to BluDoc) and another one in the LabelCreator (convert from BluDoc to Label).

Convert from Label to BluDoc (Normalizer)

Add new Label or LabelGroup Type to labelConverterConfig.json in project Blumatix.DataCollection.Normalizer in folder LabelConverter.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\LabelTypes.md - Chunk 5
Convert from Label to BluDoc (Normalizer)

Add new Label or LabelGroup Type to labelConverterConfig.json in project Blumatix.DataCollection.Normalizer in folder LabelConverter.

If the handling is standard, it is done. If not, update existing special handling (like Contact) or implement new special handling.

Convert from BluDoc to Label (LabelCreator)

Update GetLabelType and GetLabelGroupType methods in LabelConverter class in project Blumatix.LabelCreator.

If the handling is standard, it is done. If not, update existing special handling (like Contact) or implement new special handling.

If the new label is a document label (no location) it has to be added to the IsDocumentDetail in BluDocForLabelsManager class.

Add to Capture Automation Database

To be able to create Benchmarks with the new label type it has to be added to InvoiceDetailType table in BlumatixCaptureAutomation database:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\LabelTypes.md - Chunk 6
Add to Capture Automation Database

To be able to create Benchmarks with the new label type it has to be added to InvoiceDetailType table in BlumatixCaptureAutomation database:

INSERT INTO [dbo].[InvoiceDetailType] ([Name],[Version]) VALUES ('PaymentReference.Id',0) May be you have to add two spellings: BluDoc Label and old label enum (without ".")

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Migrate-BciDb.md - Chunk 0
Code First: Add new class(es)

Open Blumatix.Capture.Invoice.DB Add class(es) to Blumatix.Capture.Invoice.DB.Model - name ending with Entity - check for correct EntityBase base class - add navigation properties

Create und publish new Blumatix.Capture.Invoice.DB.Model nuget package.

Add new class(es) to Context

Update Blumatix.Capture.Invoice.DB.Model nuget package to latest version in Blumatix.Capture.Invoice.DB

Add a line like public virtual DbSet<PackageTagEntity> PackageTag { get; set; } to class BciContect in Blumatix.Capture.Invoice.DB

Create Migration

Open project file of Blumatix.Capture.Invoice.DB project. Uncomment PropertyGroup for migration (setting TargetFramework to netcoreapp3.1)

```

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Migrate-BciDb.md - Chunk 1
```

```

Unload Blumatix.Capture.Invoice.DB.Tests project (not compatible).

Add connection string for Db in BciContext (get from Keeper) - start with BciDb_Dev to test and then use BciDb in production.

Use Package Manager Console to execute migration commands: - Add-Migration

Test database changes

Change connection string for production Db - Update-Database

Undo setting of connection string. Undo change in project file of Blumatix.Capture.Invoice.DB project. Load Blumatix.Capture.Invoice.DB.Tests project again.

New Blumatix.Capture.Invoices.DB nuget package

Update package number of Blumatix.Capture.Invoices.DB project Build and publish new nuget package

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Management-Wiki\How-To\Upload-documents-via-learn.bludelta.ai.md - Chunk 0
This wiki shows how to upload documents via learn.bludelta.ai if you want to specify a "CompanyName":

Python

```python import requests

Set the endpoint URL

url = "http://104.45.79.166/package-uploader/v1/Package"

Set the headers

headers = { "X-ApiKey": "+GW0eDt4E72U/i0ZJcJKKLZ5LWa3gasMbpnufOGAwhFbvSQ4phapOQV/jIgR/Ej6FBGjnMI4nHhHdrZ14AEWsg==" }

Set the request body as multipart/form-data

files = { "Package": ("filename.zip", open(r"C:\Users\rudi\Downloads\README.zip", "rb"), "application/zip"), "DocumentType": (None, ""), "CompanyName" : (None, "MyCompany") }

Make the request

response = requests.post(url, headers=headers, files=files)

Print the response content

print(response.content) ```

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Active-Learning.md - Chunk 0
Where we wanna go to

a) Using difference of model-confidence from first to second guess

b) Using entropy of model-confidence

c) Using a model assembly to get multiple predictions and using the avg score. The model assembly can consist of various model architectures or different training sets, e.g. three models splitting the dataset into 3 parts, using 2/3 of the data for each (not sure about how much overlap is good, point for discussion). This is done to prevent the active learning from converging into a local minima.

d) More complex ideas are to use Monte-Carlo Dropout and/or Stochastic weight modelling and/or Generalized Chernoff (Just heard the terms mentioned, would need to research more if those even make sense for our usecase).

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Active-Learning.md - Chunk 1
e) Best case scenario is to retrain the model after each datapoint, that has been labeled, and then to rerun the predictions over the whole dataset (this is limited by the resources we have at hand). For us an approach stochastic approach would make more sense, e.g. running predictions for 1000 random docs => Labeling the worst 50 => retrain model assembly => pick 950 random + the next 50 worst from previous run and make predictions on them => reiterate

f) Possible to use high-confidence predictions to automatically generate labels. Might be useful to have a yes/no tool for labeling, to check quickly by hand, which one's are really okay, so we can save the labels to the db.

Src: https://www.youtube.com/watch?v=W2bJH0iXTKc&t=29s

Src: https://www.youtube.com/watch?v=o-g3XmeNNRE

Resources

Human-In-The-Loop Machine Learning: Active Learning and Annotation for Human-Centered AI

Git Repo for 'Human-In-The-Loop'

Konfuzio: Active learning for data-centric AI

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Active-Learning.md - Chunk 2
Resources

Human-In-The-Loop Machine Learning: Active Learning and Annotation for Human-Centered AI

Git Repo for 'Human-In-The-Loop'

Konfuzio: Active learning for data-centric AI

Mphasis: Active Learning for Building and Maintaining High Performing Machine Learning Models

Introduction to Active Learning

Active Learning in Machine Learning

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Kooperation-FH.md - Chunk 0
Introduction

Since LLMs do not include prior knowledge about areas, we want to add the context of areas and position to improve LLM results on semi structured documents.

First step is to train a model to generate layout information (collection of areas/segments) of a document. It is not clear, if semantic information is needed for the segments to be helpful for the LLM. So we start with semantic segments for invoices, which can be abstracted to just boxes if semantic information is not needed.

Invoice Layout

Designing an invoice layout involves organizing the content into segments that are clear, logical, and functional. Here's a detailed layout suggestion that segments an invoice into distinct sections, each defined by bounding boxes to keep the information organized:

Header

Purpose: Displays the business name and invoice title. Contents: Business name at the top, followed by "Invoice" or a similar term prominently displayed. Location: Top of the page, spanning the full width.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Kooperation-FH.md - Chunk 1
Logo

Purpose: Reinforces the brand. Contents: Business logo. Location: Upper left corner within the header or just below the header, depending on design preference.

Contacts

Purpose: Provides both sender's and the recipient's contact information. Contents: Business name, address, phone number, email, and website, ... Location: Either side by side on the top (below the header) or your contact on the left and the recipient's on the right.

Invoice Details

Purpose: Specifies invoice-specific information. Contents: Invoice number, date of issue, and payment due date. Location: Top right, below the header or next to the contacts section.

Line Item Table

Purpose: Details the products or services provided. Contents: Description, quantity, unit price, total, ... for each line item. Location: Below the contacts and invoice details, occupying the central part of the layout.

VAT/Table Summary

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Kooperation-FH.md - Chunk 2
VAT/Table Summary

Purpose: Breaks down taxes and totals. Contents: Applicable tax rates, subtotal before tax, tax amount, and grand total. Location: Below the line item table, spanning the full width.

Payment Information

Purpose: Instructs how to make the payment. Contents: Payment methods accepted, payment terms, and bank account details or payment links. Location: Below the VAT/table summary or in a separate section to the right or left, depending on the layout.

Footer

Purpose: Provides additional information or legal text. Contents: Copyright notice, confidentiality note, thank you message, or other legal disclaimers. Location: Bottom of the page, spanning the full width.

Samples

Sample 1

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Kooperation-FH.md - Chunk 3
Proposal of ChatGPT: 1. Header Location: At the very top of the invoice, there is a slogan or tagline that says "Seit 1956 Ihr Fachhändler im Nürnberger Land!" This acts as a header. 2. Logo Location: Just below the header, in the center, there is an orange emblem that serves as the company logo. 3. Contacts Location: On the top right side, the company's contact information is provided, including the name "Bedachungsfachhandel Lutz", address, telephone number, and email address. 4. Invoice Details Location: Below the contact information on the left side, this section includes the invoice number ("Rechnungs Nr."), invoice date ("Rechnungsdatum"), service date ("Leistungsdatum"), customer number ("Ihre Kunden-Nr."), the company’s tax identification number ("Unsere USt-IdNr."), and delivery slip number ("Lieferschein-Nr."). 5. Line Item Table Location: In the middle section, a table lists out each line item with details such as article number ("Art.-Nr."), quantity ("Menge"), unit

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Kooperation-FH.md - Chunk 4
slip number ("Lieferschein-Nr."). 5. Line Item Table Location: In the middle section, a table lists out each line item with details such as article number ("Art.-Nr."), quantity ("Menge"), unit ("Einh."), description ("Bezeichnung"), unit price ("Einz."), discount rate ("Rab. %"), and total price ("Ges. Preis"). 6. VAT/Table Summary Location: Just below the line item table, this section summarizes the financial details including the net value of goods ("Warenwert"), value-added tax ("MwSt. 19%"), and the total invoice amount ("Rechnungsbetrag"). 7. Payment Information Location: At the bottom of the invoice, within the footer section, there are bank details provided which include the bank's IBAN, BIC, and the name and location of the bank. This section can be considered as payment information as it details how payment should be made. 8. Footer Location: The very bottom of the invoice includes a note on the left about the terms of payment and retention of title until full payment is

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Kooperation-FH.md - Chunk 5
as it details how payment should be made. 8. Footer Location: The very bottom of the invoice includes a note on the left about the terms of payment and retention of title until full payment is received. Bank details are also included in this section. Each of these segments is properly sectioned off and would correspond to the standard segments you've described for an invoice layout.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Kooperation-FH.md - Chunk 6
Sample 2

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Kooperation-FH.md - Chunk 7
Proposal of ChatGPT: 1. Header Location: The word "Rechnung" at the very top of the page serves as the header of the invoice. 2. Logo Location: The "1&1" logo is located in the top right corner of the invoice. 3. Contacts Location: The contact information for the recipient is on the left side under the header, which includes the name and address of the recipient. The contact information for the issuer (1&1 Internet AG) is on the top right, along with the address. 4. Invoice Details Location: To the right of the recipient's contact information, details such as the invoice date ("Rechnungsdatum"), invoice number ("Rechnungsnummer"), contract number ("Vertragsnummer"), customer number ("Kundennummer"), and VAT ID ("USt-IdNr.") are provided. 5. Line Item Table Location: Center of the page, under the section titled "Ihre Rechnung (1&1 Virtual-Server XL)", which lists services provided ("Die Leistungen im Überblick") with the tariff, units, and cost (including VAT) for each item. 6.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Kooperation-FH.md - Chunk 8
under the section titled "Ihre Rechnung (1&1 Virtual-Server XL)", which lists services provided ("Die Leistungen im Überblick") with the tariff, units, and cost (including VAT) for each item. 6. VAT/Table Summary Location: Below the line item details, there's a section that includes the subtotal ("Zwischensumme (Netto)"), the VAT rate ("+ Mehrwertsteuer (0.00%)"), and the total amount due ("Zu zahlender Betrag"). 7. Payment Information Location: In the footer section, there's a note that explains the direct debit authorization for payment ("Der Rechnungsbetrag wird wie vereinbart von Ihrem Konto Nr... abgebucht."). 8. Footer Location: At the very bottom of the invoice, there are additional details regarding the company's executive board ("Vorstand"), the location of registration, and bank details (IBAN and BIC). These segments are consistent with the typical layout of an invoice, with each segment clearly delineated and containing the relevant information.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview.md - Chunk 0
[[TOSP]]

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Paper-Collection.md - Chunk 0
General Knowledge

Formal Algorithms for Transformer. The most important components of Transformer architecture as pseudocode explained: https://arxiv.org/abs/2207.09238

Model Architecture

LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding https://arxiv.org/abs/2104.08836

Donut: Document Understanding Transformer without OCR https://arxiv.org/abs/2111.15664

A Generalization of Transformer Networks to Graphs: https://arxiv.org/abs/2012.09699 Transformers have proven their value in processing text, images, and other data types. This work makes them more useful with graphs. Although the Graph Transformer model fell short of the best graph neural network, this work establishes a strong baseline for further work in this area. https://info.deeplearning.ai/the-batch-machine-learning-for-martian-drone-regulators-punish-meta-for-algorithmic-bias-transformers-conquer-graphs

Model Performance

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Paper-Collection.md - Chunk 1
Model Performance

FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence https://arxiv.org/abs/2001.07685v2

Big Self-Supervised Models are Strong Semi-Supervised Learners https://arxiv.org/abs/2006.10029 training method for image recognition that outperformed the state of the art in self-supervised learning and beat fully supervised models while using a small fraction of the labels. The new work extends their earlier SimCLR.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Paper-Collection.md - Chunk 2
Convolutional Xformers for Vision https://arxiv.org/abs/2201.10271 The amounts of computation and memory required by a transformer’s self-attention mechanism rises quadratically with the size of its input, while the amounts required by linear attention scale linearly. Using linear attention instead should boost efficiency. Furthermore, self-attention layers process input images globally, while convolutions work locally on groups of adjacent pixels. So adding convolutions should enable a transformer to generate representations that emphasize nearby pixels, which are likely to be closely related. Convolutions offer additional benefits, too, such as translation equivariance (that is, they generate the same representation of a pattern regardless of its location in an image).

Small Datasets

Vision Transformer for Small-Size Datasets https://arxiv.org/abs/2112.13492

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Paper-Collection.md - Chunk 3
Small Datasets

Vision Transformer for Small-Size Datasets https://arxiv.org/abs/2112.13492

GROKKING: GENERALIZATION BEYOND OVERFITTING ON SMALL ALGORITHMIC DATASETS https://mathai-iclr.github.io/papers/papers/MATHAI_29_paper.pdf As the models trained, validation accuracy rose, fell, and — after the number of training steps continued to rise by a factor of 1,000 — rose a second time. (In the case of modular division, validation accuracy improved from nearly 5 percent to nearly 100 percent). In experiments using reduced datasets, the authors found that the smaller the training set, the more training was needed to achieve the second increase. For instance, when training on 30 percent as many examples, roughly 45 percent more training steps were required. This work provides evidence that we've been mistaken about the meaning of overfitting. Models can continue to learn after they overfit and can go on to become quite capable.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Paper-Collection.md - Chunk 4
DeiT III: Revenge of the ViT https://arxiv.org/abs/2204.07118 Vision Transformers (ViTs) are overtaking convolutional neural networks (CNN) in many vision tasks, but procedures for training them are still tailored for CNNs. The CNN and transformer architectures differ. For instance, when processing an image, a CNN works on one group of pixels at a time, while a transformer processes all pixels simultaneously. Moreover, while the computational cost of a CNN scales proportionally to input size, a transformer’s self-attention mechanism requires dramatically more processing as input size increases. Training recipes that take these differences — and other, less obvious ones — into account should impart better performance.

Unlabelled Data

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Paper-Collection.md - Chunk 5
Unlabelled Data

Segmented Images, No Labeled Data https://arxiv.org/abs/2203.08414 A feature extractor (the transformer DINO, which was pretrained in an unsupervised manner on ImageNet) generated features for each pixel of input images. A vanilla neural network trained on COCO-Stuff refined the features into a representation of each pixel.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Active-Learning\Active-Learning-LineItems-v0.1.md - Chunk 0
13318

Current Architecture

https://whiteboard.office.com/me/whiteboards/p/c3BvOmh0dHBzOi8vYmx1bWF0aXhjb25zdWx0aW5nZ21iaC1teS5zaGFyZXBvaW50LmNvbS9wZXJzb25hbC9wX2dyYWZlbmRvcmZlcl9ibHVtYXRpeF9hdA%3d%3d/b!_C4TGKWX90auS-e04n6bKah6r3z5f_tIo0hDcS7hnrkMICSXUwnkSLELzlgDjOwx/01LGJQVTQCS34N7547ZNG34OFGLQFLMUL4

Pipeline

We find the productive kubelfow pipeline at Kubeflow and the standard directory on the NAS for the configs and in- and output at \\nas-01\TrainingsData\active_learning

BciDb-DataSampler

Config

There are two ways to set the Ids that are used for sampling

Via database views

Via a text file

If a valid txt file is given, it will be used instead of the view.

A comma-separated list of views that should be used, that are Union merged. Normally only use one. bcidb_id_view: ActiveLearningClusterLineItemIds, ActiveLearningRandomLineItemIds

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Active-Learning\Active-Learning-LineItems-v0.1.md - Chunk 1
A comma-separated list of views that should be used, that are Union merged. Normally only use one. bcidb_id_view: ActiveLearningClusterLineItemIds, ActiveLearningRandomLineItemIds

Path to a txt file for ids, this is a new line separate list, so you can just copy and paste Ids from the database. path_to_relevant_invoice_ids_for_sampling: \ //nas-01/TrainingsData/active_learning/relevant_bcidb_invoive_entity_ids.txt

The integer value of the sample size that will be drawn from the given document ids number_of_random_ids_to_sample: 2000

A comma-separated list of label ids. Lookup in the user DB to get all doc ids that are assigned with those label ids. label_ids_to_filter_cause_already_assigned: 51,52,53,54,55,56,57,58,59,60

A comma-separated list of languages. Lookup in the OcrResult DB to filter for only those languages. languages_to_filter: de, en

Process

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Active-Learning\Active-Learning-LineItems-v0.1.md - Chunk 2
A comma-separated list of languages. Lookup in the OcrResult DB to filter for only those languages. languages_to_filter: de, en

Process

Since we do not have a Workflow-Engine yet, we have decided to call the dev-sdk to get the sdk-response with scores. In the future, the Workflow-Engine should be used to call OCR-NER-Typhon to get all the information needed for more sophisticated active learning, like margin or entropy.

The Sampler gets a sample of ids (either from a file or from a view) to use.

Those ids are then filtered by the given language(s)

Those ids are then filtered by the ids already assigned for the given label ids.

Then x ids from that sample are randomly drawn.

For each id the document is pulled from the database and then sent to the dev-sdk.

A dictionary of id: response is produced and saved at the end for the sampled x ids.

Output

A dictionary with id:sdk-response, is used as input for the active learner component. id_response_dict.json

ActiveLearner

Input

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Active-Learning\Active-Learning-LineItems-v0.1.md - Chunk 3
Output

A dictionary with id:sdk-response, is used as input for the active learner component. id_response_dict.json

ActiveLearner

Input

A dictionary with id:sdk-response, the automatic output of the sampler. id_response_dict.json

Config

How many ids of the ranked documents are shown? If this is the same as the sample size, then you get all of them as a ranked list. number_of_ids_for_labeling: 50

Name of the output file. output_file_path_for_ids: next_ids_for_lineitem_labeling_sorted.tsv

Process

Only LineItems are looked up for now.

The mean of the scores of the LineItemDetails and the Regression Score of the LineItem is calculated.

Then the mean of the lower 50%-scored of the LineItems per document is calculated. This is done to get a bigger emphasis on the lower scores => If one LineItem of a LineItemTable is wrong the whole table is wrong.

RelevantForTrainingScore is calculated by 1 - mean of lower fifty percent and can be expanded in the future.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Active-Learning\Active-Learning-LineItems-v0.1.md - Chunk 4
RelevantForTrainingScore is calculated by 1 - mean of lower fifty percent and can be expanded in the future.

The scores are then sorted and the x-highest ranked are then written to the output file.

Output

A tsv file with the columns id, RelevantForTrainingScore, and LabelType. The LabelType always says LineItems for now but will be used for the various label types in the future.

Design (not yet fully automated)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Classifier.md - Chunk 0
Document Classifier - Classifies Documents into Korean Workflow / Normal Workflow

15868

17323

Design

Train-Dataset

The pdfs are converted to images via the phoenix action

The pure trainingsdata is found in \\nas-01\TrainingsDataExt4\doc_classifier\data - those categories are then packed together locally on the training machine into two categories easyocr and nuance for model training.

Korean Id List provided by Hasch: Korean Id List.txt - this is only for Korean and not for Chinese. Chinese documents were provided by Klemens via NAS \\nas-01\CustomerData\Dachser\wave_4\dachser_wave4_data_delivery_2023-07-07\CN\CN_training_3

The dataset is divided into three segments: Training (80%), Validation (10%), and Testing (10%). Please note that the dataset has not been cluster cleaned; it contains all the data gathered.

During the training phase, the following data augmentation techniques are applied:

Images are resized to the smallest possible size of 768x768.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Classifier.md - Chunk 1
During the training phase, the following data augmentation techniques are applied:

Images are resized to the smallest possible size of 768x768.

Data is normalized for consistent scale across features.

Images are randomly tilted by up to 10 degrees to simulate different viewing angles.

The data is randomly translated up to a factor of 0.1.

Images are sheared by up to 5 degrees for perspective distortion.

Images are randomly rotated by 0, 90, 180, or 270 degrees to diversify the dataset.

Finally, the images are randomly cropped to their original sizes.

The training data is randomly stratified before each epoch.

Model and Training Parameters

The model employed is a Resnet18 model initialized with default pretrained weights. The training phase is controlled by a learning rate of 0.001 and momentum of 0.9.

Training proceeds until there's no improvement in the validation set for 5 consecutive epochs or a maximum of 100 epochs have been reached, whichever comes first.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Classifier.md - Chunk 2
Training proceeds until there's no improvement in the validation set for 5 consecutive epochs or a maximum of 100 epochs have been reached, whichever comes first.

Optimizer: Adadelta. This is an extension of Adagrad that seeks to reduce its aggressive, monotonically decreasing learning rate. Instead of accumulating all past squared gradients, Adadelta restricts the window of accumulated past gradients to a fixed size w. The sum of gradients is recursively defined as a decaying average of all past squared gradients. The running average E[g^2]_t at time step t then depends only on the previous average and the current gradient. We set w to be the running average's decay factor. The benefit of Adadelta is that it doesn't require an initial learning rate setting, unlike most other optimizers. The learning rate dynamically adapts over time.

Benchmark

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Classifier.md - Chunk 3
Benchmark

For benchmarking purposes, the Test set is used. However, the Test set is not merely a random 10% subset of the dataset. Instead, it's composed of the cluster masters from the entire dataset, leading to a balance between the training and test sets. This approach ensures that the test data provides a representative and rigorous benchmark for model performance.

Results

Find optimal resolution => 448px

448 pixels

Epoch 52 - Full: 2583 - Train: 1266, Val: 258, Test: 1059 - Patience 7

Precision Recall F1-score Support Korean 0.94 0.98 0.96 859 Standard 0.88 0.74 0.80 200 accuracy 0.93 1059 macro avg 0.91 0.86 0.88 1059 weighted avg 0.93 0.93 0.93 1059

Korean Standard Korean 839 20 Standard 52 148

400 pixels

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Classifier.md - Chunk 4
Korean Standard Korean 839 20 Standard 52 148

400 pixels

Epoch 52 - Full: 2583 - Train: 1266, Val: 258, Test: 1059 - Patience 7 | | Precision | Recall | F1-score | Support | |---------------|-----------|--------|----------|---------| | Korean | 0.94 | 0.95 | 0.94 | 859 | | Standard | 0.76 | 0.73 | 0.75 | 200 | | accuracy | | | 0.91 | 1059 | | macro avg | 0.85 | 0.84 | 0.84 | 1059 | | weighted avg | 0.90 | 0.91 | 0.91 | 1059 |

Korean Standard Korean 812 47 Standard 53 147

350 pixels

Epoch 42 - Full: 2583 - Train: 1266, Val: 258, Test: 1059 - Patience 7

Precision Recall F1-score Support Korean 0.95 0.87 0.91 859 Standard 0.59 0.80 0.68 200 accuracy 0.86 1059 macro avg 0.77 0.84 0.80 1059 weighted avg 0.88 0.86 0.87 1059

Korean Standard Korean 750 109 Standard 40 160

512 pixel

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Classifier.md - Chunk 5
Korean Standard Korean 750 109 Standard 40 160

512 pixel

Epoch 42 - Full: 2583 - Train: 1266, Val: 258, Test: 1059 - Patience 7 | | Precision | Recall | F1-score | Support | |---------------|-----------|--------|----------|---------| | Korean | 0.96 | 0.93 | 0.95 | 859 | | Standard | 0.74 | 0.81 | 0.78 | 200 | | accuracy | | | 0.91 | 1059 | | macro avg | 0.85 | 0.87 | 0.86 | 1059 | | weighted avg | 0.92 | 0.91 | 0.91 | 1059 |

Korean Standard Korean 803 56 Standard 37 163

650 pixels

Epoch 22 - Full: 2583 - Train: 1266, Val: 258, Test: 1059 - Patience 7 | | Precision | Recall | F1-score | Support | |---------------|-----------|--------|----------|---------| | Korean | 0.96 | 0.87 | 0.92 | 859 | | Standard | 0.61 | 0.85 | 0.71 | 200 | | accuracy | | | 0.87 | 1059 | | macro avg | 0.79 | 0.86 | 0.81 | 1059 | | weighted avg | 0.90 | 0.87 | 0.88 | 1059 |

Korean Standard Korean 750 109 Standard 30 170

768 pixels

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Classifier.md - Chunk 6
Korean Standard Korean 750 109 Standard 30 170

768 pixels

Epoch 25 - Full: 2583 - Train: 1266, Val: 258, Test: 1059 - Patience 7 | | Precision | Recall | F1-score | Support | |---------------|-----------|--------|----------|---------| | Korean | 0.96 | 0.86 | 0.91 | 859 | | Standard | 0.59 | 0.86 | 0.70 | 200 | | accuracy | | | 0.86 | 1059 | | macro avg | 0.77 | 0.86 | 0.80 | 1059 | | weighted avg | 0.89 | 0.86 | 0.87 | 1059 |

Korean Standard Korean 737 122 Standard 28 172

850 pixel

Epoch 54 - Full: 2583 - Train: 1266, Val: 258, Test: 1059 - Patience 7

Precision Recall F1-score Support Korean 0.93 0.87 0.90 859 Standard 0.57 0.72 0.64 200 accuracy 0.85 1059 macro avg 0.75 0.80 0.77 1059 weighted avg 0.86 0.85 0.85 1059

Korean Standard Korean 751 108 Standard 55 145

Result for random test set (train data and test data intersect here)

448 pixel

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Classifier.md - Chunk 7
Korean Standard Korean 751 108 Standard 55 145

Result for random test set (train data and test data intersect here)

448 pixel

Precision Recall F1-score Support Korean 0.94 0.94 0.94 249 Standard 0.95 0.95 0.95 294 accuracy 0.94 543 macro avg 0.94 0.94 0.94 543 weighted avg 0.94 0.94 0.94 543

Korean Standard Korean 234 15 Standard 16 278

Finally the model is trained with all data - patience 11 (train data and test data intersect here)

2583 Trainingdata !!! 194 in directory "Unsure" - those are still waiting to be labeled, depending on which workflow they return better results at.

Cluster Master Test

Precision Recall F1-score Support Korean 0.96 0.98 0.97 859 Standard 0.91 0.81 0.85 200 accuracy 0.95 1059 macro avg 0.93 0.90 0.91 1059 weighted avg 0.95 0.95 0.95 1059

Korean Standard Korean 842 17 Standard 38 162

Random Test Set

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Classifier.md - Chunk 8
Korean Standard Korean 842 17 Standard 38 162

Random Test Set

Precision Recall F1-score Support Korean 0.93 1.00 0.96 249 Standard 1.00 0.94 0.97 294 accuracy 0.97 543 macro avg 0.96 0.97 0.96 543 weighted avg 0.97 0.97 0.97 543

Korean Standard Korean 248 1 Standard 18 276 3

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 0
[[TOC]]

Stories August-September 2024

further todos / ideas

optimize prompt further (maybe just a one word answer: [1, 2, 3, ..., null])

overfit resnet model?

higher resolution?

train with deeper resnets

train vit model where pages are merged next to each other, instead of layers

calc entropies and analyse training data

calc entropies and analyse benchmark

save whole responses of the llm

analyse bm mistakes of the llm (e.g. why is result files correct so high, if other metrics are worse - what characteristics do these docs have?)

finetune llm

trainingsdata pipeline

trainings pipeline

Story 22375

22375

Finished

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 1
finetune llm

trainingsdata pipeline

trainings pipeline

Story 22375

22375

Finished

From the results, comparing the threshold 0.75, that we deployed in the last spring => Accuracy goes from 84.80% to 85.56% - an increase of 0.76%. About 27% are processed by the LLM, this means for the others the LLM return a null value, meaning there was probably no clear page indication. We basically see, that the resnet model also learns to see the page numbers pretty well and that the hard one's are those pages, where we have basically no page indication. For me it looks like, that we should rather get more training data and to get the sliding window approach working with a model.

GPT 3.5-turbo seems to be enough for this task - 4o doesn't really provide better result (we would need to try out a multimodal approach) - many of the pages just don't have any page no

doc splitter resnet service was updated to not give static response for one pagers

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 2
doc splitter resnet service was updated to not give static response for one pagers

updated so that the llm only predicts page number - if none is found it is send to resnet model

Results

Average tokens per Page for window size 50 (gpt-4o): - 750 prompt Tokens - 32.3 completion Tokens

Average tokens per Page for window size 1 (gpt-35): - 2011 prompt Tokens - 24.2 completion Tokens

Max Window sizes, so you don't run into token limit - GPT 4o windows size is about max 52 pages - GPT 3.5-turbo window size is about max 4-6 pages - I built a mechanism that resends a smaller window size, if it hits the token limit, but this is still bad as it is an extra request.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 3
Model Name Test Set TP FP TN FN Accuracy Precision Recall F1 Score processed by LLM gpt35-prompt-v3 (window size 1, 2 OOM Exceptions) result global 349 3 2210 718 78.02 % 99.15 % 32.71 % 49.19 % result files correct 2 50 N/A N/A 3.85 % N/A N/A N/A gpt4o-prompt-v3 (window size 52, 2 OOM Exceptions) result global 392 43 2205 700 77.75 % 90.11 % 35.90 % 51.34 % result files correct 6 48 N/A N/A 11.11 % N/A N/A N/A gpt35-prompt-v3-plus-resnet (t=0.5, window size 1, 2 OOM Exceptions) result global 918 189 2059 174 89.13 % 82.93 % 84.07 % 83.49 % 27.07% result files correct 20 34 N/A N/A 37.04 % N/A N/A N/A gpt35-prompt-v3-plus-resnet (t=0.5, window size 1) result global 1033 189 2059 174 89.49 % 84.53 % 85.58 % 85.06 % 26.16% result files correct 22 34 N/A N/A 39.29 % N/A N/A N/A (t=0.6) result global 952 137 2111 255 88.65 % 87.42 % 78.87 % 82.93 % result files correct 21 35 N/A N/A 37.50 % N/A N/A N/A (t=0.7) result global 813 59 2189 394 86.89 % 93.23 % 67.36 % 78.21 % result files

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 4
global 952 137 2111 255 88.65 % 87.42 % 78.87 % 82.93 % result files correct 21 35 N/A N/A 37.50 % N/A N/A N/A (t=0.7) result global 813 59 2189 394 86.89 % 93.23 % 67.36 % 78.21 % result files correct 20 36 N/A N/A 35.71 % N/A N/A N/A (t=0.75) result global 737 29 2219 470 85.56 % 96.21 % 61.06 % 74.71 % result files correct 18 38 N/A N/A 32.14 % N/A N/A N/A (t=0.8) result global 654 8 2240 553 83.76 % 98.79 % 54.18 % 69.98 % result files correct 16 40 N/A N/A 28.57 % N/A N/A N/A (t=0.9) result global 531 2 2246 676 80.38 % 99.62 % 43.99 % 61.03 % result files correct 11 45 N/A N/A 19.64 % N/A N/A N/A gpt4o-prompt-v3-plus-resnet result global 803 50 2198 404 86.86 % 94.14 % 66.53 % 77.96 % 27.99% (t=0.75, window size 52) result files correct 24 32 N/A N/A 42.86 % N/A N/A N/A (t=0.8) result global 734 33 2215 473 85.35 % 95.70 % 60.81 % 74.37 % result files correct 21 35 N/A N/A 37.50 % N/A N/A N/A (t=0.9) result global 588 28 2220 619 81.27 % 95.45 % 48.72 % 64.51 % result files

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 5
result global 734 33 2215 473 85.35 % 95.70 % 60.81 % 74.37 % result files correct 21 35 N/A N/A 37.50 % N/A N/A N/A (t=0.9) result global 588 28 2220 619 81.27 % 95.45 % 48.72 % 64.51 % result files correct 16 40 N/A N/A 28.57 % N/A N/A N/A gpt-4o-prompt-v5-resnet-mulitmodal result global 1690 10 295 911 89.50 % 98.91 % 75.54 % 85.66 % 74.57% result files correct 20 35 N/A N/A 36,36 % N/A N/A N/A gpt-4o-prompt-v7-resnet result global 924 6 2242 283 91,64 % 99,35 % 76,55 % 86,48 % 58.58% result files correct 24 32 N/A N/A 42,86 % N/A N/A N/A

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 6
Model Selection for PDF Splitting Task

Key Metrics to Consider:

Precision: Indicates how many of the predicted splits were correct. High precision is crucial for minimizing false positives, which lead to unnecessary splits.

Recall: Measures how many of the actual splits the model captured. High recall is important to avoid missing true split points, minimizing false negatives.

F1 Score: Provides a balance between precision and recall. The higher the F1 score, the better the trade-off.

False Positives (FP) and False Negatives (FN): Lower FP and FN values reduce the need for manual corrections in both over-splitting (FP) and under-splitting (FN).

Analysis of the Models:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 7
False Positives (FP) and False Negatives (FN): Lower FP and FN values reduce the need for manual corrections in both over-splitting (FP) and under-splitting (FN).

Analysis of the Models:

Model Accuracy Precision Recall F1 False Positives (FP) False Negatives (FN) LLM Usage % gpt-4o-prompt-v7-resnet 0.9164 0.9935 0.7655 0.8648 6 283 58.58 gpt-4o-prompt-v5-resnet-multimodal 0.8950 0.9891 0.7554 0.8566 10 295 74.57 gpt-35-prompt-v3-resnet 0.8949 0.8453 0.8558 0.8506 189 174 26.16 gpt-4o-prompt-v3-resnet 0.8686 0.9414 0.6653 0.7796 50 404 27.99 512px-all-data-benchmark 0.8570 0.7658 0.8509 0.8061 314 180

Best Model for our Use Case:

1. gpt-4o-prompt-v7-resnet:

Precision (0.9935): Almost all of the predicted splits are correct, meaning it has only 6 false positives. This is extremely important because unnecessary splits increase manual intervention.

F1 (0.8648): Highest F1 score among all models, showing the best balance between precision and recall.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 8
F1 (0.8648): Highest F1 score among all models, showing the best balance between precision and recall.

Recall (0.7655): Reasonably high recall ensures it captures most true split points, although there are 283 false negatives, meaning it misses some splits.

Conclusion: This model would require the least manual correction for over-splitting and performs well in reducing under-splitting. It is the best fit for minimizing manual intervention.

2. gpt-4o-prompt-v5-resnet-multimodal:

Precision (0.9891): Only 10 false positives, meaning very few unnecessary splits.

F1 (0.8566): Very high F1 score, though slightly lower than the v7 model.

Recall (0.7554): Slightly lower than the v7 model, meaning it will miss more true splits, leading to 295 false negatives.

Conclusion: This model is very close to the v7 model and is a strong contender for minimizing manual intervention due to its high precision and good balance overall.

3. gpt-35-prompt-v3-resnet:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 9
Conclusion: This model is very close to the v7 model and is a strong contender for minimizing manual intervention due to its high precision and good balance overall.

3. gpt-35-prompt-v3-resnet:

Recall (0.8558): Best recall among the top models, meaning it captures the most true split points. However, it has 189 false positives, which could lead to unnecessary manual corrections for over-splitting.

Conclusion: If recall (minimizing missed splits) is more critical for your task than precision, this model is a good choice. But it requires more manual intervention due to its higher false positives.

Conclusion:

gpt-4o-prompt-v7-resnet is the best model overall, with extremely high precision (minimizing false positives) and a strong balance with recall and F1 score. This model will require the least manual intervention for your PDF splitting task.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 10
gpt-4o-prompt-v5-resnet-multimodal is a close second, offering slightly lower performance than v7 but still performing exceptionally well with very few false positives.

If we are focused on minimizing missed splits (false negatives) rather than preventing unnecessary splits, we could also consider gpt-35-prompt-v3-resnet, but this comes with more false positives and thus more manual intervention for merging.

Cost Estimation for Model Deployment

Model Input Token Output Tokens $/1 Page $/1K Pages $/10K Pages $/1M Pages Azure GPT-4o Turbo 750 33 0.01 8.49 84.90 8490.00 Azure GPT-3.5 Turbo 750 33 0.00 0.42 4.25 425.50 Azure GPT-4o Turbo 2011 25 0.02 20.86 208.60 20860.00 Azure GPT-3.5 Turbo 2011 25 0.00 1.04 10.43 1043.00 Azure GPT-4o Turbo 2114 154 0.03 25.76 257.60 25760.00 Azure GPT-3.5 Turbo 2114 154 0.00 1.29 12.88 1288.00 OpenAI GPT 4o mini 2114 154 0.00 0.41 4.09 409.50

Story 22215

22215

Finished

training new models with new data (512px, sliding window, ...)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 11
Story 22215

22215

Finished

training new models with new data (512px, sliding window, ...)

training view in db

multi gpu training on aime

LLM evaluation

LLM Workflow for doc splitting (still missing using dynaPdf, performance, and errors)

added threshold mechanism for doc-splitter-service to get less false positives => we should align with Dachser, what they want here.

best => 512px model with 0.75 threshold

save scores for threshold calculation

Benchmarks

validation set: is a 10% random sample of the training data result global: is calculated over all pages from the benchmark real data given by Dachser: \\nas-01\CustomerData\Dachser\ClassificationAndSplit-Phase2\dachser_ProdSamplesForSplitting_2024-08-06 result files correct: is calculated by only counting files correct, if every single page in the doc was classified correctly

With new Data (~250/6500 new pdfs) / LLM

We see that we get slightly better results with more data.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 12
Model Name Test Set TP FP TN FN Accuracy Precision Recall F1 Score gpt3.5-turbo prompt-v1 (3 docs failed) result global 242 40 2107 711 75.77 % 85.82 % 25.39 % 39.19 % result files correct 2 51 N/A N/A 3.77 % N/A N/A N/A gpt4o prompt-v1 (3 docs failed) result global 432 33 2215 619 80.24 % 92.90 % 41.10 % 56.99 % result files correct 25 28 N/A N/A 47.17 % N/A N/A N/A two layer sliding window validation set 2244 232 1698 162 90.91 % 90.63 % 93.27 % 91.93 % result global 894 276 1972 313 82.95 % 76.41 % 74.07 % 75.22 % result files correct 20 36 N/A N/A 35.71 % N/A N/A N/A tls-window (threshold 0.7) result global 487 19 2229 720 78.61 % 96.25 % 40.35 % 56.86 % result files correct 10 46 N/A N/A 17.86 % N/A N/A N/A tls-window (threshold 0.8) result global 225 0 2248 982 71.58 % 100.00 % 18.64 % 31.42 % result files correct 4 52 N/A N/A 7.14 % N/A N/A N/A 512px with rotations validation set 558 116 646 92 85.27 % 82.79 % 85.85 % 84.29 % result global 1027 314 1934 180 85.70 % 76.58 %

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 13
18.64 % 31.42 % result files correct 4 52 N/A N/A 7.14 % N/A N/A N/A 512px with rotations validation set 558 116 646 92 85.27 % 82.79 % 85.85 % 84.29 % result global 1027 314 1934 180 85.70 % 76.58 % 85.09 % 80.61 % result files correct 20 36 N/A N/A 35.71 % N/A N/A N/A 512px (threshold 0.6) result global 918 211 2037 289 85.53 % 81.31 % 76.06 % 78.60 % result files correct 17 39 N/A N/A 30.36 % N/A N/A N/A 512px (threshold 0.75) result global 757 75 2173 450 84.80 % 90.99 % 62.72 % 74.25 % result files correct 20 36 N/A N/A 35.71 % N/A N/A N/A 512px (threshold 0.8) result global 482 18 2230 725 78.49 % 96.40 % 39.93 % 56.47 % result files correct 14 42 N/A N/A 25.00 % N/A N/A N/A 512px (threshold 0.9) result global 267 4 2244 940 72.68 % 98.52 % 22.12 % 36.13 % result files correct 6 50 N/A N/A 10.71 % N/A N/A N/A 512px ResNet34 validation set 595 106 660 51 88.88 % 84.88 % 92.11 % 88.34 % result global 1044 389 1859 163 84.02 % 72.85 % 86.50 % 79.09 % result files correct 23 33 N/A

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 14
N/A N/A 10.71 % N/A N/A N/A 512px ResNet34 validation set 595 106 660 51 88.88 % 84.88 % 92.11 % 88.34 % result global 1044 389 1859 163 84.02 % 72.85 % 86.50 % 79.09 % result files correct 23 33 N/A N/A 41.07 % N/A N/A N/A 512px ResNet34 (threshold 0.7) result global 834 152 2096 373 84.80 % 84.58 % 69.10 % 76.06 % result files correct 21 35 N/A N/A 37.50 % N/A N/A N/A

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 15
No new data

Model Name Test Set TP FP TN FN Accuracy Precision Recall F1 Score 512px model with rotations validation set 644 34 667 23 95.83 % 94.99 % 96.55 % 95.76 % result global 995 306 1942 212 85.01 % 76.48 % 82.44 % 79.35 % result files correct 21 35 N/A N/A 37.50 % N/A N/A N/A 512px model with rotations - 16-mixed validation set 572 106 630 60 87.87 % 84.37 % 90.51 % 87.33 % result global 973 312 1936 234 84.20 % 75.72 % 80.61 % 78.09 % result files correct 21 35 N/A N/A 37.50 % N/A N/A N/A two images sliding window - 16-mixed validation set 2291 241 1698 55 93.09 % 90.48 % 97.66 % 93.93 % result global 823 412 1836 384 76.96 % 66.64 % 68.19 % 67.40 % result files correct 18 38 N/A N/A 32.14 % N/A N/A N/A

Story 21156

21156

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 16
Story 21156

21156

Model Name Test Set TP FP TN FN Accuracy Precision Recall F1 Score poc result global 641 335 1913 566 73.92 % 65.68 % 53.11 % 58.73 % result files correct 15 41 N/A N/A 26.79 % N/A N/A N/A 224px validation set 619 10 727 12 98.39 % 98.41 % 98.10 % 98.25 % result global 947 543 1705 219 77.68 % 63.56 % 81.22 % 71.31 % result files correct 22 33 N/A N/A 40.00 % N/A N/A N/A 512px validation set 636 8 720 4 99.12 % 98.76 % 99.38 % 99.07 % result global 1043 630 1618 164 77.02 % 62.34 % 86.41 % 72.43 % result files correct 19 37 N/A N/A 33.93 % N/A N/A N/A

POC

Model for Document Splitting

Trained on Dachser Only Data so far

Not Typhon, directly trained on the images - Resnet18 End-To-End Model

Next Steps

questions: - is it worse if it splits wrongly, or equally worse if it doesnt split. False Positives and Negatives

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 17
Not Typhon, directly trained on the images - Resnet18 End-To-End Model

Next Steps

questions: - is it worse if it splits wrongly, or equally worse if it doesnt split. False Positives and Negatives

possible improvements - better training data quality - use ocr engine in separate service for pngs - input data: with page before (and after) - bigger input images for model - better model (find best model architecture for image classification) - real world data for benchmark (invoice staple, how many are stapled) - active learning

production: - Benchmarks in BmEngine - Bm for sequence model with randomized merged documents - Production ready model training

Data Quality Results

\\nas-01\CustomerData\Dachser\PoC_ClassificationAndSplit

All Data (A-Quality + Austria Dachser)

Total: 5197

Good: 2888/3184 = 91%

Bad: 219/3184 = 07%

Unsure: 73/3184 = 02%

Garbage: 4/3184 = 00%

Not labeled: 2013

Test-Set from All-Data

Total: 519

Good: 467/519 = 90%

Bad: 48/519 = 09%

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 18
Total: 5197

Good: 2888/3184 = 91%

Bad: 219/3184 = 07%

Unsure: 73/3184 = 02%

Garbage: 4/3184 = 00%

Not labeled: 2013

Test-Set from All-Data

Total: 519

Good: 467/519 = 90%

Bad: 48/519 = 09%

Unsure: 0/519 = 00%

Garbage: 4/519 = 01%

Not labeled: 0

A-Quality

Total: 3555

Good: 1842/1890 = 97%

Bad: 40/1890 = 02%

Unsure: 6/1890 = 00%

Garbage: 2/1890 = 00%

Not labeled: 1665

Test-Set from A-Quality

Total: 370

Good: 322/331 = 97.28%

Bad: 7/331 = 2.11%

Unsure: 0/331 = 0.00%

Garbage: 2/331 = 0.60%

Not labeled: 39

pdf2image - Library

86 of 5197 = 1,7% pdfs could not be converted - all pages returned are empty

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 19
Bad: 7/331 = 2.11%

Unsure: 0/331 = 0.00%

Garbage: 2/331 = 0.60%

Not labeled: 39

pdf2image - Library

86 of 5197 = 1,7% pdfs could not be converted - all pages returned are empty

ids: '173390', '36966', '36658', '153396', '162261', '154104', '36853', '36596', '36086', '36360', '36842', '36661', '168415', '36731', '36440', '173465', '36558', '168293', '36380', '36861', '157938', '176224', '158142', '36620', '36622', '37032', '153248', '36869', '173350', '37026', '153482', '36699', '37036', '176045', '36630', '36765', '36928', '36812', '37039', '176253', '160498', '176089', '176140', '36896', '153272', '36735', '36978', '153159', '36664', '176073', '36686', '36937', '173466', '36427', '36687', '153108', '168378', '36718', '36727', '36128', '36179', '36509', '36145', '36665', '154109', '176093', '36307', '176214', '36476', '165472', '36830', '36744', '153354', '173500', '36879', '173388', '168791', '36286', '36818', '36221', '36474', '36501', '37054', '152989', '36757', '36790'

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 20
Results

bm - 10% random sampled from A Quality Training Data

Tests-Sets - 519 = 10% random sample from a-quality + Dachser Austria invoices - 329 = subset of 519, only a-quality ids, but invoice class is missing - 368 = subset of 519, only a-quality ids, with invoice class - 389 = 10% random sample from a-quality, not trained with those - this is the most reliable for now

Models: - model-affine = only all a-quality data trained - model-20k = all a- and b-quality data trained

BM-Results: - 394/519 = 75.92% are correctly predicted, data from phoenix pngs, model trained on 20k data - 434/519 = 83.62% are correctly predicted, data from pdf pngs, model-20k - 311/329 = 94,53% are correctly predicted, model-affine - 318/329 = 96,66% are correctly predicted, model-20k - 362/389 = 93.06% are correctly predicted, random affine - 364/389 = 93.57% are correctly predicted, model-20k - this is the most reliable for now - 357/368 = 97.01% are correctly predicted, model-20k

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 21
Page count: - Min: 1 - Max 91 - Mean: 2.468 - Median: 1

Page Count #Documents 1 281 2 145 3 33 4 16 5 9 6 8 7 5 8 3 9 3 10 2 12 2 14 2 18 4 21 2 24 1 25 1 42 1 91 1

Min: 1

Max: 91

Median: 1.0

Mean: 2.468208092485549

Doc Type Count => 519

Doc Type Count CertificateOfOrigin 31 CustomsDutyReceipt 36 DangerousGoodsNote 43 DeliveryNoteCustoms 39 DeliveryNoteTransit 32 ExportAccompanyingDocument 49 Invoice 184 ProformaInvoice 36 TransitNoteT1 29 TransitNoteT2 40

Document Type Count => 331

Document Type Count CertificateOfOrigin 31 CustomsDutyReceipt 36 DangerousGoodsNote 43 DeliveryNoteCustoms 37 DeliveryNoteTransit 32 ExportAccompanyingDocument 48 Invoice 39 ProformaInvoice 36 TransitNoteT1 28 TransitNoteT2 40

Scores

Min 2.5277235138993978e-14

Max 1.0

Mean 0.9638948680706394

Median 0.9998418688774109

Count (0.0, 0.1] 0 (0.1, 0.2] 0 (0.2, 0.3] 0 (0.3, 0.4] 0 (0.4, 0.5] 0 (0.5, 0.6] 20 (0.6, 0.7] 35 (0.7, 0.8] 35 (0.8, 0.9] 54 (0.9, 1.0] 1092

US 22256

22556

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 22
Median 0.9998418688774109

Count (0.0, 0.1] 0 (0.1, 0.2] 0 (0.2, 0.3] 0 (0.3, 0.4] 0 (0.4, 0.5] 0 (0.5, 0.6] 20 (0.6, 0.7] 35 (0.7, 0.8] 35 (0.8, 0.9] 54 (0.9, 1.0] 1092

US 22256

22556

Evaluation of new Models can be found here.

Sliding Window Model

Transformer based model which takes features of two images - outcome of two calls two a Resnet model - as input and predicts whether the two pages are a first pages.

GPT 4o-mini

Switched to GPT-4o-mini. Created a new GPT-4o-mini Deployment in Azure Sweden Central

LLMConfig

Implemented a new LLM configuration mechanism which is shown in the following UML class diagram. Can be configured for every workflow.

Example:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 23
LLMConfig

Implemented a new LLM configuration mechanism which is shown in the following UML class diagram. Can be configured for every workflow.

Example:

json "DocSplitterLLMWorkflowConfig": { "LLMConfig": { "LLMProviderConfig": { "Name": "AzureGPT", //"|OpenAI|Claude|Mistral", "ApiKeyName": "ApiKeyEnvironmentVariableName", "ApiKey": null, // overrides the ApiKeyName, useful for development "Settings": { "ResourceName": "bd-openai-swe-001", "DeploymentId": "gpt-4o-mini", "ModelName": "gpt-4o-mini", "ApiVersion": "2024-02-15-preview" } }, "LLMParameterConfig": { "Temperature": 0.7, "Seed": 42, "MaxTokens": 800, "TopP": 0.95, "FrequencyPenalty": 0.0, "PresencePenality": 0.0 } } }

DSPy

First experiments with DSPy for prompt optimization and Arize Phoenix as obersavabilty tool for LLMs

Phoenix

Costs

Cost Estimation for Model Deployment

Model Input Token Output Tokens $/1 Page $/1K Pages $/10K Pages $/1M Pages OpenAI GPT 4o mini 2114 154 0.00 0.41 4.09 409.50

Metrics

LLM Errors

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 24
Costs

Cost Estimation for Model Deployment

Model Input Token Output Tokens $/1 Page $/1K Pages $/10K Pages $/1M Pages OpenAI GPT 4o mini 2114 154 0.00 0.41 4.09 409.50

Metrics

LLM Errors

Bennu

Implemented two new features: - DocSplitting Feature - DocSplitting BM Analyzer: AI assisted BM analyzer

Local FineTuning with LLMs

Carried out first local fine tuning experiments of MMLM with llama_factory

Implemented an OpenAI API compliant service which can load different LLMs and can be used for custom LLM testing.

Llama Factory

Processing Times

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 25
Filename Processing Time (seconds) Number of Pages Avg Time per Page (seconds) MIXED_001_01b957ab-3747-4667-9c78-ef3637c747f7_marked.pdf 138.059 78 1.76999 MIXED_002_097ff013-c434-4623-968d-8796f19adcc6_marked.pdf 252.033 117 2.15413 MIXED_003_0aac838a-c318-427e-a2f1-5a8171ca3edb_marked.pdf 117.222 82 1.42954 MIXED_004_0ac5d46f-d649-405b-87e2-80ce0c9c6b13_marked.pdf 11.983 7 1.71186 MIXED_005_0bdb3c8e-bcdf-47d7-916a-e375d2cf9972_marked.pdf 16.225 9 1.80278 MIXED_006_0e489fff-17fc-4883-8db0-bea880368b8d_marked.pdf 141.196 96 1.47079 MIXED_007_0e7deaad-a66b-40d6-901b-090a432313c3_marked.pdf 31.288 16 1.9555 MIXED_008_0ebaddd4-054c-4fca-8390-1d7e16426d09_marked.pdf 92.764 24 3.86517 MIXED_009_0f020523-e0e5-4ce0-a07e-37aba60b6dd6_marked.pdf 15.57 5 3.114 MIXED_010_0f0a3c2e-7b20-423f-9565-1d7d3abccaf2_marked.pdf 10.987 6 1.83117 MIXED_011_107f1ec8-6cb9-4936-aa76-547b8ddc32b6_marked.pdf 12.375 5 2.475 MIXED_012_10ebb7e6-1bf5-40a6-9dc8-2c52817f944c_marked.pdf 177.753 66 2.69323

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 26
10.987 6 1.83117 MIXED_011_107f1ec8-6cb9-4936-aa76-547b8ddc32b6_marked.pdf 12.375 5 2.475 MIXED_012_10ebb7e6-1bf5-40a6-9dc8-2c52817f944c_marked.pdf 177.753 66 2.69323 MIXED_013_119a3efc-ab33-480f-815f-1226506291f5_marked.pdf 13.47 5 2.694 MIXED_014_13b45c51-cf63-4821-a6ae-725ee3e6432a_marked.pdf 21.611 11 1.96464 MIXED_015_16f78f5e-8e6f-46a2-8411-58adf40d27d0_marked.pdf 25.018 11 2.27436 MIXED_016_16fddf8a-1dfd-4e9e-8898-da6dbb1bd7da_marked.pdf 18.52 8 2.315 MIXED_017_1756e74f-5375-4be7-a3ff-a4a8088b10bf_marked.pdf 73.567 48 1.53265 MIXED_018_1920a1b8-d0cb-4b17-8a9f-3c22bddb01de_marked.pdf 190.681 99 1.92607 MIXED_019_1a4efdf9-5b36-4066-b18d-94fe1b8aaf37_marked.pdf 31.672 13 2.43631 MIXED_020_1adce0a3-28b3-4841-9bba-62277a214fdf_marked.pdf 14.446 9 1.60511 MIXED_021_1b2c91d3-f96e-4a03-8663-323039896ca8_marked.pdf 24.9 11 2.26364 MIXED_022_1c121c4c-55a2-420c-85c9-353a08e62746_marked.pdf 94.302 51 1.84906 MIXED_023_1de5edee-a589-43d2-a0ff-a26fefd9ab01_marked.pdf 66.897 31 2.15797

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 27
24.9 11 2.26364 MIXED_022_1c121c4c-55a2-420c-85c9-353a08e62746_marked.pdf 94.302 51 1.84906 MIXED_023_1de5edee-a589-43d2-a0ff-a26fefd9ab01_marked.pdf 66.897 31 2.15797 MIXED_024_364_63c79640-cea6-4dd3-9629-5f714155e5eb_marked.pdf 11.829 7 1.68986 MIXED_025_48605739-349f-40dc-88f4-46bcab0b2fd5_marked.pdf 71.177 34 2.09344 MIXED_026_5595e69b-5069-4fac-8021-db917eec6034_marked.pdf 18.647 10 1.8647 MIXED_027_953788_marked.pdf 24.046 17 1.41447 MIXED_028_a30b4b46-ebb5-494d-85b8-6970d843d055_marked.pdf 9.261 3 3.087 MIXED_029_a65a8297-1535-44e5-ba58-774855acab31_marked.pdf 9.776 4 2.444 MIXED_030_b7c5ef5b-b72f-4434-bfe4-7b1215054f84_marked.pdf 9.763 3 3.25433 MIXED_031_d0db2127-dcc9-4c46-84c3-b602df4ea73c_marked.pdf 13.464 5 2.6928 MIXED_032_d74f1a20-2e13-417d-8226-fb3a94470547_marked.pdf 256.346 151 1.69766 MIXED_033_e2ddb485-4d41-4e02-b6e6-729ada3c41af_marked.pdf 292.923 202 1.45011 MIXED_034_f183d65a-41e0-4038-bbef-59c2d87f1416_marked.pdf 24.518 18 1.36211

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 28
256.346 151 1.69766 MIXED_033_e2ddb485-4d41-4e02-b6e6-729ada3c41af_marked.pdf 292.923 202 1.45011 MIXED_034_f183d65a-41e0-4038-bbef-59c2d87f1416_marked.pdf 24.518 18 1.36211 MIXED_035_fe9c55df-162b-4a5b-80b6-066fc1555a26_marked.pdf 9.494 3 3.16467 NOSPLIT_001_4e83352c-f4e0-441b-9d2e-933fbd928eef_marked.pdf 638.6 549 1.16321 NOSPLIT_002_7a14c633-5e53-49cc-aa02-952d9da23b08_marked.pdf 366.171 311 1.1774 NOSPLIT_003_781ce951-e370-49f1-94cd-1224015d6dcc_marked.pdf 244.201 203 1.20296 NOSPLIT_004_b1866a47-b9e8-4b34-ac6b-030b12044700_marked.pdf 89.413 80 1.11766 SAME_001_02221d27-100b-4ad1-a59f-d28b94d627b2_marked.pdf 155.955 47 3.31819 SAME_002_0270c6dd-b001-4839-b602-d53c30969e3c_marked.pdf 52.547 36 1.45964 SAME_003_0864644e-55f4-4d97-9b2a-3dadd2c0a7bd_marked.pdf 34.765 15 2.31767 SAME_004_0e3fa5d9-041e-430a-8cf8-b07bed75bfd5_marked.pdf 29.004 12 2.417 SAME_005_0f6db96e-5ff8-4ef4-bc3f-39273cc71932_marked.pdf 96.621 68 1.4209 SAME_006_106ef539-7021-4f6e-b1de-4ab7bf7e6ee4_marked.pdf 36.341

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 29
29.004 12 2.417 SAME_005_0f6db96e-5ff8-4ef4-bc3f-39273cc71932_marked.pdf 96.621 68 1.4209 SAME_006_106ef539-7021-4f6e-b1de-4ab7bf7e6ee4_marked.pdf 36.341 29 1.25314 SAME_007_11d6f298-4957-492f-a307-eb1c0756ec9f_marked.pdf 65.045 51 1.27539 SAME_008_1711b269-3646-4185-b6dc-1d968b0da25a_marked.pdf 25.435 13 1.95654 SAME_009_176936c3-ff50-44bf-9323-811fa7338102_marked.pdf 26.35 6 4.39167 SAME_010_1d33aaac-a0eb-49a6-a8c6-f074e41ae327_marked.pdf 222.232 68 3.26812 SAME_011_1fc9d1d3-f2c8-4f57-a761-6de4f6909bfd_marked.pdf 96.588 41 2.3558 SAME_012_20729960-a925-4231-81f2-8f9018c84698_marked.pdf 39.808 20 1.9904 SAME_013_2497495f-8c00-42cf-84ad-37682b944328_marked.pdf 8.511 2 4.2555 SAME_014_9b7e58b8-7e6e-402e-96ac-13ad60a0333c_marked.pdf 14.902 7 2.12886 SAME_015_a43e5556-1a02-4e4c-b618-ed4d0384c64e_marked.pdf 15.182 6 2.53033 SAME_016_e58f7f8a-62ec-4257-86a5-936e11b013a0_marked.pdf 327.053 240 1.36272 SAME_017_e7de737f-f640-4b01-84a5-a4ef39c2ef26_marked.pdf 494.852 386 1.282

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Document-Splitting-(doc-splitter).md - Chunk 30
Overall Average Time per Page: 2.13 seconds

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Splitting-Evaluation.md - Chunk 0
Model Improvements

56 Documents:

provide by Dachser

real test - not inlcuded in training or validation set

Line Numbers are taken into account

Benchmark Results

Model Accuracy Precision Recall F1 Score False Positives (FP) False Negatives (FN) Sprint Prod-Model (t=0.75) 0.8145 0.9237 0.5112 0.6581 51 590 G4Rv7 0.9164 0.9935 0.7655 0.8648 6 283 139 G4MRv7 0.8993 0.9965 0.7142 0.8320 3 345 139 G4MSWv7v2 0.93314 0.993927 0.8136 0.8948 6 225 140 G4MSWv10v2 0.940666 0.992141 0.836785 0.907865 8 197 140 G4MRv10 0.947612 0.982143 0.865783 0.920299 19 162 140 G4MSWv10v4_v3 0.962663 0.982975 0.908865 0.944468 19 110 140

---

4 Documents - Evaluation Outcome

File: MIXED_003_0aac838a-c318-427e-a2f1-5a8171ca3edb

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Splitting-Evaluation.md - Chunk 1
---

4 Documents - Evaluation Outcome

File: MIXED_003_0aac838a-c318-427e-a2f1-5a8171ca3edb

Model Accuracy Precision Recall F1 Score TP FP FN TN G34v3 0.987805 1.0 0.987654 0.993789 80 0 1 1 512px-all-data 0.97561 0.987654 0.987654 0.987654 80 1 1 0 512px-with-rotations 0.97561 0.987654 0.987654 0.987654 80 1 1 0 512px 0.926829 0.987013 0.938272 0.962025 76 1 5 0 224px 0.695122 0.982759 0.703704 0.820144 57 1 24 0 sliding 0.658537 0.981818 0.666667 0.794118 54 1 27 0 poc 0.573171 0.979167 0.580247 0.728682 47 1 34 0 G4MRv7 0.353659 1.0 0.345679 0.513761 28 0 53 1 G4v3 0.280488 1.0 0.271605 0.427184 22 0 59 1 G4v6 0.47561 1.0 0.469136 0.638655 38 0 43 1 512px_prod 0.2561 1.000000 0.2469 0.3960 20 0 61 1

File: MIXED_004_0ac5d46f-d649-405b-87e2-80ce0c9c6b13_marked

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\Splitting-Evaluation.md - Chunk 2
File: MIXED_004_0ac5d46f-d649-405b-87e2-80ce0c9c6b13_marked

Model Accuracy Precision Recall F1 Score TP FP FN TN G4MRv7 1.0 1.0 1.0 1.0 5 0 0 2 G4v3 0.857143 1.0 0.8 0.888889 4 0 1 2 G4Rv3 1.0 1.0 1.0 1.0 5 0 0 2 G4v5 1.0 1.0 1.0 1.0 5 0 0 2 512px_prod 0.5714 1.000000 0.4000 0.5714 2 0 3 2

File: MIXED_007_0e7deaad-a66b-40d6-901b-090a432313c3_marked

Model Accuracy Precision Recall F1 Score TP FP FN TN G4v5 0.875 1.0 0.777778 0.875 7 0 2 7 G4v6 0.875 1.0 0.777778 0.875 7 0 2 7 512px-with-rotations 0.875 0.888889 0.888889 0.888889 8 1 1 6 G4MRv7 0.8125 1.0 0.666667 0.8 6 0 3 7 512px_prod 0.5625 0.750000 0.3333 0.4615 3 1 6 6

File: MIXED_006_0e489fff-17fc-4883-8db0-bea880368b8d_marked

Model Accuracy Precision Recall F1 Score TP FP FN TN G4MRv7 1.0 1.0 1.0 1.0 8 0 0 88 G4v5 1.0 1.0 1.0 1.0 8 0 0 88 G4v6 1.0 1.0 1.0 1.0 8 0 0 88 G4v7 1.0 1.0 1.0 1.0 8 0 0 88 512px_prod 0.9479 1.000000 0.3750 0.5455 3 0 5 88

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\US-22556-Report.md - Chunk 0
Model Improvements

56 Documents:

provide by Dachser

real test - not inlcuded in training or validation set

LLM: For LineNumber Detection

New Sliding Window Model: Classifies pages as "Start" or "Other". Takes two pages into account. Transformer based.

Benchmark Results

Model Accuracy Precision Recall F1 Score False Positives (FP) False Negatives (FN) Sprint Prod-Model (t=0.75) 0.8145 0.9237 0.5112 0.6581 51 590 G4Rv7 0.9164 0.9935 0.7655 0.8648 6 283 139 G4MRv7 0.8993 0.9965 0.7142 0.8320 3 345 139 G4MSWv7v2 0.93314 0.993927 0.8136 0.8948 6 225 140 G4MSWv10v2 0.940666 0.992141 0.836785 0.907865 8 197 140 G4MRv10 0.947612 0.982143 0.865783 0.920299 19 162 140 G4MSWv10v4_v3 0.960781 0.97999 0.90624 0.941674 22 113 141

Confidence Intervals

Best Model: G4MSWv10v4_v3

Metric Lower Bound Upper Bound Accuracy 0.9599561335345513 0.9616068187085746 F1 Score 0.9404329523961028 0.942915167934121

Benchmark Results in Production Environment

Successfully Processed Files

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\US-22556-Report.md - Chunk 1
Filename Nr Pages ProcessingTime (ms) MIXED_001_01b957ab-3747-4667-9c78-ef3637c747f7_marked.pdf 78 160401 MIXED_002_097ff013-c434-4623-968d-8796f19adcc6_marked.pdf 117 216321 MIXED_003_0aac838a-c318-427e-a2f1-5a8171ca3edb_marked.pdf 82 113175 MIXED_004_0ac5d46f-d649-405b-87e2-80ce0c9c6b13_marked.pdf 7 9416 MIXED_005_0bdb3c8e-bcdf-47d7-916a-e375d2cf9972_marked.pdf 9 14595 MIXED_006_0e489fff-17fc-4883-8db0-bea880368b8d_marked.pdf 96 131662 MIXED_007_0e7deaad-a66b-40d6-901b-090a432313c3_marked.pdf 16 25331 MIXED_008_0ebaddd4-054c-4fca-8390-1d7e16426d09_marked.pdf 24 91158 MIXED_009_0f020523-e0e5-4ce0-a07e-37aba60b6dd6_marked.pdf 5 33940 MIXED_010_0f0a3c2e-7b20-423f-9565-1d7d3abccaf2_marked.pdf 6 8690 MIXED_011_107f1ec8-6cb9-4936-aa76-547b8ddc32b6_marked.pdf 5 8974 MIXED_012_10ebb7e6-1bf5-40a6-9dc8-2c52817f944c_marked.pdf 66 154055 MIXED_013_119a3efc-ab33-480f-815f-1226506291f5_marked.pdf 5 8849 MIXED_014_13b45c51-cf63-4821-a6ae-725ee3e6432a_marked.pdf 11 17030

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\US-22556-Report.md - Chunk 2
MIXED_012_10ebb7e6-1bf5-40a6-9dc8-2c52817f944c_marked.pdf 66 154055 MIXED_013_119a3efc-ab33-480f-815f-1226506291f5_marked.pdf 5 8849 MIXED_014_13b45c51-cf63-4821-a6ae-725ee3e6432a_marked.pdf 11 17030 MIXED_015_16f78f5e-8e6f-46a2-8411-58adf40d27d0_marked.pdf 11 20606 MIXED_016_16fddf8a-1dfd-4e9e-8898-da6dbb1bd7da_marked.pdf 8 16327 MIXED_017_1756e74f-5375-4be7-a3ff-a4a8088b10bf_marked.pdf 48 75259 MIXED_018_1920a1b8-d0cb-4b17-8a9f-3c22bddb01de_marked.pdf 99 181433 MIXED_019_1a4efdf9-5b36-4066-b18d-94fe1b8aaf37_marked.pdf 13 27334 MIXED_020_1adce0a3-28b3-4841-9bba-62277a214fdf_marked.pdf 9 16452 MIXED_021_1b2c91d3-f96e-4a03-8663-323039896ca8_marked.pdf 11 22336 MIXED_022_1c121c4c-55a2-420c-85c9-353a08e62746_marked.pdf 51 89080 MIXED_023_1de5edee-a589-43d2-a0ff-a26fefd9ab01_marked.pdf 31 54155 MIXED_024_364_63c79640-cea6-4dd3-9629-5f714155e5eb_marked.pdf 7 10806 MIXED_025_48605739-349f-40dc-88f4-46bcab0b2fd5_marked.pdf 34 63272 MIXED_026_5595e69b-5069-4fac-8021-db917eec6034_marked.pdf 10

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\US-22556-Report.md - Chunk 3
MIXED_024_364_63c79640-cea6-4dd3-9629-5f714155e5eb_marked.pdf 7 10806 MIXED_025_48605739-349f-40dc-88f4-46bcab0b2fd5_marked.pdf 34 63272 MIXED_026_5595e69b-5069-4fac-8021-db917eec6034_marked.pdf 10 16184 MIXED_027_953788_marked.pdf 17 21855 MIXED_028_a30b4b46-ebb5-494d-85b8-6970d843d055_marked.pdf 3 17155 MIXED_029_a65a8297-1535-44e5-ba58-774855acab31_marked.pdf 4 7686 MIXED_030_b7c5ef5b-b72f-4434-bfe4-7b1215054f84_marked.pdf 3 7192 MIXED_031_d0db2127-dcc9-4c46-84c3-b602df4ea73c_marked.pdf 5 10907 MIXED_034_f183d65a-41e0-4038-bbef-59c2d87f1416_marked.pdf 18 22291 MIXED_035_fe9c55df-162b-4a5b-80b6-066fc1555a26_marked.pdf 3 7212 NOSPLIT_003_781ce951-e370-49f1-94cd-1224015d6dcc_marked.pdf 203 218110 NOSPLIT_004_b1866a47-b9e8-4b34-ac6b-030b12044700_marked.pdf 80 87349 SAME_001_02221d27-100b-4ad1-a59f-d28b94d627b2_marked.pdf 47 47256 SAME_002_0270c6dd-b001-4839-b602-d53c30969e3c_marked.pdf 36 50193 SAME_003_0864644e-55f4-4d97-9b2a-3dadd2c0a7bd_marked.pdf 15 29514

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\US-22556-Report.md - Chunk 4
SAME_001_02221d27-100b-4ad1-a59f-d28b94d627b2_marked.pdf 47 47256 SAME_002_0270c6dd-b001-4839-b602-d53c30969e3c_marked.pdf 36 50193 SAME_003_0864644e-55f4-4d97-9b2a-3dadd2c0a7bd_marked.pdf 15 29514 SAME_004_0e3fa5d9-041e-430a-8cf8-b07bed75bfd5_marked.pdf 12 23231 SAME_005_0f6db96e-5ff8-4ef4-bc3f-39273cc71932_marked.pdf 68 96104 SAME_006_106ef539-7021-4f6e-b1de-4ab7bf7e6ee4_marked.pdf 29 34479 SAME_007_11d6f298-4957-492f-a307-eb1c0756ec9f_marked.pdf 51 65574 SAME_008_1711b269-3646-4185-b6dc-1d968b0da25a_marked.pdf 13 21582 SAME_009_176936c3-ff50-44bf-9323-811fa7338102_marked.pdf 6 23703 SAME_010_1d33aaac-a0eb-49a6-a8c6-f074e41ae327_marked.pdf 68 67258 SAME_011_1fc9d1d3-f2c8-4f57-a761-6de4f6909bfd_marked.pdf 41 77450 SAME_012_20729960-a925-4231-81f2-8f9018c84698_marked.pdf 20 37797 SAME_013_2497495f-8c00-42cf-84ad-37682b944328_marked.pdf 2 6255 SAME_014_9b7e58b8-7e6e-402e-96ac-13ad60a0333c_marked.pdf 7 12358 SAME_015_a43e5556-1a02-4e4c-b618-ed4d0384c64e_marked.pdf 6 12585

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Data-Science\Models-Overview\US-22556-Report.md - Chunk 5
Files with Gateway Timeout

MIXED_032_d74f1a20-2e13-417d-8226-fb3a94470547_marked.pdf

MIXED_033_e2ddb485-4d41-4e02-b6e6-729ada3c41af_marked.pdf

NOSPLIT_001_4e83352c-f4e0-441b-9d2e-933fbd928eef_marked.pdf

NOSPLIT_002_7a14c633-5e53-49cc-aa02-952d9da23b08_marked.pdf

SAME_016_e58f7f8a-62ec-4257-86a5-936e11b013a0_marked.pdf

SAME_017_e7de737f-f640-4b01-84a5-a4ef39c2ef26_marked.pdf

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\!POLICIES!.md - Chunk 0
Detailed Description: Policies & Best Practices.pptx

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Azure-Load-Testing.md - Chunk 0
Azure Load Testing allows to simulate a big load from many clients (Engines) without to stress our local network

Traffic can be simulated either within our vnet in Azure or coming from a public network

For very easy tests you can use the Plain UI of the portal

But in reality you will want to use a JMeter-Script-Based test

Doing stuff with JMeter is not always easy or straight forward

You can run local tests, but to be sure that the test works you need to uplaod the JMeter script to your Azure Load-Test, and that is very time consuming (like developing VS DevOps pipelines)

The provsioning phase when running a test takes several minutes -> so this is time-consuming

Apache JMeter has a bug when sending multipart-form request --> our WAF blocks such requests --> check dedicated section further down

Using csv-files especially via Portal-UI is error-prone and testing can be time-consuming

Doing tests with Apache JMeter is really benefitial versus doing them via the Portal UI

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Azure-Load-Testing.md - Chunk 1
Using csv-files especially via Portal-UI is error-prone and testing can be time-consuming

Doing tests with Apache JMeter is really benefitial versus doing them via the Portal UI

When doing tests via portal UI, you have to be very carefull when you use variables from csv file:

Do not create column headers in csv

Defines the headers in the UI of the Portal (in the textbox of the uploaded csv-file) like this: no,document

Values in csv files must be escaped

Use like this: json {"OcrEngines":[2], "Parameter":{"MaxPages":10}, "Document":${document}}

Install Apache JMeter on your local system

Beanshell Pre-/Post-Processor scripts seem to work better than JSR223 Processors (but maybe it was only a coincidence)

Do not create base64 strings with powershell! Use C# instead! --> Watch out. trap!

To create a csv file with all Urls to files on a blob storage, simply select all files in Azure Storage Explorer -> Right click --> Copy Urls --> Paste into csv

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Azure-Load-Testing.md - Chunk 2
To create a csv file with all Urls to files on a blob storage, simply select all files in Azure Storage Explorer -> Right click --> Copy Urls --> Paste into csv

Secrets (sas-token for access to blob storage) are stored in a key-vault and passed forward to the JMeter script

In our loop, a first request downloads the files from a blob storage

The second request sends the file to the service under test

rg-bludelta-lt-prod-weu-01

lt-bludelta-prod-weu-01 (Azure Load Testing)

kv-lt-prod-weu-01 (Key Vault)

Process to connect KeyVault with Azure Load Testing: - The sas-token to access the blob storage is saved as secret in the key-vault. - Turned on system identity for Azure Load Testing: - Azure Load Testing gets the right to access secrets in keyVault: - Azure Load Test passes secret to JMeter script - Tests against services in our private network (meta-ocr) need to place the test-engine-environment in our vnet:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Azure-Load-Testing.md - Chunk 3
Test Directory Files Test name in lt-bludelta-prod-weu-01 Description Receipt Workflow (partner.css-Receipt_50_perf) [root]\dev-ops\azure-load-testing\receipt-workflow receipt-workflow.jmx receipt-workflow-blob-urls.csv workflow-receipt-dev-load-05-jmx-keyvault 1.) Gets Sas Token from Azure 2.) Downloads file from blob store 3.) Sends Multipartform Request to Workflow-Server Beware: Not working via AppGateway Receipt Workflow WAF Fix broken! *** (partner.css-Receipt_50_perf) [root]\dev-ops\azure-load-testing\receipt-workflow receipt-workflow-test-fix-waf.jmx receipt-workflow-blob-urls.csv jmeter-truststore.jks - 1.) Manually set blob_sas_token - is not checked in! 2.) Downloads file from blob store 3.) Multiple approaches to send custom Beanshell Multipartform Request to Workflow-Server Beware: Not working - byte-array broken! Azure Read via Meta Ocr (partner.css-Receipt_469_uniform3) [root]\dev-ops\azure-load-testing\meta-ocr-azure-read meta-ocr-azure-read.jmx

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Azure-Load-Testing.md - Chunk 4
to Workflow-Server Beware: Not working - byte-array broken! Azure Read via Meta Ocr (partner.css-Receipt_469_uniform3) [root]\dev-ops\azure-load-testing\meta-ocr-azure-read meta-ocr-azure-read.jmx meta-ocr-azure-read-base64-blob-urls.csv meta-ocr-dev-load-07-jmx-all-receipts 1.) Gets Sas Token from Azure 2.) Downloads base64 from blob store 3.) Sends Base64 Request to Meta-Ocr

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Azure-Load-Testing.md - Chunk 5
***This test is checked-in because it has a lot of beanshell scripting in it which might be helpfull in the future

The currently most up-to-date Apache JMeter version (5.6.3) has a bug when sending multipart-form request! Bug-Thread on Github It adds "charset=UTF-8" to the Content-Type header.

Content-Type multipart/form-data; boundary=9SOTBR4Tmr8mbRyi3Q-UycY1agcICj0Rb4mL; charset=UTF-8

That is no problem when sending the request directly to our workflow-server. But our App-Gateway (WAF) will reply with 403 forbidden! A very time consuming workaround in JMeter with Beanshell, trying to build the whole request from scratch, allowed us to pass the WAF, but in that case the binary file was not correctly added to the request. Maybe JSR223 would have been the better choice here?!

Option suggested by ChatGPT: Add a WAF Custom Rule for Whitelisting

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Azure-Load-Testing.md - Chunk 6
Option suggested by ChatGPT: Add a WAF Custom Rule for Whitelisting

To allow requests with the problematic Content-Type header: 1. In the WAF policy settings, go to Custom rules. 2. Click Add custom rule and define a rule to allow requests with the Content-Type header: * Match conditions: * Match type: Request Headers * Header name: Content-Type * Operator: Contains * Value: charset=UTF-8 * Priority: Set a low number to ensure the rule is evaluated first. * Action: Allow.

Use KeyVault with Load Test and pass secrets to JMeter Script

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Benchmark-Overview.md - Chunk 0
BenchmarkToolchain.pptx

BenchmarkDataModel_V2.pptx

Possible [BenchmarkTelemetryItem].Keys for performance measurements which are sent when requested by admin user from Workflow-Server: - quotation: - OcrBoxProxyActivity - EntityRecognitionProxyActivity - TyphonServiceProxyActivity_typhon_contact - TyphonServiceProxyActivity_typhon_lineitems - TyphonServiceProxyActivity_typhon_vatgroups - TyphonInferenceProxyActivity_typhon_quotation_typhon_vat_tax_id - order-confirmation: - OcrBoxProxyActivity - EntityRecognitionProxyActivity - TyphonServiceProxyActivity_typhon_contact - TyphonServiceProxyActivity_typhon_lineitems - TyphonInferenceProxyActivity_typhon_order_confirmations - receipt - MetaOcrProxyActivity - EntityRecognitionProxyActivity - TyphonServiceProxyActivity_typhon_header_details_receipt - TyphonServiceProxyActivity_typhon_vatgroups_receipt - llm-worfklow (ocr based) - MetaOcrProxyActivity - LLMProxyActivity - generic-llm-workflow - LLMProxyActivity

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Benchmark-Overview.md - Chunk 1
For Each document category (Invoice | Quotation | OrderConfirmation) we have the following: - Seperate Dev and QA pipelines (and Benchmark Sets) Dev = Regression tests --> High diversity, low number of docs --> Go for fast execution QA = Quality Assurance --> High diversity, high number of docs --> Go for a good quality statement - Seperate Dev and QA Reports Dev = Do selective perf measurements with baselines QA = Do selective perf measurements (no baselines)

Doc Category Pipeline BenchmarkSet Report Definition Order Confirmation oc-benchmarks-cloud-dev OrderConfirmation_Dev_Set OrderConfirmation_Dev_Report oc-benchmarks-cloud-qa OrderConfirmation_QA_Set OrderConfirmation_QA_Report Quotation quotation-benchmarks-cloud-dev Quotation_Dev_Set Quotation_Dev_Report quotation-benchmarks-cloud-qa Quotation_QA_Set Quotation_QA_Report Invoice invoice-benchmarks-cloud-dev Invoice_Dev_Set Invoice_Dev_Report invoice-benchmarks-cloud-qa Invoice_QA_Set Invoice_QA_Report

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Benchmark-Overview.md - Chunk 2
The execution of a Dev-Pipeline shall not take longer than 1 hour

The baseline tags (Report- and BMRun-tags) for Dev-Reports shall always be named "DevBase"

As of now, there is no strict rule when to set a new baseline, but maybe we should create a new one after each sprint?

It must be clearly defined who of the Dev-Team is responsible to keep the nightly dev-reports "green"! Currently: Prediction-Quality = Marcus & Performance = Bernhard

Execution of QA-Pipelines can take much longer than Dev, because we need a good quality-statement.

Before we start a new deployment, we should execute the corresponding QA-pipeline(s) once to ensure good quality before we deploy stuff.

Target: We want to have a Stageing-environment for Deployments which represents a copy of production + only those changes which shall be deployed next. As soon as we have this, we can also compare perf-measurements with a baseline here.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Benchmark-Overview.md - Chunk 3
As long as we execute the QA-Benchmarks against the Prod-Environment (after deployment), we do not compare performance-measurements with a baseline (makes no sense)

The responsibility to validate the QA-Reports lies with the same people who validate the Dev-reports.

After a successful deployment, we set the new baseline(s) for the QA-Report(s) named after the new version of the Prod-Environment.

Example: Execute benchmarks with TyphonLineItems model version 2

x `"Config.TyphonLineItemsModelVersion=2`" The 'arguments' parameter is used to pass any kind of arguments to the phoenix command which executes the benchmark(s) --> .\phoenix.exe evaluation bm_run ...

https://blumatix.visualstudio.com/Rechnungserkennung/_build?definitionId=373

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Benchmark-Overview.md - Chunk 4
https://blumatix.visualstudio.com/Rechnungserkennung/_build?definitionId=373

BEWARE: If you also want to create a report and you have multiple benchmarks to execute, then you have to encapsulate them into a benchmarkSet an pass the corresponding 'benchmarkSetName' parameter. Otherwise you will get a seperate report of each executed benchmark.

Since 12.12.2024 there exists the option to send telemetry to ApplicationInsights for Requests executed by the BenchmarkEngine. By selecting a request performed by phoenix, you will see the complete activity-graph inclusive requests from downstream services. This allows to determine how much time is "lost" sending the initial request to the endpoint and receiving the response.

To send telemetry data, you have to set an APPINSIGHTS_INSTRUMENTATIONKEY in App.config of phoenix:

xml <appSettings> ... <add key="APPINSIGHTS_INSTRUMENTATIONKEY" value="..."/> </appSettings>

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Benchmark-Pipeline-Setup.md - Chunk 0
Config-Example with Invoice and OrderConfirmation ("Benchmark\demos\demo-pipeline-config-v1.1-a\demo-pipeline-config-v1.1-a.json") { "UrlKeys":[ { "Name": "invoice-dev", "Value": "https://api-dev.bludelta.ai/v1-18" }, { "Name": "oc-dev", "Value": "https://capture-dev.bludelta.ai/order-confirmation/v1/order-confirmation" }], "ApiKeys":[ { "Name": "unrestricted", "Value": "+GW..." }, { "Name": "dachserIntegration", "Value": "L30..." }], "BenchmarkTasks": [ { "Name": "dachser_MY_100_uniform_dev", "UrlKeyName": "invoice-dev", "ApiKeyName": "dachserIntegration", "Arguments": "-x Config.TyphonVatTaxIdModelVersion=2" }, { "Name": "dachser_OrderConf_duocomp", "UrlKeyName": "oc-dev", "Tasks": 2 } ] }

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Benchmark-Pipeline-Setup.md - Chunk 1
The Url can also be defined on top level for a json configuration file ("Benchmark\demos\demo-pipeline-config-v1.1-b\demo-pipeline-config-v1.1-b-invoice.json") { "Url": "https://api-dev.bludelta.ai/v1-18", "ApiKeys":[ { "Name": "unrestricted", "Value": "+GW..." }, { "Name": "dachserIntegration", "Value": "L30..." }], "BenchmarkTasks": [ { "Name": "dachser_TH_100_uniform_dev", "ApiKeyName": "dachserIntegration", "Arguments": "-x Config.TyphonVatTaxIdModelVersion=2" }, { "Name": "dachser_MY_100_uniform_dev", "ApiKeyName": "dachserIntegration", "Arguments": "-x Config.TyphonVatTaxIdModelVersion=2" } ] }

Pipeline-Example with multiple json files ("Benchmark\demos\demo-pipeline-config-v1.1-b") --> *.json

... variables: - group: cicd-pipeline-common-config - name: pipelineDirectoryName value: 'demos/demo-pipeline-config-v1.1-b' - name: pipelineJsonConfigFileName value: '*.json' ...

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Benchmark-Pipeline-Setup.md - Chunk 2
... variables: - group: cicd-pipeline-common-config - name: pipelineDirectoryName value: 'demos/demo-pipeline-config-v1.1-b' - name: pipelineJsonConfigFileName value: '*.json' ...

Example is a deployment where we have to run BMs for Invoice, OrderConfirmation, Quotation and Receipt (happens often recently)

1.) Create a single qa-pipeline for the deployment 2.) Copy all json config files from the dev-pipelines into the new pipeline folder 3.) Edit these json config files and set the Url on Top-Level 4.) Edit the yaml file and set '*.json' as pipelineJsonConfigFileName 5.) ---> HINT: Maybe it is more benefitial to split Invoices and Workflow-Docs into 2 Reports. We can achieve this by 2 template steps in the pipeline-yaml (be careful, 2 lists of BMs and so on...)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview.md - Chunk 0
Plugin release Lifecycle/responsibilities

Plugin creation task --> Is created by PMs

Plugin development --> Is done by Bludelta Team --> add plugin to this Wiki-page!!! a) Create Plugin in ..\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins b) Add Integrationtest to ..\Blumatix.Capture.IntegrationTests\CaptureSdkIntegrationTestsJsonSmartFilters.cs i) Add docs to ..\Blumatix.Capture.IntegrationTests\Invoices ii) Link Json-PlugIn to ..\Blumatix.Capture.IntegrationTests\Resources iii) When updating the .json and debugging, check the /bin, if update has been uploaded, otherwise delete the json in the /bin directory

Plugin delivery Cloud --> Is done automatically by DevOps Pipelines --> Developer has to add plugin-entry to "[root]\Deployment\bludelta_cloud_plugins.json" (not in solution)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview.md - Chunk 1
Plugin delivery Cloud --> Is done automatically by DevOps Pipelines --> Developer has to add plugin-entry to "[root]\Deployment\bludelta_cloud_plugins.json" (not in solution)

Plugin delivery OnPremise --> If it is a customer-specific plugin (JSON or DLL), add it to "[root]\Deployment\OnPremise\bludelta_op_customer_plugins.json" --> If it is a DLL plugin for all OP customers, add it to "[root]\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\bludelta_onpremise_plugins.json" --> If it is a JSON plugin for all OP customers, in VS set file as: Copy to output directory --> Copy if newer a) New plugin will be delivered with next OP Release - plugin package is automatically created b) Release Creator will upload plugin into Azure release storage and will created a download link for each plugin c) Release Creator will inform PMs about new download links d) PMs will inform customer about new download links

Cloud Plugins

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview.md - Chunk 2
Customer Filenames Location MappedKeys First Release [all] AmazonSmartFilters.dll ..\CustomSmartFilters\AmazonSmartFilters - v1.15 [all] FbSmartFilters.dll ..\CustomSmartFilters\FbSmartFilters - v1.15 [all] TelekomSmartFilters.dll ..\CustomSmartFilters\TelekomSmartFilters - v1.15 [all] HeaderDetailsSmartFilters.dll ..\CustomSmartFilters\HeaderDetailsSmartFilters - v1.18.1 Strabag StrabagSmartFilters.dll ..\CustomSmartFilters\StrabagSmartFilters [UnrestrictedTester] [Strabag Test] [Strabag Produktiv] < v1.10 Dachser DachserSmartFilters.dll ..\CustomSmartFilters\DachserSmartFilters [Dachser Dev] [dachser] [Dachser Test] [dachser.integration] v1.18.26 Strabag StrabagReceiverOrderIdSmartFilters.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins [UnrestrictedTester] [Strabag Produktiv] [Strabag Test] v1.18 OeRK OerkSmartFilters.dll ..\CustomSmartFilters\OerkSmartFilters [UnrestrictedTester] [OeRK Stmk Partner Produktiv] [OeRK Stmk

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview.md - Chunk 3
[UnrestrictedTester] [Strabag Produktiv] [Strabag Test] v1.18 OeRK OerkSmartFilters.dll ..\CustomSmartFilters\OerkSmartFilters [UnrestrictedTester] [OeRK Stmk Partner Produktiv] [OeRK Stmk Partner Test] <=  1.11 ETL DueDateSmartFilters.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins [UnrestrictedTester] [eurodata Produktiv] [Domonda Produktiv] [Domonda Test] <= v1.10 Red Bull PurchaseOrderNumberSmartFilters.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins [UnrestrictedTester] [Red Bull Test] [Red Bull Produktiv] v1.11 Kuttruff KuttruffProjectNumberSmartFilters.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins [UnrestrictedTester] [Kuttruff Produktiv] [Kuttruff Test] v1.14 Xbit DFDSGrandTotalAmountSmartFilters.json

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview.md - Chunk 4
[UnrestrictedTester] [Kuttruff Produktiv] [Kuttruff Test] v1.14 Xbit DFDSGrandTotalAmountSmartFilters.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins [UnrestrictedTester] [Xbit Produktiv] [XBit Test] v1.14 Xbit DFDSInvoiceIdSmartFilters.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins [UnrestrictedTester] [Xbit Produktiv] [XBit Test] v1.14 Xbit DFDSSenderNameSmartFilters.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins [UnrestrictedTester] [Xbit Produktiv] [XBit Test] v1.14 Depending on File Content [Other-Type-Of-Plugin] PdfFilter.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins - v1.16 Accantum AccantumTourIdSmartFilters.json .\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins [UnrestrictedTester]

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview.md - Chunk 5
- v1.16 Accantum AccantumTourIdSmartFilters.json .\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins [UnrestrictedTester] [Accantum Digital Productive via Accantum MainKey.btk] v1.18.6 RedBull RedBullApproverWhiteList.json .\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins [Red Bull Produktiv] [Red Bull Test] [WhiteList Test (FOR INTEGRATION TESTS)] v1.18.24 Dachser DachserPurchaseOrderId.json .\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins [Dachser Dev] [dachser] [Dachser Test] [dachser.integration] v1.18.26 RAG RagReceiverOrderIdSmartFilters.json .\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins [WhiteList Test (FOR INTEGRATION TESTS)] [rag] [rag. ] [partner.rag] [partner.rag. ] [RAG Austria Test] v1.18.46 RAG RagApproverWhiteList.json

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview.md - Chunk 6
[WhiteList Test (FOR INTEGRATION TESTS)] [rag] [rag. ] [partner.rag] [partner.rag. ] [RAG Austria Test] v1.18.46 RAG RagApproverWhiteList.json .\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins [WhiteList Test (FOR INTEGRATION TESTS)] [rag] [rag. ] [partner.rag] [partner.rag. ] [RAG Austria Test] v1.18.46 RAG RagClientWhiteList.json .\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins [WhiteList Test (FOR INTEGRATION TESTS)] [rag] [rag. ] [partner.rag] [partner.rag. ] [RAG Austria Test] v1.18.46 RAG RagSupplierWhiteList.json .\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins [WhiteList Test (FOR INTEGRATION TESTS)] [rag] [rag. ] [partner.rag] [partner.rag. ] [RAG Austria Test] v1.18.46 Diözese Linz Production Customer DLinzCostCenterSmartFilters.json

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview.md - Chunk 7
[WhiteList Test (FOR INTEGRATION TESTS)] [rag] [rag. ] [partner.rag] [partner.rag. ] [RAG Austria Test] v1.18.46 Diözese Linz Production Customer DLinzCostCenterSmartFilters.json .\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins [JsonPlugin Test (FOR INTEGRATION TESTS)] [Diözese Linz Production Customer] [R&S Präsentation] v1.18.58 Artaker Customer Test ArtakerRealEstateObjectsWhiteList.json .\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins [WhiteList Test (FOR INTEGRATION TESTS)] [Artaker Customer Test] v1.18.59

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview.md - Chunk 8
Cloud ExternalPostprocessing Plugins

Customer Filenames Location MappedKeys First Release (PostProcessing Version) [Dach und Wand Handels GmbH Customer] DachUndWandReplaceUidAndIbanPredictions.cs ...PostProcessing.Business\Plugins.. [Dach und Wand Handels GmbH Customer] [ JsonPlugin Test (FOR INTEGRATION TESTS) ] v1.0.154 [dachser] DachserTransportTourId.cs ...PostProcessing.Business\Plugins.. [dachser] [Dachser Dev] [Dachser Test] [dachser.integration] v1.0.154 [partner.jbx] RegexFinder.cs ...PostProcessing.Business\Plugins.. [partner.jbx.*] v1.0.155 [Red Bull Produktiv] RedBullTwoBiggestIndianSuppliersVatGroups.cs ...PostProcessing.Business\Plugins.. [Red Bull Produktiv] [Red Bull Test] v1.0.167

OnPremise Plugins

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview.md - Chunk 9
Customer Filenames Location MappedKeys First Release [all] AmazonSmartFilters.dll ..\CustomSmartFilters\AmazonSmartFilters - v1.15 [all] FbSmartFilters.dll ..\CustomSmartFilters\FbSmartFilters - v1.15 [all] TelekomSmartFilters.dll ..\CustomSmartFilters\TelekomSmartFilters - v1.15 ETL LekkerlandSmartFilters.dll ..\CustomSmartFilters\LekkerlandSmartFilters - v1.15 ETL Compacer DueDateSmartFilters.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins - ETL <= v1.10 Compacer ab v1.14.3 POI PiaSmartFilters.dll ..\PiaSmartFilters\bin\x64\Release [UnrestrictedTester] "at-pia" < v1.10 POI VehicleIdentificationNumberSmartFilters.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins - v1.14 Compacer (Hornbach) InvoiceIdHornbach8959SmartFilters.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins - v1.14 Compacer (Vossko)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview.md - Chunk 10
- v1.14 Compacer (Hornbach) InvoiceIdHornbach8959SmartFilters.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins - v1.14 Compacer (Vossko) VosskoDeliveryDateSmartFilters.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins - v1.14 Compacer (Vossko) VosskoGrandTotalAmountSmartFilters.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins - v1.14 Compacer (Vossko) VosskoInvoiceDateSmartFilters.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins - v1.14 Compacer (Vossko) VosskoInvoiceIdSmartFilters.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins - v1.14 Compacer (Vossko) VosskoReceiverSmartFilters.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins - v1.14

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview.md - Chunk 11
- v1.14 Compacer (Vossko) VosskoReceiverSmartFilters.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins - v1.14 Compacer (Vossko) VosskoSenderSmartFilters.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins - v1.14 Compacer (Vossko) VosskoSenderVatIdSmartFilters.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins - v1.14 Compacer DeliveryDateCompacerSmartFilters.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins - v1.14.3 Compacer DeliveryNoteIdCompacerSmartFilters.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins - v1.14.3 Compacer ReceiverOrderIdCompacerSmartFilters.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins - v1.14.3 Compacer

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview.md - Chunk 12
- v1.14.3 Compacer ReceiverOrderIdCompacerSmartFilters.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins - v1.14.3 Compacer SenderOrderIdCompacerSmartFilters.json ..\Blumatix.Capture.Webservice.Client.Selfhosted\Blumatix.Capture.Webservice.Client.Selfhosted\Plugins - v1.14.3

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview.md - Chunk 13
Old OnPremise Plugins (no more delivered)

Customer Filenames Location MappedKeys First Release No more delivered since POI VgrdSmartFilters.dll ..\VgrdSmartFilters\bin\x64\Release [UnrestrictedTester] "de-vgrd" < v1.10 v1.18.12

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\DynaPdf-(iText7-replacement).md - Chunk 0
We have 1 Professional Developer license for DynaPdf and we can use this for as many applications and install-locations as we want (Verified by Martin and Jens Boschulte from DynaForms GmbH) --> Official rule: Each developer who does DynaPdf-related development tasks needs a license.

"Officially" Bernhard is the DynaPdf Guy at Blumatix Intelligence Gmbh --> So all Support Requests to DynaForms GmbH should run via Bernhard!

New versions of the DynaPdf library have to be downloaded manually via their homepage: DynaPdf Download

The download contains the C++ library, a C# Wrapper Code-File (Wrappers for different programing languages), a library manual (~800 pages) and many code examples also for C#.

From the C++ Dll and the C# Wrapper we build and push a Nuget-package (DynaPdfCSharp) to our Blumatix feed, which matches the released DynaPdf library version. Solution Url: 3rdPartyLibs.sln

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\DynaPdf-(iText7-replacement).md - Chunk 1
From the C++ Dll and the C# Wrapper we build and push a Nuget-package (DynaPdfCSharp) to our Blumatix feed, which matches the released DynaPdf library version. Solution Url: 3rdPartyLibs.sln

Any logic which uses the DynaPdf library (to extract infos from pdf files or manipulate existing files) is placed in a shared-library project (BlumatixLibraries.sln) and provided as Nuget-package (Blumatix.DynaPdf) to any application which can make use of it.

QA, regarding iText7 replacement with DynaPdf, was done via Unit- and Integration-Tests, Memory Profiling (only managed memory!), DynaPdf Benchmark Report for prediction-quality and performance (=all Cloud and OP Benchmarks)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\DynaPdf-(iText7-replacement).md - Chunk 2
The DynaPdf Benchmark Report (DynaPdf_Report / ReportTag: DynaPdf) shows regarding prediction-Quality for 1 Invoice of the B_RedBull_NL benchmark. It seems that DynaPdf finds vector graphics and low-resolution images on this document and therefor some specific ocr-settings get applied which seem to have a negative impact for the OCR-Result of this specific document. This small degradation was accepted.

The DynaPdf Benchmark Report (DynaPdf_Report / ReportTag: DynaPdf) shows for document-info/preparation and ResultPdf creation. (Disposal of iText7 documents was incredibly slow -> ~500ms)

There is active when building ResultPdfs with Focus Layers (POI only). The input pdf-files are opened and closed with DynaPdf before any drawing logic with Spire.Pdf is done. This is required to prevent some lost layers for VW invoices (these documents come with broken pdf-trees). We can remove the workaround if a newer version of DynaPdf comes with an improved repair logic.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\DynaPdf-(iText7-replacement).md - Chunk 3
During iText7 replacement some suspicous code-parts where found which should have previously resulted in errors for specific types of documents (edge-cases) with more than 10 pages. These issues should be fixed now too.

Previously, for iText7, a specic plugin (dll) for asian fonts was loaded. We created ResultPdfs for invoices from HongKong (text- and image-based) with the new DynaPdf version of BLU DELTA and everything seemed ok.

2 phoenix actions (IsScanAction/IsScanBatchAction) still use some iText7 code which is not yet replaced with DynaPdf. This is no problem --> phoenix is not a commercial product.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Git-Commands.md - Chunk 0
Here we write Git commands and their explanations:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Git-Commands.md - Chunk 1
Command Explanation git config --global user.name " " Sets the global username for Git. git config --global user.email Sets the global email address for Git. git config --global init.default branch main Sets the default branch name to 'main'. git init Initializes a new Git repository in the current directory. git status Shows the current status of the repository. git add Stages a specific file for commit. git add --all or -A . Stages all changes in the repository. git commit -m " " Commits only staged changes with a message. git diff Shows differences between files in the working directory and the staging area. git restore --staged Unstages a file from the staging area. git commit -a -m " " Commits all changes in tracked files, skipping staging. git rm Removes a file from the repository and working directory. git restore Restores a file from the repository. git mv Renames or moves a file. git log Displays commit history. git log --oneline Displays an abbreviated commit history. git

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Git-Commands.md - Chunk 2
and working directory. git restore Restores a file from the repository. git mv Renames or moves a file. git log Displays commit history. git log --oneline Displays an abbreviated commit history. git log -p Shows changes made in each commit. git reset Resets the repository to a previous commit. git reset HEAD~1 Undo last local commit (File changes are still active in local repo) git branch Creates a new branch. git branch Lists all branches. git switch Switches to a specified branch. git merge Merges a specified branch into the current branch. git branch -d Deletes a specified merged branch. git push --all Pushes all local branches to the remote repository. git fetch Fetches updates from a remote repository. git pull Fetches and merges updates from a remote repository. git rebase -i --root Opens an interactive rebase editor to modify commit history. git commit --amend Amends the last commit with a new message or changes. git stash save " " Temporarily saves uncommitted changes (both

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Git-Commands.md - Chunk 3
Opens an interactive rebase editor to modify commit history. git commit --amend Amends the last commit with a new message or changes. git stash save " " Temporarily saves uncommitted changes (both tracked and untracked files) to a stash with a description, allowing you to work on a clean working directory. Use this to save your progress without committing. git stash list Displays a list of all stashed changes, showing their index, description, and the branch they were created on. Use this to view and manage your stashed work. git stash apply stash@{2} Applies the changes from the specified stash (in this case, stash@{2} ) to your working directory without removing it from the stash list. Use this to restore specific stashed changes. git stash pop stash@{2} Applies the changes from the specified stash (e.g., stash@{0} ) to your working directory and removes it from the stash list. Use this to restore specific stashed changes and clean up the stash.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Git-Commands.md - Chunk 4
Git Rebase tutorial

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\ISMS_-Secure-Coding-Course.md - Chunk 0
As part of story #16899 the following course was done and is documented here: https://www.udemy.com/course/secure-coding-secure-application-development/

Secure Coding

1. ISO 27001 Standard - Requirements

Availability Data Backup: Implementing regular data backup procedures to prevent data loss in the event of an accidental deletion or data corruption. Redundancy: Establishing redundant systems or data centers to ensure continued operation in case of system failure or a catastrophic event. Disaster Recovery Plan: Developing and testing a disaster recovery plan to ensure that data and services remain available or can be quickly restored in various disaster scenarios.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\ISMS_-Secure-Coding-Course.md - Chunk 1
Integrity Checksum Verification: Using checksums and hashing algorithms to verify that data has not been altered during transmission or storage. Change Management: Establishing a comprehensive change management process that ensures all changes to data or systems are authorized, logged, and validated to prevent unauthorized or harmful modifications. Data Validation: Implementing data validation mechanisms to ensure that any data input or output is accurate, valid, and reliable.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\ISMS_-Secure-Coding-Course.md - Chunk 2
Confidentiality Encryption: Encrypting data in transit (using protocols like TLS) and at rest (using algorithms like AES) to protect it from unauthorized access or breaches. Access Control: Establishing robust access control measures, ensuring that only authorized personnel can access sensitive information. This might involve user authentication, authorization, and regular audits. Privacy Policies: Developing and implementing privacy policies and procedures that ensure customer and employee data are handled confidentially and in compliance with applicable data protection regulations.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\ISMS_-Secure-Coding-Course.md - Chunk 3
Authenticity and Non-Repudiation Authenticity: Digital Certificates: Utilizing digital certificates issued by trusted Certificate Authorities (CA) to confirm the authenticity of websites or systems. Multi-Factor Authentication (MFA): Implementing MFA to verify user identity, often by requiring a combination of something the user knows (password) and something the user has (a token or phone). Non-Repudiation: Digital Signatures: Employing digital signatures to ensure that messages or documents are signed by the originator, providing a layer that verifies the sender's identity and intent. Audit Trails: Maintaining comprehensive audit trails that log all actions performed on critical data or systems, ensuring that any transaction or action cannot be denied later.

Most Common Attacks

Ransomware

Trojans and backdoors

Banker malwares

DDOS

=> Most common: Phishing via email, chat, etc. 30% of attacks are from insiders (people working in the company)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\ISMS_-Secure-Coding-Course.md - Chunk 4
Most Common Attacks

Ransomware

Trojans and backdoors

Banker malwares

DDOS

=> Most common: Phishing via email, chat, etc. 30% of attacks are from insiders (people working in the company)

2. Methodologies for developing secure code

Pen-testing and threat-modelling in the design phase of the software

Very important to test: Unit, Integration, Validation tests

Risk Analysis

Has the asset a vulnerability?

Is the asset subject to a threat?

How much damage can it produce?

High, medium, low risk?

Use something like forticlient vulnerability scan to find potential problems

Threat modelling

Create application overview (like Data Flow Diagram)

Check and think about all components

Spoofing, Tampering, Repudiation, Information Disclosure, Denial of Service, Elevation of Privilege

Microsoft Threat Modelling Tool

Analysis Tools

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\ISMS_-Secure-Coding-Course.md - Chunk 5
Check and think about all components

Spoofing, Tampering, Repudiation, Information Disclosure, Denial of Service, Elevation of Privilege

Microsoft Threat Modelling Tool

Analysis Tools

Static Application Security Testings tools: https://checkmarx.com/cxsast-source-code-scanning, https://www.synopsys.com/software-integrity/security-testing/static-analysis-sast.html, https://www.sonarsource.com/products/sonarqube/, https://www.microfocus.com/it-it/cyberres/application-security/static-code-analyzer

Dynamic Application Security Testing tools

OWASP - Open Web Application Security Project

https://owasp.org/www-project-top-ten/ https://owasp.org/projects/

Secure Coding Guidelines

https://wiki.sei.cmu.edu/confluence/display/seccode https://learn.microsoft.com/en-us/dotnet/standard/security/secure-coding-guidelines https://cwe.mitre.org/top25/archive/2021/2021_cwe_top25.html

3. VAPT - Vulnerability Assessment and Penetration Test

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\ISMS_-Secure-Coding-Course.md - Chunk 6
3. VAPT - Vulnerability Assessment and Penetration Test

https://owasp.org/www-project-web-security-testing-guide/stable/

Tools

https://portswigger.net/burp

Fiddler

Vulnerability Scanners - https://www.tenable.com/products/nessus - https://www.openvas.org/ - https://www.rapid7.com/products/nexpose/ - https://www.acunetix.com/product/standard/ - https://www.qualys.com/apps/vulnerability-management-detection-response/

Penetration Testing - https://www.kali.org/ - https://www.coresecurity.com/products/core-impact - https://www.metasploit.com/ - https://immunityinc.com/products/canvas/

4. Input validation

All data that comes from outside into the application should be checked.

Best to have a centralized input validation routine for the application.

Validation failures should result in input rejection

Validate all client provided data before processing, including all parameters, URLs, HTTP Header content (e.g. cookie names and values).

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\ISMS_-Secure-Coding-Course.md - Chunk 7
Validation failures should result in input rejection

Validate all client provided data before processing, including all parameters, URLs, HTTP Header content (e.g. cookie names and values).

Check input for hazardous cahracters, like <>"'%()&+\'\"

Check uploaded files for malicious content - https://cheatsheetseries.owasp.org/cheatsheets/File_Upload_Cheat_Sheet.html

Check for path altering parameters like "...."

Deserializing xmls or jsons

Buffer overflow, mainly in c and cpp

SQL Injection - Check in Log-In-Form, etc. - use parametric queries - https://cheatsheetseries.owasp.org/cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html - Use a single quote ' at the input form to see if you get SQL Code back instead of an Login-Rejection - easy way to see if the form is unsecured

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\ISMS_-Secure-Coding-Course.md - Chunk 8
LDAP, XPATH, XSS Injection - https://cheatsheetseries.owasp.org/cheatsheets/LDAP_Injection_Prevention_Cheat_Sheet.html - https://owasp.org/www-community/attacks/XPATH_Injection - https://cheatsheetseries.owasp.org/cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html - Countermeasures are parametric queries

5. Authentication of applications

In credential story, only cryptographically strong one-way salted hashes of passwords should be stored and the db is only writeable by the application

Password hashing must be implemented on a trusted system

Don't provide which part of authentication was wrong - instead of 'wrong username' write 'wrong credentials'

No passwords in source code, only in secure locations

Only use HTTP POST for credentials

Use Multifactor-Authentication

6. Security of Session Management

Disallow persistent logins an enforce periodic session terminations

New session after a successful login, always close old sessions

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\ISMS_-Secure-Coding-Course.md - Chunk 9
6. Security of Session Management

Disallow persistent logins an enforce periodic session terminations

New session after a successful login, always close old sessions

Generate a new session identifier on any re-authentication

Do not allow concurrent logins with the same user ID

Do not expose session identifiers in URLs, errors messages or logs. Should only be in the HTTP cookie header, never pass in GET parameters

7. Secure Coding Practices for Cryptography

Symmetric/private-key or asymmetric/public-key algorithms

Always use library build in methods for generating GUIDs, random numbers, file names, etc.

Symmetric encryption - should have a key lengths > 256 bits - does not guarantee the authentication of the sender

Asymmetric encryption - High bit number for the keys > 1024 - By using sender's private key and the recipient's public key, authenticity of sender and security are simultaneously guaranteed - needs public key infrastructure => certificates

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\ISMS_-Secure-Coding-Course.md - Chunk 10
Hashing - guarantee data integrity - MD5, SHA-1, SHA-2(minimal collisions)

8. References

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\KubeCon-2023-Report.md - Chunk 0
Cloud Native Computing Foundation = Part of Linux Foundation

Oversees and evaluates open source projects (with focus on cloud-native computing)

Operational control of Kubernetes was handed over to CNCF community by Google in 2018

https://www.cncf.io/projects/

Sandbox = experimental, not yet widely tested in production Incubating = Used successfully in production by a small number of users (healthy pool of contributors) Graduated = Stable, widely adoped and production ready, attracting thousands of contributors Archived = Reached end of lifecycle (inactive)

Location: RAI Amsterdam Convention Centre

Solutions ShowCase --> 200+ Vendors/Project Teams

10.000+ Visitors per day (more OPs then Devs)

186 Sessions/Talks (347 Speakers) KubeCon-EU23-Signage_SS_Map_3000x2000_v4.pdf

Find sessions on CNCF Youtube Channel (8th May 2023) https://www.youtube.com/channel/UCvqbFHwN-nwalWPjPUKpvTA

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\KubeCon-2023-Report.md - Chunk 1
186 Sessions/Talks (347 Speakers) KubeCon-EU23-Signage_SS_Map_3000x2000_v4.pdf

Find sessions on CNCF Youtube Channel (8th May 2023) https://www.youtube.com/channel/UCvqbFHwN-nwalWPjPUKpvTA

Building High-Throughput Applications with Bulk Messaging in Dapr - Shubham Sharma, Microsoft - Dapr = Distributed Application Runtime (service-to-service communication) - Pub/Sub is core building block of Dapr for event-driven applications - With the v1.10 release, Dapr has introduced a new set of capabilities to the pub/sub building block - Bulk Publish and Bulk Subscribe.

Choose Your Own Adventure: The Treacherous Trek to Development - Whitney Lee, VMware & Viktor Farcic, Upbound - Funny talk where audience could decide (live) which technologies and tools were used to deploy an application as container to a k8s cluster

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\KubeCon-2023-Report.md - Chunk 2
The RPC Revolution: Getting the Most Out of gRPC - Richard Belleville & Kevin Nilson, Google - gRPC = google Remote Procedure Calls - Anounced new observability features for gRPC - Concept talk why gRPC can be used for "REST"-style applications (Talk about Concurrency, etc...)

How to Develop a Robust Operator for Day-2 (Lesson Learned on KubeVirt/HCO) - Simone Tiraboschi, Red Hat - Developing Cluster Operator for the KubeVirt project (manages VMs for Virtual Machine-based workloads that cannot be easily containerized) - Too(!) deep technical talk for 40 mins

Using DevSpace to Usher in an Era of Peace for Our Developers - Rajsimman Ravichandiran, Independent - Work with a Dev-Cluster, without to break container-logic during development

Breakpoints in Your Pod: Interactively Debugging Kubernetes Applications - Daniel Lipovetsky, D2IQ - Showed how to debug an application inside k8s --> A complex approach via 'Ephemeral Containers'

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\KubeCon-2023-Report.md - Chunk 3
Breakpoints in Your Pod: Interactively Debugging Kubernetes Applications - Daniel Lipovetsky, D2IQ - Showed how to debug an application inside k8s --> A complex approach via 'Ephemeral Containers'

Tilt Your World! Lessons Learned in Improving Dev Productivity with Tilt - Yuvaraj Balaji Rao Kakaraparthi & Sagar Muchhal, VMware - Development environment for Teams that deploy to Kubernetes - Easier Debugging setup !

How GitOps Changed Our Lives & Can Change Yours Too! - Priyanka Ravi, Weaveworks; Christian Hernandez, Red Hat; Filip Jansson, Strålfors; Roberth Strand, Amesto Fortytwo; Leigh Capili, VMware - Very inspiring talk!

Open GitOps What is GitOps

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\KubeCon-2023-Report.md - Chunk 4
Open GitOps What is GitOps

Flux Beyond Git: Harnessing the Power of OCI - Stefan Prodan & Hidde Beydals, Weaveworks - OCI can serve as the single source of truth for application code (container images) and configuration (OCI artifacts) - Can be used as a package manager for distributing Kubernetes configs and Terraform modules as OCI artifacts Flux (Get started)

How to Blow up a Kubernetes Cluster - Felix Hoffmann, iteratec - Interesting talk regarding configuration of CPU- and Memory-Limits - The speaker describes how miss-configuration of memory-limits can lead to serious troubles - Conclusion: + Memory request == memory limit + No CPU limit

Disaster Recovery: Bringing Back Production from Scratch in Under 1 Hour Using KOps, ArgoCD and Velero - Andre Jay Marcelo-Tanner, Ada Support - Real life incident story - Whole cluster needed to be rebuilt (job done in 51 minutes) - GitOps + ArgoCD saved the day

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\KubeCon-2023-Report.md - Chunk 5
Kubernetes Defensive Monitoring with Prometheus - David de Torres Huerta & Mirco De Zorzi, Sysdig - Talk about some specific usage-scenarios of Prometheus (together with Falco for alerting) + Detect ingress creation (security) + High timeouts in ingress + High CPU comsumption of specific containers + Certificates which expire

Prevent Embarrassing Cluster Takeovers with This One Simple Trick! - Daniele de Araujo dos Santos & Shane Lawrence, Shopify - Most attacks are possible due to missconfiguration - Kubeaudit (Open source tool) helps to ensure that pods have least required permissions - In various demos they show attacks to a webstore and how these could be prevented with kubeaudit

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\KubeCon-2023-Report.md - Chunk 6
Hacking and Defending Kubernetes Clusters: We'll Do It LIVE!!! - Fabian Kammel & James Cleverley-Prance, ControlPlane - Demos of common attacks against clusters and options to protect against them + Restrict traffic via network segmentation (Block nodeport ports 30000-32767) + Strong authentication (2-Factor) + Restrict API server access + Principle of least privilege - Exploit your cluster before someone else does (penetration test)

19 - 22 March, 2024 https://events.linuxfoundation.org/kubecon-cloudnativecon-europe-2024/

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Naming-Conventions-for-Repos,-Service-and-more.md - Chunk 0
Naming Conventions

Here are some general guidelines to follow when creating your naming convention:

Use lowercase letters, numbers, and hyphens. Avoid special characters and spaces

Keep names short and concise but descriptive enough to convey their purpose

Follow a consistent pattern for all components to make it easier for team members to understand and work with

Use versioning for container images to track changes and roll back if necessary.

Service Naming Convention

Primarily, this is about Dotnet services that are deployed in Kubernetes clusters.

The service name should be used consistently throughout.

Project Repo Name

Repo: {ServiceName} Format: Camel case

```bash

example

PostProcessing ```

GitOps Repo Name

Camel case with '.GitOps' as suffix for CD Pipeline

Repo: {ServiceName}.GitOps Format: Camel case

```bash

example

PostProcessing.GitOps

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Naming-Conventions-for-Repos,-Service-and-more.md - Chunk 1
```

GitOps Repo Name

Camel case with '.GitOps' as suffix for CD Pipeline

Repo: {ServiceName}.GitOps Format: Camel case

```bash

example

PostProcessing.GitOps ```

CD Pipeline

Filename: azure.pipelines.yaml Format: lowercase, word separator '.'

The CD pipeline is determined by two parameters:

Service Name

ACR Repository Name

Pipeline: {service-name}-cd Format: lowercase, word separator '-'

```bash

example

post-processing-cd ```

ACR-Repository: {service_name} Format: lowercase, word separator '_' (for historical reasons)

```bash

example

post_processing

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Naming-Conventions-for-Repos,-Service-and-more.md - Chunk 2
```

The two variables service-name and acr-repository are set accordingly.

json - name: service-name value: post-processing - name: acr-repository value: post_processing

From this, further derivations are required to be present.

bash name: post-processing-cd $(Date:yyyyMMdd)$(Rev:.r) # set in powershell name: '$(service-name)-cd' - group: $(service-name)-config-${{ env }} acr-repository: '$(acr-repository)' --namespace bludelta \ --values $(Build.SourcesDirectory)/manifest/'$(service-name)'/values.yaml \ --wait $(aks-release-name) $(Build.SourcesDirectory)/manifest/'$(service-name)'

Helm Chart

[!ATTENTION] Warning The folder must be named exactly like the service name, otherwise the CD pipeline will not work>

Path: /manifest/{service-name} Format: lowercase, word separator '-'

CI Pipeline

Repo: {ServiceName} Path: Root Folder Filename: azure.pipelines.yaml Format: lowercase, word separator '.'

K8s Service Name

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Naming-Conventions-for-Repos,-Service-and-more.md - Chunk 3
CI Pipeline

Repo: {ServiceName} Path: Root Folder Filename: azure.pipelines.yaml Format: lowercase, word separator '.'

K8s Service Name

Service Name: {service-name} Format: lowercase, word separator '-'

```bash

example

post-processing

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Naming-Conventions-for-Repos,-Service-and-more.md - Chunk 4
```

Ingress Url

Ingress Url: /{service-name} Format: lowercase, word separator '-'

```bash

example

http://10.0.0.1/post-processing ```

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Naming-Conventions.md - Chunk 0
Container

Pipelines

Machine Learning Pipelines

Naming convention of continuous training pipelines: ml-{model-name}-ct. This means that each pipeline starts with 'ml-' (machine learning), then comes 'model-name-' which is the name of the model that shall be trained and finally 'ct' for contiuous training, e.g. ml-header-details-ct or ml-training-line-items-ct

Models

{model_type}_{model_detail}

e.g.:

typhon_doc_type

typhon_header_detail

typhon_line_item

typhon_vat_group

bert_payment_condition

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix.md - Chunk 0
Create a sub-page here for each action

Each day at 20:00, a new phoenix version is automatically built and uploaded by the Azure DevOps pipleine "phoenix-ci".

You can download the most actual phoenix version from our 'buildartifcats' blob storage (yes, this typo is for real) which you can find in the 'blumatix-dev' subscription. - a) Download directly via Azure Portal, or - b) Use ' Microsoft Azure Storage Explorer'

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Replace-Spire.PDF-with-DynaPDF.md - Chunk 0
Execution Plan

Plan A) Replace Spire.Pdf with DynaPdf

The only real way to find out if it works is to do it

Fail Fast!!! Start with the methods where we see the most potential to fail

Plan B) Buy full OEAM license for Spire.Pdf

Esimated effort

1 Developer for 1-2 Sprints

Functionalities to replace

The main functionalities, where the Spire.PDF library needs to be replaced with DynaPDF, are in BlumatixCaptureComplete.sln Blumatix Capture repository.

List all layers in a PDF (retrieve the names of the layers)

Blumatix.Capture.PdfBuilder: SpirePdfUtils

Create a new layer in a PDF (including a new canvas for drawing)

Blumatix.Capture.PdfBuilder: SpirePdfUtils

Draw a rectangle on the canvas of a layer (rectangle border and background, ARGB – with transparency)

Blumatix.Capture.PdfBuilder: SpirePdfUtils

Draw an image on the canvas of a layer

Blumatix.Capture.PdfBuilder: SpirePdfUtils

Draw an image on the canvas

Project Blumatix.Capture.BluDeltaCli: WriteToPdf.cs

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Replace-Spire.PDF-with-DynaPDF.md - Chunk 1
Draw an image on the canvas of a layer

Blumatix.Capture.PdfBuilder: SpirePdfUtils

Draw an image on the canvas

Project Blumatix.Capture.BluDeltaCli: WriteToPdf.cs

Blumatix.Capture.PdfBuilder: SpirePdfUtils

Write text to pdf

Project Blumatix.Capture.BluDeltaCli: EntityRecognitionInfo.cs, ErrorAnalysisResult.cs, MetaInfo.cs, PdfWriter.cs, PredictionInfo.cs

Write table to pdf

Project Blumatix.Capture.BluDeltaCli: FeatureContributionInfo.cs, IndicatorInfo.cs, PdfWriter.cs

Draw/write text on the canvas of a layer (specifying FontFamily, font size, and color - ARGB)

Project Blumatix.Capture.BluDeltaCli: PdfWriter.cs, MetaInfo.cs

Blumatix.Capture.PdfBuilder: SpirePdfBuilder.cs

Blumatix.Capture.PdfBuilder: SpirePdfResultFont.cs

Blumatix.Capture.PdfBuilder: SpirePdfUtils

Remove digital signatures from a PDF

Blumatix.Capture.PdfBuilder: SpirePdfUtils

Add a new page to a PDF → Yes, this is possible → Append().

Convert a PDF (or PDF page) to PNG.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Replace-Spire.PDF-with-DynaPDF.md - Chunk 2
Remove digital signatures from a PDF

Blumatix.Capture.PdfBuilder: SpirePdfUtils

Add a new page to a PDF → Yes, this is possible → Append().

Convert a PDF (or PDF page) to PNG.

Project Blumatix.Capture.BluDeltaCli: PdfToPngAction.cs

Convert a PNG to PDF → This should also work → Create a new PDF and draw the image inside. We might not need this, since the code where it was used is obsolete.

Rotate a PDF page by 90, 180, or 270 degrees

Blumatix.Capture.PdfBuilder: MathUtils.cs

Split PDF by indicies → This works with Dyna

UploaderTool in ExternalTools.sln

Email Query to DynaPDF regarding the functionalities

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Replace-Spire.PDF-with-DynaPDF.md - Chunk 3
Blumatix.Capture.PdfBuilder: MathUtils.cs

Split PDF by indicies → This works with Dyna

UploaderTool in ExternalTools.sln

Email Query to DynaPDF regarding the functionalities

We received following answer from Jens Boschulte info@dynaforms.com: - List all layers in a PDF (retrieve the names of the layers) → This can be done with GetOCUINode(). There is an example in the help file regarding its usage. - Create a new layer in a PDF (including a new canvas for drawing) → see BeginLayer() / EndLayer() - Draw a rectangle on the canvas of a layer (rectangle border and background, ARGB – with transparency) → To use alpha transparency, an extended graphics state must be created. See CreateExtGState() and the example alpha_transparency. Images, text, and vector graphics can also be output in layers. There is no difference in rendering these objects within or outside a layer.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Replace-Spire.PDF-with-DynaPDF.md - Chunk 4
Remove digital signatures from a PDF → Signatures are always removed during import. However, deleted signature fields remain available and can be flattened if needed to preserve their appearance.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\REST-api-guidelines.md - Chunk 0
REST api guidlines

Use lowercase letters for URLs and separate words with hyphens.

Use the HTTP methods GET, POST, PUT, and DELETE to define CRUD operations.

Use singular nouns for resource names in the URL, for example, /user instead of /userlist.

Use verbs not in the URL, but in the HTTP method, for example, POST /user instead of /create-user.

Use parentheses to indicate optional parameters in the URL, for example, /user/{id} for a single user resource or /user/{id}/messages for a list of messages associated with a specific user.

An example URL using this naming convention would be:

GET /v1/user/1234

This would send a GET request for the user resource with ID 1234.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Tech-Conception-(TBIs).md - Chunk 0
3.10.2022 (Gü, Bernhard)

Hottest Topics: - Rollout-Process for new AKS-Containers - Benchmarks -> it must be clearly defined and traceable which components exactly are used - Define process for benchmarking during deployments - Automatically generate internal Release-Notes (component-based vs. multiple components) - BLU DELTA Environment version (automate) - Response Caching --> active for all Customers - Cloud Costs --> go for .Net7 --> go for Linux --> next steps? - Architecture must be scaleable - Central spot for Configurations

Brainstorming

Avoid Dependency Tree Components have to be totally independantly releaseable!

CaptureSdk DocType ResourceService ...

Rollout strategy - Dev-Environment - QA-Environment - Prod-Environment

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Tech-Conception-(TBIs).md - Chunk 1
Current Problems 1. We are currently not able to create the whole BLU DELTA Environment from scratch with a pipeline --> Disaster Recovery --> TBI needed 2. Currently, we need the benchmark reports to validate if the BLU DELTA Environment is correct when a single component (lik typhon-contacts) shall be released. In the world of microservices you have to be able to deploy and validate(!) a single (micro-)service independant from the other services! So we have to be able to execute a benchmark against a single container and validate those predictions (Dasboard and BLU BOARD should be capable to view these results) ---> TBI needed Another reason is, that our current training mechanism, which requires a stable BLU DELTA Environment (dev) to execute benchmarks for models which are trained automatically (via datacollection & kubeflow/argo) will create a lot of troubles! The Dev-Environment is not stable and the deployment and benchmarking of multiple models at the same time will not work

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Tech-Conception-(TBIs).md - Chunk 2
(via datacollection & kubeflow/argo) will create a lot of troubles! The Dev-Environment is not stable and the deployment and benchmarking of multiple models at the same time will not work because these processes will get in each others way.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\TETA-Tasks-(Technical-Tasks).md - Chunk 0
General stuff

Do not log Ping requests on INFO level --> Do not log them at all or just on DEBUG level For the c# services we have aspNetCore derived Ping Classes - the problem is, if you deactivate the ping logging is, that you still get middleware logging for the ping, which still spams it, the solution would be to also change that to only log warning and above, but we have to talk and define, if this is what we want: ``` { "Logging": { "LogLevel": { "Default": "Information" } }, "AllowedHosts": "*", "UploadLimit": 100,

"Serilog": { "Using": [ "Serilog.Sinks.Console" ], "MinimumLevel": { "Default": "Information", "Override": { "Microsoft": "Information", "Microsoft.AspNetCore": "Warning", "Blumatix.PostProcessing.Api.Controllers.PingController": "Warning" } }, ``` - We should create some kind of guideline for logging --> what needs to be logged and on which level - Concept for customer- and request-tracking accross all services needed (use AppGateway tracking-id?)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\TETA-Tasks-(Technical-Tasks).md - Chunk 1
All Python Containers

Use same logging format as for C# containers

CaptureSdk (& CaptureService?)

Use Serilog

The caching mechanism, does not correctly work when 2 (or more) instances of the Resource Service are used (behind a loadbalancer). The state-key has to be generated from the state of the resourcefiles (size and/or date) and not only as guid.

OnPremise: Container should be built with a different config --> ETL shall not be able to read out of appsettings.json that Dachser is one of our customers

We need to extend the interface at some point to also include the "subcustomer"-name, that can be provided via the .-notation on the ApiIdentifier, like ASDFIJSI234==.CustomerXYZ - this is important for the plugins, since some of our customers want certain plugin functionality only for their subcustomer/branch/etc.

Fix Memory Leak #18138 - about 200mb in two weeks

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\TETA-Tasks-(Technical-Tasks).md - Chunk 2
Fix Memory Leak #18138 - about 200mb in two weeks

Dachser-PP: Accessing properties of Hits must be more defensive! Property might not exist due to [null]-value: Have seen such exceptions: "The given key 'vat registration number' was not present in the dictionary"

Maybe(!), Post Processing Service should not crash on start-up if I retrieves an exception from elastic. Elasticsearch is often not yet ready when a new cluster is created. The problem is that the whole PostProcessing service is not functional otherwise (also plugins which do not need elastic). But we have to ensure that OPS receives an alert that post-processing cannot communicate with elastic!!

Check dedicated wiki page: OnPremise Automation (CICD) - Important1: Automate which container versions to use (auto update compose file) - Important2: Automate models to use

typhon_model.py only supports data augmentation for one head, see how to change this in chagrid_model_segonly.py

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\TETA-Tasks-(Technical-Tasks).md - Chunk 3
typhon_model.py only supports data augmentation for one head, see how to change this in chagrid_model_segonly.py

make typhon heads exchangeable, so that you can retrain a model with any number of heads by just changing the config ``` In the BLU DOC format the Confidence values are the scores.

A Confidence value can be between “0.0000”…”1.0000”; 1 indicating the Ground Truth. The Confidence value is normalized to 4 digits after the comma

If we do NOT find a value, then the confidence should be: a) For simplicity and as quick workaround: “0.0000” b) Mid-term: we use the background class score to set the confidence

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\TETA-Tasks-(Technical-Tasks).md - Chunk 4
```

BenchmarkRun-Details view should have a unique Url (with Id in url-parameters), so that you can send this link to someone

Link to BLU BOARD must be configurable via Web.config (check _NavBar.cshtml)

Need to be able to set a new Baseline (Predictions and/or Perf) for a Report directly via a Button/Dialog --> reuse code from phönix-action in backend

Context Cleanup is not executed if a workflow takes a different path and does not end up in ResultBuilderActivity

Implement PropertyStoreKey.OpsData_All (Currently this is used only by WorkflowServer)

The git-repo-tagging task at the end of the ocr-box-ci pipeline does not work! --> It brings fatal-error but we do not understand why, because we do it in the same way as in other repos

Check Bug #22433 --> First part of this Bug is a exception which is thrown by DynaPdf! Fix it when we have to touch DynaPdf again.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Versioning-Concept.md - Chunk 0
Version Strategy - Versioning through URI Path

Die Versionierung sollte bei allen Services (intern und nach außen sichtbar) gleich sein. Syntax bzw. Strategie sollte immer die gleiche sein.

Welche Syntax bzw. welche Art der Versionierung wollen wir verwenden? Es gibt verschieden Strategien, siehe [1]. Wir haben uns für "Versioning through URI Path" entschieden, d.h. die API Version wird im URI Path mitgegeben.

Examples: - https://api.bludelta.ai/v1-18/invoicedetails - http://localhost/v1/package

Internal Format

The internal version of the API uses the 1.2.3 format, so it looks as follows:

MAJOR.MINOR.PATCH

Major version: The version used in the URI and denotes breaking changes to the API. Internally, a new major version implies creating a new API and the version number is used to route to the correct host.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Versioning-Concept.md - Chunk 1
Minor and Patch versions: These are transparent to the client and used internally for backward-compatible updates. They are usually communicated in change logs to inform clients about a new functionality or a bug fix.

The version should be returned in the response: - A VersionNumber which identifies all services (internal and public) (TBD) - Guid could also be returned. This guid represents all services (+ their version number) which were involved during request processing.

Should we introduce a separate Version for our json format????

Breaking Changes

Wie gehen wir mit „Breaking Changes“ um. Wir sollten noch definieren was genau ein Breaking Change ist. - Generally, additive changes are not breaking changes: - Adding new Endpoints - New (optional) query string parameters - Adding new properties to DTOs

Replacing or removing things in our API cause breaking changes:

Changing the type of DTO property

Removing a DTO property or endpoint

Renaming a DTO property or endpoint

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Versioning-Concept.md - Chunk 2
Replacing or removing things in our API cause breaking changes:

Changing the type of DTO property

Removing a DTO property or endpoint

Renaming a DTO property or endpoint

Adding a required field on the request

Renaming from constant values/strings (Bludelta Specific Use Case)

Backward-Compatibility

Was heißt bei uns „rückwärts kompatibel“?

Public visible endoints:

must be available for a looooong time

Interface/contract/reponse must exist

OpenApi conform

No Breaking Changes

Guarantee backwards compatiblity:

There exists a VersionMapper which guarantees backward compatibility between minor version of the same major version and possibly between major versions.

URI Path without a version number?

NO: Problem: Rückwätskompatibilität kann dadurch nur sehr schwer oder gar nicht garantiert werden.

Wie gehen wir mit normalen Änderungen

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Versioning-Concept.md - Chunk 3
URI Path without a version number?

NO: Problem: Rückwätskompatibilität kann dadurch nur sehr schwer oder gar nicht garantiert werden.

Wie gehen wir mit normalen Änderungen

Was machen wir wenn sich das Interface eines internen Services ändert, bzw wenn es dort zu einem Breaking Change kommt. Müssen wir dann alle Dienste die dieses Service verwenden ge-patched werden? Müssten wir dann auch diese Dienste mit einer neuen Endpoint Url ausliefern oder nur in speziellen Fällen wenn sich durch die interne Änderung auch das Interface nach außen ändert?

Resources:

[1] https://www.xmatters.com/blog/blog-four-rest-api-versioning-strategies [2] https://stackoverflow.com/questions/389169/best-practices-for-api-versioning [3] https://code-maze.com/aspnetcore-api-versioning

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Virtualization-Help.md - Chunk 0
--> Example: v1.15

docker rmi (docker images | select-string v1.15 | % { $_ -replace '\s+', ' ' } | % {$_.Split(' ')[0]} | % {$_ + ":v1.15"})

Shrink WSL2 virtual disc

Quit Docker

Run powershell as Admin

Shutdown wsl: wsl --shutdown

Navigate to docker data folder: cd 'C:\Users\[YOURNAME]\AppData\Local\Docker\wsl\data'

Reclaim disc space optimize-vhd -Path .\ext4.vhdx -Mode full

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\WATCH-OUT,-TRAP!.md - Chunk 0
Windows... Renders to "\r\n"

Linux... Renders to "\n"

Trap: A string with linebreaks is generated in a windows-Service (f. ex OCR-RawText). Another service (which can run as windows EXE or linux Container) takes this string and splits it by Environment.NewLine --> BOOM!! Works as EXE but fails as Linux-Container.

Good Solution: ?

Workaround: Split by: "\r\n" explicitly --> But, what if the original string is generated from Linux later?

Trap:

Base64 string from powershell may look exactly identical as the string from a C# application, but it is not! A hidden character/Encoding will lead to an excpetion when converting back to file in C#.

So dont use this in powershell ps $base64String = [Convert]::ToBase64String([IO.File]::ReadAllBytes($file.FullName)) # Convert-ToBase64 -FilePath $file.FullName $base64String | Out-File -FilePath $outputFile -NoNewline -Encoding UTF8

Good Solution: Use C#

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\WATCH-OUT,-TRAP!.md - Chunk 1
Good Solution: Use C#

csharp var outputDir = @"D:\# Blumatix\Blumatix Capture\SPRINTS\# Working\# S144\partner.css-Receipt_469_uniform3-base64-csharp"; var files = Directory.GetFiles(@"D:\PhoenixTemp\partner.css-Receipt_469_uniform3"); foreach(var file in files) { var bytes = File.ReadAllBytes(file); var base64 = Convert.ToBase64String(bytes); // get filename only (without extension) var filename = Path.GetFileNameWithoutExtension(file); File.WriteAllText(Path.Combine(outputDir, filename + ".txt"), base64); }

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Workshop.md - Chunk 0
Workshop Location: Firma

Workshop Dauer: 1.5 Tage

0.5 Tage: Theorie und über Teams

1.0 Tag: Praxis in der Firma

Was ist das übergeordnete Ziel:

Gemeinsames BLUDELTA Verständnis, und standardisierter Entwicklungsprozess und dadurch eine quantitative und qualitative Steigerung der Produktivität und Verbesserung unserer Software Qualität

Agenda

Teil I – Bludelta in der Theorie

Bludelta Architektur – Ist-Zustand und wo wollen wir hin. Aktueller Stand: ML Modelle (wo und wie werden die aufgerufen etc.)

Wie bauen wir in der Blumatix Software – Best Practices, Software Development Process

Entwicklungsumgebung

Cloud/OnPremise, Lokaler Cluster (Rancher Desktop)

Entwicklung

Templates inkl. DataCollection

Deployment

CI/CD

OnPremise

Argo-Workflow

ML Workflow

Typhon training (wie, was, etc.). MLFLow, Kubeflow

TEIL II – Bludelta in der Praxis

Konkrete Aufgabe die wir gemeinsam umsetzen und die uns für die Zukunft auch etwas bringt.

Was sollen wir konkret vortragen bzw. machen:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Workshop.md - Chunk 1
TEIL II – Bludelta in der Praxis

Konkrete Aufgabe die wir gemeinsam umsetzen und die uns für die Zukunft auch etwas bringt.

Was sollen wir konkret vortragen bzw. machen:

Train a CustomerID Model

Provide Typhon Service

Integrate into WorkflowEngine

Deploy it to Kubernetes

References

Workshop.pptx

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\!BEST-PRACTISES!\Best-Practice-for-External-Dev-Work.md - Chunk 0
Min. Requirements for any Dev Work within BLU DELTA Team (incl. externals)

[ ] Definition of Done needs to be part of requirements and communicated

[ ] Configuration needs to be defined upfront (what / best BLU DELTA practice for config)

[ ] Logging: Best BLU DELTA practice (e.g. System critical errors vs. WARN. vs. INFO, DEBUG)

[ ] Swagger OpenAPI description must be deployable under the endpoint xxx/openapi

[ ] Annotation for Online Document generation of the endpoint must be available explaining output, input and edge/failure cases

[ ] Githup project templates need to be aligned and used

E.g. for Python

Configuration:

Best Practice: hydra color log;

All configuration parameter should be set via request (dictionary)

Default configuration should be in a config.yaml file

Logging:

Best Practice: hydra: https://hydra.cc/

All of following situations must be logged:

System crashes or a status of total system failure must be logged with highest criticality in the logs

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\!BEST-PRACTISES!\Best-Practice-for-External-Dev-Work.md - Chunk 1
Logging:

Best Practice: hydra: https://hydra.cc/

All of following situations must be logged:

System crashes or a status of total system failure must be logged with highest criticality in the logs

Failures leading to unsuccessful requests must be logged as 2nd level criticality

Uncommon situations should have warning level

Important information helfpul to analyse issuee should have INFO or DEBUG level

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\!BEST-PRACTISES!\Best-Practices-Guidlines.md - Chunk 0
Introduction

At Blumatix, we strive to maintain a high standard of software development by following best practices that ensure the quality and reliability of our products. As a small development team, it is essential that our development strategy is concise, simple, and that all team members are aware of and adhere to our best practices guidelines. By consistently following these guidelines, we can ensure that our software is well-designed, easy to maintain, and meets the needs of our customers.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\!BEST-PRACTISES!\Best-Practices-Guidlines.md - Chunk 1
At Blumatix, our developers are committed to creating software that not only meets the needs of our customers but also scales to accommodate future growth, is reliable and cost-effective. We understand that software development can be a complex process, but by utilizing best practices such as modular design, testing, and code reviews, we can ensure that our software is efficient and can handle the demands of a rapidly changing business environment. Additionally, our developers regularly evaluate new technologies and strategies to ensure that our software remains cost-effective while providing the necessary functionality to our customers. By utilizing these best practices, we can ensure that our software is not only of the highest quality but also that it can adapt to the ever-changing needs of our customers.

Best Practices

Software Development

Cookiecutter templates for c# and python Services and azure functions

No Manual deployment. There must be a pipeline for everything

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\!BEST-PRACTISES!\Best-Practices-Guidlines.md - Chunk 2
Best Practices

Software Development

Cookiecutter templates for c# and python Services and azure functions

No Manual deployment. There must be a pipeline for everything

One Interface for all predictions and even for plugins. Return BluDoc

Use a Workflow Engine

There shall be a workflow for every customer and every use case.

Store customer settings like workflows in a database.

Cache BluDoc result in Redis or in a database.

Use a separate result builder, BluDocAggregator

Code Reviews

UnitTest and IntegrationTest for the most important Code parts must be available

Documnent Public interfaces and methods.

Software Deployment

CI/CD pipelines are the only valid way to deploy any container (C4 container)

Monitoring

Monitoring via prometheus.

Use Grafana

Logging

Logging the right way - structured logging.

Use loki.

Use Serilog in C#

Use struct log in python

Use Structured Logging

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\!BEST-PRACTISES!\Best-Practices-Guidlines.md - Chunk 3
Monitoring

Monitoring via prometheus.

Use Grafana

Logging

Logging the right way - structured logging.

Use loki.

Use Serilog in C#

Use struct log in python

Use Structured Logging

Structured logging is beneficial because it allows for better searchability, analysis, and troubleshooting of log data. With structured logging, log data is stored in a structured format (such as JSON) rather than in unstructured text. This allows for easy parsing and querying of log data, which can greatly improve the efficiency of troubleshooting and debugging. Additionally, structured logging can also facilitate integration with other monitoring and alerting systems, which can help to quickly identify and address potential issues.

Security

Use Key Vault

HTTPs is the only way to communicate with our public APIs

Rest APIs and HTTP/gRPC communication

Use http Codes the rigth way.

Naming conventions for Http routes

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\!BEST-PRACTISES!\Best-Practices-Guidlines.md - Chunk 4
Security

Use Key Vault

HTTPs is the only way to communicate with our public APIs

Rest APIs and HTTP/gRPC communication

Use http Codes the rigth way.

Naming conventions for Http routes

Re-Doc and Swagger for Http based Services. Api documentation must be Auto generatable

Images should not be returned as b64 strings in a http/REST response

Use message based communication internally.

Use dapr

Use serverless whenever possible.

Data

Store OCR and other json or text based documents in elasticsearch

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\!BEST-PRACTISES!\Best-practise-for-new-components.md - Chunk 0
Use the existing project templates for new components!

For C# service components:

--> Repo 'BlumatixTemplates' --> Folder: BlumatixServiceTemplate --> File: cookiecutter.json

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\!POLICIES!\Conceptual-Policies.md - Chunk 0
"Be carefull with websites and resources (javascripts, css, ...)"

"DB size explodes - operation & maintainance is difficult, query performance is often degrading (EF6 joins!), ...."

Passwords, Tokens, Connection strings,.. --> Plugins: Map via CustomerName instead of ApiKey!"

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\!POLICIES!\Dev-Policies-&-Principles.md - Chunk 0
"If something will not work, you should discover it as soon as possible! Applies to code and concepts." Details regarding code Details regarding concepts

"Avoid wasted effort on features that are assumed to be needed at some point." Details

Single Responsibility Principle (SRP) Open/Closed Principle (OCP) Liskov Substitution Principle (LSP) Interface Segregation Principle (ISP) Dependency Inversion Principle (DIP)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\!POLICIES!\Dev-Policies-&-Principles.md - Chunk 1
Ask yourself the following questions: - Single Responsibility Principle (SRP) Question: Does this class/module/function have one, and only one, reason to change? Is it doing more than one type of work? - Open/Closed Principle (OCP) Question: Are the changes to the code adding new functionality in a way that doesn’t alter existing code directly? Can the new behavior be added without modifying the existing code? - Liskov Substitution Principle (LSP) Question: If there are any new subclasses, can they be used interchangeably with their base class without causing errors or changing the expected behavior? - Interface Segregation Principle (ISP) Question: Does this interface contain only those methods that are necessary for its clients, or are there methods that some clients might never use? - Dependency Inversion Principle (DIP) Question: Does the code depend more on abstractions than on concrete classes? Are high-level modules independent of low-level modules and communicate with them

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\!POLICIES!\Dev-Policies-&-Principles.md - Chunk 2
- Dependency Inversion Principle (DIP) Question: Does the code depend more on abstractions than on concrete classes? Are high-level modules independent of low-level modules and communicate with them through interfaces or abstract classes?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\!POLICIES!\Dev-Policies-&-Principles.md - Chunk 3
SOLID principles in C#

"Duplication in logic should be eliminated via abstraction; duplication in process should be eliminated via automation." Details

"Break up the code into chunks that are finalized tiny pieces of the system each able to complete a simple distinct job." Details

"Any team member should be able to release updates at any time in a sustainable way." Details

"Technical debt vs new features is a bad way to think about coding…" Details => "Every change should be easy to implement. If not, then refactor the code, so that the change is easy to implement."

"Always code as if the guy who ends up maintaining your code will be a violent psychopath who knows where you live." Martin Golding Details

"Follow our best practises" Best practises to store local secrets (C-Sharp)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\!POLICIES!\DevOps-Policies.md - Chunk 0
Changes of the following productive ressources need to be announced internally and/or externally and have to be documented with a corresponding Wiki page: - Application Gateway - BLU DELTA Resources: CaptureSdk, CaptureService, Python-Containers, AKS, DB-server or database "bcsdb_auth" - SME Resources:

Maintainance job template

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\!POLICIES!\Log-Level-Policy.md - Chunk 0
ERROR: Indicates a failure within the application's operation, requiring attention by the operations team to prevent or address disruptions in service.

WARN: Signals a potential issue or an unexpected situation that doesn't currently disrupt the service but should be reviewed to prevent future errors.

INFO: Provides insights into the application's normal operations, useful for tracking the flow and state of processes without indicating any error or warning condition.

DEBUG: Offers detailed diagnostic information (intended for developers)

Always configure log level for productive services!!

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview\Json-Plugins-Mechanics-and-Rules.md - Chunk 0
SmartLib Plugin Solution

https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/541/SmartLib-Plugin-Solution

Whitelist Plugins

There exits Json Plugins and Whitelist Json Plugins. For the later, see: WhiteListSearch

How To

The json file must end with "...SmartFilters.json".

Plugin Activation Logic

if no ApiKeys and no CustomerNames are given the plugin is always activated (used for OnPremise)

if one or more ApiKeys are given the plugin will be activated for all of the customers using these ApiKeys (meaning also all Child-Customers, which use the same ApiKey)

The CustomerNames are lower case string matches, meaning that it will only be activated for the exact given CustomerName. A customer name can be e.g.: "Parent Company", "Parent Company.SubUser2", "Child Company", "Child Company.SubUser", "Company.*"

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview\Json-Plugins-Mechanics-and-Rules.md - Chunk 1
"Company.*" The "*"-Operator activates the Plugin for all SubUsers given in the Api-Identifier after the "." of the given "Company", but not for the "Company" itself.

If the company should be added as a whole and is a parent, then just use the ApiKey. If it is a child "Child Company" and "Child Company.*" have to be added, to activate it for all request from "Child Company".

Important: Parent and child company only share an ApiKey, this relationship is lost in processing, thus using "Parent.*" will not activate the Plugin for "Child". We would have to implement a not-Operator to be able to activate a PlugIn for all Child-Companies of a Parent, but not the parent itself.

Json Plugin - Structure

A plugin is defined in a .json file as follows:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview\Json-Plugins-Mechanics-and-Rules.md - Chunk 2
Json Plugin - Structure

A plugin is defined in a .json file as follows:

{​​​​​ "Version": "1.0.0", "PluginName": "TestSmartFilters", "CustomerName": "TestCustomer", "ApiKeys": [ "ApiKey1", "ApiKey2" ], "CustomerNames": [ "Customer1", "CustomerABC" ], "InvoiceDetailType": "InvoiceId", "ValueToSet": null, "ReturnSingleResult" : "true", "OverwriteExistingPrediction": "false", "Patterns": [...], "PatternGroups": [ {​​​​​ "PatternNames": [...], }​​​​​​​​​​​​​​​​​​​, {​​​​​​​​​​​​​​​​​​​ "PatternNames": [...], }​​​​​​​​​​​​​​​​​​​ ] }​​​​​​​​​​​​​​​​​​​

Properties

Version: Major: interface is incompatible, like detail name changes InvoiceDetailType=>Type or InvoiceId=>InvoiceNo; Minor: new functionality, like a new regex pattern for the detail; Patch: bugfixes, etc.

PluginName: The name of plugin. A plugin name must be unique for a given api-key - multiple plugins with the same name for a given api-key are not supported.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview\Json-Plugins-Mechanics-and-Rules.md - Chunk 3
PluginName: The name of plugin. A plugin name must be unique for a given api-key - multiple plugins with the same name for a given api-key are not supported.

CustomerName: Name of the Customer who ordered this Plugin, this property is not checked for authentification.

ApiKeys: List of ApiKeys for which the plugin is activated

CustomerNames: List of Customer for which the plugin should be activated, if using this, at least one ApiKey (UnrestrictedUser) should be given (otherwise the plugin is always activated), but no ApiKey of the Customers, since the ApiKey overrules this for now. (This property should replace the ApiKeys in the future, by being dependant on the Names instead of the Keys - keys might change).

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview\Json-Plugins-Mechanics-and-Rules.md - Chunk 4
InvoiceDetailTypeName: The invoice detail type for which the plugin is used. If this is a existing invoice detail type the plugin will overwrite the value for that specific invoice detail type, if property OverwriteExtistingPrediction is activated. Otherwise, a new custom invoice detail will be generated with the name of the custom invoice detail corresponding to the value specified here. PAY ATTENTION to inconsistent DetailsTypes like UId and Receiver-/SenderVatId.

ValueToSet: If the plugin should overwrite the value of the specified invoice detail with a fixed value, this value needs to be entered here as string.

ReturnSingleResult: This field is only relevant for custom invoice details. If this field is set to true only one prediction for the specified custom invoice detail will be returned in the result .json of our capture solution. Otherwise all unique matches that are generated by the pattern groups will result in a separate prediction in the output.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview\Json-Plugins-Mechanics-and-Rules.md - Chunk 5
OverwriteExistingPrediction: In the case of a non-custom invoice detail determines whether existing predictions for the invoice detail type will be overwritten or whether the predictions from the pattern will be added to the existing predictions.

Patterns: A list of pattern objects that are used in this plugin - refer to section 'Json Plugin - Patterns' for a description of the pattern object.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview\Json-Plugins-Mechanics-and-Rules.md - Chunk 6
Patterns: A list of pattern objects that are used in this plugin - refer to section 'Json Plugin - Patterns' for a description of the pattern object.

PatternGroups: The patterns which are defined in the 'Patterns' list need to be entered into at least on pattern group via their name to be active. Within a pattern group patterns are linked with a logical AND, meaning that only if all patterns in the group match, the whole pattern group will match. Between pattern groups there exists a logical OR connection, meaning that if one pattern group matches successfully the match for the specified invoice detail will be returned. If multiple pattern groups return different matches the 'ReturnSingleResult' decides which match shows up as prediction in the result .json of our service.

Json Plugin - PatternGroup

PatternNames: Names of the patterns that belong to this pattern group as defined in Patterns

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview\Json-Plugins-Mechanics-and-Rules.md - Chunk 7
Json Plugin - PatternGroup

PatternNames: Names of the patterns that belong to this pattern group as defined in Patterns

SkipIdPostProcessing: If you want IdPostProcessing to be skipped set this to true. Can lead to the same prediction being returned twice if a scored word with the same value if found by either another SmartPattern or the regular prediction pipeline.

ContinueAfterGroupMatches: Other groups in this pattern return their matches as predictions as well if this is set to true. Otherwise the first prediction group that matches something stops other pattern groups from being applied.

Json Plugin - Patterns

A pattern in the .json file looks as follows:

{​​​​ "PatternName": "MyStringMatchPattern", "MatchOnlyIfFalse": "false", "Topology": "Before", "TopologyPositionSpecifier": "1", "PatternType": "StringMatch", "IncludeMatchInValue": "true", "PatternProperties": {​​​​​​​​​​​...}​​​​​​​​​​​​​​​​​​ }​​​​​​​​​​​​​​​​​​​​​​​​​

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview\Json-Plugins-Mechanics-and-Rules.md - Chunk 8
PatternName: The name of the pattern. This name is used to enter a pattern into a pattern group.

MatchOnlyIfFalse: If this flag is set to true the functionality of the pattern is inverted. In the case of a pattern that checks for a string match for example this would mean that the pattern returns all words on the invoice that do not match the specified strings instead of returning all words that match.

Topology: The topology of the pattern. Valid options are: 'Before', 'After', 'Above', 'Below' and 'Self'. Not all patterns support all topologies, since not all topologies do always make sense - refer to section 'Json Plugin - Pattern Types' if you want to know which topology your pattern supports. In the case of a string match pattern the topology 'Before' would for example mean that the word that is

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview\Json-Plugins-Mechanics-and-Rules.md - Chunk 9
TopologyPositionSpecifier: Specifies how many positions away from the 'target word' the topology should be applied. The combination 'Topology': 'Before', 'TopologyPositionSpecifier' : '3' would for example mean 3 positions before the target word. In the case of 'Before' and 'After' the threshold of a position is a whitespace.

PatternType: The type of the pattern. Valid options are: 'StringMatch', 'OrderedStringMatch', 'DataType', 'Regex', 'InvoiceContains' and 'LineContains'. For a description of the functionality each pattern type provides refer to section 'Json Plugin - Pattern Types'. A string match pattern is for example used to compare strings, while a invoice contains pattern checks whether the invoice contains a specific word.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview\Json-Plugins-Mechanics-and-Rules.md - Chunk 10
IncludeMatchInValue: A boolean indicating whether the word that succesfully matched should be included in the prediction. The order in which include values are concatenated to a result string follows the order of patterns within a pattern group. If you for example have 3 string match patterns where one pattern checks the word before the target word, one the target word itself and one the word after the target word and you want the matches of the 'Before' and 'After' pattern to be included in the final prediction you would need to specify the patterns in the corresponding order in the pattern group and set the 'IncludeMatchInValue' flag to true for all three patterns.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview\Json-Plugins-Mechanics-and-Rules.md - Chunk 11
PatternProperties: A properties object that looks different for each pattern type and is used for the match-logic of that pattern. In the case of a string match pattern for example one pattern property is a list of strings that is used for the word comparison. Another property in this specific example could be used to specify whether we want the comparison to be case sensitive or not.

Json Plugin - Pattern Types

StringMatch

Supported Topologies: Before, After, Self, Above, Below

"StringsToCheckFor": A list of type string. If any of the strings specified in the list matches, the pattern matches. Strings specified here can not contain white spaces.

"IgnoreCase": A boolean indicating whether the string comparison should be case sensitive or not.

"CompareWithRaw": A boolean indicating whether the string comparison should use the raw text value of a word as it is written on the invoice or a normalized value coming from our datatypes (if possible).

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview\Json-Plugins-Mechanics-and-Rules.md - Chunk 12
"AdditionalSplitSigns": A list of strings that are used to separate words in addition to white spaces - an example use case would be where we want to find two numbers that are comma separated (so ',' would be a split sign) with no space in between them (12345,6789) separately (as 12345 and 6789).

OrderedStringMatch

Supported Topologies: Before, After

"WhiteSpaceSeparatedWords": A string containing words separated by whitespaces. The 'white-space words' specified in this string are used in the order they are specified with the given topology to create a match. This pattern was introduced to enhance the readability of the plugin .json file and basically provides the same functionality as the StringMatch pattern with the difference that it allows to white space separation in the target strings while on the other hand only accepting one string instead of a list.

"IgnoreCase": A boolean indicating whether the string comparison should be case sensitive or not.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview\Json-Plugins-Mechanics-and-Rules.md - Chunk 13
"IgnoreCase": A boolean indicating whether the string comparison should be case sensitive or not.

"CompareWithRaw": A boolean indicating whether the string comparison should use the raw text value of a word as it is written on the invoice or a normalized value coming from our datatypes (if possible).

"AdditionalSplitSigns": A list of strings that are used to separate words in addition to white spaces - an example use case would be where we want to find two numbers that are comma separated (so ',' would be a split sign) with no space in between them (12345,6789) separately (as 12345 and 6789).

DataType

Supported Topologies: Before, After, Self, Above, Below

"Datatype": A string that corresponds to the data type you want to check for. If you want to check for a Date datatype this field would for example contain 'Date'.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview\Json-Plugins-Mechanics-and-Rules.md - Chunk 14
"Datatype": A string that corresponds to the data type you want to check for. If you want to check for a Date datatype this field would for example contain 'Date'.

"IncludeRaw": This value is only relevant if the IncludeMatchInValue property of the pattern is set to true. This value contains a boolean indicating whether the included value should be the raw text as found on the invoice or the normalized value coming from the datatype.

Regex

Supported Topologies: Before, After, Self, Above, Below

"RegexString": A regular expression that is used for the match. Does not support white space separation. White spaces must be represented by combining multiple regex patterns with different topology position specifiers.

"CompareWithRaw": A boolean indicating whether the regex comparison should use the raw text value of a word as it is written on the invoice or a normalized value coming from our datatypes (if possible).

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview\Json-Plugins-Mechanics-and-Rules.md - Chunk 15
"RegexesExcludeInValue": A list of strings that are converted to regexes and then used via the Regex.Replace method to replace all matches of the regex in the prediction value with empty strings.

"AdditionalSplitSigns": A list of strings that are used to separate words in addition to white spaces - an example use case would be where we want to find two numbers that are comma separated (so ',' would be a split sign) with no space in between them (12345,6789) separately (as 12345 and 6789).

InvoiceContains

Supported Topologies: Irrelevant for this pattern

"StringsToCheckFor": A list of type string. If any of the strings specified in the list is contained in the invoice, the pattern matches. Strings specified here can not contain white spaces. Can be used to represent clusters of invoices.

"IgnoreCase": A boolean indicating whether the string comparison should be case sensitive or not.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview\Json-Plugins-Mechanics-and-Rules.md - Chunk 16
"IgnoreCase": A boolean indicating whether the string comparison should be case sensitive or not.

"CompareWithRaw": A boolean indicating whether the string comparison should use the raw text value of a word as it is written on the invoice or a normalized value coming from our datatypes (if possible).

"AdditionalSplitSigns": A list of strings that are used to separate words in addition to white spaces - an example use case would be where we want to find two numbers that are comma separated (so ',' would be a split sign) with no space in between them (12345,6789) separately (as 12345 and 6789).

LineContains

Supported Topologies: Self, Above, Below

"StringsToCheckFor": A list of type string. If any of the strings specified in the list is contained in the line above/below the target word or the line of target word itself in the case of the Self topology, the pattern matches. Strings specified here can not contain white spaces.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview\Json-Plugins-Mechanics-and-Rules.md - Chunk 17
"IgnoreCase": A boolean indicating whether the string comparison should be case sensitive or not.

"CompareWithRaw": A boolean indicating whether the string comparison should use the raw text value of a word as it is written on the invoice or a normalized value coming from our datatypes (if possible).

"AdditionalSplitSigns": A list of strings that are used to separate words in addition to white spaces - an example use case would be where we want to find two numbers that are comma separated (so ',' would be a split sign) with no space in between them (12345,6789) separately (as 12345 and 6789).

Further Development

We could simplify the Json Plugins by only using Regexes on Word, Line or Document basis. Adding more Topology settings, so one can search for a circle, and also up to X away. Check if removable and remove CustomerName-property and all references, since CustomerNames now exist.

11908

Json Plugin - Examples

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Bludelta-PlugIn-Overview\Json-Plugins-Mechanics-and-Rules.md - Chunk 18
11908

Json Plugin - Examples

In Blumatix.Capture.SDK.Tests -> SmartLibs there exist unit tests for each pattern that extensively cover possible usages on the example invoice with ID 10995. These can be used as a reference for the usage of each of the patterns.

A complete Json-File with exemplary pattern definitions would look as follows: https://blumatix.visualstudio.com/Rechnungserkennung/_git/Blumatix%20Capture?path=/Blumatix.Capture.Webservice.Client.Selfhosted/Blumatix.Capture.Webservice.Client.Selfhosted/Plugins

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Net6-Conversion\Breaking-changes.md - Chunk 0
T4 Templates are not supported anymore -> Automatic Code Generation of ML.Net InputClasses does not work anymore

CallContext which used in the AmbientSingleton doesn't exist anymore. Therefore a CallContext class which mimicks CallContext was implemted

ConfigurationManager: The ConfigurationManager must be installed as a nuget package. Currently we the following version:

<PackageReference Include="System.Configuration.ConfigurationManager" Version="4.7.0" />

ApplicationInsights: Old version: 2.17 -> new version: 2.20

<PackageReference Include="Microsoft.ApplicationInsights" Version="2.20.0" />

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Net6-Conversion\Convert-old-project-to-new-structure.md - Chunk 0
dotnet migrate-2019 wizard

The easiest way to do this is with the dotnet migrate-2019 wizard

Wizard Installation (via powershell) dotnet tool install --global Project2015To2017.Migrate2019.Tool --version 4.1.3

Migration-Example (via powershell) dotnet migrate-2019 wizard "D:\BLUMATIX GIT\Rechnungserkennung\Blumatix Capture\Blumatix.Capture.Monitoring\Blumatix.Capture.Monitoring.csproj"

Manual tasks (which may be needed after migration) - Remove ItemGroup with "Reference Include" Tags. Example: <ItemGroup> <Reference Include="System.Configuration" /> <Reference Include="System.Web" /> <Reference Include="System.Data.DataSetExtensions" /> <Reference Include="Microsoft.CSharp" /> </ItemGroup> Till now these references where not needed any more

Manually delete directory "Properties" with file "AssemblyInfo.cs"

Some tags from the top-most PropertyGroup of the project file shall be removed/adapted. Should look like this:

<Project Sdk="Microsoft.NET.Sdk">

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Net6-Conversion\Convert-old-project-to-new-structure.md - Chunk 1
Some tags from the top-most PropertyGroup of the project file shall be removed/adapted. Should look like this:

<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <OutputType>Library</OutputType>
    <TargetFramework>netstandard2.0</TargetFramework>
    <Platforms>AnyCPU</Platforms>
    <DebugType>portable</DebugType>
  </PropertyGroup>

Check that there is NO

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Net6-Conversion\Migrated-projects.md - Chunk 0
BlumatixCapture.sln

Blumatix.Capture.Communication

Blumatix.Capture.Json

Blumatix.Capture.Logging

Blumatix.Capture.Monitoring

Blumatix.Capture.Utils.Core

Blumatix.Capture.Utils.Logging

Blumatix.Capture.Utils.Azure

Blumatix.Capture.Webservice.Primitives

Blumatix.Capture.MLNet.Model

Blumatix.Capture.Store.Db.Shared

Blumatix.Capture.Store.Db.Model

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Net6-Conversion\New-Project-Structure.md - Chunk 0
Project file example

The folllowing xml is an example of new cs project for the netstandard 2.0 framework. Note: There are no ItemGroups for cs files or assemblies. We have only an ItemGroup form PackageRefernces

<Project Sdk="Microsoft.NET.Sdk">
    <PropertyGroup>
        <OutputType>Library</OutputType>
        <TargetFramework>netstandard2.0</TargetFramework>
        <Platforms>AnyCPU</Platforms>
    </PropertyGroup>

    <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Debug|AnyCPU'">
        <OutputPath>bin\Debug</OutputPath>
    </PropertyGroup>

    <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='Release|AnyCPU'">
        <OutputPath>bin\Release</OutputPath>
    </PropertyGroup>
  <ItemGroup>
    <PackageReference Include="Microsoft.ApplicationInsights" Version="2.20.0" />
  </ItemGroup>
</Project>

From packages.config to PackageReferences

1.) Default approach (does not work for Asp.Net projects !!!)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Net6-Conversion\New-Project-Structure.md - Chunk 1
From packages.config to PackageReferences

1.) Default approach (does not work for Asp.Net projects !!!)

Right-click "References" or "packages.config" and select --> "Migrate packages.config to PackageReference..."

2.) Hacky workaround for Asp.Net projects (somehow does not work for all our projects --> does not work for Blumatix.Capture.Webservice.Hosted)

Open the csproj

Replace the ProjectGuid by and remove ProjectTypeGuids

Now right click on reference, you should be able to migrate

Put back the previous ProjectType and ProjectTypeGuids

Enjoy!

--> Caution!: This does not really seem to work correctly, but it can be a starting point if you have to create the PackageReferences manually

Known Issues / complications

Mixing packages.config and PackageReferences in project dependency tree can result in missing dlls in output folder. Example:

Blumatix.Capture.Logging is a .Net Standard 2.0 Project which uses PackageReferences. EasyLogger is a package consumed by this project.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Net6-Conversion\New-Project-Structure.md - Chunk 2
Blumatix.Capture.Logging is a .Net Standard 2.0 Project which uses PackageReferences. EasyLogger is a package consumed by this project.

Blumatix.Capture.Webservice.Client.Hosted is a .Net Framework 4.6.1 project which uses packages.config The reference to Blumatix.Capture.Logging does not correctly result in copying EasyLogger to the bin-folder of the Hosted Sdk project when building

--> Workaround: Directly reference Nuget "Easy.Logger" in Blumatix.Capture.Webservice.Client.Hosted -->

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Net6-Conversion\NuGet-Package-Versioning.md - Chunk 0
https://blog.inedo.com/nuget/package-versioning

Example: (ask Rudi or Bernhard if you need the Key) nuget.exe push -Source "https://blumatix.pkgs.visualstudio.com/_packaging/blumatix_nuget/nuget/v3/index.json" -ApiKey [KEY] .\Blumatix.Capture.ResourceServiceHttpClient.0.1.2.nupkg

The key can be found in Keeper under the name "git Artifacts (blumatix feed)".

After executing the above command you might have to enter a username and password. As username enter your email (with which you log in to blumatix.visualstudio.com) and for password you have to create a access token.

Follow the steps: - Click on "User settings" icon and then on "Personal access tokens" - After that click on "+ New Token" and create a new token by enabling "Read, write & manage" option for "Packaging" - The created access token is used as password.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Benchmark-Compare-only-(BenchmarkCompareAction).md - Chunk 0
Performs a new benchmark comparison, without to create predictions first

Table of parameters Parameters:

-n BenchmarkExecutionName [string] Name of the BenchmarkExecution for which new comparison results shall be created -c Comment [string] Comment for BenchmarkComparison and -Runs -t NrTasks [int] Concurrency level. The number of tasks which shall be used for parallel processing. -g LabelSource [string] String representation of a label source --> f.ex.: path to a file

Examples:

Example 1 --> Perform new comparison

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Create-Benchmark-Report-(BMReportCreateAction).md - Chunk 0
Can create a benchmark report from a BenchmarkSetExecution or single BenchmarkExecution

Can tag the report and/or the benchmark runs

Table of parameters Parameters:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Create-Benchmark-Report-(BMReportCreateAction).md - Chunk 1
Can tag the report and/or the benchmark runs

Table of parameters Parameters:

-r ReportDefinitionName [string] Name of the BMReportDefinition for which a report which shall be created -s BenchmarkSetExecutionName [string] Name of the BenchmarkSetExecution which contains the predictions for the report -e BenchmarkExecutionName [string] Name of the BenchmarkExecution which contains the predictions for the report -n ReportInstanceName [string] Name (ReportInstanceName) of the report which shall be created -c EmailRecipients [string] Email adress of report recipient -m MemoryCachedOnly [switch] Does not write any data to the DB (in-memory mode) -j BMReportTags [string] Comma-seperated list of Tags to apply to the BMReport -y BMRunTags [string] Comma-seperated list of Tags to apply to the corresponding benchmark runs -A AutoUpdateReportDefinition [bool] If [true], will automatically create or update the ReportDefinition passed with -r

Examples:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Create-Benchmark-Report-(BMReportCreateAction).md - Chunk 2
Examples:

Example 1 --> Creates a report for an executed BenchmarkSet and creates tags for report and runs

Example 1 --> Creates a report for a single executed Benchmark and creates tags for report and runs

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Create-Benchmark-Tags-(BMTagAction).md - Chunk 0
Can tag a benchmark report and/or the corresponding benchmark runs

Table of parameters Parameters:

-r ReportInstanceName [string] Name of the BMReportDefinition for which a new report shall be created -t ReportTags [string] Comma-seperated list of Tags to apply to the benchmark report -u BMRunTags [string] Comma-seperated list of Tags to apply to the corresponding benchmark runs

Examples:

Example 1 --> Applies tags to an existing benchmark report and the corresponding benchmark runs

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Create-OCR-for-document-(InvoiceAction).md - Chunk 0
Can tag a benchmark report and/or the corresponding benchmark runs

Table of parameters Parameters:

[TODO] |--|--|--|--|

Examples:

Example 1 --> Convert a pdf to an image:

Example 2 --> Convert multiple pdf files from a directory

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Dachser-Csv-Resources-Update-(DachserCsvUpdaterAction).md - Chunk 0
Replace records (entire rows) in a dachser csv file with records from another dachser csv file

Table of parameters Parameters:

-s SourceCsvFile [string] Path to a CSV file with records that we want to write into the target file -t TargetCsvFile [string] Path to a CSV file with records that we want to replace -o OutputCsvFile [string] Path to a final output CSV file which shall be created -n FilterColumnName [string] The Column-Name which is used for filtering. All rows with one of the specified values (FilterColumnValues) in this column will be replaced -v FilterColumnValues [string] The Column-Values (comma-seperated) which are used for filtering. All rows with one of these values in the specified column (FilterColumnName) will be replaced -k KeepAllExistingTargetRecords [bool] If set, No records will be deleted from the target-file before inserting records from the source-file

Examples:

Example 1 --> replace all records for countries 'MA,UK,FI,LU,IE,CN' in receivers file

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Exec-Load-Test-(ExecuteLoadTestAction).md - Chunk 0
Can execute a load test against the CaptureSdk (default) or the Workflow server

Has 3 different modes:

Endless-Mode: Send documents of the source-directory randomly endless with specified number of tasks

Directory-Mode: Send each document of the source directory exactly once with specified number of tasks

Load-Test-Mode: Send [x] waves with [n] documents with a fixed interval and wait for all results before the next wave is started

Table of parameters Parameters:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Exec-Load-Test-(ExecuteLoadTestAction).md - Chunk 1
-c CaptureSdkUrl [string] Base url to the CaptureSdk (or Workflow server) -f InvoiceFolder [string] The folder with the invoices (docs!) that are to be used in the load test -t NrTasks [int] The number of tasks used to send invoices (docs!) to the service. Default is two. -p CreatePdfResult [bool] [CaptureSdk only] If this flag is set, phoenix requests additionally a PdfResult which is stored into the output path folder. Default is false -r AddOcrResult [bool] [CaptureSdk only] If this flag is set, the response object (json) will contain the ocr-result. Default is false -a AddOcrPageImages [bool] [CaptureSdk only] If this flag is set, phoenix additionally requests the OCR page images. Default is false -j SkipJunkPages [bool] [CaptureSdk only] If this flag is set, the service will try to detect pages which do not contain any useful information (like AGBs) and it will skip them from the analysis. Default is false -o Timeout [int] Time in minutes for which the load test should be

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Exec-Load-Test-(ExecuteLoadTestAction).md - Chunk 2
to detect pages which do not contain any useful information (like AGBs) and it will skip them from the analysis. Default is false -o Timeout [int] Time in minutes for which the load test should be running. If the test should never time out set this value to 0. Default is 0. -m DoMemoryProfiling [bool] [Deprecated, may not work as expected] If this flag is set, memory profiling via DotMemory will be done during the execution of the load test and snapshots will be saved to the specified location (default is .\Snapshots). You need to be running your CaptureSdk instance locally for memory profiling to work. Default is false -s SnapshotDirectory [string] The directory to which the memory profiling snapshots will be saved. -i SnapshotInterval [int] Time interval in seconds between memory snapshots. Default value is 300 (5min). The first snapshot will be taken after the first interval period has expired. Default is 300 -d DirectoryMode [bool] In directory mode, each thread will predict all

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Exec-Load-Test-(ExecuteLoadTestAction).md - Chunk 3
Default value is 300 (5min). The first snapshot will be taken after the first interval period has expired. Default is 300 -d DirectoryMode [bool] In directory mode, each thread will predict all invoices of the InvoiceFolder exactly one time and the action stops afterwards. Default is false -h HttpTimeoutSeconds [int] [CaptureSdk only] Timeout (in seconds) to use for the http-requests. if parameter is not passed, then a default timeout of 900 seconds (15 minutes) will be used so that a nightly load-test can run forward if a single request fails to come back -l LoadTestInterval [int] Interval (in milliseconds) for Load-Test-Mode. In this mode we do not create a fixed number of threads. Instead we send invoices in the specified interval. Default is 0 (=mode is deactivated) -n LoadTestNumOfDocsPerWave [int] In Load-Test-Mode you can specify the number of documents to send for each Wave. The next wave starts when all docs are processed. Default is 0 (=mode is deactivated) -w

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Exec-Load-Test-(ExecuteLoadTestAction).md - Chunk 4
[int] In Load-Test-Mode you can specify the number of documents to send for each Wave. The next wave starts when all docs are processed. Default is 0 (=mode is deactivated) -w LoadTestNumOfWaves [int] "In Load-Test-Mode you can specify the number of waves to execute. Each wave sends the specified number of documents and waits for all the results. Default is 1 -k KindOfEndpoint [string] Defines which endpoint is load-tested. This info is required to create correct requests and to be able to deal with the responses. Possible values: "CaptureSdk" or "Workflow". Default is "CaptureSdk"

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Exec-Load-Test-(ExecuteLoadTestAction).md - Chunk 5
Examples:

Example 1 --> Execute CaptureSdk load-test / Endless-Mode / 4 tasks

Example 2 --> Execute CaptureSdk load-test / Directory-Mode / 4 tasks

Example 3 --> Execute Workflow-Server (Receipt) load-test / Load-Test-Mode / 2 secs interval / 20 docs per wave / 10 waves

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Invoice-autorelease.md - Chunk 0
Can autorelease labels

Table of parameters Parameters:

[TODO] |--|--|--|--|

Examples:

Example 1 --> Autorelease labels for a given list of ids:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Plugin-Upload_Delete_Info-(PluginAction).md - Chunk 0
Can upload a new plugin

Can delete an existing plugin

can retrieve infos about installed plugins

Table of parameters Parameters:

-c CaptureSdkUrl [string] Default --> http://localhost:8090 -i PluginInfo [switch] If set, plugin information is requested. Default --> false -u PluginUpload [switch] If set, the specified plugin (-s) will be uploaded. Default --> false -d PluginDelete [switch] If set, the specified plugin (-p) will be deleted. Default --> false -s SmartLibPath [string] Path to the plugin file -n CustomerName [string] Name of the customer -p PluginName [string] Name of the plugin -a ApiKey [string] Api key of the plugin that should be deleted. Default --> [our unrestricted tester key] -t PluginType [string] JsonPlugin | AssemblyPlugin | WhiteListPlugin Default --> JsonPlugin

Examples:

Example 1 --> Upload a new json plugin

Example 2 --> Upload a WhiteListSearch plugin

Example 3 --> Delete an existing json plugin

Example 4 --> Retrieve infos about installed plugins

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Predict-documents.md - Chunk 0
.\phoenix.exe evaluation predict ...

Predicts document/all documents in folder and returns different result types

Parameters:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Predict-documents.md - Chunk 1
predict Predicts invoice details and lineitems of invoices InvoiceFolder -f Invoice folder. A folder which contains the invoices that shall be predicted. InvoiceFile -i Invoice file path. A single invoice that shall be predicted. CsvFile -s A csv file which contains a comma separated list of invoice ids BenchmarkName -b The name of a benchmark whose invoices shall be predicted. OutputPath -o Output path where the prediction results per invoice will be stored. If any path is provided than results will be written to stdout. NrTasks -t Concurrency level. The number of tasks which shall be used for parallel processing. Default is 2 tasks DrawLineItems -l Draws the LineItems onto the provided invoice DrawDetails -d Draws the InvoiceDetails onto the provided invoice CaptureClientUrl -c Base url of the capture client service SdkVersion -v SdkVersion. Default value is string.Empty CreatePdfResult -p If this flag is set, phoenix requests additionally a PdfResult which is stored into the output

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Predict-documents.md - Chunk 2
of the capture client service SdkVersion -v SdkVersion. Default value is string.Empty CreatePdfResult -p If this flag is set, phoenix requests additionally a PdfResult which is stored into the output path folder. AddOcrPageImages -a If this flag is set, phoenix additionally requests the OCR page images. AddOcrResult -r If this flag is set, the response object (json) will contain the ocr-result. AddDocumentText -u If this flag is set, the response will contain the plain text of the document as detected by the OCR. AdditionalProps -x Additional properties. Must be provided as a comma separated string in the following format "prop1=val1, prop2=val2,..." WithoutTypeInfo -w If true then the PredictionResult will be returned without C# type information, i.e. a clean json result will be returned ApiKey -k ApiKey to use for the request(s) ApiIdentifier -z ApiIdentifier to use for the request(s) FilenameAsSessionLogId -S Use filename as SessionLogId. Will be used as unique identifier in the

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Predict-documents.md - Chunk 3
ApiKey -k ApiKey to use for the request(s) ApiIdentifier -z ApiIdentifier to use for the request(s) FilenameAsSessionLogId -S Use filename as SessionLogId. Will be used as unique identifier in the log files. SkipJunkPages -j If this flag is set, the service will try to detect pages which do not contain any useful information (like AGBs) and it will skip them from the analysis. InvoiceIds -e Prediction by InvoiceIds. A comma separated string of ids, e.g "1,2,3". Ids must be available in the BCI database Languages -n Pass all potential languages for the current document as a comma separated list

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Replace-Text-on-text-based-docs-(ReplaceTextAction).md - Chunk 0
Table of parameters Parameters:

-i InputDocument [string] Path to the document where the texts shall be replaced -s CsvFile [string] A csv file which contains replacement mappings -o OutputPath [string] Output path. Result will be stored there.

Examples:

Example 1 --> Replace texts on a text-based pdf

Replacement mapping CsvFile content example:

Company Name 1|Xxxxxxxxxx Xxxxxxxx Xxxxx Street 42|Xxxxxxxx XxxX X XxxXX City XYZ|Xxxxxxxxxxxxxxxx Xxxx IBAN 1234567890|Xx Xxxxxxxxxx X

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Run-Benchmark-(CaptureSdkBenchmarkAction).md - Chunk 0
Can execute a single benchmark or a benchmark set

Can create a report in the end

can tag the report and/or the benchmark runs

Table of parameters Parameters:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Run-Benchmark-(CaptureSdkBenchmarkAction).md - Chunk 1
-f BenchmarkConfigFilePath [string] [deprecated] Use -a instead -a BenchmarkTaskName [string] Name of the BenchmarkTask in the BCA-DB -b BenchmarkSetName [string] To execute a whole benchmark set at once -n BenchmarkSetExecutionName [string] To execute a single benchmark (together with -a) in the context of a benchmark set -s CaptureSdkUrl [string] Default --> http://localhost:8090 -z CaptureSdkStartProcess [switch] Starts a local CaptureSdk -d CaptureSdkRootDirectory [string] Automatically searches from phoenix directory upwards -o CaptureSdkBuildConfiguration [string] Debug -e CaptureSdkRunAsAdmin [switch] If set, tries to run the CaptureSdk elevated (as admin) -E EmailRecipients [string] Comma-seperated list of E-mail addresses which shall get the benchmark report (-r) -p PredictionSource [string] TSV/Generic-Benchmarks… -g LabelSource [string] Generic Benchmarks… -c Comment [string] To pass a comment for BenchmarkExecution & -Runs -t NrTasks [int] Number of concurrent tasks to use

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Run-Benchmark-(CaptureSdkBenchmarkAction).md - Chunk 2
[string] TSV/Generic-Benchmarks… -g LabelSource [string] Generic Benchmarks… -c Comment [string] To pass a comment for BenchmarkExecution & -Runs -t NrTasks [int] Number of concurrent tasks to use -x AdditionalProps [string] Comma separated string like \"prop1=val1, prop2=val2,...\"" -l Languages [string] Comma separated string like \"de,en,es\"" -k ApiKey [string] Default --> [UnrestrictedTester] -m MemoryCachedOnly [switch] Does not write any data to the DB (in-memory mode) -r ReportDefinitionName [string] Name of the benchmark report to generate in the end -w CaptureSdkStartWindowsService [bool] If set, local CaptureSdk Windows Services will be tried to stop/start -i InvariablePluginDirectory [string] If set, all Plugins will be taken from this directory -u UidClassificationLogPath [string] No more used -v MeasurePredictionPerformance [switch] To measure Performance (return TelemetryData) -j BMReportTags [string] Comma-seperated list of Tags to apply to the BMReport (is only used

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Run-Benchmark-(CaptureSdkBenchmarkAction).md - Chunk 3
No more used -v MeasurePredictionPerformance [switch] To measure Performance (return TelemetryData) -j BMReportTags [string] Comma-seperated list of Tags to apply to the BMReport (is only used when a report definition is passed with -r) -y BMRunTags [string] Comma-seperated list of Tags to apply to the benchmark runs which are created -A AutoUpdateReportDefinition [bool] If [true], will automatically create or update the ReportDefinition passed with -r

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Run-Benchmark-(CaptureSdkBenchmarkAction).md - Chunk 4
Examples:

Example 1 --> Executes default CaptureSdk Benchmark and starts the SDK locally (Labels from DB / Predictions from CaptureSdk)

Example 2 --> Executes a CaptureSdk Benchmark (Labels from TSV / Predictions from CaptureSdk)

Example 3 --> Executes a CaptureSdk TSV Benchmark (Labels from DB / Predictions from TSV)

Example 4 --> Executes a Generic Address Benchmark (Labels from TSV / Predictions from TSV)

Example 5 --> Executes a BenchmarkSet against the Cloud (V1-14 staging) and creates a report afterwards

Example 6 --> Executes a BenchmarkSet against a local SDK (automatically starts it) and creates a report afterwards

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Run-Error-Analysis-From-DB.md - Chunk 0
Runs the error analysis for documents in the DB.

Table of parameters Parameters:

see also .\phoenix.exe erroranalysis --help

-d Date [string] From which date on it should check for support invoices e.g. 02-02-2022 (This would look at all invoices from this date till today.If no date is set, it is only fetched for today. Format yyyy-mm-dd -f individualTimeSpan [string] Fetch, check and execute for date between date 1 to date 2. Format: yyyy-mm-dd,yyyy-mm-dd -s SupportErrorAnalysis [bool] If this flag is set, phoenix requests/searches invoice ids from db to know for which in voices the EA should be executed. -i invoiceids [string] If you don't want to just execute EA for support invoices from the db, set your invoice ids seperated by comma. -u CaptureClientUrl [string] Base url of the capture client service

Examples:

Example 1: .\phoenix.exe erroranalysis ErrorAnalysisFromDB -d "2024-01-01" -s "TRUE" -u "https://api.bludelta.ai/V1-18"

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Run-Error-Analysis-From-DB.md - Chunk 1
Examples:

Example 1: .\phoenix.exe erroranalysis ErrorAnalysisFromDB -d "2024-01-01" -s "TRUE" -u "https://api.bludelta.ai/V1-18"

Example 2: .\phoenix.exe erroranalysis ErrorAnalysisFromDB -d "2024-01-01" -i "271128, 274763" -u "https://api.bludelta.ai/V1-18"

ATTENTION Make sure that the phoenix.exe.config is updated: <add key="PyInvoiceCapture" value="http://app-bludelta-container-pycapturesdk-dev-weu-01.azurewebsites.net"/> <add key="ContactsUri" value="http://app-bludelta-container-contact-dev-weu-01.azurewebsites.net"/> <add key="VatGroupUri" value="http://app-bludelta-container-vatgroup-dev-weu-01.azurewebsites.net"/> <add key="DocTypeUri" value="http://52.236.159.89/doctype-service"/>

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Phoenix\Set-new-BenchmarkReportDefinition-Baselines-(BMReportDefinitionBaselinesAction).md - Chunk 0
Can set new prediction- and/or performance baselines for an existing BMReportDefinition

Table of parameters Parameters:

-r BMReportDefinitionName [string] Name of the Report (BMReportDefinition) for which the baselines shall be set -e PredictionBaselineReportTagName [string] This is the new Report TagName for the prediction baseline (=TagName of the BenchmarkReport from which we get the info how much PassedValuePercent is 1 dropped result) --> like: 'V1.18.28 END' -u PredictionBaselineBmRunTagName [string] This is the new TagName for BenchmarkRuns which act as prediction Baseline (=TagName of the BenchmarkRuns to compare with) --> like: 'V1.18.28 CLOUD' -p PerformanceBaselineReportTagName [string] This is the new Report TagName for the performance baseline

Examples:

Example 1 --> Sets new prediction baselines

Example 2 --> Sets new performance baselines

Example 3 --> Sets new prediction and performance baselines

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\PhoenixService\TNetDataGeneration.md - Chunk 0
Before we used the PhoenixService to import documents into our bci-db, this was done with the phoenix CommandLine tool.

a) Phoenix CommandLine Tool = Windows EXE => Executed locally on any windows PC b) Phoenix Service = Windows Docker Container based upon microsoft image: servercore:20H2

When a document is imported we create the OCR-representation with the OcrEngine of our choice.

OCR-representation = Text + BoundingBoxes + PageImages

This used to be Nuance in the past, may have been EasyOcr for some specific docs and it is moving towards AzureRead now. When Nuance is used, the OcrWorkers are running in a Sub-App-Domain of the phoenix or phoenix-service process.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\PhoenixService\TNetDataGeneration.md - Chunk 1
If a textbased-pdf is imported and the font is missing, you can get a totally different OCR-representation as when the font is installed! The outcomes definetly depend on the structure of the PDF file itself, but Nuance does not simply extract the text from the DOM of the Pdf - not with the Settings which are active by default! You can re-construct this with Bci InvoiceId 368526 (or 176675 from BUG 22051)

The labels which are then created via the LabelingTool are based on the OCR-representation that is produced by the Import.

Typhon training data depends on OCR-representation (Text + BoundingBoxes + PageImages) and Labels.

For valid Training-data it is highly important that the Ground-Truth (Labels) matches the OCR-representation!

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\PhoenixService\TNetDataGeneration.md - Chunk 2
For valid Training-data it is highly important that the Ground-Truth (Labels) matches the OCR-representation!

Some important problems of training-data generation with phoenix service in the past: - Until 6th of June 2024, PhoenixService was creating a new OCR-representation for the training data by sending the orignal imported document - From 6th of June 2024 forward (till now -> V1.32), PhoenixService was creating a new OCR-representation for the training data by sending a tif which was generated from the PageImages created during document-import. - Until Sprint 137 (BugFix 22051) the config for trainingdata-generation had properties to define which OcrEngine shall create the OCR Options where: + Nuance + EasyOcr (till this was deprecated) + AzureRead + AzureReadWithTextBasedNuance ( -> if doc is textbased then Nuance, otherwise AzureRead)

1.) Building a new docker image for PhoenixService installs all Fonts now

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\PhoenixService\TNetDataGeneration.md - Chunk 3
1.) Building a new docker image for PhoenixService installs all Fonts now

2.) Training-data generation now always uses the OCR-representation from the DB

As a matter of fact, we have Labels in our DB which are built upon "dirty" OCR-representations (due to missing fonts). But there is not really a need to re-create or fix the OCR and the corresponding labels as long as the same OCR-representation is used for labeling and training. Re-creating this data might (at least slightly) improve the outcome, but we think it does not justify the high effort (or risc if you write a script therefor)!

It is a good idea (especially for AzureRead) to keep OCR-Results in a Cache, so that we do not have to create the same OCR again and again during training and benchmarks (we pay for it). But there is a mayor difference between training in inference!

For training we have to use the OCR-representation which was used for labeling!

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\PhoenixService\TNetDataGeneration.md - Chunk 4
For training we have to use the OCR-representation which was used for labeling!

For the inference it would be benefitial to re-create the OCR from time to time (when AzureRead has improved) to reflect the newest outcomes

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Technologies\Docker-Compose.md - Chunk 0
docker-compose

Remove Old Version

Ubuntu: sudo apt-get remove docker-compose

Curl: sudo rm /usr/local/bin/docker-compose

Pip: pip uninstall docker-compose

Install New Version

```sh

Install the newest version

VERSION=$(curl --silent https://api.github.com/repos/docker/compose/releases/latest | grep -Po '"tag_name": "\K.*\d')

Install a dedicated version - use this version!!!!

VERSION=v2.16.0 DESTINATION=/usr/local/bin/docker-compose sudo curl -L https://github.com/docker/compose/releases/download/${VERSION}/docker-compose-$(uname -s)-$(uname -m) -o $DESTINATION sudo chmod 755 $DESTINATION ```

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Technologies\Docker.md - Chunk 0
Docker Website Docker Desktop: A tool which run on windows, linux, MacOs for handling docker images and containers etc.

Cheetsheet

docker run: This command is used to run a new container from a specified image. For example, docker run ubuntu would run a new container from the ubuntu image.

docker ps: This command lists all the containers that are currently running on the host machine.

docker images: This command lists all the images that are available locally on the host machine.

docker pull: This command is used to pull a specified image from a Docker registry, such as Docker Hub, to the host machine. For example, docker pull ubuntu would pull the ubuntu image to the host machine.

docker start: This command is used to start a stopped container. For example, docker start my_container would start the container named my_container.

docker stop: This command is used to stop a running container. For example, docker stop my_container would stop the container named my_container.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Technologies\Docker.md - Chunk 1
docker stop: This command is used to stop a running container. For example, docker stop my_container would stop the container named my_container.

docker rm: This command is used to remove a container. For example, docker rm my_container would remove the container named my_container.

docker rmi: This command is used to remove an image. For example, docker rmi ubuntu would remove the ubuntu image.

docker build: This command is used to build a new image from a specified Dockerfile. For example, docker build . would build a new image from the Dockerfile in the current directory.

docker exec: This command is used to run a command in a running container. For example, docker exec my_container ls would run the ls command in the my_container.

docker inspect: This command is used to inspect the details of a container or image. For example, docker inspect my_container would show all the details of the my_container container.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Technologies\Docker.md - Chunk 2
docker inspect: This command is used to inspect the details of a container or image. For example, docker inspect my_container would show all the details of the my_container container.

docker logs: This command is used to view the logs of a container. For example, docker logs my_container would show the logs of the my_container container.

docker tag: This command is used to tag an image with a new repository name and tag. For example, docker tag old_image new_image:new_tag would tag the old_image with the repository name new_image and tag new_tag.

docker push: This command is used to push an image to a Docker registry. For example, docker push new_image:new_tag would push the image with repository name new_image and tag new_tag to the Docker registry.

Portforwarding

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Technologies\Docker.md - Chunk 3
Portforwarding

Port forwarding: Docker containers run isolated from the host machine, and by default, are not accessible from the host machine. Port forwarding allows you to map a port on the host machine to a port in a container. This allows you to access applications running inside the container as if they were running on the host machine. For example, if you have a web server running in a container on port 80, you can map it to port 8080 on the host machine using the -p option in the docker run command, like this: docker run -p 8080:80 my_container.

Volumes

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Technologies\Docker.md - Chunk 4
Volumes

Mounting volumes: By default, data written to the file system inside a container is not persisted, meaning that if you stop the container or delete it, the data is lost. Mounting volumes allows you to persist data by mapping a directory on the host machine to a directory inside the container. This way, data written to the mapped directory in the container is saved to the host machine, and can be restored even if the container is stopped or deleted. For example, you can mount a directory on the host machine to a directory in the container using the -v option in the docker run command, like this: docker run -v /host/data:/container/data my_container.

Additional Documentation

REF1

How to start dockerd manually on windows

sh & "C:\Program Files\Docker\Docker\resources\dockerd.exe" --run-service --service-name docker -G docker-users --config-file C:\ProgramData\Docker\config\daemon.jsonC:\ProgramData\Docker\config\daemon.json

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Versioning-Concept\Api-Versioning---How-its-done.md - Chunk 0
Reference/Example project for this Wiki-Page: ResourceService.Api

Each build of a webservice project should create a unique version number for the generated exe. This version number has 4 parts --> [0].[1].[2].[3]

[0]...Major Version [1]...Minor Version [2]...Build Version [3]...Revision

Ideally we can use this version number for the generated exe file (Assembly/Product version) as well as for the Url-Part of the endpoints.

To automatically increment the AssemblyVersion on each build, you can follow this article (we slightly improved this approach): .NET Core/Standard Auto Incrementing Versioning

The following steps are required: (Check in example project)

1.) Add the following PropertyGroup to your project (.csproj file):

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Versioning-Concept\Api-Versioning---How-its-done.md - Chunk 1
<PropertyGroup> <VersionSuffix>1.0.$([System.DateTime]::UtcNow.ToString(yy))$([System.DateTime]::UtcNow.DayOfYear.ToString()).$([System.DateTime]::UtcNow.ToString(HHmm))</VersionSuffix> <AssemblyVersion Condition=" '$(VersionSuffix)' == '' ">0.0.0.1</AssemblyVersion> <AssemblyVersion Condition=" '$(VersionSuffix)' != '' ">$(VersionSuffix)</AssemblyVersion> <Version Condition=" '$(VersionSuffix)' == '' ">0.0.1.0</Version> <Version Condition=" '$(VersionSuffix)' != '' ">$(VersionSuffix)</Version> <FileVersion>$(VersionSuffix)</FileVersion> <ProductVersion>$(VersionSuffix)</ProductVersion> </PropertyGroup> Here we define the current Major and Minor version and auto-increment-calculations for build version and revision. The build version is calculated by the last 2 digits of the year and the day of the year (This approach will fail in the year 2065, because the max allowed value for a version number is 65k+) The revision is calculated by hours and minutes of the current day.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Versioning-Concept\Api-Versioning---How-its-done.md - Chunk 2
2.) Build your project and check that it works

You can check if your version is updated correctly by navigating to the build dll and check the file version via mouseover in windows.

To add API versioning to your project, you can follow these articles: API Versioning in ASP.NET Core Versioning an ASP.NET Core API

The following steps are reqired: (Check in example project)

1.) Add the following nuget packages to your project: - Microsoft.AspNetCore.Mvc.Versioning - Microsoft.AspNetCore.Mvc.Versioning.ApiExplorer

2.) Create a base class (ControllerBaseExt) for all your API Controllers and let your controllers inherit from this class:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Versioning-Concept\Api-Versioning---How-its-done.md - Chunk 3
2.) Create a base class (ControllerBaseExt) for all your API Controllers and let your controllers inherit from this class:

``` [ApiController] [Route("v{version:apiVersion}/[controller]")] public abstract class ControllerBaseExt : ControllerBase { protected string GetApiVersion() { // check ApiVersion Attribute on calling Method var callingMethod = (new System.Diagnostics.StackTrace())?.GetFrame(1)?.GetMethod(); var apiVersionAttr = callingMethod?.GetCustomAttributes(typeof(ApiVersionAttribute), true).FirstOrDefault() as ApiVersionAttribute;

    // check ApiVersion on calling Controller
    if(apiVersionAttr == null)
    {
        apiVersionAttr = this.GetType().GetCustomAttributes(typeof(ApiVersionAttribute), true).FirstOrDefault() as ApiVersionAttribute;
    }

    return (apiVersionAttr != null && apiVersionAttr.Versions?.Count > 0)
        ? apiVersionAttr.Versions[0].ToString()
        : Startup.VERSION;
}

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Versioning-Concept\Api-Versioning---How-its-done.md - Chunk 4
return (apiVersionAttr != null && apiVersionAttr.Versions?.Count > 0)
        ? apiVersionAttr.Versions[0].ToString()
        : Startup.VERSION;
}

} ``` The method "GetApiVersion()" can be used to set the current detailed version (Major.Minor.Build.Revision) onto an "ApiVersion" property of your DTOs

2.) Now, configure the automatic API versioning in your Program.cs file. (The preferred way to do this is adding a Startup.cs class)

``` private void ConfigureApiVersioning(WebApplicationBuilder builder) { builder.Services.AddApiVersioning(o => { o.AssumeDefaultVersionWhenUnspecified = false; o.ReportApiVersions = true; o.ApiVersionReader = ApiVersionReader.Combine( new UrlSegmentApiVersionReader());

    var versionParts = VERSION.Split(".").Select(v => Int32.Parse(v)).ToList();
    if (versionParts == null || versionParts.Count < 2)
    {
        throw new Exception("An ApiVersion needs to be specified! (At least Major and Minor version)");
    }

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Versioning-Concept\Api-Versioning---How-its-done.md - Chunk 5
Assembly? asm = Assembly.GetAssembly(typeof(Program));
    var controllerTypes = asm?.GetTypes().Where(type => typeof(ControllerBaseExt).IsAssignableFrom(type)) ?? new List<Type>();
    foreach (var controllerType in controllerTypes)
    {
        // add api-version attribute if none is defined yet
        if (Attribute.GetCustomAttribute(controllerType, typeof(ApiVersionAttribute)) == null)
        {
            // As Api Version
            o.Conventions.Controller(controllerType).HasApiVersion(new ApiVersion(versionParts[0], versionParts[1]));
        }
    }
});

}

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Versioning-Concept\Api-Versioning---How-its-done.md - Chunk 6
```

This will add an [ApiVersion]-Attribute to all Controller classes which inherit from your Base-class

3.) Now you can extend the default swagger page, so that it lets you choose the API-version for which you want to view the endpoints. This is especially helpful when Endpoints for multiple major versions are supported. Therefor you have to add some more code to your Startup class:

``` private void ConfigureSwagger(WebApplicationBuilder builder) { builder.Services.AddVersionedApiExplorer(options => { // add the versioned api explorer, which also adds IApiVersionDescriptionProvider service // note: the specified format code will format the version as "'v'major[.minor][-status]" options.GroupNameFormat = "'v'VVV";

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Versioning-Concept\Api-Versioning---How-its-done.md - Chunk 7
// note: this option is only necessary when versioning by url segment. the SubstitutionFormat
    // can also be used to control the format of the API version in route templates
    options.SubstituteApiVersionInUrl = true;
});
builder.Services.AddTransient<IConfigureOptions<SwaggerGenOptions>, ConfigureSwaggerOptions>();
builder.Services.AddSwaggerGen(options => options.OperationFilter<SwaggerDefaultValues>());

public class SwaggerDefaultValues : IOperationFilter { public void Apply(OpenApiOperation operation, OperationFilterContext context) { var apiDescription = context.ApiDescription; operation.Deprecated |= apiDescription.IsDeprecated();

    if (operation.Parameters == null)
        return;

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Versioning-Concept\Api-Versioning---How-its-done.md - Chunk 8
if (operation.Parameters == null)
        return;

    // REF: https://github.com/domaindrivendev/Swashbuckle.AspNetCore/issues/412
    // REF: https://github.com/domaindrivendev/Swashbuckle.AspNetCore/pull/413
    foreach (var parameter in operation.Parameters)
    {
        var description = apiDescription.ParameterDescriptions.First(p => p.Name == parameter.Name);
        if (parameter.Description == null)
        {
            parameter.Description = description.ModelMetadata?.Description;
        }

        if (parameter.Schema.Default == null && description.DefaultValue != null)
        {
            parameter.Schema.Default = new OpenApiString(description.DefaultValue.ToString());
        }

        parameter.Required |= description.IsRequired;
    }
}

public class ConfigureSwaggerOptions : IConfigureOptions

public ConfigureSwaggerOptions(IApiVersionDescriptionProvider provider) => _provider = provider;

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Versioning-Concept\Api-Versioning---How-its-done.md - Chunk 9
public class ConfigureSwaggerOptions : IConfigureOptions

public ConfigureSwaggerOptions(IApiVersionDescriptionProvider provider) => _provider = provider;

public void Configure(SwaggerGenOptions options)
{
    // add a swagger document for each discovered API version
    // note: you might choose to skip or document deprecated API versions differently
    foreach (var description in _provider.ApiVersionDescriptions)
    {
        options.SwaggerDoc(description.GroupName, CreateInfoForApiVersion(description));
    }
}

private static OpenApiInfo CreateInfoForApiVersion(ApiVersionDescription description)
{
    var info = new OpenApiInfo()
    {
        Title = "Sample API",
        Version = description.ApiVersion.ToString(),
    };

    if (description.IsDeprecated)
    {
        info.Description += " This API version has been deprecated.";
    }

    return info;
}

}

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Development\Versioning-Concept\Api-Versioning---How-its-done.md - Chunk 10
```

Finally, in your Startup class, replace the call to "app.UseSwaggerUI()" with the following code:

``` app.UseSwaggerUI(options => { var provider = builder.Services.BuildServiceProvider().CreateScope().ServiceProvider.GetRequiredService

    // build a swagger endpoint for each discovered API version
    foreach (var description in provider.ApiVersionDescriptions)
    {
        options.SwaggerEndpoint($"/swagger/{description.GroupName}/swagger.json", description.GroupName.ToUpperInvariant());
    }
});

```

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Diplomarbeiten\Exposé.md - Chunk 0
[[TOC]]

Automatische Annotation von semi-strukturierten Dokumenten mit Hilfe von Large Language Models unter Berücksichtigung von Layoutinformation

Expose_Thaler.pdf

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Calculate-Recommended-Thresholds---Confusion-Matrix-depending-on-Threshold.md - Chunk 0
Analyse Scores for different thresholds

Create Benchmark without thresholds

Execute Benchmark with "Best Match" property: Config.ForceReturnBestMatches=true

Execute Confusion Matrix Action

Execute Phönix action: .\phoenix erroranalysis confusionmatrix -n "B_Dachser_AT_500_20230303 08.08.11" -o "D:\tmp\ConfusionMatrix" -e "0.5, 1, 3, 5" -i "" -n ... Benchmark Execution name of benchmark without thresholds (take "Execution name" in Benchmark Executions view) -e ... ErrorRates (in %, comma separated list) -o ... result files directory -s ... threshold step size (default 0.1) -i ... list of doc ids of the bm that will be used (if not used all ids of benchmark)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Calculate-Recommended-Thresholds---Confusion-Matrix-depending-on-Threshold.md - Chunk 1
The action creates three files: - Confidence Matrices per detail (e.g. ConfidenceMatrices-B_Dachser_AT_500_20230303 08.08.11.tsv) - Error rates per detail with according thresholds (e.g. ErrorRatesPerDetail-B_Dachser_AT_500_20230303 0808.11.tsv) - Dynamic config formatted details with thresholds (e.g. DynamicConfigPerErrorRate-B_Dachser_AT_500_20230303 0808.11.json)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Calculate-Recommended-Thresholds---Confusion-Matrix-depending-on-Threshold.md - Chunk 2
For the Asian Benchmarks two different workflows and thus different models are used. To get the thresholds just for one model use the following sql query and then use only those ids in the calculation: ``` SELECT [BlumatixCaptureAutomation].[dbo].BenchmarkTelemetryItemContainer.BciInvoiceId FROM [dbo].BenchmarkTelemetryItemContainer JOIN dbo.BenchmarkTelemetryItem ON dbo.BenchmarkTelemetryItemContainer.Id = dbo.BenchmarkTelemetryItem.BenchmarkTelemetryItemContainerId WHERE dbo.BenchmarkTelemetryItemContainer.Id IN ( SELECT Id FROM [dbo].BenchmarkTelemetryItemContainer WHERE BenchmarkExecutionId = ( SELECT Id FROM dbo.BenchmarkExecution WHERE [Name] = 'B_Korea_US15811_20230707 17.42.24' ) ) AND [Key] = 'AsiaWorkflow'

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Calculate-Recommended-Thresholds---Confusion-Matrix-depending-on-Threshold.md - Chunk 3
```

(Optional) Draw Diagram

Import ConfidenceMatrices .tsv result file into Excel

Daten Transformieren to "Erste Zeile als Überschrift verwenden" Schließen und laden Format all Values to Prozent (1 digit) Insert Diagram (chose Vorlage)

Select Recommended Thresholds and Deploy

Copy from the third file (dyn config) the according data to the dynamic_config.json Check which detail threshold should be used by analysing the error rates file. Then deploy the dynamic_config

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection.md - Chunk 0
DataCollection Pipeline - Logical View

Architecture of the DataCollection pipeline

DataChannel Components

[ ] Bludelta DataChannel: not yet implemented

[ ] SME/Support DataChannel: must be refactored. Replace CSV with Predictions/Corrections

[ ] DocGenerator DataChannel: runs in dev environment

[ ] Error Analysis: not yet implemented

Monitoring

DataCollection

Website

https://learn.bludelta.ai/swagger/index.html

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Detailstraining-for-BluDelta-Typhon.md - Chunk 0
Dachser (endpoint) until 30.04.2022

LabelMapper TODO Open: Labelrelease

Status:

1.) Done

2.) Done

3.) Done

4.) Done

5.) Open

6.) Done

7.) Open

8.) Open

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Model-Deployment-Decision-Strategies.md - Chunk 0
Introduction

We have deep learning models and a steadily growing dataset. New training data is added on a daily basis. Deployment and validation strategies must be developed and introduced in order to being able to decide whether a newly trained model can be deployed.

How can we decide when to deploy a new model?

Deciding when to deploy a new deep learning model depends on several factors, including your specific application, the rate of improvement in the models, and the cost of deploying new models. Here are some guidelines to help you determine when to deploy a new model:

Performance metrics: Establish performance metrics and benchmarks for your model. These can include accuracy, precision, recall, F1 score, or any other domain-specific metric that is relevant to your application. Monitor the improvement in these metrics as new training data is added. If the model's performance improves significantly beyond a predetermined threshold, consider deploying the new model.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Model-Deployment-Decision-Strategies.md - Chunk 1
Validation set: Use a validation set to assess the performance of the model periodically. This helps to ensure that the model is not overfitting to the training data and generalizes well to new, unseen data. If the model's performance on the validation set consistently improves, it may be a good time to deploy the updated model.

Cost of deployment: Consider the cost of deploying a new model, both in terms of time and resources. Depending on the specific use case, the cost of deploying a new model may be significant, so it's essential to strike a balance between model improvements and deployment costs.

Stability of the model: Ensure that the model is stable and does not exhibit erratic behavior or sudden drops in performance. A model that is well-behaved and exhibits consistent improvements with new data is more likely to be a good candidate for deployment.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Model-Deployment-Decision-Strategies.md - Chunk 2
Domain-specific criteria: Depending on your application, there may be domain-specific criteria that determine when a new model should be deployed. For example, in a medical application, regulatory or safety concerns might dictate the frequency of model updates. Be sure to consider any such constraints when deciding to deploy a new model.

Real-world testing: Before fully deploying a new model, consider running A/B tests or other experiments in a controlled setting to compare the performance of the new model to the current one. This will give you an indication of how well the new model performs in real-world situations.

Business impact: Assess the potential impact of deploying a new model on your organization's business objectives. If the improvements offered by a new model lead to significant cost savings, increased revenue, or other tangible benefits, it might be worth deploying the new model sooner.

How to deal with a varying/growing Dataset

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Model-Deployment-Decision-Strategies.md - Chunk 3
How to deal with a varying/growing Dataset

Create a fixed validation/test set: Keep a fixed validation/test set that remains unchanged over time. This can help you measure the performance of different models in a consistent manner. You can update this fixed set periodically (e.g., every few months) to include more recent data, but ensure that you use the same set for all model comparisons during a given period.

Use a time-based split: If your data is time-sensitive, such as in stock market predictions or weather forecasting, you can split your data into training, validation, and test sets based on time. For example, you can use data from the last month as your test set, data from two to three months ago as your validation set, and data older than three months as your training set. This way, you can compare your models' performance on recent, unseen data. (NOT REALLY OUT USE-CASE)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Model-Deployment-Decision-Strategies.md - Chunk 4
Rolling validation/test sets: Another approach is to use a rolling window for your validation/test sets. For example, you can always use the most recent N days of data for validation/testing and update this window as new data comes in. This can help ensure that your models are evaluated on the most up-to-date data while still allowing for comparisons between different versions.

Train multiple models: Train multiple models using different time periods or data splits, and compare their performance on the same validation/test set. This can help you understand the generalization capabilities of each model and allow for a more reliable comparison.

Use performance metrics with confidence intervals: When comparing the performance of different models, calculate confidence intervals for your performance metrics to account for any variability due to the changing validation/test sets. This can help you assess the significance of the observed differences in performance between models.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Model-Deployment-Decision-Strategies.md - Chunk 5
Monitor performance over time: Track the performance of your models over time using a moving average or other smoothing techniques. This can help you identify trends in model performance and make more informed decisions about when to deploy a new model.

Ensemble methods: Consider using ensemble methods to combine the predictions of multiple models, including the old and new models. This can help you leverage the strengths of different models and potentially achieve better overall performance.

Optimistic Strategy

The main idea for optimistic strategy: we have small timespans from one model deployment to the next and just adding training data should improve the models or, at least, do no harm.

This strategy will save a lot of work doing QA.

Process

Precondition: since last deployment nothing but trainingdata has changed!

Nothing changed means no changes to - Selection view - Fasttext - Model parameters - Model Container

and Training is done with base of last model

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Model-Deployment-Decision-Strategies.md - Chunk 6
Nothing changed means no changes to - Selection view - Fasttext - Model parameters - Model Container

and Training is done with base of last model

Input: new model trained and stored in MlFlow

Checks: do some simple plausibility checks

To make sure that nothing unexpected happened, we do a limited check on model metrics - MeanIoU not dropped more than 1%. - loss did not raise more than (not relevant if you take meanIoU into consideration) - number of training data increased - no significant increase of training epochs. - model not from epoch 0

To make sure that nothing unexpected happended, wo check the benchmarks executed in training pipeline

If all chesks are ok, continue.

Deployment

New model is provided in a MOP

New model is deployed on Production on Friday or Saturday evening

Quality assurance

Cloud Benchmarks are executed on Production

Results are checked on Monday morning

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Model-Deployment-Decision-Strategies.md - Chunk 7
New model is deployed on Production on Friday or Saturday evening

Quality assurance

Cloud Benchmarks are executed on Production

Results are checked on Monday morning

If results are ok, model deployment is done If results are not ok, undo model deployment und restore former model

Automation

We want to do that process manually three times. If this process is reasonable we will automate all steps.

Summary

In summary, when dealing with a constantly growing dataset, it's essential to establish a systematic approach for handling the validation/test sets and comparing model performance. By implementing one or more of the strategies mentioned above, we can ensure fair comparisons between your new and old models and make informed decisions about when to deploy updated models.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Training.md - Chunk 0
Typhon Training Pipeline:

The training pipeline is implemented as a Kubeflow pipeline and can be found here

Tensorboard for 'real-time' model-training tracking

MLFlow for model tracking

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Triton---Model-Lifecycle.md - Chunk 0
Model Distribution Strategy

Model Deployment

The model deployment process is very similar to that of a CI-CD pipeline for software components. The deployment process consists of four stages as it is shown in the figure below.

Stage 0: A new model, e.g. for header-details is trained. At the end of the training the best model, in ckpt as well as onnx format, is uploaded and tagged with a certain version number into MLFlow. NOTE: additional, useful tags have to be defined.

Stage 1: The uploaded model is copied into triton's model store of the development environment (AKS-DEV). Benchmarks with the new model are executed in the Development-Environment. Go back to Stage 0 if BM(s) haven't improved - this could be a manual decision!!!

Stage 2: Copy the model into triton's model store of the QA environment if BMs have been improved. Execute the same BM(s) in the QA environment. If there are any improvements go back to Stage 0.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Triton---Model-Lifecycle.md - Chunk 1
Stage 2: Copy the model into triton's model store of the QA environment if BMs have been improved. Execute the same BM(s) in the QA environment. If there are any improvements go back to Stage 0.

Stage 3: If BM(s) have improved than this new model is ready for deployment. A new baseline shall be set and the new model is copied into triton's model store of the Production-Environment. Customer shall be notified and get read-only access to the model store shall be provided to them. If there is a breaking change, e.g. different features are used, interface has changed or bugs are fixed, then the corresponding docker image and the model must be provided to our clients.

Model Format

We will use and distributed all our models in onnx format if possible. Currently, all our models are deployed as onnx models.

Model Version

The version starts at 1 and is simply incremented by 1 whenever a new model is trained. There should be a "Version" tag in mlflow reflecting the model's version.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Triton---Model-Lifecycle.md - Chunk 2
Model Version

The version starts at 1 and is simply incremented by 1 whenever a new model is trained. There should be a "Version" tag in mlflow reflecting the model's version.

OnPremise Model Deployment

We propose the following OnPremise setup with Triton support The setup consists of two parts: - Windows Part: - Linux Part:

A different possible architecture

Prerequisites

Triton must be installed on a linux maschine. We use the following docker image: nvcr.io/nvidia/tritonserver:21.10-py3

The Triton Inference Server can be started in CPU-Mode-Only or in GPU-Mode if you have CUDA compliant GPUs. For further information please refer to the Triton-User-Manual

Example 1) Running Triton in GPU Mode:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Triton---Model-Lifecycle.md - Chunk 3
Example 1) Running Triton in GPU Mode:

sh docker run --gpus=1 --rm -p 8000:8000 -p 8001:8001 -p 8002:8002 \ -v /mnt/d/triton-models:/models \ nvcr.io/nvidia/tritonserver:21.10-py3 tritonserver \ --model-repository=/models \ --log-verbose=true \ --log-info=true \ --log-warning=true \ --strict-model-config=false \ --strict-readiness=true \ --exit-timeout-secs=9999 \ --allow-gpu-metrics=true \ --allow-metrics=true \ --model-control-mode=poll \ --repository-poll-secs=120

Example 2) Running Triton in CPU Mode: sh docker run --rm -p 8000:8000 -p 8001:8001 -p 8002:8002 \ -v /mnt/d/triton-models:/models \ nvcr.io/nvidia/tritonserver:21.10-py3 tritonserver \ --model-repository=/models \ --log-verbose=true \ --log-info=true \ --log-warning=true \ --strict-model-config=false \ --strict-readiness=true \ --exit-timeout-secs=9999 \ --allow-gpu-metrics=true \ --allow-metrics=true \ --model-control-mode=poll \ --repository-poll-secs=120

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Triton---Model-Lifecycle.md - Chunk 4
A ModelStore folder must be provided. If a docker image is used than you can mount a host directory into the triton docker container. The host folder must contain the following sub-folders. For each model there must be a separate folder, e.g. contact_lines_classifier and within that folder there must be at least one model version folder "1". Models are stored in onnx format in the corresponding model version folder "1" ```txt D:\TRITON-MODELS ├───contact_lines_classifier │ │ │ └───1 │ model.onnx │ ├───contact_ner │ │ │ └───1 │ model.onnx │ ├───delivery_period_bert_ner │ │ │ └───1 │ model.onnx │ ├───payment_condition │ │ │ └───1 │ model.onnx │ ├───typhon_contacts | └───1 model.onnx

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Triton---Model-Lifecycle.md - Chunk 5
```

Model-Only Update

Customer get informed whenever Blumatix releases a new model. What do they get: - Model name: we tell them which model can be updated, e.g. typhon_contacts - A link to an azure file share from where the new model (model.onnx) can be download - The old model shall be replaced with the new model

Breaking Changes

There can be several reasons for breaking changes. Breaking changes may have an impact on the model's service or on both - the model's service and the model.

Update Docker Image

A docker image must be updated when: - Bugs have been fixed - Its REST endpoint has changed and isn't backward compatible anymore. In that case the customer gets notified and gets permissions for downloading the new docker image.

Update Docker Image and Model

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Triton---Model-Lifecycle.md - Chunk 6
Update Docker Image and Model

Both, the docker image and the model, have to be updated when: - The ML/DL architecture has changed - Different, new or additional features are used. In that case the customer gets notified and gets permissions for downloading the new docker image and does also get the download link for the new model.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Argo-Workflows.md - Chunk 0
Related: https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/397/Receive-and-Store-Customer-Data

We use Argo Workflows as our workflow engine for (parallel) job orchestration in Kubernetes. Arg Workflows can be used for: - Define workflows where each step in the workflow is a container. - Model multi-step workflows as a sequence of tasks or capture the dependencies between tasks using a directed acyclic graph (DAG). - Easily run compute intensive jobs for machine learning or data processing in a fraction of the time using Argo Workflows on Kubernetes. - Run CI/CD pipelines natively on Kubernetes without configuring complex software development products.

Argo Installation

Quick Start

```sh

Create an argo namespace.

kubectl create ns argo

Install argo into the argo namespace

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Argo-Workflows.md - Chunk 1
Argo Installation

Quick Start

```sh

Create an argo namespace.

kubectl create ns argo

Install argo into the argo namespace

sudo kubectl apply -n argo -f https://raw.githubusercontent.com/argoproj/argo-workflows/master/manifests/quick-start-postgres.yaml sudo kubectl apply -n argo -f https://github.com/argoproj/argo-workflows/releases/download/v3.4.3/install.yaml

Port forwarding of argo ui

sudo kubectl -n argo port-forward svc/argo-server 2746:2746 --address 0.0.0.0

Change service type to LoadBalancer - no portforwarding needed.

sudo kubectl patch svc argo-server -n argo -p '{"spec": {"type": "LoadBalancer"}}'

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Argo-Workflows.md - Chunk 2
```

Check out chargrid-pytorch repository and execute cd chargrid-pytorch/kubernetes/clusters/tnet-cluster-rybuntu01/ make apply-cluster-base

Finally disable authentication - useful for local development - In the containers section for the argo-server, you'll see an args field. This field currently contains server, which is the default argument for running the Argo server. - Modify this section to include the --auth-mode=server argument. This will disable the authentication. The modified section should look like this: ```sh sudo kubectl edit deployment/argo-server -n argo

.... args: - server - --auth-mode=server

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Argo-Workflows.md - Chunk 3
```

Argo Installation: a more detailed description

Argo in our local Kubernetes Cluster

Argo runs in our local cluster (192.168.137.78).

Workflow Definition

A workflow is "normally" defined in yaml. The Argo Team provides examples for many different use cases. The yaml examples can be found here

Blumatix DataCollection Workflow Definition

The DataCollection workflow files are located in DataMining/workflows

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Auto-Release.md - Chunk 0
Responsibility

Analyse all labels for a datapoint and determine label quality.

Current Situation

Currently the label quality is a binary value: released and not released. "Released" status is used for benchmarks and training.

Auto Release is a scheduled nightly task (Task Scheduler on Ryzen 7) that executes a Phönix action.

Strategies

Quality (Released/Not Released) is based on quality of all labels for a datapoint. Quality of a single label is mainly based on the source of the label, which is provided in properties User and CreatedVia. There a different strategies, which are executed for each datapoint.

Standard Strategy

This is the strategy we implemented in the very beginning. If all labels of the same InvoiceDetailType are equal and at least two different Users (e.g. Labelers) annotated these Datapoints, the labels can be released.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Auto-Release.md - Chunk 1
Labelgroups are grouped again by there position on the Invoice. Only Labelgroups in the same position are compared, because there can be multiple Labelgroups of the same type on an Invoice.

Single Structured Strategy

Labels created from structured data will always have the correct value, so only the position has to be considered. If the value of a label created from structured data is only found once on a document, it is certain that this label is correct and can therefore be released.

Multiple Structured Strategy

For labels generated from structured data that appear multiple times on the same invoice, we compare them to other labels from a specified source (default: BLU DELTA API). If a single label from the API matches the structured label, the API label is released. GrandTotalAmount and DueDate are excluded from this strategy.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Auto-Release.md - Chunk 2
The InvoiceDetailTypes GrandTotalAmount and DueDate are excluded from this strategy, as these details where deemed to be not accurate enough for this strategy at the time of implementation.

Validated GroundTruth

Labels created from RIPEye have been validated and fixed, they were released instantly. However due to poor quality this is not the case anymore. Now only support documents (identified by S_ + Issue Number) are released via this strategy. Currently there is an additional check for bounding box, because corrected RIPEye labels often have no bounding box. Some InvoiceDetailTypes as well as unavailable labels are exempt from this check as their bounding boxes are always 0.

While the RIPEye labels will always be released, all other labels will still have to be checked by comparing them to the RIPEye label and setting the verified and correct flags accordingly.

Vision

Auto Release is part of Data Collection

Label quality is not binary

Issues

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Auto-Release.md - Chunk 3
Vision

Auto Release is part of Data Collection

Label quality is not binary

Issues

Auto release was provided in the Dashboard, but is not working any longer. No real need.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Create-BLUDELTA-API-labels.md - Chunk 0
1. Create API predictions

To create bludelta api labels, you need predictions in json format. To obtain those predictions you can call phoenix with

phoenix.exe evaluation predict -s "dachser_wave_4\wave4_predictions.txt" -c "https://api.bludelta.ai/v1-18" -o "dachser_wave_4/predictions" -w -t 4 -k "myKey"

This example gives predictions from the productive API (version 1-18) created with the Dachser API key. This is necessary to call Dachser specific modules or patterns. We can call the api with 4 tasks in parallel. This should be a reasonable choice during night hours.

2. Insert predictions as labels into BCIDB

After the predictions are obtained, we load all detail predictions as labels into the database with the following command: phoenix invoice insertLabels -l "dachser_wave_4\predictions" -c "BLU DELTA API" The c parameter specifies the CreatedVia field in the database. Usually this is always BLU DELTA API

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Create-BLUDELTA-API-labels.md - Chunk 1
Important!! If you make predictions against the productive system with more than two tasks, you have to inform Günter about that.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\FolderBasedDataChannel.md - Chunk 0
Responsibility

Download uploaded documents and their groundtruth to internal NAS folder.

Summary

The DownloadAction class in the Blumatix.FolderBasedDataChannel namespace is responsible for downloading and processing zip files stored in Azure File Shares. It utilizes the FileSharePackage and FileSharePackageBuilder classes to handle the packages efficiently.

DownloadAction

The DownloadAction class takes the following arguments:

OutputFolder: The output folder where the downloaded and unzipped files will be stored.

FileSharePrefix: Name of file share where all uploaded packages will be stored in sub directories. There is directory per Provider/Customer.

PackagesFilePath: The path where the package summary will be written as a JSON file.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\FolderBasedDataChannel.md - Chunk 1
PackagesFilePath: The path where the package summary will be written as a JSON file.

The class fetches the file share name using the given prefix and retrieves provider directories. For each provider directory, it uses the FileSharePackageBuilder class to create a list of FileSharePackage instances. Then, it downloads, stores, and deletes the packages asynchronously.

FileSharePackageBuilder

The FileSharePackageBuilder class takes an IFileShare object as input and constructs FileSharePackage instances. It groups the files by their names without extensions and builds pairs of zip and JSON files for each group. The pairs are then transformed into PrivatePackage objects with additional properties such as PackageId and ProviderName. Finally, the PrivatePackage objects are converted into FileSharePackage objects.

FileSharePackage

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\FolderBasedDataChannel.md - Chunk 2
FileSharePackage

The FileSharePackage class represents a package with properties such as PackageId, ZipFile, JsonFile, and an output directory. It provides methods for downloading, storing, and deleting the package from the Azure File Share. The class also offers methods to extract document information and ground truth files from the downloaded package.

By integrating these classes, the DownloadAction class provides a streamlined approach to handling zip files stored in Azure File Shares.

Pseudo Code

This pseudo code outlines the main flow of the FolderBasedDataChannel when using the DownloadAction class. The code initializes the DownloadAction instance, processes command line arguments, and iterates through the provider directories to handle the zip files stored in Azure File Shares.

```sh initialize DownloadAction

parse command line arguments - set OutputFolder - set FileSharePrefix - set PackagesFilePath

get FileShareName using prefix

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\FolderBasedDataChannel.md - Chunk 3
```sh initialize DownloadAction

parse command line arguments - set OutputFolder - set FileSharePrefix - set PackagesFilePath

get FileShareName using prefix

create FileShare instance with FileShareName

get list of provider directories from FileShare

create FileSharePackageBuilder instance with FileShare

for each providerDirectory in providerDirectories: - log "Processing Provider: {providerDirectory.Name}" - create list of FileSharePackages using FileSharePackageBuilder - for each fileSharePackage in FileSharePackages: - try: - download, store, and delete the fileSharePackage - add package information to packages list - catch Exception: - log error message and continue with next package

write packages summary to PackagesFilePath ```

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Importer.md - Chunk 0
Responsibility

Imports Documents into database

Import

The given documents are imported into our Document Database. - Document is stored - Ocr is calculated (Languages, Number of Pages) - Provider is stored

Issues

Phönix Service is used which makes it more complex

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Label-Creation.md - Chunk 0
Label Creation.pptx

Label Definition

Two main aspects: - Text is original format from document - given Bounding Box (except for labels describing properties of document like document type or currency or language=

Channels for Label Creation

Many channels for labels with different information: - text is free formatted, normalized or original format - position exists or is missing

Channel agnostic label creation

Independent from channel the label creation just depends on information provided 1. Normalize text 2. Find on document a) given position: search text on document within given boundingbox -> use original text to create label b) no given position: search text on document (compare normalized text) -> use orignal text to create label(s)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Label-Creator.md - Chunk 0
Responsibility

Create Labels and store them to database.

BluDoc to Labels

BluDoc is organized similar to Labels. Both define their structure hierachically. DocumentEssentials that can be nested in BluDoc , LabelGroups and Label in label definition.

Process

There are three steps to create labels from BluDoc

Create Label-BluDoc

Since the BluDoc may miss location (and original text) we try to find both on the document. When finding the details on the document we add those completed DocumentEssentials to the new Label-BluDoc. Sometimes we find the values on several locations on the document so we create several DocumentEssentials.

Missing Bounding Boxes and Original Text

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Label-Creator.md - Chunk 1
Missing Bounding Boxes and Original Text

BluDocs created from Structured Data don't include bounding boxes. This is fine for some labels like DocumentType, InvoiceCurrency or DachserSenderId... Where bounding boxes are needed we try to find to content on the invoice. To compare the words we use the normalized text. When we find the content multiple times on the invoice we create multiple labels with different bounding boxes and the original text, found on the invoice.

Convert Label-BluDoc to Invoice Entity

There is a LabelConverter to convert BluDoc to InvoiceEntity with LabelTypes and LabelGroupTypes. This is the reverse part of the LabelConverter that converts InvoiceEntities to BluDoc, that is part of the BluDoc.Convert nuget package from Normalizer.

Filter and Store Labels

Not all labels should be stored. - if there is already a released label for this detail no more label is stored - if there is already a label from the same CreatedVia, no more label is stored

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Label-Creator.md - Chunk 2
Not all labels should be stored. - if there is already a released label for this detail no more label is stored - if there is already a label from the same CreatedVia, no more label is stored

Remaining labels are stored to the BCI Db

Issues

handle empty Groups (check that no children exist?)

LabelConverter from LabelCreator should be merged to LabelConverter in BluDoc.Converter.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Normalizer.md - Chunk 0
Responsibility

Convert given formats to latest BluDoc.

Convert to BluDoc

Already BluDoc It is checked if .json file is a BluDoc file. If so, the version is checked and migrated to latest BluDoc , if necessary.

API Response If the .json file is an API response from our service it is converted. The original file is stored with an "_ori" postfix in the name and the new BluDoc file gets the name of the original .json file.

Package.DocumentType If a DocumentType has been provided, a new BluDoc files are created including the DocumentType information.

Structured Data The ground truth is provided by a .csv file. This is one file for all documents.This file does not include bounding boxes. A mapping definition (column names in .csv to label names and formatting ) enables to create BluDoc files. Currently there are two .csv Mapper implemented: for ETL and Dachser. The mapper is chosen based on the provider information.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Normalizer.md - Chunk 1
Dachser BluDoc For Dachser we defined an early BluDoc format to be uses for the Learn API. This format is converted to BluDoc.

API Response Formats to be converted

Currently just DetectResponse in version V1.14 can be converted. This is not the latest API Response format (e.g. does not include list of Contacts.

BluDoc Source and SourceVersion

BluDoc includes information about its Source and Source Version.

When BluDoc is created in the Normalizer those properties are set like this:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Normalizer.md - Chunk 2
Original Description already impl. Format Provider Label User BluDoc Source BluDoc SourceFormat DocGenerator BluDocs created by DocGenerator yes BluDoc BluDocGenerator Mr. LabelCreator BluDelta Document Generator DocGenerator Version: 1.0.11 Blu Delta API API Response from current production service no API Response json package.Provider Mr. LabelCreator BluDelta API BluDelta Version (missing) RIPEye Validated API Response; Bounding Boxes might be missing yes API Response json package.Provider Provider_1 RIPEye Blu Delta Version (missing) Structured Data Customer Ground Truth; Bounding Boxes usually missing curr Csv - one file for all documents package.Provider Provider_1 StructuredData ? RIPEye  LabelingTool RIPEye used as Labeling Tool no API Response json package.Provider Labeler_Id RIPEye Labeling Tool version of RIPEye Labeling Tool Document Type Definition of new Document Types yes package.DocumentType package.Provider Provider_1 Package.DocumentType ?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Normalizer.md - Chunk 3
Open questions: - how can Normalizer distinquisch Blu Delta API and RIPEye? add Property to API Response json or use Score!

Issues

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Operational-View.md - Chunk 0
Hardware and Software Components and Cloud Services

Start phoenix services on ServerBdKub01

bash PS LocalHost> ssh rudi@ad.blumatix.com@192.168.137.70 PS D:> cd D:\

bash PS D:\> docker-compose.exe -f docker-compose-winservices.yml up -d PS D:\> docker-compose.exe -f .\docker-compose-ocrservices.yml up -d

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Operational-View.md - Chunk 1
bash PS D:\> docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 6a69c28aafce blumatixdevregistry.azurecr.io/phoenix_service:latest "C:\\app\\Blumatix.Cap…" Less than a second ago Up Less than a second 0.0.0.0:10000->10000/tcp default_phoenix-training-dev_1 c8ed57e02d7f blumatixdevregistry.azurecr.io/phoenix_service:1.7 "C:\\app\\Blumatix.Cap…" Less than a second ago Up Less than a second 0.0.0.0:10002->10000/tcp default_phoenix-import-dev_1 744c620d3ee1 blumatixdevregistry.azurecr.io/phoenix_service:1.8 "C:\\app\\Blumatix.Cap…" Less than a second ago Up Less than a second 0.0.0.0:10001->10000/tcp default_phoenix-training-prod_1 90a78598939f blumatixdevregistry.azurecr.io/phoenix_service:1.7 "C:\\app\\Blumatix.Cap…" Less than a second ago Up Less than a second 0.0.0.0:10003->10000/tcp default_phoenix-import-prod_1 cd3a3094963f blumatixdevregistry.azurecr.io/nginx-win:latest "C:\\app\\nginx.exe" 9 seconds ago Up 5 seconds 0.0.0.0:9090->9090/tcp default_nginx_1 b5baeef5b950

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Operational-View.md - Chunk 2
default_phoenix-import-prod_1 cd3a3094963f blumatixdevregistry.azurecr.io/nginx-win:latest "C:\\app\\nginx.exe" 9 seconds ago Up 5 seconds 0.0.0.0:9090->9090/tcp default_nginx_1 b5baeef5b950 blumatixdevregistry.azurecr.io/ocrbox:latest "C:\\app\\Blumatix.Cap…" 13 seconds ago Up 10 seconds 9090/tcp default_ocr-service_1 195157d337f4 blumatixdevregistry.azurecr.io/ocrbox:latest "C:\\app\\Blumatix.Cap…" 13 seconds ago Up 10 seconds 9090/tcp default_ocr-service_4 dd015a719d20 blumatixdevregistry.azurecr.io/ocrbox:latest "C:\\app\\Blumatix.Cap…" 13 seconds ago Up 10 seconds 9090/tcp default_ocr-service_2 a405157eec82 blumatixdevregistry.azurecr.io/ocrbox:latest "C:\\app\\Blumatix.Cap…" 13 seconds ago Up 10 seconds 9090/tcp default_ocr-service_3

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Operational-View.md - Chunk 3
Argo

Argo runs in our local kubernetes cluster. The Argo Dashboard can be accessed at: https://192.168.137.78:2746

Source Code

You find the code for all components but the phoenixservice in the DataMining repo - PackageUploader: - Url to the PackageUploader API description: http://40.68.145.176:13800//swagger/index.html - Use this URL to PackageUploader: https://learn.bludelta.ai/swagger/index.html - Folder-Based-DataChannel: - DocumentImporter: - Clustering: - LabelCreator: - Reporting: - PhoenixService:

DevOps Pipelines

DataCollection Pipelines: - PackageUploader: Builds and pushes a docker image into our registry and deploys it into AKS-DEV - Report: Builds and pushes a docker image into our registry

DataCollection Component Template

Use the following dotnet template for a any DataCollection Component that is written in C#: - Blumatix.Utility.Templates: NOTE: this template is a beta version and will be modified, updated, extended in the future.

DataCollection Outputs:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Operational-View.md - Chunk 4
DataCollection Outputs:

Downloaded packages are stored in: \nas-01\DataCollection{PROVIDER_NAME}

Reports are currently stored in: \nas-01\DataCollection\reports

Monitoring and Logging

Prometheus

Grafana Dashboard: http://192.168.137.78:31000/d/data-collection-overview/data-collection-overview?orgId=1

Logging via Loki: Log messages are collected from all components via Loki and are displayed in the DataCollection Dashboard as well. Even log messages from phoenix-service are collected and displayed in the Dashboard although it is not hosted insided our kubernetes cluster.

Phoenix-Service Logging

Phoenix-Service uses Serilog for logging and a special 'Loki' sink which it uses to send log messages to Loki. Serilog is automatically added into a dotnet application if you use the BlumatixConsoleApp Template. You can also install Serilog by installing the following nuget packages from our Blumatix Nuget Feed: - Blumatix.Logging - Blumatix.Logging.Interface

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Operational-View.md - Chunk 5
```json ... "WriteTo": [ { "Name": "GrafanaLoki", "Args": { "uri": "http://192.168.137.78:32400", "labels": [ { "key": "app", "value": "phoenix_service" }, { "key": "environment", "value": "prod" } ], "createLevelLabel": true, "queueLimit": 10, "textFormatter": "Serilog.Sinks.Grafana.Loki.LokiJsonTextFormatter, Serilog.Sinks.Grafana.Loki", "outputTemplate": "[{Timestamp:yyyy/MM/dd HH:mm:ss} {Level:u10}] {SourceContext:l} {Message:lj} {NewLine}{Exception}{NewLine}" } },

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Operational-View.md - Chunk 6
```

The following screenshot shows the DataCollection Dashboard

Phoenix Service - API

You can get the API description in your Browser: http://192.168.137.70:10000/swagger-ui

Known Issues:

Bug: Crashes: if FileShare folder does not exist

Monitoring is missing

Update Template

DataCollection namespace was created manually in AKS-DEV

Secret for Docker Registry was also added manually to the namespace

Phoenix-Service

Kubernetes

Endausbau

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Package-Uploader.md - Chunk 0
Responsibility

The (one and only) endpoint to upload any kind of documents and ground truth into our Data Collection.

Upload

Url for upload: https://learn.bludelta.ai/swagger

Public Parameters:

CompanyName ... Provider (must) NOTE: In current version (16.11.2022) there is no verification of the CompanyName. e.g. misspellings will end up in inconsistent data and new company names need to be aligned with Data Management Team

Document ... Package zip file (must)

[ ] zip file with flat structure, accepted file types can be pdf, png, jpg, jpeg or tiff

[ ] Every file needs to represent one document (e.g. in images more than one page, etc)

[ ] Groundtruth can be added as BluDoc or API-json format; file name must be same as document filename (except extension); only corrected of proven data including bounding boxes should be uploaded (data without bounding boxes will come later)

[ ] Recommended size: max. 1000 documents per zip package (smaller recommended)

DocumentType (optional)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Package-Uploader.md - Chunk 1
[ ] Recommended size: max. 1000 documents per zip package (smaller recommended)

DocumentType (optional)

Possible values: https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/1199/Supported-Doc-Types

Tags (optional) comma seperated list of tags to describe package, e.g. "tag" or "tag1, tag2, tag3"

Internal Parameters

Property Store a "key-value pair" dictionary of strings {"Key1":"Value1","Key2":Value2"}

Selection of OCR Engine, used in Importer Component Key: "OCREngine" Values: "EasyOcr", "NuanceOcr", "PaddleeOcr" Definition found in Blumatix.DataCollection.Components project in PropertyStoreConstants.cs

Error Handling

Error 400 - no Company Name - DocumentType is given, but value not accepted

New Document Type

Open Solution Open PackageUploader solution in DataMining Repo

Update doc type definition for validation Add new document type to validDocTypes.txt in config folder of PackageUploader project.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Package-Uploader.md - Chunk 2
Open Solution Open PackageUploader solution in DataMining Repo

Update doc type definition for validation Add new document type to validDocTypes.txt in config folder of PackageUploader project.

Update Swagger documentation Add new document type to SwaggerSchema DocumentType, Description property.

Import Paths:

dev:

prod:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Packages.md - Chunk 0
[[TOC]]

Introduction

Uploads for the Learn API (Package Uploader) are organized in Packages. Each Upload creates one Package with a unique GUID Id.

Properties

A Package includes this information

Package

Property Description Type Sample Naming Convention Id Unique identifier Guid - CreationDate Date of package upload DateTimeOffset - Provider Customer Key string Dachser - DocumentType any valid document type, optional string "TermsAndConditions" - FilePath Path to package folder on NAS string - Tags list of tags, optional list of string "tag1, tag2" Project name or Context according to Files-and-Directories ; Azure Item Number #nnnnnn e.g. #20402 DocumentInfos list of document infos list of DocumentInfo - PackageProperties list of package properties list of PackageProperty -

DocumentInfo

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Packages.md - Chunk 1
DocumentInfo

Property Description Type Sample InvoiceId reference to imported invoice long IsNew flag, that indicates of this document was currently imported (true) or has already been imported before (false) bool DocumentFileName file name of original document string "RechnAB123.pdf" GroundTruthFileName file name of provided ground truth, optional string "RechnAB123.json"

PackageProperty

Property Description Type Sample Key key of property string "OCREngine" Value value of property string "EasyOCR"

Database Diagram

Queries

Packages Overview

View dbo.PackageOverview shows overview for each package including all properties

Get Invoice Ids for Tag

SELECT di.* FROM [dbo].[DocumentInfo] di JOIN [dbo].[Package] p ON di.PackageId = p.Id JOIN [dbo].[PackageTag] pt ON p.Id = pt.PackageId JOIN [dbo].[Tag] t ON pt.TagId = t.Id WHERE t.TagName = 'TaxiBus'

Get Cluster for Tag

bcidb ->

'GetMaxNInvoiceIdsForEachClusterInRange' ->

Execute Stored Procedure ->

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Packages.md - Chunk 2
Get Cluster for Tag

bcidb ->

'GetMaxNInvoiceIdsForEachClusterInRange' ->

Execute Stored Procedure ->

Provide a Tag such as 'MyTag' and the number 'N' of InvoiceIds you would like to get for each ClusterId.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Phoenix-Service.md - Chunk 0
The phoenix service is used by several components, e.g. in the DataCollection pipeline. The following diagram shows a possible implementation of the "PhoenixService"

Phoenix service deployment and release notes

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Report-Creator.md - Chunk 0
Responsibility

Does basic analysis and creates report

Create Report

Issues

Very limited analysis

How to access report?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Scheduled-Task.md - Chunk 0
How to Schedule a Task

Example:

``sh cd D:\ .\scheduled_task.ps1 -Action NewTask

Executable docker.exe -Argument "run blumatixdevregistry.azurecr.io/data-collection-client:latest .\Blumatix.BludeltaSme.DataCollection.Client.exe" -AtTime "04:00 AM" -User SYSTEM -TaskName "DataCollectionClient" ```

sh Get-ScheduledTask -TaskName DataCollectionClient

sh Disable-ScheduledTask -TaskName DataCollectionClient

sh Unregister-ScheduledTask -TaskName DataCollectionClient

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Bludelta-Dashboard-Release-Notes.md - Chunk 0
Dashboard Release Notes V1.6.24

2024-09-10

22361

Labeling Tool url in Web config updated on Ryzen7virt

Dashboard Release Notes V1.6.23

2024-04-10

19726

9218

new Label Type "Payment Reference Id" and "Region"

Dashboard Release Notes V1.6.22

2023-12-28

17573

new Label Type "Attention"

Dashboard Release Notes V1.6.21

2023-10-11

17699

Export benchmark report now includes all documents (before it was an error report filtering just those with passed exact = false)

Dashboard Release Notes V1.6.20

2023-08-23

16694

new Label Types for Quotation

Dashboard Release Notes V1.6.19

2023-08-04

16405

new Label Types

Dashboard Release Notes V1.6.18

2023-07-31

16702

Dashboard geht wieder auf die Produktiv BCI Db

Dashboard Release Notes V1.6.17

2023-06-05

16145

Dashboard geht wieder auf die Produktiv BCI Db

Dashboard Release Notes V1.6.16

2023-06-02

15915

Transport Tour Id added

7070: updated ingress url

Dashboard Release Notes V1.6.15

2023-04-27

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Bludelta-Dashboard-Release-Notes.md - Chunk 1
Dashboard geht wieder auf die Produktiv BCI Db

Dashboard Release Notes V1.6.16

2023-06-02

15915

Transport Tour Id added

7070: updated ingress url

Dashboard Release Notes V1.6.15

2023-04-27

7070: updated ingress url

Dashboard Release Notes V1.6.14

2023-04-14

15316: Add SenderTaxId and ReceiverTaxId

Dashboard Release Notes V1.6.13

2023-04-06

15287 (BUGFIX): Fix connection string for bca to calculate total recognition rate

Dashboard Release Notes V1.6.12

15005 (BUGFIX): Fix a Dashboard Bug which did not allow to show the Details of an Invoice any more (OCR, Labels, etc...)

Dashboard Release Notes V1.6.11

8004: Add missing InvoiceLabelTypes to enum in Dashboard

Dashboard Release Notes V1.6.10

11239: None-functional update (BCI-Schema changed)

Dashboard Release Notes V1.6.9.3

10763: None-functional update (BCA-Schema changed)

Dashboard Release Notes V1.6.9.2

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Bludelta-Dashboard-Release-Notes.md - Chunk 2
11239: None-functional update (BCI-Schema changed)

Dashboard Release Notes V1.6.9.3

10763: None-functional update (BCA-Schema changed)

Dashboard Release Notes V1.6.9.2

10161: Update Blumatix.Ocr nuget packages of Dashboard project to current version 1.6.9 --> Fixes an exception when viewing invoices in Dashboard

7070: Fix a bug which happened in some views of the dashboard, where the function which does the filtering of list-data was triggered twice when the Enter-key was pressed

Dashboard Release Notes V1.6.9.1

9957: New version required due to schema changes in bcidb (LineItemTable labeling as nested LabelGroups)

Dashboard Release Notes V1.6.9

9599: Benchmark-Invoice-ClusterSize is correctly displayed and handled in dashboard-views and calculations

Dashboard Release Notes V1.6.8

9381: BMReport Modules are displayed via new Dashboard (+++Extend BCA-DB with Comment columns)

Dashboard Release Notes V1.6.7.1

7070: Fix Translation Service Bug

Dashboard Release Notes V1.6.7

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Bludelta-Dashboard-Release-Notes.md - Chunk 3
9381: BMReport Modules are displayed via new Dashboard (+++Extend BCA-DB with Comment columns)

Dashboard Release Notes V1.6.7.1

7070: Fix Translation Service Bug

Dashboard Release Notes V1.6.7

8425: Add not yet finished Views for BMReports (List & DetailView)

7070: Some minor visual dashboard refactorings

Dashboard Release Notes V1.6.6

7070: Integrate the SessionHandling fix for the DemoWebsite into the Dashboard

8971: Show compare info instead of CustomOcr in benchmark runs view

8971: Show additional infos as tooltip in benchmark executions view of dashboard

Dashboard Release Notes V1.6.5

8424: Added a new BenchmarkSetExections View

8424: Integrated a taging-system into all benchmark views (BenchmarkSetExecution, BenchmarkExecution, BenchmarkRun)

Dashboard Release Notes V1.6.4

8776 Added F1 Score, Precision and Recall metrics to the Benchmark Runs/Executions

Dashboard Release Notes V1.6.3

8312: Add support for manual release of LabelGroups.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Bludelta-Dashboard-Release-Notes.md - Chunk 4
8776 Added F1 Score, Precision and Recall metrics to the Benchmark Runs/Executions

Dashboard Release Notes V1.6.3

8312: Add support for manual release of LabelGroups.

Dashboard Release Notes V1.6.2

7761: Extend BenchmarkExecutions View --> Add drop down to select a comparison --> when drop down value changes, or the 'Show' button is pressed --> show the BM-Runs of the specified comparison only

Dashboard Release Notes V1.6.1

8372: Add support for 64-bit InvoiceDetailType

Dashboard Release Notes V1.6.0

7762: Add a new BenchmarkExecutions module to the dashboard

7762: Allow to show only BenchmarkRuns which belong to a specific BenchmarkExecution

7762: Re-arrange confusion matrix in BenchmarkResults view

7762: Always show a minimum of 100 records in BenchmarkRun and BenchmarkExecution views

Dashboard Release Notes V1.5.9

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Bludelta-Dashboard-Release-Notes.md - Chunk 5
7762: Re-arrange confusion matrix in BenchmarkResults view

7762: Always show a minimum of 100 records in BenchmarkRun and BenchmarkExecution views

Dashboard Release Notes V1.5.9

#7976: Use full available horizontal space for BenchmarkResults view in Dashboard #7976: Show confidence columns in BenchmarkRunDetails view of Dashboard #7976: Slightly prettify responsive behavior of benchmarkRunDetails view of Dashboard #7976: Use different PassedValue ConfusionMatrix Calculation for Confidence DetailType #7976: Add PassedConfidence-ConfusionMatrix to BenchmarkRunDetails view of Dashboard #7976: Do not show missleading values in confidence columns of the BenchmarkRunDetails view in the dashboard for the total invoice confidence DetailType #7976: Show PassedConfidenceRate column in BenchmarkRuns view of Dashboard

Dashboard Release Notes V1.5.8

#7762: Speed up BenchmarkRuns view in dashboard

Dashboard Release Notes V1.5.7

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Bludelta-Dashboard-Release-Notes.md - Chunk 6
Dashboard Release Notes V1.5.8

#7762: Speed up BenchmarkRuns view in dashboard

Dashboard Release Notes V1.5.7

#8127: Raise sql command timeout for BenchmarkRun queries (BCA db) from 30 to 300 seconds to fix an exception which sometimes popped up in the BenchmarkRuns view.

Dashboard Release Notes V1.5.6

#7875 Add new label types to Dashboard (BankAccount, BankCode, ISR & Kid)

Dashboard Release Notes V1.5.5

#7664: Correctly show 'DueDate' labels in Dashboard #7070: Fix a Dashboard-bug which prevented the loading-dialog to go away (removed 'fade' css class from dialog)

Dashboard Release Notes V1.5.4

#7439 Make Dashboard compatible with new bca database schema (BenchmarkExecution-entity)

Dashboard Release Notes V1.5.3

#7407 enable manual release of different values for receiver and sender order id

Dashboard Release Notes V1.5.2

7390: Fix downloading functionality for Invoices via Dashboard (could not handle special characters in filenames)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Bludelta-Dashboard-Release-Notes.md - Chunk 7
Dashboard Release Notes V1.5.2

7390: Fix downloading functionality for Invoices via Dashboard (could not handle special characters in filenames)

7360: In the BenchmarkRuns view, replace the column "LogLoss" with the (filterable) column "Pipeline"

7360: Add an additional filter option to the BenchmarkRuns view (IsCompleted)

7399: The 3 new InvoiceLabelTypes for Stadt Wien are now visible (and edit- & releaseable)

Dashboard Release Notes V1.5.1

7326: Rename label Type 'RkstLocation' to 'OerkLocation'

7341: AutoRelease (AutoRelease) will now also release labelled tables

7341: AutoRelease (AutoRelease) will deliver more accurate progressbar updates

7341: AutoRelease should perform slightly better now because preprocessed Invoice-Objects will only be created when really needed

7341: A "Main-Record" (Release entity) is created and stored into the DB now for each started AutoRelease-process

Dashboard Release Notes V1.5.0

7326: Integrate new label Type 'RkstLocation'

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Bludelta-Dashboard-Release-Notes.md - Chunk 8
7341: A "Main-Record" (Release entity) is created and stored into the DB now for each started AutoRelease-process

Dashboard Release Notes V1.5.0

7326: Integrate new label Type 'RkstLocation'

Dashboard Release Notes V1.4.9

7070: Improve selection of rows in the Benchmark-Runs view (no more server round-trips)

7070: Fix multiple occurencies (esp. Manual Release & Edit Label) where server-side-json-strings were inserted into javascript-code-blocks, because the used approach created exception when special characters like '\' occured in the json text.

7070: Fix a bug when comparing Benchmark-results with different amounts of completed invoices

Dashboard Release Notes V1.4.8

7338: Extend the Benchmark-Run view with a 'TRR'-button which will calculate a Total-Recognition-Rate (together with more detailed analysis) for all selected BenchmarkRuns

7338: Add a working global error logging mechanism to the dashboard

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Bludelta-Dashboard-Release-Notes.md - Chunk 9
7338: Add a working global error logging mechanism to the dashboard

7338: Add an 'Export Errors' button to the TRR-dialog to export all details into a comma-seperated TSV-file

Dashboard Release Notes V1.4.7

(Buggy version which was never released)

Dashboard Release Notes V1.4.6

7338: Fix a bug when viewing invoices --> add 4 new InvoiceLabelTypes: SenderZipCode, SenderCity, ReceiverZipCode, ReceiverCity

Dashboard Release Notes V1.4.5

7091: Add the "Add Label" button onto the "Edit Labels" view of the Dashboard.

7070: Add a "Refresh" button onto the "Edit Labels" view of the Dashboard.

7070: Remove 1 of the 2 confirm dialogs when saving changes for a label via the "Edit Labels" view of the Dashboard.

Dashboard Release Notes V1.4.4

7320: Fix a bug in the dashboard-benchmark-confusion matrix

Dashboard Release Notes V1.4.3

7320: Extend BenchmarkRun DetailView of Dashboard --> Display confusion matrix

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Bludelta-Dashboard-Release-Notes.md - Chunk 10
7320: Fix a bug in the dashboard-benchmark-confusion matrix

Dashboard Release Notes V1.4.3

7320: Extend BenchmarkRun DetailView of Dashboard --> Display confusion matrix

7320: Extend BenchmarkRun DetailView of Dashboard --> If there are missing invoice results, the user can download a list of the missing Ids

Dashboard Release Notes V1.4.2

7070: No specific Dashboard features or fixes, but a lot of small things have changed in the pre-processing (internal types) since the last update

Dashboard Release Notes V1.4.1

7296: Added some navigation options to the manual release view

7296: Improved the error handling in the manual release view

7070: Added some coloring to the completed-state-column of the benchmark runs view

Dashboard Release Notes V1.4.0

7271: Improve AutoRelease ---> Added "MayContainMultipleWords"-Attribute to Sender/Receiver Street and Sender/Receiver ZipLocation

Dashboard Release Notes V1.3.9

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Bludelta-Dashboard-Release-Notes.md - Chunk 11
Dashboard Release Notes V1.4.0

7271: Improve AutoRelease ---> Added "MayContainMultipleWords"-Attribute to Sender/Receiver Street and Sender/Receiver ZipLocation

Dashboard Release Notes V1.3.9

7209: Manual Release/Edit Labels ---> Show "N/A" when "Available" property of a label is [false], and not when "Text" property is [null]

7225: Adding a specific label, via the "Add Label" button on the Manual-Release view, will work correctly once the Labelling Tool is updated to V2.0.2, also when the user has assigned table types for labelling.

The url of the Labelling Tool is configurable in the appSettings section of the web.config of the Dashboard. (required for development)

7268: Refreshing the page (F5) on the Manual-Release view will not result in an error when some labels where released for another invoice of the "package" before.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Bludelta-Dashboard-Release-Notes.md - Chunk 12
7268: Refreshing the page (F5) on the Manual-Release view will not result in an error when some labels where released for another invoice of the "package" before.

7268: The process, navigating from one invoice to another on the Manual-Release view, should be much more performant now. Opening the Edit-Label view will be faster too.

7268: The request in the Dashboard, which is sent when selecting a manual release package, was changed from httpPost to httpGet. By that, pressing F5 during a manual release session will no more require the user to commit an alert message.

7268: A refresh button was added to the Manual-Release view which will simply reload the releasable labels for the current invoice (press this, after adding a new label)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Bludelta-Labeling-Tool-Release-Notes.md - Chunk 0
Labeling Tool Release Notes V2.1.38

2024-11-04

20888

Bug fixed for new line item details; new document type added

Labeling Tool Release Notes V2.1.37

2024-10-10

20888

Labeling Tool Release Notes V2.1.36

2024-05-17

21154

Labeling Tool Release Notes V2.1.35

2024-05-07 Use of produktion Resource Service

Labeling Tool Release Notes V2.1.34

2024-04-10

19726

9218

Labeling Tool Release Notes V2.1.33

2024-04-09

19325

Additional Document Types available to select in Drop Box.

Labeling Tool Release Notes V2.1.32

2023-12-20

17573

18250

Labeling Tool references Labeling Instruction website instead of old documents.

Labeling Tool Release Notes V2.1.31

2023-10-25

17815

Enable Release of Contacts (like Line Items)

Labeling Tool Release Notes V2.1.13

2023-08-23

16694

Labels added needed for Quotation: QuotationId, QuotationDate Labels added for Automotive: FirstRegistrationDate, PlateId, Mileage

Labeling Tool Release Notes V2.1.12.0

2023-08-04

16405

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Bludelta-Labeling-Tool-Release-Notes.md - Chunk 1
16694

Labels added needed for Quotation: QuotationId, QuotationDate Labels added for Automotive: FirstRegistrationDate, PlateId, Mileage

Labeling Tool Release Notes V2.1.12.0

2023-08-04

16405

Labels added needed for OrderConfirmations: OrderConfirmationId, OrderConfirmationDate, DeliveryTerm, Surcharge, additional Contacts (Delivery, Invoice) Add additional Document Types to ComboBox of DocumentType

Labeling Tool Release Notes V2.1.11.0

2023-06-02

15915

Transport Tour Id added

Labeling Tool Release Notes V2.1.10.0

2023-05-27

16095

Text for labels was wrong: Storno instead of Skonto

16094

English version of labeling instruction included comment view.

Labeling Tool Release Notes V2.1.9.0

2023-05-19

15981

Some fields that are needed by Dachser have not been internationalized in the tool. This has been fixed.

15982

VehicleIdentficationNumber labeling failed - this has been fixed.

Labeling Tool Release Notes V2.1.8.0

2023-05-11

15845

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Bludelta-Labeling-Tool-Release-Notes.md - Chunk 2
15982

VehicleIdentficationNumber labeling failed - this has been fixed.

Labeling Tool Release Notes V2.1.8.0

2023-05-11

15845

Change DocumentTyp definition to include Other in case of neither Invoice no Creditmemo

Labeling Tool Release Notes V2.1.7.0

2023-04-27 INGRESS Url updated

Labeling Tool Release Notes V2.1.6.0

2023-04-13

15316

add SenderTaxId and ReceiverTaxId

Labeling Tool Release Notes V2.1.5.0

2023-03-31

15385: add "Vat Exemption" as Default to "Vat Exemption Reason" Combobox

Labeling Tool Release Notes V2.1.4.0

15343,#15374: Workaround for LabelGroups with doNotSaveChildsIfGroupIsNA --> Re-create empty comments when such Labels are saved. Otherwise User would get same invoice again after saving.

Labeling Tool Release Notes V2.1.3.0

15104,#15140: Change the following LabelGroupTypes, so that LabelEntities ar created for each (Child-)LabelType, when the group is labeled as NA: Project, CostCenter, LicensePlate, DeliveryPeriod, VatExcemption

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Bludelta-Labeling-Tool-Release-Notes.md - Chunk 3
Labeling Tool Release Notes V2.1.2.0

15067: Fix bug of LabellingTool which creates empty comments whenever Labels are saved

Labeling Tool Release Notes V2.1.1.0

No new features, but a new Deployment was required due to a shema-update of the BciDb (New Table: ErrorClass)

Labeling Tool Release Notes V2.1.0.9

10762 and changed log4net file path to view with kudos tool

Labeling Tool Release Notes V2.1.0.8

8985: Fix labeling of LineItemDeliveryNoteIdHeaders

Labeling Tool Release Notes V2.1.0.7

10190: Add Option to release LabelGroups (LineItems,...) to LabelingTool

Labeling Tool Release Notes V2.1.0.6

???

Labeling Tool Release Notes V2.1.0.5

10205: Add 'LineItemCount' Label to LabelingTool

10244: Add contact labeling to Labeling Tool

Labeling Tool Release Notes V2.1.0.4

9957: Implemented LineItemTable Labeling via nested LabelGroups (and also a lot of minor visual updates)

Labeling Tool Release Notes V2.1.0.3

8860: Add TRY currency.

Labeling Tool Release Notes V2.1.0.2

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Bludelta-Labeling-Tool-Release-Notes.md - Chunk 4
Labeling Tool Release Notes V2.1.0.3

8860: Add TRY currency.

Labeling Tool Release Notes V2.1.0.2

8002: Bug fix. Labels which were set to Done are now taken into account when assigning labels, i.e when LabelViewModel is created.

Labeling Tool Release Notes V2.1.0.1

8002: Bug fix. Text property of Label was not set to NULL if Label is not available

Labeling Tool Release Notes V2.1.0

8312: Added support for LabelGroups

Labeling Tool Release Notes V2.0.9

8287: Extend LabelingTool to allow 'N/A' labeling for InvoiceCurrency

Labeling Tool Release Notes V2.0.8

7758 Added language switch. it's now possible to switch between german and englisch

7758 Improve Language selection of Labeling Tool (Keep active selection between different session, logins,....)

7875 Extend Labelling Tool to allow labelling of BankAccount, BankCode, ISR & Kid

Labeling Tool Release Notes V2.0.7

7664: Add 'DueDate' to LabellingTool (+ some minor EditView-refactorings)

Labeling Tool Release Notes V2.0.6

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Bludelta-Labeling-Tool-Release-Notes.md - Chunk 5
Labeling Tool Release Notes V2.0.7

7664: Add 'DueDate' to LabellingTool (+ some minor EditView-refactorings)

Labeling Tool Release Notes V2.0.6

7478: New bcidb connection string

7467: Some refactorings regarding the Currency type and I18N

Labeling Tool Release Notes V2.0.5

7399: The 3 new InvoiceLabelTypes for Stadt Wien can be labelled now

Labeling Tool Release Notes V2.0.4

7326: Rename label Type 'RkstLocation' to 'OerkLocation'

7341: Implement and activate an easier table labeling mode

Labeling Tool Release Notes V2.0.3

7293: Pressing the "Add Label" button in the Dashboard (from the Manual Release view) will now always lead to the correct view in the labeling tool, also when the user has to perform a login first.

7326: Integrate new label Type 'RkstLocation'

7339: Integrate the label types "SenderZipCode", "SenderCity", "ReceiverZipCode" & "ReceiverCity" into the Labeling Tool

7339: Refactor sender & receiver parts of the labeling tool view (HTML)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\BluDoc-Converter-Business-NuGet-Package-Release-Notes.md - Chunk 0
BluDoc NuGet Package Release Notes V2.0.2

2024-11-11

23212

DeliveryNote.Id and DeliveryNote.Date are mapped in LabelConverter

BluDoc NuGet Package Release Notes V2.0.1

2024-10-29

20888

22976

BluDoc NuGet Package Release Notes V1.0.21

2024-05-14

21151

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\BluDoc-NuGet-Package-Release-Notes.md - Chunk 0
BluDoc NuGet Package Release Notes V1.1.52

2024-10-25

22687

Validation added to check multiple values for document details

BluDoc NuGet Package Release Notes V1.1.47

2024-10-14

20888

Line Item details have been changed for Delivery Note

BluDoc NuGet Package Release Notes V1.1.46

2024-10-11

20888

BluDoc includes constants and factory method for DeliveryNote.

BluDoc NuGet Package Release Notes V1.1.45

2024-06-04

20582

BluDoc includes Document.Type for all document types and BluDoc factory can create BluDoc for any document type.

BluDoc NuGet Package Release Notes V1.1.44

2024-05-15

21105

BluDoc Normalize for Type Rate has been extended: values like 0.16000 are normalized as 16.0

BluDoc NuGet Package Release Notes V1.1.43

2024-04-30

20980

bug fixed

BluDoc NuGet Package Release Notes V1.1.42

2024-04-30

20838

additional contact types added to empty quotation

BluDoc NuGet Package Release Notes V1.1.40

2024-04-26

20790

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\BluDoc-NuGet-Package-Release-Notes.md - Chunk 1
20980

bug fixed

BluDoc NuGet Package Release Notes V1.1.42

2024-04-30

20838

additional contact types added to empty quotation

BluDoc NuGet Package Release Notes V1.1.40

2024-04-26

20790

Implement new Schema 1.4.0: - DocumentBinaries structure added

BluDoc NuGet Package Release Notes V1.1.36

2024-04-17

20811

Implement new Schema 1.3.1: - "Line required" was defined on wrong level in DocumentTexts schema.

BluDoc NuGet Package Release Notes V1.1.35

2024-04-16

19057

Implement new Schema 1.3.0: - DocumentEssentials not required any longer - DocumentTexts structure and its classes (Line, Word) added

BluDoc NuGet Package Release Notes V1.1.33

2024-04-11

19726

9218

add to BluDoc Factory: CreateReceipt() method to create empty Receipt

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Clustering.md - Chunk 0
Responsibility

Creates clusters for imported documents

Clustering

The imported documents are clustered in two ways - provider cluster - overall cluster and the result is stored in the BCI

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Data-Collection-Release-Notes.md - Chunk 0
Not maintainded any longer - check out Learn API Release Notes

DataCollection 0.6.16

02.08.2023

16702

Update connection strings to BciDb

Version of new images: - blumatixdevregistry.azurecr.io/folderbaseddatachannel:1.0.11 - blumatixdevregistry.azurecr.io/normalizer:1.0.58 - blumatixdevregistry.azurecr.io/documentimporter:1.0.8 - blumatixdevregistry.azurecr.io/label_creator:1.0.47 - blumatixdevregistry.azurecr.io/clustering:1.0.7 - blumatixdevregistry.azurecr.io/reporting:1.1.0

DataCollection 0.6.11

15.06.2023

16146

The Normalizer can handle "Dachser BluDoc" Format provided in the Learn API and convert it the current DataCollection BluDoc format. Therefore labels are created for Dachser in the Data Collection.

Version of new images: - blumatixdevregistry.azurecr.io/normalizer:1.0.56

DataCollection 0.6.10

13.06.2023

14878

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Data-Collection-Release-Notes.md - Chunk 1
Version of new images: - blumatixdevregistry.azurecr.io/normalizer:1.0.56

DataCollection 0.6.10

13.06.2023

14878

The DataCollection can handle the additional internal property "PropertyStore". This PropertyStore is part of the new Package class and so it is available in all components.

Version of new images: - blumatixdevregistry.azurecr.io/documentimporter:1.0.8 - blumatixdevregistry.azurecr.io/folderbaseddatachannel:1.0.11 - blumatixdevregistry.azurecr.io/normalizer:1.0.52 - blumatixdevregistry.azurecr.io/label_creator:1.0.46

DataCollection 0.6.9

09.05.2023

15846

15844

The Dachser Mapper has the capability to manage various delimiters in the ground truth file.

Version of new images: - blumatixdevregistry.azurecr.io/normalizer:1.0.51

DataCollection 0.6.8

03.05.2023

15495

The folder-based data channel can now handle the new package uploader format while still being backward compatible.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Data-Collection-Release-Notes.md - Chunk 2
DataCollection 0.6.8

03.05.2023

15495

The folder-based data channel can now handle the new package uploader format while still being backward compatible.

the Version of new images: - blumatixdevregistry.azurecr.io/folder_based_datachannel:1.0.10

DataCollection 0.6.7

28.04.2023

15709

15758

Resource Service URL in Label Creator is now provided by environment variable and is set differently for dev and production. Normalizer can handle unknown ground truth format without exception The cluster component can handle documents that failed to be imported Label Creator logging improved

the Version of new images: - blumatixdevregistry.azurecr.io/normalizer:1.0.49 - blumatixdevregistry.azurecr.io/label_creator:1.0.44 - blumatixdevregistry.azurecr.io/clustering:1.0.5

DataCollection 0.6.6

24.04.2023

15663

Provider with spaces are now processed correctly (folder-name) Document type and currency from RIPEye are processed correctly.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Data-Collection-Release-Notes.md - Chunk 3
DataCollection 0.6.6

24.04.2023

15663

Provider with spaces are now processed correctly (folder-name) Document type and currency from RIPEye are processed correctly.

the Version of new images: - blumatixdevregistry.azurecr.io/label_creator:1.0.40 - blumatixdevregistry.azurecr.io/folder_based_data_channel:1.0.9

DataCollection 0.6.5

12.04.2023

15462

DocumentType is not written correctly.

the Version of new images: - blumatixdevregistry.azurecr.io/label_creator:1.0.38

DataCollection 0.6.4

03.04.2023

15400

Non-valid packages are skipped.

the Version of new images: - blumatixdevregistry.azurecr.io/folder_based_data_channel:1.0.8

DataCollection 0.6.3

20.03.2023

15242

Missing DueDates threw an exception, and no bluDoc file was created. This has been fixed.

the Version of new images: - blumatixdevregistry.azurecr.io/normalizer:1.0.48

DataCollection 0.6.2

15.03.2023

15180

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Data-Collection-Release-Notes.md - Chunk 4
the Version of new images: - blumatixdevregistry.azurecr.io/normalizer:1.0.48

DataCollection 0.6.2

15.03.2023

15180

For structured data from Dachser, a new Label "DachserToDachser" is created out of DachserSenderId and DachserReceiverId details.

the Version of new images: - blumatixdevregistry.azurecr.io/label_creator:1.0.37 - blumatixdevregistry.azurecr.io/normalizer:1.0.47

DataCollection 0.6.1

09.02.2023

14739 showed that the data collection stops processing packages as soon as one package fails or already exists in our NAS DataCollection Folder (in the specific customer directory).

Update: If a package fails in the folder-based data channel, the package is skipped and deleted s.t. all the other packages can be further processed.

A most recent image of the folderBasedDataChannel application: - blumatixdevregistry.azurecr.io/folderbaseddatachannel:1.0.8 - blumatixdevregistry.azurecr.io/normalizer:1.0.46

DataCollection 0.5.0

13.1.2023

13976

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Data-Collection-Release-Notes.md - Chunk 5
DataCollection 0.5.0

13.1.2023

13976

Normalizer has been extended to handle ground truth provided in .csv files. Dachser Mapper has been extended to create Labels for ReceiverOrderId, SenderTaxNo, SenderVatId and DachserSenderId and DacherserReceiverId

Label Creator has been extended to get missing bounding boxes and original text from an invoice for structured data ground truth. Label Creator has been extended to get the original text from an invoice for RIPEye ground truth.

Version of components:

blumatixdevregistry.azurecr.io/folderbaseddatachannel:1.0.6

blumatixdevregistry.azurecr.io/normalizer:1.0.46

blumatixdevregistry.azurecr.io/documentimporter:1.0.5

blumatixdevregistry.azurecr.io/label_creator:1.0.35

blumatixdevregistry.azurecr.io/clustering:1.0.4

blumatixdevregistry.azurecr.io/reporting:1.1.0

DataCollection 0.0.4

30.12.2022 BluDoc Source information used in CreatedVia Label User fixed Bug fix: API Response with nullable properties is now process466

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Learn-API-Release-Notes.md - Chunk 0
Learn API 1.1.41

2024-12-17

Updated Components

Service/Config Version Workflow Definition 0.6.29 normalizer 1.0.126 label_creator 1.0.95

21940

23212

DeliveryNode.Id and DeliveryNote.Date were missing in the Label Converter.

Learn API 1.1.40

2024-10-29

Updated Components

Service/Config Version package_uploader 1.1.42 Workflow Definition 0.6.28 folderbaseddatachannel 1.0.37 normalizer 1.0.125 label_creator 1.0.94

20888

21650

Learn API 1.1.39

2024-09-11

Updated Components

Service/Config Version package_uploader 1.1.40

22288

new document type added: DangerousGoodsNoteTrunk

Learn API 1.1.38

2024-09-03

Updated Components

Service/Config Version Workflow Definition 0.6.27 clustering 1.0.22 document-importer 1.0.57 normalizer 1.0.115

11680

21436

21938

Learn API 1.1.37

2024-07-16

Updated Components

Service/Config Version package_uploader 1.1.39

Release Notes

21448

Add log warning for invalid request

Learn API 1.1.36

2024-06-25

Updated Components

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Learn-API-Release-Notes.md - Chunk 1
2024-07-16

Updated Components

Service/Config Version package_uploader 1.1.39

Release Notes

21448

Add log warning for invalid request

Learn API 1.1.36

2024-06-25

Updated Components

Service/Config Version Workflow Definition 0.6.26 folderbaseddatachannel 1.0.33 normalizer 1.0.114 label_creator 1.0.91 validator 1.0.38

Release Notes

21161

Learn API 1.1.35

2024-05-29

Updated Components

Service/Config Version Workflow Definition 0.6.25 clustering 1.0.17

Release Notes

21243

Learn API 1.1.34

2024-05-28

Updated Components

Service/Config Version Workflow Definition 0.6.24 package_uploader 1.1.38

Release Notes

21177

21184

Learn API 1.1.33

2024-05-25

Updated Components

Service/Config Version Workflow Definition 0.6.24 clustering 1.0.16

Release Notes

21243

Learn API 1.1.32

2024-05-23

Updated Components

Service/Config Version Workflow Definition 0.6.23 clustering 1.0.15

Release Notes

20499

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Learn-API-Release-Notes.md - Chunk 2
Release Notes

21243

Learn API 1.1.32

2024-05-23

Updated Components

Service/Config Version Workflow Definition 0.6.23 clustering 1.0.15

Release Notes

20499

Clustering component hat problems with documents that have failed during import. This bug has been fixed.

Workflow definition: Bots are now deleted after one hour (we had problems with too many "open file handlers"

Learn API 1.1.31

Updated Components

Service/Config Version Workflow Definition 0.6.22 normalizer 1.0.109 label_creator 1.0.90 documentimporter 1.0.56

Release Notes

20790

19057

BluDoc with new Schema 1.3.0, 1.3.1 and 1.4.0 are accepted for ground truth.

17187

Learn API 1.1.30

Updated Components

Service/Config Version Workflow Definition 0.6.21 normalizer 1.0.102 label_creator 1.0.87

Release Notes

19726

9218

Learn API 1.1.29

Updated Components

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Learn-API-Release-Notes.md - Chunk 3
Learn API 1.1.30

Updated Components

Service/Config Version Workflow Definition 0.6.21 normalizer 1.0.102 label_creator 1.0.87

Release Notes

19726

9218

Learn API 1.1.29

Updated Components

Service/Config Version Workflow Definition 0.6.20 packageuploader 1.1.36 folderbaseddatachannel 1.0.32 normalizer 1.0.101 label_creator 1.0.86 documentimporter 1.0.54 clustering 1.0.14

Release Notes

17184

Additional property for package uploading: 'Tags' enables to define a tag or list of tags associated with the package. The 'Tags' property allows to add descriptive keywords to the document package, enhancing searchability and organization. Input these as a comma-separated list in this optional field to help categorize your content more effectively.The package definition is now stored in the database.

19325

New doctypes valid for upload: CollectionOrder,ForwardingOrder,BillOfLading,ExportAccompanyingDocument,CRMConsignmentNote,TermsAndConditions

19811

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Learn-API-Release-Notes.md - Chunk 4
19325

New doctypes valid for upload: CollectionOrder,ForwardingOrder,BillOfLading,ExportAccompanyingDocument,CRMConsignmentNote,TermsAndConditions

19811

APIResponse Converter fixed to create BluDoc NotAvailables.

18817

To handle inconsistent Text/Value in DocumentEssentials, a check has been added and in case of inconsistency, the original Text and its location is searched on the document.

19905

Label Converter fixed to create DeliveryDate in Line Items.

19709

Label Converter fixed to create bounding boxes not just for line item details, but also for the line item itself.

18974

Label Converter fixed to handle Payment Discount and Due Date.

18372

18049

Label Converter fixed for Delivery Period and Delivery Date.

18052

Label Converter fixed to create line items.

Page Calculation has been added to Label Converter. Label-BluDoc is written to NAS with _label extension.

Learn API 1.1.28

Updated Components

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Learn-API-Release-Notes.md - Chunk 5
18052

Label Converter fixed to create line items.

Page Calculation has been added to Label Converter. Label-BluDoc is written to NAS with _label extension.

Learn API 1.1.28

Updated Components

Service/Config Version Workflow Definition 0.6.18 normalizer 1.0.82 label-creator 1.0.78

Release Notes

18230

Data Collection has been updated to handle new BluDoc 1.2.1 Ground Truth can be uploaded in BluDoc Schema 1.2.1; Migration for BluDoc 1.2.0 to 1.2.1 in BluDoc Converter

18288

Remove N/A line items (when mixed with existing ones) in label converter to fix benchmark compare for line items.

18052

Not available Contacts must be include not available items to be comparable in benchmark.

Learn API 1.1.27

Updated Components

Service/Config Version Workflow Definition 0.6.17 folder-based-datachannel 1.0.25 normalizer 1.0.72 document-importer 1.0.8 label-creator 1.0.77 clustering 1.0.7

Release Notes

15948

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Learn-API-Release-Notes.md - Chunk 6
Service/Config Version Workflow Definition 0.6.17 folder-based-datachannel 1.0.25 normalizer 1.0.72 document-importer 1.0.8 label-creator 1.0.77 clustering 1.0.7

Release Notes

15948

Ground Truth can be uploaded in BluDoc Schema 1.2.0 Ground Truth provided as BluDelta Service Response (e.g. from RIPEye) is now processed including the original text (so far, the original text has been searched on the document)

16611

The reason for this situation (VatGroup with many children because of missing location) has been fixed: those VatGroups are not created any longer

Internal

BluDoc 1.2.0 is used as standard format in the DataCollection

Normalizer converts all possible ground truth formats to BluDoc 1.2.0

All converters (API Response, Dachser BluDoc, Structured Data Mapping, Doc Generator BluDoc, DocumentType) no implement an interface and are organized in a nuget Package and can be used outside DataCollection

Label Creator has been refactored

Package Uploader 1.1.12

02.03.2023

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\DataCollection\Releases\Learn-API-Release-Notes.md - Chunk 7
Label Creator has been refactored

Package Uploader 1.1.12

02.03.2023

14909

Schnittstellenänderung: Document property renamed to Package

Die Online Doku wurde auf Redoc umgestellt und ihr könnt über folgenden link drauf zugreifen: https://learn.bludelta.ai/api-docs/index.html

Package Uploader 1.1.3

2.1.2023 Package size limit raised to 1 GB

Package Uploader 1.1.0

9.12.2022 DocumentTypes extended: - CreditMemo - VehicleRegistration - Order - CertificateOfOrigin - CustomsDutyReceipt - DangerousGoodsNote - TransitNoteT1 - TransitNoteT2 - ProformaInvoice - ExportAccompanyingDocument - DeliveryNoteCustoms - DeliveryNoteTransit

"Bescheid" was renamed to "Notice" 4680

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Extraction.md - Chunk 0
Goal

Extract relevant information from document with LLM (AI Agents)

Agent "Document Expert Customized"

Extract relevant details from document for given document type and given relevant document details

Input

Document (Image)

Document Type (e.g. Delivery Note)

For each relevant document detail -- Name of detail -- Description of detail -- Format / Datatype -- Structure

Task

"Find the expected details and return in structured format and explain why (what is the reason for it)"

Output

BluDoc representation of document und relevant details

Agent "Document Expert General"

Extract relevant details for any document type

Input

Document (Image)

Task

"What kind of document is it and return the relevant details in structured format and explain why (what is the reason for it)"

Output

BluDoc representation of document und relevant details

Agent "Normalizer"

see Normalizer

Agent "Visualizer"

Visualize (find location) for extracted info and its indicators and reason.

Input

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Extraction.md - Chunk 1
BluDoc representation of document und relevant details

Agent "Normalizer"

see Normalizer

Agent "Visualizer"

Visualize (find location) for extracted info and its indicators and reason.

Input

Document (Image)

Document info extracted and its reason (result of other agents)

Task

"Visualize the extracted info on the document (including reasoning)"

Output

Document including Locations of info extracted

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Local-LLM.md - Chunk 0
There are several possibilities to run a LLM locally:

Huggingface' Text-Generation-Inference

"Text Generation Inference (TGI) is a toolkit for deploying and serving Large Language Models (LLMs). TGI enables high-performance text generation for the most popular open-source LLMs, including Llama, Falcon, StarCoder, BLOOM, GPT-NeoX, and T5."

Docker:

Here is a docker example

```sh model=HuggingFaceH4/zephyr-7b-beta volume=$PWD/data # share a volume with the Docker container to avoid downloading weights every run

docker run --gpus all --shm-size 1g -p 8080:80 -v $volume:/data ghcr.io/huggingface/text-generation-inference:1.4 --model-id $model

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Local-LLM.md - Chunk 1
```

Text-Generation-Inference provides a REST endpoint and can be accessed as follows:

sh curl 127.0.0.1:8080/generate \ -X POST \ -d '{"inputs":"What is Deep Learning?","parameters":{"max_new_tokens":20}}' \ -H 'Content-Type: application/json'

Local Examples

Currently you can run models on rybuntu02 (192.168.137.80) and on aimebuntu01 (192.168.137.88) 1. download text generation inference docker image: 2. set environment variable sh export volume="$PWD/data" 2. run e.g. mistral: sh docker run --gpus all --shm-size=1g -p 8080:80 -v $volume:/data ghcr.io/huggingface/text-generation-inference:1.1.0 --model-id TheBloke/Mistral-7B-Instruct-v0.1-AWQ --quantize awq --max-input-length 4096 --max-total-tokens 8000

References: - Text-Generation-Inference - github

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Normalization.md - Chunk 0
Goal

Normalize given text (given datatypes and context) using LLM

Input

List of datatypes and their normalized format

This list provides the LLM the information of the way how datatypes should be normalized. This can be just a format information or some standardizing definition like ISO or an advice.

Data types list:

data type normalize definition samples date ISO 8601 YYYY-MM-DD 2024-03-27 amount decimal separator '.'; no group separator; two decimal digits -10234.50, 9.00 country ISO 3166-1 Alpha 2 DE ... ... ...

List of text to be normalized

This list contains all text that should be normalized, including it's datatype. e.g. predictions to be normalized

data type text to be normalized date 27.3. 2024 date 3rd of December, 2024 date 112.6.12 amount 123,- country Österreich ... ...

image of document

The image of the document provides necessary context, like language(s), countries, etc.

Output

List of normalized values (could be json)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Normalization.md - Chunk 1
image of document

The image of the document provides necessary context, like language(s), countries, etc.

Output

List of normalized values (could be json)

text value 27.3.2024 2024-03-27 3rd of December, 2024 2024-12-03 112.6.12 2024-06-12 Österreich AT ... ...

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Prompts.md - Chunk 0
Contacts:

``` Assistant, your primary and ONLY objective is to extract contact information from invoices and present it DIRECTLY in the specified JSON format.

Do NOT add any additional context, framing, or explanation. The output should be a JSON object and nothing else.

The exact structure of the desired JSON output is:

{{ "action": "Final Answer", "action_input": {{ "sender": {{ "name": "

Note: The fields

To guide you, here are two examples of previous interactions that were correctly handled:

User: Extract all contacts from the invoice and return them as a JSON object. Differentiate between invoice sender and receiver.

Invoice:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Prompts.md - Chunk 1
Invoice:

RECHNUNG Handelsagentur Fux DATUM: 25.03.2020 Rechnung Nr.: 1954746731 KUNDEN-ID: HVK1A Schwarzstraße 45 5020 Salzburg RECHNUNGSADRESSE LIEFERADRESSE Massimo Mustermann Match GmbH Bergheimerstraße 14 5020 Salzburg +436608553947 Rechnungsadresse Bestellnummer: 258934 Bestelldatum: 15.3.2020 Auftragsnummer: A1237B Auftragsdatum: 15.3.2020 BESCHREIBUNG Menge Steuersatz Preis (netto) Lieferdatum: 20.3.2020 Lieferscheinnummer: LS185 Steinway Konzert Flügel Weiß 1 20 % 499 000.00 € Dirigierstab Elfenbein 1 20 % 780.00 € Lieferdatum: 22.3.2020 Lieferscheinnummer: LS187 nVidia GPU M60 'Tesla' 4 20 % 28 560.00 € Mars Riegel 1000 10 % 800.00 € Gesamtbetrag netto 529 140.00 € 10 % 20 % Steuerbetrag 80.00 € 105 668.00 € 105 748.00 € Netto Betrag 800.00 € 528 340.00 € 529 140.00 € Summe brutto 880.00 € 634 008.00 € 634 888.00 € Zahlung: innerhalb von 10 Tagen 2 % Skonto 30 Tage netto Alle Zahlungen an Handelsagentur Fux

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Prompts.md - Chunk 2
Assistant: {{"action": "Final Answer", "action_input": {{ "sender": {{ "name": "Handelsagentur Fux", "address": "Schwarzstraße 45 5020 Salzburg", }}, "receiver": {{ "name": "Massimo Mustermann", "address": "Match GmbH, Bergheimerstraße 14, 5020 Salzburg" }} }} }}

User: Extract all contacts from the invoice and return them as a JSON object. Differentiate between invoice sender and receiver.

Invoice:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Prompts.md - Chunk 3
User: Extract all contacts from the invoice and return them as a JSON object. Differentiate between invoice sender and receiver.

Invoice:

Verwaltung und Braustätte Landgrabengasse 15-18 90321 Nürnberg Telefon 0911 2211-0 Telefax 0911 2211-111 enju.istiııer-Zrãu Ætrníerj Rechnung Abr Per : Tagesfaktura Angustiner Bitte bei Zahlung /Rückfrage angeben Datum Belegnr. Kundennr. Seite 28.02.2016 16616022803 56899865 1/1 Warenempfänger: 56899865 Angustiner-Bräu Nürnberg AG I Landgrabengasse 15-18 190321 Nürnberg An Sebastian Becker Ludwigstraße 83 91765 Nürnberg ART-NR BEZEICHNUNG / INHALT Menge HL/LTR Preis Betrag - EUR LIEFERUNG 512864812 vom 28.02.2016 Ab: Depot Roßtal 1820 Angustiner Kellerbier dunkel P-Keg .20 L 8 1,600 135,00 1.080,00 1252 Angustiner Lagerbier hell P-Keg .20 L 5 1,000 143,00 715,00 6200 Angustiner Spezi Mixgetränk 20/0,5 57 5,700 8,00 456,00 Summe Warenwert 2.251,00

Assistant:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Prompts.md - Chunk 4
Assistant:

{{"action": "Final Answer", "action_input": {{ "sender": {{ "name": "Angustiner-Bräu Nürnberg AG", "address": "Landgrabengasse 15-18, 90321 Nürnberg" }}, "receiver": {{ "name": "Sebastian Becker", "address": "Ludwigstraße 83, 91765 Nürnberg" }} }} }}

Process the invoice provided by the user and extract the necessary contact details. Remember to STRICTLY adhere to the aforementioned JSON structure and provide NO additional context or explanation.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Prompts.md - Chunk 5
```

LineItems

``` Assistant, your primary and ONLY objective is to extract line item details from invoices and present them DIRECTLY in the specified JSON format.

Do NOT add any additional context, framing, or explanation.
The output should be a JSON object and nothing else.

The exact structure of the desired JSON output is:

{{
    "action": "Final Answer",
    "action_input": {{
        "items": [
            {{
                "description": "<Item Description>",
                "quantity": "<Quantity>",
                "price": "<Price>"
            }},
        ]
    }}
}}

Note: The fields <Item Description>, <Quantity>, and <Price> are placeholders and should be replaced with the relevant details extracted from the invoice.

To guide you, here are two examples of previous interactions that were correctly handled:

User: Extract all line items from the invoice and return them as a JSON object.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Prompts.md - Chunk 6
To guide you, here are two examples of previous interactions that were correctly handled:

User: Extract all line items from the invoice and return them as a JSON object.

### Invoice:
RECHNUNG
Handelsagentur Fux
DATUM: 25.03.2020
Rechnung Nr.: 1954746731
KUNDEN-ID: HVK1A
Schwarzstraße 45 5020 Salzburg
RECHNUNGSADRESSE LIEFERADRESSE
Massimo Mustermann
Match GmbH
Bergheimerstraße 14
5020 Salzburg
+436608553947
Rechnungsadresse
Bestellnummer: 258934 Bestelldatum: 15.3.2020
Auftragsnummer: A1237B Auftragsdatum: 15.3.2020
BESCHREIBUNG
Menge Steuersatz Preis (netto)
Lieferdatum: 20.3.2020 Lieferscheinnummer: LS185
Steinway Konzert Flügel Weiß 1 20 % 499 000.00 €
Dirigierstab Elfenbein 1 20 % 780.00 €
Lieferdatum: 22.3.2020 Lieferscheinnummer: LS187
nVidia GPU M60 'Tesla'
4 20 % 28 560.00 €
Mars Riegel
1000 10 % 800.00 €
###

Assistant:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Prompts.md - Chunk 7
Assistant:

{{"action": "Final Answer",
    "action_input": {{
        "items": [
            {{
                "description": "Steinway Konzert Flügel Weiß",
                "quantity": "1",
                "price": "499 000.00 €"
            }},
            {{
                "description": "Dirigierstab Elfenbein",
                "quantity": "1",
                "price": "780.00 €"
            }},
            {{
                "description": "nVidia GPU M60 'Tesla'",
                "quantity": "4",
                "price": "28 560.00 €"
            }},
            {{
                "description": "Mars Riegel",
                "quantity": "1000",
                "price": "800.00 €"
            }}
        ]
    }}
}}

User: Extract all line items from the invoice and return them as a JSON object.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Prompts.md - Chunk 8
User: Extract all line items from the invoice and return them as a JSON object.

### Invoice:
Verwaltung
und Braustätte
Landgrabengasse 15-18
90321 Nürnberg
Rechnung
Abr Per : Tagesfaktura Angustiner
Datum Belegnr. Kundennr. Seite
28.02.2016 16616022803 56899865 1/1
Warenempfänger: 56899865
Angustiner-Bräu Nürnberg AG I Landgrabengasse 15-18 190321 Nürnberg
An
Sebastian Becker
Ludwigstraße 83
91765 Nürnberg
ART-NR BEZEICHNUNG / INHALT Menge HL/LTR Preis Betrag - EUR
LIEFERUNG 512864812 vom 28.02.2016 Ab: Depot Roßtal
1820 Angustiner Kellerbier dunkel P-Keg .20 L 8 1,600 135,00 1.080,00
1252 Angustiner Lagerbier hell P-Keg .20 L 5 1,000 143,00 715,00
6200 Angustiner Spezi Mixgetränk 20/0,5 57 5,700 8,00 456,00
###

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Prompts.md - Chunk 9
{{"action": "Final Answer",
    "action_input": {{
        "items": [
            {{
                "description": "Angustiner Kellerbier dunkel P-Keg",
                "quantity": "8",
                "price": "135,00"
            }},
            {{
                "description": "Angustiner Lagerbier hell P-Keg",
                "quantity": "5",
                "price": "143,00"
            }},
            {{
                "description": "Angustiner Spezi Mixgetränk 20/0,5",
                "quantity": "57",
                "price": "8,00"
            }}
        ]
    }}
}}

Process the invoice provided by the user and extract the necessary line item details.
Remember to STRICTLY adhere to the aforementioned JSON structure and provide NO additional context or explanation.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Prompts.md - Chunk 10
```

Address Parser

``` Assistant, your primary and ONLY objective is to extract detailed information from unstructured contact information, including type, name, and address. Present this information DIRECTLY in the specified JSON format.

Do NOT add any additional context, framing, or explanation. The output should be a JSON object and nothing else.

The exact structure of the desired JSON output is:

{{ "type": "

Note: The fields in angle brackets, such as

To guide you, here's a condensed example:

User: Extract all necessary details from the contact and return them as a JSON object.

Contact:

BergBau Ltd., Mozartgasse 4, 1040 Wien, Österreich

Assistant:

{{ "type": "Company", "name": "BergBau Ltd.", "address": "Mozartgasse 4, 1040 Wien, Österreich" }}

Process the contact provided by the user and extract the necessary details. Remember to STRICTLY adhere to the aforementioned JSON structure and provide NO additional context or explanation. ``` An improved version:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Prompts.md - Chunk 11
``` Assistant, your primary and ONLY objective is to extract detailed information from unstructured contact information, filtering out any unrelated words that do not pertain to the core contact details. The desired details include the type, name, and address of the contact. Present this information DIRECTLY in the specified JSON format.

Do NOT add any additional context, framing, or explanation. The output should be a JSON object and nothing else.

The exact structure of the desired JSON output is:

{{ "type": "

Note: The fields in angle brackets, such as

To guide you, here's a condensed example:

User: Extract all necessary details from the contact and return them as a JSON object.

Contact:

BergBau Ltd., Customer ID: AB12345 Mozartgasse 4, 1040 Wien, Österreich

Assistant:

{{ "type": "Company", "name": "BergBau Ltd.", "address": "Mozartgasse 4, 1040 Wien, Österreich" }}

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Prompts.md - Chunk 12
Contact:

BergBau Ltd., Customer ID: AB12345 Mozartgasse 4, 1040 Wien, Österreich

Assistant:

{{ "type": "Company", "name": "BergBau Ltd.", "address": "Mozartgasse 4, 1040 Wien, Österreich" }}

Process the contact provided by the user, filter out any unrelated details, and extract the necessary contact information. Remember to STRICTLY adhere to the aforementioned JSON structure and provide NO additional context or explanation.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Prompts.md - Chunk 13
```

Instruction Prompt:

User: Extract contact information from the given unstructured contact string and return them as a JSON object. {Content}

Fx Rates

``` SYSTEM PROMPT: ==============

Objective: Extract all Foreign Exchange (FX) Rates from an invoice document.

Instructions:

Identify Currency Information:

Locate any currency symbols (e.g., $, €, £) and currency codes (e.g., USD, EUR, GBP). Determine the base currency (currency in which the invoice is issued) and the target currency (currency to which the invoice will be converted). Locate FX Rates:

Look for sections or lines in the invoice that mention "Exchange Rate", "FX Rate", "Conversion Rate", "Rate of Exchange", or similar terms. FX rates might be presented as numerical values often accompanied by currency codes (e.g., 1 USD = 0.85 EUR). Read Surrounding Context:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Prompts.md - Chunk 14
Pay attention to the context around numerical values to ensure they represent FX rates and not other financial figures (e.g., total amount, tax rate). Common formats include: "1 [Base Currency] = [FX Rate] [Target Currency]" or simply "[FX Rate] [Target Currency] per 1 [Base Currency]". Extract and Validate:

Extract all FX rates ensuring they are correctly associated with the base and target currencies. Validate the extracted rates to ensure they fall within reasonable real-world values (e.g., between 0.5 and 2.0 for major currency pairs). Output the FX Rates:

Present all FX rates in the following JSON format: { "FxRates" : [ { "base_currency": "

Example:

Given the following text from an invoice:

Invoice Date: 2024-05-01 Total Amount: $1000 Exchange Rate: 1 USD = 0.85 EUR Special Rate: 1 GBP = 1.15 EUR Payment Terms: Net 30 days

The extracted FX Rates should be:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Prompts.md - Chunk 15
Invoice Date: 2024-05-01 Total Amount: $1000 Exchange Rate: 1 USD = 0.85 EUR Special Rate: 1 GBP = 1.15 EUR Payment Terms: Net 30 days

The extracted FX Rates should be:

{ "FxRates": [ { "base_currency": "USD", "target_currency": "EUR", "fx_rate": 0.85 }, { "base_currency": "GBP", "target_currency": "EUR", "fx_rate": 1.15 } ] }

Additional Notes:

If multiple FX rates are present, extract all relevant rates and specify their applicable sections if indicated. Handle variations in terminology and formatting that may differ across invoices.

Process the invoice provided by the user and extract the necessary contact details. Remember to STRICTLY adhere to the aforementioned JSON structure and provide NO additional context or explanation.

USER PROMPT:

Extract the FX rates from this invoice and provide it in JSON format. {Content}

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Prompts.md - Chunk 16
```

Orders

``` System Prompt: Extracting Order Details from Raw OCR Document

Objective: Extract all relevant order details from the provided raw OCR document. The extracted details should be returned in JSON format and include the following fields:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Prompts.md - Chunk 17
Objective: Extract all relevant order details from the provided raw OCR document. The extracted details should be returned in JSON format and include the following fields:

Order Number: The unique identifier for the order. Order Date: The date when the order was placed. Supplier Information: Supplier Name Supplier Address Supplier Contact Information (Phone, Fax, Email) Buyer Information: Buyer Name Buyer Address Buyer Contact Information (Phone, Fax, Email) Order Items: Item Number Item Description Quantity Ordered Unit Price Total Price for the Item Total Order Value: The total amount of the order before taxes. Delivery Information: Requested Delivery Date Delivery Address Special Delivery Instructions (if any) Payment Terms: The payment terms agreed upon for the order. Shipping Terms: The shipping terms specified for the order. Additional Notes or Comments: Any additional notes or special instructions related to the order. Format for Output:

json { "OrderNumber": "

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Prompts.md - Chunk 18
json { "OrderNumber": "3010552291", "OrderDate": "03.11.2021", "SupplierInformation": { "Name": "Innotec Automotive VertriebsgmbH", "Address": "Lofererstraße 83, 6322 Kirchbichl", "Contact": { "Phone": "0043/1/86 639 0", "Fax": "0043/1/869 70 88", "Email": "info@innotec.at" } }, "BuyerInformation": { "Name": "Birner GmbH", "Address": "Mühlgasse 91, 2380 Perchtoldsdorf", "Contact": { "Phone": "+43 1 79024 - 6550", "Fax": "+43 1 79024 - 6003", "Email": "Andreja.Stankovic@birner.at" } }, "OrderItems": [ { "ItemNumber": "105", "Description": "(Description not provided)", "Quantity": "12.00 Stück", "UnitPrice": "5.17 EUR", "TotalPrice": "62.04 EUR" }, { "ItemNumber": "1360-1", "Description": "Hi-Temp Wax - Spray - Dun", "Quantity": "8.00 Stück", "UnitPrice": "9.58 EUR", "TotalPrice": "76.64 EUR" }, { "ItemNumber": "1360", "Description": "Hi-Temp Wax - Spray - Tre", "Quantity": "4.00 Stück", "UnitPrice": "9.58 EUR", "TotalPrice": "38.32 EUR" }, { "ItemNumber": "1362", "Description":

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Prompts.md - Chunk 19
EUR" }, { "ItemNumber": "1360", "Description": "Hi-Temp Wax - Spray - Tre", "Quantity": "4.00 Stück", "UnitPrice": "9.58 EUR", "TotalPrice": "38.32 EUR" }, { "ItemNumber": "1362", "Description": "Hi-Temp Wax PRO dunkelbra", "Quantity": "44.00 Stück", "UnitPrice": "10.66 EUR", "TotalPrice": "469.04 EUR" }, { "ItemNumber": "1361", "Description": "Hi-Temp Wax PRO transpare", "Quantity": "4.00 Stück", "UnitPrice": "10.66 EUR", "TotalPrice": "42.64 EUR" }, { "ItemNumber": "1664-1", "Description": "Linen Tape Exterior (19 m)", "Quantity": "10.00 Stück", "UnitPrice": "5.43 EUR", "TotalPrice": "54.30 EUR" }, { "ItemNumber": "1360-2", "Description": "Hi-Temp Wax - Spray - Sch", "Quantity": "12.00 Stück", "UnitPrice": "9.50 EUR", "TotalPrice": "114.00 EUR" } ], "TotalOrderValue": "857.94 EUR (excl. tax)", "DeliveryInformation": { "RequestedDeliveryDate": "KW 45 / 2021", "DeliveryAddress": "Birner Linz", "SpecialInstructions": "N/A" }, "PaymentTerms": "Zahlbar 30 Tage 3% Skonto",

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Prompts.md - Chunk 20
EUR (excl. tax)", "DeliveryInformation": { "RequestedDeliveryDate": "KW 45 / 2021", "DeliveryAddress": "Birner Linz", "SpecialInstructions": "N/A" }, "PaymentTerms": "Zahlbar 30 Tage 3% Skonto", "ShippingTerms": "Lieferung lt. gültiger Konditionsvereinbarung", "AdditionalNotesOrComments": "N/A" } Instructions:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Prompts.md - Chunk 21
Parse the provided OCR document to identify and extract each of the fields listed above. Ensure that the extracted information is accurately represented in the specified JSON format. If any information is not available in the document, denote it as "N/A". ```

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Road-to-BluDelta-Production.md - Chunk 0
Missing Features

Location

Current LLM results don't have location information.

Solution: implement separate, general component to add location

Score

Current LLM results don't have score information. Scores as metrics directly from the model are not available in LLMS.

Solution: there are approaches to test some "uncertainty" of the model by requesting similar information multiple times. There are also approaches of text instead of numbers, but the principal problem is the same.

Usage Limits

Each model and usage plan has Usage limits. We have to check for the model we want to use.

Possible Limits: - Number of Requests / Time - Number of Tokens / Time - Size of Image

Note: Token calculation might differ from model to model

2024-10-02: using AzureGPT 4o -2024-05-13 we see a 4096 tokens limit for output (cutting our line items json). The gpt-4o-2024-08-06 has a limit of 16.384 tokens.

We need a mechanism to handle documents with many pages that do not fit the prompt limit!

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Road-to-BluDelta-Production.md - Chunk 1
We need a mechanism to handle documents with many pages that do not fit the prompt limit!

Pricing

Most plans are based on number of tokens.

Pricing Calculator

Performance

Current LLM is slower than current Service.

Solution: implement asynch calls

Prompt versioning

Prompts are similar like models in the past and have to be versioned together with models to be trackable.

Solution: Tool support

Policies

The usage of LLM models might be restricted (e.g. model scraping).

Compare e.g. https://learn.microsoft.com/en-us/legal/cognitive-services/openai/transparency-note?tabs=text#use-cases

Evaluate Models

We define two documents (e.g. one single pager and a multiple pager) and fill this table for each model evaluated:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\LLMs---Large-Language-Models\Road-to-BluDelta-Production.md - Chunk 2
Evaluate Models

We define two documents (e.g. one single pager and a multiple pager) and fill this table for each model evaluated:

Model Document Id Details Input Tokens Output Tokens Duration [msec] Price [US cent] Result gpt-4o-mini 2024-02-15-preview muster_rechnung_de-AT.pdf 96687 receipt 38630 235 4561 0.594 VatGroup 20% is wrong (total taken) gpt-4o 2024-02-01 muster_rechnung_de-AT.pdf 96687 receipt 2900 238 9305 0.963 correct

Reports

LLM for Line Items.pptx LLM LineItems Testserie.xlsx LLM Receipt Testserie.xlsx

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Training\Continuous-Training-Schedule.md - Chunk 0
We have scheduled runs for our machine learning continuous training pipelines:

Pipeline Name Scheduled Trigger Used GPUs ml-transport-ct Sunday 06:00 UTC 0 1 ml-order-confirmation-ct Sunday 18:00 UTC 0 1 ml-header-details-ct Monday at 18:00 UTC 0 1 2 3 ml-line-items-ct Tuesday at 18:00 UTC 0 1 2 3 ml-vat-groups-ct Wednesday at 18:00 UTC 0 1 2 3 ml-quotation Thursday at 06:00 UTC 0 1 ml-doc-type Thursday at 18:00 UTC 0 1 ml-dachser-asia-ct Friday at 18:00 UTC 0 ml-contact-ct Saturday at 06:00 UTC 0 1 ml-vat-tax-id-ct Saturday at 18:00 UTC 2 3

Configs: https://blumatix.visualstudio.com/Rechnungserkennung/_git/chargrid-pytorch.GitOps?path=/ml/config

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Training\Kubeflow-Pipelines.md - Chunk 0
Installation

The following shows how kubeflow pipelines can be installed via kubectl command. For further details please refer to Kubeflow-Pipelines

NOTE: Kubeflow installation shall be integrated into our k8s automation process.

```bash

/bin/bash

export PIPELINE_VERSION=1.7.0

export PIPELINE_VERSION=1.8.1

kubectl apply -k "github.com/kubeflow/pipelines/manifests/kustomize/cluster-scoped-resources?ref=$PIPELINE_VERSION" kubectl wait --for condition=established --timeout=60s crd/applications.app.k8s.io kubectl apply -k "github.com/kubeflow/pipelines/manifests/kustomize/env/platform-agnostic-pns?ref=$PIPELINE_VERSION" ```

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Training\Training-Data-Generation.md - Chunk 0
Training Data Generation in ML Workflow

Introduction

Training data generation is a critical process in machine learning (ML) workflow, enabling the creation of high-quality datasets used to train ML models. The training data generation process is executed in a pipeline and can run basically autonomous. However, the pipeline definition generation is structured like a workflow as well and can therefore be automated. This process incorporates continuous integration (CI), continuous deployment (CD), and versioning. By following this workflow, the team ensures that the training data are always up-to-date and generated using the latest data understanding and best practices.

Pipeline Architecture - CI/CD

CI-CD Pipeline

The CI-CD pipeline is responsible for automating the integration, testing, and deployment of training data generation code, as well as the generation of the pipeline definition. It consists of the following stages:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Training\Training-Data-Generation.md - Chunk 1
TrainingData CI Stage: This stage is triggered whenever new code is pushed to the main branch of a training data generation pipeline task. The CI pipeline checks out the code, sets up the Python environment, installs dependencies, runs unit tests, creates a new Docker image, and tags it with a new version if all tests pass.

Pipeline generation CI Stage: This stage is triggered whenever new code is pushed to the main branch of the pipeline definition generation. The CI pipeline checks out the code, sets up the Python environment, installs dependencies, runs unit tests, creates a new Docker image, and tags it with a new version if all tests pass.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Training\Training-Data-Generation.md - Chunk 2
DEV-CD Stage: In this stage, the new version of the Pipeline generation Docker image is loaded, and the build pipeline task is executed in dev mode and persisted into a repository. Afterwards, the upload pipeline task loads the pipeline definition into kubeflow, where the run pipeline task executes a pipeline run for the generated definition. Dev mode enables a fast run-through of all stages in the pipeline for all models (e.g., header-detail, line-item, vat-group, etc.). On successful completion, the new version is manually approved, and the PROD-CD stage is executed.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Training\Training-Data-Generation.md - Chunk 3
PROD-CD Stage: In this final stage, the new version of the Pipeline generation Docker image is loaded, and the build pipeline task is executed and persisted into a repository. Afterwards, the upload pipeline task loads the pipeline definition into kubeflow, where the run pipeline task creates a recurring run for the generated definition and disables all existing recurring runs for the given experiment. Dev mode is disabled for this stage.

Pipeline Architecture - CG (Continuous Generation)

The CG pipeline is composed of several containers executed sequentially, forming the TrainingData pipeline. Each container plays a specific role in the ML training process.

DocumentID Extraction The database is queried for the document IDs (label sources, generated label sources) and support document IDs. The IDs are written to a file and saved on the NAS.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Training\Training-Data-Generation.md - Chunk 4
DocumentID Extraction The database is queried for the document IDs (label sources, generated label sources) and support document IDs. The IDs are written to a file and saved on the NAS.

Trainingsdata Generation The file is loaded from the NAS and the IDs are extracted. The IDs are sent to the phoenix service, which generates the training data and saves it on the NAS.

Training Setup The training data is loaded from the NAS and an index file is built via extracting the information from the training data. The index file is saved on the NAS.

Trainingset Cleanup The index file is loaded from the NAS and cleaned - means, that every row corresponding to training data that doesn't contain labels is dropped from the trainingset.

Naming Conventions

Adhering to standardized naming conventions is crucial for smooth collaboration and easy identification of different versions. The versioning and tagging process is as follows:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Training\Training-Data-Generation.md - Chunk 5
Naming Conventions

Adhering to standardized naming conventions is crucial for smooth collaboration and easy identification of different versions. The versioning and tagging process is as follows:

The CI pipeline automatically tags the repository with a new version when all tests pass, and the code is merged into the main branch.

The versioning format follows the established Blumatix convention to maintain consistency.

The PROD-CD pipeline runs only when the DEV-CD pipeline succeeds, ensuring that training data is generated using the latest approved version of the code.

Release Notes

Release notes play a crucial role in maintaining a transparent and collaborative ML workflow. Each generation step is documented as a Method of Procedure (MOP), and release notes are written manually to provide detailed information about changes, improvements, and updates made during the process.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Training\Training-Data-Generation.md - Chunk 6
By establishing this ML Process, the team ensures continuous integration, continuous training, versioning, and release notes generation. This setup guarantees that ML models are always up-to-date, well-documented, and trained using the latest data, contributing to the overall success of the ML project.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Training\Training-Process.md - Chunk 0
Introduction

Training machine learning models has many similiarities to software development and also to software deployment processes. Here we want to define an "ML Training Process". This process ensures continuous integration, continuous training, versioning, and release notes generation. So that each step in the ML training is trackable and understandable. In what follows is an overview of the process.

Pipeline Architecture - CI/CD

CI-CD pipeline

CI Stage: Whenever new code is pushed to the main branch, the CI pipeline will be triggered. This pipeline is responsible for checking out the code, setting up the Python environment, installing dependencies, running unit tests, creating a new docker image and tagging the docker image with a new version if all tests pass. Additionally, the CI pipeline will trigger the DEV-CD stage.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Training\Training-Process.md - Chunk 1
DEV-CD Stage: Set the new version of of the docker image in the corresponding variable group and executes the training pipeline in dev mode. Dev mode means a fast-run through all stages in the pipeline and for all models, e.g. header-detail, line-item, vat-group etc.... On success, the new version will be manually approved (should be automatically in the future) and PROD-CD Stage will be executed.

PROD-CD Stage: New docker image will be transferred into our pro-registry. New version will be set in the corresponding variable group. The new docker image version will be used the next time the PROD-CT pipeline runs

Pipeline Architecture - CT

The CT pipeline consists of several container which are executed sequentially. Our typhon pipeline consists of the following container.

C4 Model

Naming Conventions

Versioning and Tagging:

The CI pipeline is responsible for tagging the repository with a new version whenever all tests pass and the code is merged into the main branch.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Training\Training-Process.md - Chunk 2
Naming Conventions

Versioning and Tagging:

The CI pipeline is responsible for tagging the repository with a new version whenever all tests pass and the code is merged into the main branch.

The versioning format should follow a our standard Blumatix convention which is already used in other pipeline, this will guarantee consistency and easy identification of different versions.

The prod CT pipeline runs only when a new tag is pushed, ensuring that the ML models are trained using the latest approved version of the code.

The team can control when to apply the new tag to the prod CT pipeline using the manual approval step in the dev CT pipeline.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Training\Training-Process.md - Chunk 3
The team can control when to apply the new tag to the prod CT pipeline using the manual approval step in the dev CT pipeline.

By following this ML workflow, we ensure that our ML code is continuously integrated, tested, and deployed. It also allows for better collaboration between the ML engineers and the product owner, as the process is transparent, and release notes are generated automatically. This setup ensures that our ML models are always up-to-date and trained using the latest data and best practices.

Release Notes

Write MOP for every training step

Release Notes - write them manually

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Triton---Model-Lifecycle\Load-Unload-Triton-Models.md - Chunk 0
Triton can be started with different model control strategies (polling or explicit). When running in EXPLICIT mode than triton will only load a new model into its context when an explicit request is sent to it - either via HTTP/REST request or over gRPC.

On Prod Triton is running in polling mode, thus must be restartet to load all new models and breaks if you just copy a new model into a directory. On Dev Triton is running in explicit mode. After a restart all models must be loaded explicitly via the following commands.

Get available model repositories

sh bash> curl -X POST http://192.168.137.78:8000/v2/repository/index json [ {"name":"contact_lines_classifier"}, {"name":"contact_ner"}, {"name":"delivery_period_bert_ner"}, {"name":"typhon_contacts"},{"name":"typhon_header_details","version":"1","state":"UNAVAILABLE","reason":"unloaded"}, {"name":"typhon_header_details","version":"2","state":"UNAVAILABLE","reason":"unloaded"}, {"name":"typhon_lineitems"} ]

Load model

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Triton---Model-Lifecycle\Load-Unload-Triton-Models.md - Chunk 1
Load model

Load them individually via the following script. Check the directory, that should be loaded (e.g. 1 or 2)

Note: If multiple triton instances are running in a cluster, the following request is only sent to one of the pods by the load balancer. This results in an inconsistency between pods

sh bash> curl -X POST http://192.168.137.78:8000/v2/repository/models/typhon_header_details/load -H 'Content-Type: application/json' -d '{file:2/model.onnx}'

sh bash> curl -X POST http://192.168.137.78:8000/v2/repository/index json [ {"name":"contact_lines_classifier"}, {"name":"contact_ner"}, {"name":"delivery_period_bert_ner"}, {"name":"typhon_contacts"},{"name":"typhon_header_details","version":"1","state":"READY"}, {"name":"typhon_header_details","version":"2","state":"READY"}, {"name":"typhon_lineitems"} ]

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\ML-Workflow\Triton---Model-Lifecycle\Load-Unload-Triton-Models.md - Chunk 2
This issue can be resolved by loading the models via script for all pods. The script lists all running triton pods and loops through each of them, forwarding the port to a local one. The list of models to load are accepted as command line arguments, with a space in between. If no arguments are provided, all available models are loaded: https://blumatix.visualstudio.com/Rechnungserkennung/_git/PyBlutils?path=/scripts/unload-load-all-triton-models.sh (Linux) https://blumatix.visualstudio.com/Rechnungserkennung/_git/PyBlutils?path=/scripts/unload-load-all-triton-models.ps1 (Windows) For windows users, the possibility exists that the port forwarding process isn't stopped. If that were to happen, edit the script to increase the port every iteration (exists in the script, as a comment)

Note: The scripts expect a valid connection to a kubernetes cluster.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure.md - Chunk 0
Azure Infrastructure

Resourcenpläne

Rechnungserkennung SME Demo-Website

Kosten

Übersicht letztes Monat und Forecast Production

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Cloud-Infrastructure-and-Deployment-Strategy.md - Chunk 0
Phase 1 = Prio 1 ==> Stabilize current Cloud Environments

Fix timeouts

Maybe we can save at least some of the invoices which lead to timeouts and/or errors? --> DSGVO?!

Most-probably (AGB-) junk-detection is required on production as soon as possible!!! => We could also add a customer-based mapping for junk-detection (= as a first step, activate only for diamant?) #8647

We need a response-cache (Redis-cache?) as soon as possible! --> We must not process the same document over and over again! (add an admin-only key to the request-PropertyStore to force processing for Health-Check-Invoice). => A blacklisting-feature for specific documents will not be required in that case

Protect from overload and DoS attacks

As soon as possible we need an option (API-Management) to protect us from too much load by single/specific customers (parallel execution limit per customer)

Secure AKS --> no more public access

Phase 2 = Prio 2 ==> Short-Term Deployment improvements

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Cloud-Infrastructure-and-Deployment-Strategy.md - Chunk 1
Secure AKS --> no more public access

Phase 2 = Prio 2 ==> Short-Term Deployment improvements

Only 1 active production environment in the cloud --> 2 environments during deployment transition period Api-Management to route one specific "friendly" customer to a newly deployed environment Simulation tool (phoenix-action?) needed --> Replay real production-scenarios via TelemtryData (12.jän 2022 / v1-16) -->

Place all python-containers in AKS --> As a first step towards 1 version in the Cloud we could use the latest python containers for all SDK-Versions (==cost-reduction / )

Keep the last version as a very much downscaled environment as option for a quick rollback

During the release, deploy the CaptureSdk & -Service to the staging slots too (seperate ServicePlans may be needed for seperate versions --> memory-demand)! If a hotfix is needed, we will be able to deploy the Hotfix to staging, do all tests on staging and then simply swap to production during a maintainance window

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Cloud-Infrastructure-and-Deployment-Strategy.md - Chunk 2
OCR as seperate service --> If feasible, we should use this task to create the basic components for , and use the new mechanism for the OCR-Service. Scaling rules based on queue (length, message idle-times, etc...)

Phase 3 = Prio 3 ==> Long-Term Deployment improvements

Everything on AKS Windows-nodes in AKS (definetly needed for OCR) and we should have already ported BLU DELTA Service to .Net 6 --> Linux!

Improved scaling mechanism everywhere in place Async communication between components via Input- and output-queues. Scaling rules based on queue (length, message idle-times, etc...)

Deploy single components (Microservices) via CI/CD-Pipelines at virtually any time The following 3 seperate environments are need: Dev --> Staging --> Production (Staging exactly matches Production)

The main process (with automatic validation, etc..) has to be set up

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\AGW.md - Chunk 0
AGW Public IP Address

AGW08: 108.143.152.149

AGW Subdomains

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\AGW.md - Chunk 1
Subdomain Backend Pool Destination api backend-pool-bludelta-capture-sdk-prod-weu-120, appGateBackendPool-metadata app-bludelta-capture-sdk-prod-weu-120.azurewebsites.net, white-wave-068be1c03.azurestaticapps.net api-dev backend-pool-bludelta-capture-sdk-dev-weu-01 app-bludelta-capture-sdk-dev-weu-01.azurewebsites.net api-qa backend-pool-bludelta-capture-sdk-qa-weu-120 app-bludelta-capture-sdk-prod-weu-120-staging.azurewebsites.net bludoc backend-pool-api-gateway-prod 20.31.141.176 bludoc-dev backend-pool-api-gateway-dev 20.76.180.81 bludoc-qa backend-pool-api-gateway-qa 20.101.2.233 capture backend-pool-api-gateway-prod 20.31.141.176 capture-dev backend-pool-api-gateway-dev 20.76.180.81 capture-qa backend-pool-api-gateway-qa 20.101.2.233 classification backend-pool-api-gateway-prod 20.31.141.176 classification-dev backend-pool-api-gateway-dev 20.76.180.81 classification-qa backend-pool-api-gateway-qa 20.101.2.233 devops backend-pool-api-gateway-prod 20.31.141.176 devops-dev

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\AGW.md - Chunk 2
20.31.141.176 classification-dev backend-pool-api-gateway-dev 20.76.180.81 classification-qa backend-pool-api-gateway-qa 20.101.2.233 devops backend-pool-api-gateway-prod 20.31.141.176 devops-dev backend-pool-api-gateway-dev 20.76.180.81 devops-qa backend-pool-api-gateway-qa 20.101.2.233 labelingtool labelingtoolBackendPool bludelta-labelingtool.azurewebsites.net learn backend-pool-api-gateway-prod 20.31.141.176 learn-dev backend-pool-api-gateway-dev 20.76.180.81 learn-qa backend-pool-api-gateway-qa 20.101.2.233 split backend-pool-api-gateway-prod 20.31.141.176 split-dev backend-pool-api-gateway-dev 20.76.180.81 split-qa backend-pool-api-gateway-qa 20.101.2.233 test backend-pool-trial-page-prod thankful-stone-05c6d3403.2.azurestaticapps.net trial backend-pool-trial-page-prod thankful-stone-05c6d3403.2.azurestaticapps.net trial-dev backend-pool-trial-page-dev orange-plant-0f1dd6103.1.azurestaticapps.net upload backend-pool-ingress-prod 104.45.79.166 upload-dev backend-pool-ingress-dev

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\AGW.md - Chunk 3
trial-dev backend-pool-trial-page-dev orange-plant-0f1dd6103.1.azurestaticapps.net upload backend-pool-ingress-prod 104.45.79.166 upload-dev backend-pool-ingress-dev 52.236.159.89 validation backend-pool-sme-frontend-prod app-sme-api-prod-weu-05.azurewebsites.net validation-dev backend-pool-sme-frontend-dev white-beach-03fa1ee03.1.azurestaticapps.net validation-qa backend-pool-sme-frontend-qa app-sme-api-prod-weu-05.azurewebsites.net validation-test backend-pool-sme-frontend-test app-sme-api-test-weu-04.azurewebsites.net

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Cloud-Costs.md - Chunk 0
Cost Prod Environment April 2024

Cost Dev Environment April 2024

Costs Total incl. Reservation since 1. Jan. 2024

Costs Prod Environment 04/2023 - 03/2024

Costs Dev Environment 03/2023 - 03/2024

Costs Total 03/2023 - 03/2024

VMs

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Cloud-Costs.md - Chunk 1
Cluster Type vCPUs RAM Pool Name Quantity Price per Unit Total Price 0 aks-bludelta-aks-dev-weu-03 Standard EC4as 4.0 32GB elasticpool 2 $200,02 $400,04 1 aks-bludelta-aks-dev-weu-03 Standard EC4as 4.0 32GB cpupool2 2 $200,02 $400,04 2 aks-bludelta-aks-dev-weu-03 NC4as_T4_v3 4.0 32GB ocrpool (easyocr) 1 $480,34 $480,34 3 aks-bludelta-aks-dev-weu-03 NC4as_T4_v3 4.0 32GB gpupool 1 $153,80 $153,80 4 aks-bludelta-aks-dev-weu-03 NC4as_T4_v3 4.0 32GB gpupool 1 $480,34 $480,34 5 aks-bludelta-aks-dev-weu-03 DS2_v2 4.0 32GB masterpool 2 $99,28 $198,56 6 aks-bludelta-aks-prod-weu-118 Standard EC4as 4.0 32GB elasticpool 2 $200,02 $400,04 7 aks-bludelta-aks-prod-weu-118 Standard EC4as 4.0 32GB cpupool2 4 $200,02 $800,08 8 aks-bludelta-aks-prod-weu-118 NC4as_T4_v3 4.0 32GB ocrpool (easyocr) 1 $480,34 $480,34 9 aks-bludelta-aks-prod-weu-118 NC4as_T4_v3 4.0 32GB gpupool reserviert 4 $307,16 $1.228,64 10 aks-bludelta-aks-prod-weu-118 DS2_v2 4.0 32GB masterpool 2 $99,28 $198,56 11

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Cloud-Costs.md - Chunk 2
(easyocr) 1 $480,34 $480,34 9 aks-bludelta-aks-prod-weu-118 NC4as_T4_v3 4.0 32GB gpupool reserviert 4 $307,16 $1.228,64 10 aks-bludelta-aks-prod-weu-118 DS2_v2 4.0 32GB masterpool 2 $99,28 $198,56 11 aks-bludelta-ocr-aks-dev-weu-01 DS2_v2 4.0 32GB masterpool 1 $99,28 $99,28 12 aks-bludelta-ocr-aks-dev-weu-01 Standard E4as_v5 NaN None winpool 1 $334,34 $334,34 13 aks-bludelta-ocr-aks-prod-weu-01 DS2_v2 4.0 32GB masterpool 2 $99,28 $198,56 14 aks-bludelta-ocr-aks-prod-weu-01 Standard E4as_v5 NaN None winpool 1 $334,34 $334,34 15 app-bludelta-capture-sdk-dev-weu-01 Premium v3 P2V3 4.0 16GB generic 2 $493,48 $986,96 16 app-bludelta-container-contact-dev-weu-01 Premium v3 P2V2 2.0 7GB generic 1 $168,63 $168,63 17 app-bludelta-container-contact-prod-weu-118 Premium v3 P2V3 4.0 16GB generic 2 $259,88 $519,76 18 plan-bludelta-capture-sdk-prod-weu-120 Premium v3 P2V3 4.0 16GB generic 2 - 12 $493,48 $986,96 - $5.927,52

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Cloud-Costs.md - Chunk 3
Costs savings OCR

Kosten Jänner 2022

Forecast (Production)

Der Forecast für Februar/März 2022 liegt bei 9.080,00 EUR für die Produktivumgebung.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Disaster-Recovery.md - Chunk 0
Disaster Recovery

[[TOC]]

Create an Azure Account

Navigate to the Azure website

To create an Azure account, perform the following steps: 1. Click Try Azure for free 1. Click Start free 1. Click Create one 1. Select your country or region. Then, enter your first name, last name, email address, and phone number. Click Next 1. Click either Text me or Call me to send a verification code to your phone 1. Once you have the code, enter it in the Verify code field 1. Enter company address information 1. Select the checkbox to agree to Azure’s customer agreement and privacy agreement. Click Next. Note: You must check this box to create an account 1. Enter our billing details. Click Sign up

To start using the new Azure account, click Go to Azure portal.

Create Prod and Dev subscriptions

Navigate to Subscriptions and then select Add.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Disaster-Recovery.md - Chunk 1
To start using the new Azure account, click Go to Azure portal.

Create Prod and Dev subscriptions

Navigate to Subscriptions and then select Add.

For Prod and Dev Subscription, perform the following steps respectively. 1. On the Create a subscription page, on the Basics tab, type a Subscription name. 1. Select the Billing account where the new subscription will get created. 1. Select the Billing profile where the subscription will get created.

Create AAD Groups

Navigate to the Azure Active Directory and select Groups.

Add the following Groups to the directory:

Name Description PortalAdmins Global administrators group SupportTeamMembers Support team group K8SContributors Kubernetes contributors group

Create AAD Users

Navigate to the Azure Active Directory and select Users.

Create the following users from the list and add them to the active directory groups.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Disaster-Recovery.md - Chunk 2
Create AAD Users

Navigate to the Azure Active Directory and select Users.

Create the following users from the list and add them to the active directory groups.

Name PortalAdmins SupportTeamMembers K8SContributors Amrit Bhogal yes Bernhard Wimmer yes Dominique Watzl yes Günter Schwaiger yes Hans-Peter Haberlandner yes Julian Lipp yes Philipp Grafendorfer yes yes Rudolf Dittrich yes

Enforce MFA for all Users

After creating the users above, click Per-User MFA on the Users blade and enforce Multi factor authentication for all.

Create databases and import backups

Take the backups (bacpac) files from the Backup Server (VMBMMGTBackup) and follow this tutorial: Restore Azure Sql Database

Granting Devops Pipelines Access to Subscriptions

Navigate to the Devops Portal, select the Rechnungserkennung projekt. Go to the Project Settings and select Service Connection. Filter the list to show only the Terraform connections.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Disaster-Recovery.md - Chunk 3
Navigate to the Devops Portal, select the Rechnungserkennung projekt. Go to the Project Settings and select Service Connection. Filter the list to show only the Terraform connections.

Edit the TerraformRMConnectionDev entry and change the settings to the new created Dev subscription.

Verify that the connection is established and save the changes.

Do the same for the TerraformRMConnectionProd.

If the service connections cannot be edited, delete them and create new ones with the same names.

Create a support request regarding the quotas of the GPU VMs

Navigate to the Help & support blade in the azure portal.

Click on Create a suppurt request and fill out the form.

Increase the quota for the vCPU NCasT4v3 Series to 32.

Create Prod and Dev Container Registries

Navigate to the Container Registry blade in the azure portal.

Create the two registries for our subscriptions.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Disaster-Recovery.md - Chunk 4
Create Prod and Dev Container Registries

Navigate to the Container Registry blade in the azure portal.

Create the two registries for our subscriptions.

Name Description blumatixdevregistry Container Registry for Dev subscription BlumatixReleaseRegistry Container Registry for the Prod subscription

As a last step import nginx v1.x into the registries.

Granting Devops Pipelines Access to the Container Registries

Navigate to the Devops Portal, select the Rechnungserkennung projekt. Go to the Project Settings and select Service Connection. Filter the list to show only the Terraform connections.

Edit the ACR-connection-dev entry and change the settings to the new created Dev subscription.

Verify that the connection is established and save the changes.

Do the same for the ACR-connection-prod.

If the service connections cannot be edited, delete them and create new ones with the same names.

Create Terraform State Storage Account and configure Devops Variable Group

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Disaster-Recovery.md - Chunk 5
If the service connections cannot be edited, delete them and create new ones with the same names.

Create Terraform State Storage Account and configure Devops Variable Group

Navigate to the Storage Account blade in the azure portal.

Create a new Storage Account for the Terraform remote backand (State) in a new resource group.

Navigate to the Devops Portal into the Rechnungserkennung project Libraries blade.

Select the tf-remote-backend variable group and set values to the newly created storage account.

Now the pipelines with the terraform scripts are able to run.

Create Virtual Network for Infrastructure

Navigate to the Pipeline blade of the Rechnungserkennung project und select the bludelta-vnet-tf-iac pipeline.

Run Infrustructure Pipelines

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Disaster-Recovery.md - Chunk 6
Create Virtual Network for Infrastructure

Navigate to the Pipeline blade of the Rechnungserkennung project und select the bludelta-vnet-tf-iac pipeline.

Run Infrustructure Pipelines

Name Description bludelta-agw-tf-iac Creates the application gateway plus firewall bludelta-aks-tf-iac Creates kubernetes cluster bludelta-redis-tf-iac Creates redis cache bludelta-capture-tf-iac Creates capture sdk and service webapps bludelta-container-tf-iac Creates container instances plan bludelta-interceptor-tf-iac Creates interceptor function app bludelta-trial-tf-iac Creates trial page static webapp bludelta-telemetry-tf-iac Creates telemetry function app bludelta-monitor-tf-iac Creates azure monitor workspace bludelta-stapp-tf-iac Creates metadata static webapp sme-invoices-clean-tf-iac Creates invoice cleaner function app sme-validation-tf-iac Creates SME frontend statatic webapp and backend webapp and function apps sme-monitor-tf-iac Creates Poison Queue monitoring function app

TBD

13040

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Disaster-Recovery.md - Chunk 7
TBD

13040

Copy Models to Storage Accounts

to be done

Configure AGW backenpools and DNS entries

In the BludeltaDeployment repo is the IaC\bludelta-agw\tf\terraform.tfvars file that holds the backend pool configuration. Check that all resources are correctly configured.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Disaster-Recovery.md - Chunk 8
In the BludeltaDeployment repo is the IaC\bludelta-agw\tf\terraform.tfvars file that holds the backend pool configuration. Check that all resources are correctly configured.

```js backend_address_pools = { appGateBackendPooltest = { fqdns = null } backend-pool-devops-stapp-prod = { fqdns = ["orange-dune-0063a6803.1.azurestaticapps.net"] } backend-pool-interceptor-dev = { fqdns = ["func-interceptor-dev-weu-01.azurewebsites.net"] } backend-pool-interceptor-prod = { fqdns = ["func-interceptor-prod-weu-01.azurewebsites.net"] } appGateBackendPool-v1-18 = { fqdns = ["app-bludelta-capture-sdk-prod-weu-119.azurewebsites.net"] } # api-dev.bludelta.ai backend-pool-bludelta-capture-sdk-dev-weu-01 = { fqdns = ["app-bludelta-capture-sdk-dev-weu-01.azurewebsites.net"] } # api-qa.bludelta.ai -> prod 119 backend-pool-bludelta-capture-sdk-qa-weu-119 = { fqdns = ["app-bludelta-capture-sdk-prod-weu-119-staging.azurewebsites.net"] }

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Disaster-Recovery.md - Chunk 9
### SME backend backend-pool-sme-api-dev = { fqdns = ["app-sme-api-dev-weu-01.azurewebsites.net"] } backend-pool-sme-api-qa = { fqdns = ["app-sme-api-qa-weu-01.azurewebsites.net"] #try out test environment before roleout } backend-pool-sme-api-test = { # fqdns = ["app-sme-api-test-weu-01.azurewebsites.net"] fqdns = ["app-sme-api-test-weu-02.azurewebsites.net"] } backend-pool-sme-api-prod = { # fqdns = ["app-sme-api-prod-weu-02.azurewebsites.net"] fqdns = ["app-sme-api-prod-weu-03.azurewebsites.net"] }

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Disaster-Recovery.md - Chunk 10
### SME frontend # todo: better fqdns name with instance number backend-pool-sme-frontend-dev = { fqdns = ["white-beach-03fa1ee03.1.azurestaticapps.net"] } backend-pool-sme-frontend-qa = { fqdns = ["icy-forest-0e590d703.1.azurestaticapps.net"] #try out qa environment before roleout } backend-pool-sme-frontend-test = { # fqdns = ["icy-stone-075cda003.1.azurestaticapps.net"] fqdns = ["calm-rock-005448d03.1.azurestaticapps.net"] } backend-pool-sme-frontend-prod = { # fqdns = ["victorious-wave-08bc99303.1.azurestaticapps.net"] #next fe fqdns = ["lemon-tree-0bf606f03.1.azurestaticapps.net"] #next fe

### Labelingtool labelingtoolBackendPool = { fqdns = ["bludelta-labelingtool.azurewebsites.net"] }

### Metadata bludelta api appGateBackendPool-metadata = { fqdns = ["white-wave-068be1c03.azurestaticapps.net"] }

### Learn backend-pool-learn-dev = { fqdns = ["40.68.145.176"] #todo ingress controller } }

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Disaster-Recovery.md - Chunk 11
```

Navigate to Pipeline blade, select the bludelta-agw-tf-iac pipeline and run it again.

After the pipeline succeeds go to the azure portal and select the application gateway blade.

Go to the resource group of the AGW and select the resource of the public ip address and copy the IP Address from the overview page.

Navigate to www.kasserver.com and login.

Select Domain blade.

At the right bottom click at DNS-Einstellungen and select bludelta.ai.

Change the A records for the following sub domains:

Name Current IP api 20.224.245.58 api-dev 20.224.245.58 api-qa 20.224.245.58 devops 20.224.245.58 labelingtool 20.224.245.58 learn 20.224.245.58 validation 20.224.245.58 validation-dev 20.224.245.58 validation-qa 20.224.245.58 validation-test 20.224.245.58

Test the created Services

to be done

Create Reservations for the GPU VMs

to be done

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Ingress.md - Chunk 0
Ingress

[[TOC]]

Provisioning is currently done manually. IP Address of ingeress controler can change. The use of DNS would be a much better solution.

Dev

Name: bludelta-ingress-release-ingress Namespace: bludelta Address: 52.236.159.89

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Ingress.md - Chunk 1
Route K8s Service:Port Container Namespace \api-gateway api-gateway:13667 api_gateway:1.0.0 bludelta \authentication authentication:13860 authentication:1.0.40 bludelta \bludocvalidation bludocvalidation:13910 bludocvalidation:1.0.21 bludoc \delivery-period-service delivery-period-ner:13501 delivery_period_ner_cpu:latest bludelta \doc-classifier doc-classifier:13888 doc_classifier:1.0.0 bludelta \doc-page-classifier doc-page-classifier:13895 doc_page_classifier:1.0.0 bludelta \doc-splitter doc-splitter:13885 doc_splitter:1.0.0 bludelta \doctype-service doctype-linux:13150 doctype_linux:latest bludelta ~~\easy-ocr~~ ~~easy-ocr:13887~~ ~~easy_ocr:1.0.4~~ ~~bludelta~~ \elasticsearch elasticsearch-master-hl:9200 elasticsearch:8.6.0-debian elasticsearch \meta-ocr meta-ocr:13886 meta-ocr:1.0.0 bludelta \order-confirmation order-confirmation:13889 order_confirmation:1.0.10 bludelta \package-uploader package-uploader:13800 package_uploader:1.1.4 data-collection \payment-condition-service

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Ingress.md - Chunk 2
bludelta \order-confirmation order-confirmation:13889 order_confirmation:1.0.10 bludelta \package-uploader package-uploader:13800 package_uploader:1.1.4 data-collection \payment-condition-service payment-condition-ner:13500 invoice_ner_linux:latest bludelta \post-processing post-processing:13880 post_processing:1.0.12 bludelta \qrcode-service qrcode-service:13800 qrcode_service:latest bludelta \quotation quotation:13891 quotation:1.0.4 bludelta \resource-service resource-service:13999 resource_service:latest bludelta \resource-uploader-service resource-uploader-service:13850 resource-uploader-service:1.0.35 bludelta \state-tracker state-tracker:13897 state-tracker:1.0.11 bludelta \typhon-contact typhon-contact:13601 typhon_contact:0.0.11 bludelta \typhon-contact-service typhon-contact-cpu:13600 typhon_contact_cpu:latest bludelta \typhon-dachser-asia typhon-dachser-asia:13750 typhon_doctype:1.2.3 bludelta ~~\typhon-doctype~~ ~~typhon-doctype:13151~~ ~~typhon_doctype:0.0.5~~

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Ingress.md - Chunk 3
typhon_contact_cpu:latest bludelta \typhon-dachser-asia typhon-dachser-asia:13750 typhon_doctype:1.2.3 bludelta ~~\typhon-doctype~~ ~~typhon-doctype:13151~~ ~~typhon_doctype:0.0.5~~ ~~bludelta~~ \typhon-header-details-service typhon-header-details:13700 typhon_header_details_cpu:latest bludelta \typhon-inference typhon-inference:13894 typhon_inference:   0.0.1 bludelta \typhon-lineitems-service typhon-line-item-cpu:13200 typhon_line_item_cpu:latest bludelta ~~\typhon-order-confirmation-service~~ ~~typhon-order-confirmation:13200~~ ~~typhon_order_confirmation:0.0.0~~ ~~bludelta~~ ~~\typhon-quotation~~ ~~typhon-quotation:13769~~ ~~typhon_quotations:   0.0.8~~ ~~bludelta~~ \typhon-transport typhon-transport:13894 typhon_transport:   0.0.1 bludelta \typhon-vat-groups-service typhon-vat-groups-service:13400 typhon_vat_groups:1.0.0 bludelta \typhon-vat-tax-id typhon-vat-tax-vat-id:13893 typhon_vat_tax_id:1.0.0 bludelta \whitelistsearch whitelistsearch:13890 whitelistsearch:1.0.8 bludelta

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Ingress.md - Chunk 4
typhon_vat_groups:1.0.0 bludelta \typhon-vat-tax-id typhon-vat-tax-vat-id:13893 typhon_vat_tax_id:1.0.0 bludelta \whitelistsearch whitelistsearch:13890 whitelistsearch:1.0.8 bludelta \workflow-server workflow-server:80 workflow_server:1.0.64 bludelta

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Ingress.md - Chunk 5
Prod

Name: bludelta-ingress-release-ingress Namespace: bludelta Address: 104.45.79.166

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Ingress.md - Chunk 6
Route K8s Service:Port Container Namespace \api-gateway api-gateway:13667 api_gateway:1.0.0 bludelta \authentication authentication:13860 authentication:1.0.40 bludelta \bludocvalidation bludocvalidation:13910 bludocvalidation:1.0.21 bludoc \delivery-period-service delivery-period-ner:13501 delivery_period_ner_cpu:latest bludelta \doc-classifier doc-classifier:13888 doc_classifier:1.0.0 bludelta \doc-page-classifier doc-page-classifier:13895 doc_page_classifier:1.0.0 bludelta \doc-splitter doc-splitter:13885 doc_splitter:1.0.0 bludelta \doctype-service doctype-linux:13150 doctype_linux:latest bludelta ~~\easy-ocr~~ ~~easy-ocr:13887~~ ~~easy_ocr:1.0.4~~ ~~bludelta~~ \elasticsearch elasticsearch-master-hl:9200 elasticsearch:8.6.0-debian elasticsearch \meta-ocr meta-ocr:13886 meta-ocr:1.0.0 bludelta \order-confirmation order-confirmation:13889 order_confirmation:1.0.10 bludelta \package-uploader package-uploader:13800 package_uploader:1.1.4 data-collection \payment-condition-service

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Ingress.md - Chunk 7
bludelta \order-confirmation order-confirmation:13889 order_confirmation:1.0.10 bludelta \package-uploader package-uploader:13800 package_uploader:1.1.4 data-collection \payment-condition-service payment-condition-ner:13500 invoice_ner_linux:latest bludelta \post-processing post-processing:13880 post_processing:1.0.12 bludelta \qrcode-service qrcode-service:13800 qrcode_service:latest bludelta \quotation quotation:13891 quotation:1.0.4 bludelta \resource-service resource-service:13999 resource_service:latest bludelta \resource-uploader-service resource-uploader-service:13850 resource-uploader-service:1.0.35 bludelta \state-tracker state-tracker:13897 state-tracker:1.0.11 bludelta \typhon-contact typhon-contact:13601 typhon_contact:0.0.11 bludelta \typhon-contact-service typhon-contact-cpu:13600 typhon_contact_cpu:latest bludelta \typhon-dachser-asia typhon-dachser-asia:13750 typhon_doctype:1.2.3 bludelta ~~\typhon-doctype~~ ~~typhon-doctype:13151~~ ~~typhon_doctype:0.0.5~~

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Ingress.md - Chunk 8
typhon_contact_cpu:latest bludelta \typhon-dachser-asia typhon-dachser-asia:13750 typhon_doctype:1.2.3 bludelta ~~\typhon-doctype~~ ~~typhon-doctype:13151~~ ~~typhon_doctype:0.0.5~~ ~~bludelta~~ \typhon-header-details-service typhon-header-details:13700 typhon_header_details_cpu:latest bludelta \typhon-inference typhon-inference:13894 typhon_inference:   0.0.1 bludelta \typhon-lineitems-service typhon-line-item-cpu:13200 typhon_line_item_cpu:latest bludelta ~~\typhon-order-confirmation-service~~ ~~typhon-order-confirmation:13200~~ ~~typhon_order_confirmation:0.0.0~~ ~~bludelta~~ ~~\typhon-quotation~~ ~~typhon-quotation:13769~~ ~~typhon_quotations:   0.0.8~~ ~~bludelta~~ \typhon-transport typhon-transport:1384 typhon_transport:   0.0.1 bludelta \typhon-vat-groups-service typhon-vat-groups-service:13400 typhon_vat_groups:1.0.0 bludelta \typhon-vat-tax-id typhon-vat-tax-vat-id:13893 typhon_vat_tax_id:1.0.0 bludelta \whitelistsearch whitelistsearch:13890 whitelistsearch:1.0.8 bludelta

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Ingress.md - Chunk 9
typhon_vat_groups:1.0.0 bludelta \typhon-vat-tax-id typhon-vat-tax-vat-id:13893 typhon_vat_tax_id:1.0.0 bludelta \whitelistsearch whitelistsearch:13890 whitelistsearch:1.0.8 bludelta \workflow-server workflow-server:80 workflow_server:1.0.64 bludelta

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Key-Vault.md - Chunk 0
Azure Key Vault:

Azure Key Vault is a cloud-based service offered by Microsoft Azure that allows to securely manage keys, secrets, certificates, and other sensitive information used in your applications. It serves as a central repository for storing and managing cryptographic keys and secrets, providing a secure and scalable solution to help protect an application's sensitive data. With Azure Key Vault, hardcoding secrets in the code can be avoided, reducing the risk of exposure, and maintaining better control over access to critical information.

Description:

Azure Key Vault offers several essential features, including:

Secrets Management: Secrets can be managed and stored such as passwords, connection strings, API keys, and other sensitive data in a centralized and secure manner. Secrets are stored encrypted and can be retrieved through secure REST APIs.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Key-Vault.md - Chunk 1
Key Management: Azure Key Vault allows to create, import, and manage cryptographic keys that are used for encryption, decryption, and signing purposes. This is crucial for protecting data at rest and in transit.

Certificate Management: SSL/TLS certificates and private keys can be managed, making it easier to secure applications and services that require secure communications.

Access Control: Key Vault provides granular access control and permissions management. It can be defined who can access specific keys, secrets, and certificates, which helps maintaining separation of duties and compliance.

Using Azure Key Vault with Python:

To use Azure Key Vault with Python, the Azure SDK for Python can be used. This SDK provides a convenient way to interact with Key Vault and perform operations such as creating secrets, retrieving secrets, and managing keys. The azure-keyvault-secrets package needs to be installed using pip:

bash pip install azure-keyvault-secrets

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Key-Vault.md - Chunk 2
bash pip install azure-keyvault-secrets

Then, the SDK can be used to authenticate and interact with Azure Key Vault in your Python code. Here's a basic example of how to retrieve a secret from Azure Key Vault:

```python from azure.identity import DefaultAzureCredential from azure.keyvault.secrets import SecretClient

Configure your Key Vault URL

vault_url = "https://your-key-vault-name.vault.azure.net/"

Create a SecretClient using DefaultAzureCredential

credential = DefaultAzureCredential() secret_client = SecretClient(vault_url=vault_url, credential=credential)

Retrieve a secret by name

secret_name = "your-secret-name" secret_value = secret_client.get_secret(secret_name).value

print(f"Secret Value: {secret_value}")

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Key-Vault.md - Chunk 3
```

Using Azure Key Vault with Kubeflow Pipelines (KFP):

When working with Kubeflow Pipelines (KFP), Azure Key Vault can be integrated to securely manage secrets and configuration data used by pipeline components. This helps avoid exposing sensitive information in your pipeline definitions. The Azure SDK for Python can be used within KFP pipeline components to retrieve secrets from Azure Key Vault. The TrainingData repository uses it to provide kubeflow containers with secrets during the runtime to prevent in-text password storage.

```python from kfp.azure import use_azure_secret

Create a kubeflow task

operation = ContainerOp( name="Pipeline task", image="containerregistry.azure.com/task-image:1.0.0", arguments=[ f'--config-name={config_name}', f'--config-path={config_path}', ] )

Provide the task with azure credentials

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Key-Vault.md - Chunk 4
Provide the task with azure credentials

secret_operation = operation.apply(use_azure_secret("azure_secret")) When instantiating an image from the pipeline definition, the container expects different environment variables from a secret in its kubernetes environment. These can be set with the following command:shell kubectl create secret generic azure_secret \ --from-literal=AZ_SUBSCRIPTION_ID=

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\MISC.md - Chunk 0
Diagnosing commands:

WAF:

AzureDiagnostics | where ResourceProvider == "MICROSOFT.NETWORK" and Category == "ApplicationGatewayFirewallLog" and requestUri_s == "/doc-splitter/v1/doc-splitter"

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Monitoring-Logging.md - Chunk 0
Grafana

Grafana is a data visualization and monitoring platform that helps users analyze and understand complex data through interactive and customizable dashboards.

Loki is a log aggregation system designed to help users collect, store, and explore logs from various sources. It focuses on searching and analyzing log data efficiently, enabling users to troubleshoot and monitor their systems effectively.

Grafana documentation: https://grafana.com/docs/grafana/latest/ Loki documentation: https://grafana.com/docs/loki/

DEV Cluster

Login

PROD Cluster

Login

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\OpenAPI-Specifications.md - Chunk 0
OpenAPI Specifications

The following APIs offer OpenAPI Specification

Metadata Page

API Url Invoic Detect API https://api.bludelta.ai/v1-18/metadata

Swagger

API Url Order Confirmation API https://capture.bludelta.ai/order-confirmation/swagger Quotation API https://capture.bludelta.ai/quotation/swagger Receipt API https://capture.bludelta.ai/receipt/swagger Doc Classifier API https://classification.bludelta.ai/doc-classifier/swagger

Api-Docs

API Url Order Confirmation API https://capture.bludelta.ai/order-confirmation/api-docs Quotation API https://capture.bludelta.ai/quotation/api-docs Receipt API https://capture.bludelta.ai/receipt/api-docs Doc Classifier API https://classification.bludelta.ai/doc-classifier/api-docs

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Security-States.md - Chunk 0
Resource Security-Topic/Feature State Date of state Description/History bcdbserver/ bcsdb-auth TDE (Transparent Data Encryption) Enabled 10.09.2024 Was disabled before 10.09.2024 / We do not see a high risc here - communication is behind firewall bcdbserver/ bcsdb-bi TDE Disabled 10.09.2024 We have to decide if this shall be enabled / We do not see a high risc here - communication is behind firewall / DB-Size is huge and close to limit bcdbserver/ bcsdb TDE Disabled 10.09.2024 We have to decide what we do with this DB --> I think this DB is deleteable - holds only old telemetry-data bcdbserver/ bcsdb-sme-v1.0 TDE Enabled 10.09.2024 Was already enabled since (?) bcdbserver/ smedb-v1.0 TDE Enabled 10.09.2024 Was already enabled since (?)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Services.md - Chunk 0
Services

[[TOC]]

Authentication Service

Value Comment K8S Name authentication Repo Authentication, Authentication.GitOps Container authentication:1.0.41 Container ENV - Container Port 13860 Service Port 13860 Dependencies - Referenced by Package Uploader, Resource-Uploader, CaptureSDK, Doc Splitter Requires GPU NO CPU ?? MEM ?? Replicas 2 Workers - Dynamic Config - Model - Pipeline authentication-ci authentication-cd Ingress Uri \authentication ## Delivery Period ### Todo - [ ] Version numbering

Doc Classifier

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Services.md - Chunk 1
Doc Classifier

Value Comment K8S Name doc-classifier Repos DocClassifier DocClassifier.GitOps Container doc_classifier Container ENV TRITON_MODEL_VERSION, TRITON_URL, TRITON_MODEL_NAME Container Port 13888 Service Port 13888 Dependencies none Referenced by CaptureSdk Requires GPU - CPU - MEM 350Mi/800Mi Replicas 2 Workers - Dynamic Config no Model doc-classifier Pipelines doc-classifier-cd doc-classifier-ci Variable Group doc-classifier-config Ingress Uri /doc-classifier Description Provides class prediction "Korean", "Standard" for CaptureSdk to know which workflow rout to use.

Doc Splitter

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Services.md - Chunk 2
Doc Splitter

Value Comment K8S Name doc-splitter Repos DocSplitting DocSplitting.GitOps Container doc_splitter Container ENV AUTHENTICATION_URL, TRITON_MODEL_VERSION, TRITON_URL, TRITON_MODEL_NAME Container Port 13885 Service Port 13885 Dependencies authentication Referenced by - Requires GPU - CPU 125m/250m MEM 125Mi/250Mi Replicas 2 Workers - Dynamic Config - Model doc-splitter Pipelines doc-splitter-ci doc-splitter-cd Variable Group doc-splitter-config-dev doc-splitter-config prod Ingress Uri /doc-splitter Description Provides ....

Doctype

Todo

[ ] Doctype or Doc Type

[ ] Version numbering

Elastic Importer

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Services.md - Chunk 3
Doctype

Todo

[ ] Doctype or Doc Type

[ ] Version numbering

Elastic Importer

Value Comment K8S Name elastic-importer Repo Elasticsearch Elasticsearch.GitOps Container elasticimporter Container ENV ElasticSearchUrl, blobUri, sasToken, AzureWebJobsStorage Container Port 80 Service Port 13997 Dependencies FileShares, Azure WebJob Storage Referenced by - Requires GPU no CPU 1 MEM 1.4Gi (not set yet) Replicas 1 Workers - Dynamic Config - Model - Pipeline elastic-importer-ci elastic-importer-cd Ingress Uri - Variable Group elastic-importer-config-dev elastic-importer-config-prod Description Azure function that imports uploaded customer files

Elasticsearch

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Services.md - Chunk 4
Elasticsearch

Meaning Comment K8S Name Elasticsearch Repo Elasticsearch.GitOps Container elasticsearch, coordinating-hl, data-hl, ingest-hl, master-hl, kibana Container ENV - Container Port 9200 Service Port 9200 Dependencies Fileshare Referenced by - Requires GPU no CPU ? MEM ? Replicas 2 Workers - Dynamic Config - Model - Pipeline elasticsearch-cd Variable Group - Ingress Uri /elasticsearch Description Elasticsearch Environment - Helm Chart from Milos

Payment Condition

Todo

[ ] Version numbering

Post Processing

Value Comment K8S Name post-processing Repos PostProcessing PostProcessing.GitOps Container post_processing Container ENV - Container Port 13880 Service Port 13880 Dependencies elasticsearch Referenced by CaptureSDK Requires GPU no CPU ? MEM ? Replicas 2 Workers - Dynamic Config - Model - Pipelines Ingress Uri /post-processing Description Provides ....

QRCode Service

Todo Description of service

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Services.md - Chunk 5
QRCode Service

Todo Description of service

Value Comment K8S Name qrcode-service Repo QRCode Container qrcode_service:latest qrcode_service:1.0.72 Container ENV - Container Port 80 Service Port 13800 Dependencies - Referenced by CaptureSDK Prod CaptureSDK Prod.Staging CaptureSDK Dev CaptureSDK Dev.Staging Configured manualy in CaptureSDK Dev in azure portal. Rest is configured by variable group in cicd pipeline Requires GPU NO CPU ?? MEM ?? Replicas 2 Workers - Dynamic Config YES Model - Pipeline Ingress Uri \qrcode-service

Resource Service

Todo Description of service

Value Comment K8S Name resource-service Repo BlumatixI18N Container resource_service:latest resource_service:1.0.30 Container ENV - Container Port 13999 Service Port 13999 Dependencies - Referenced by Doc Type Typhon Contact Requires GPU NO CPU ?? MEM ?? Replicas 2 Workers - Dynamic Config - Model - Pipeline resource-service-cicd Ingress Uri \resource-service

Typhon Contact

Todo

[ ] Version numbering

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Services.md - Chunk 6
Typhon Contact

Todo

[ ] Version numbering

Typhon Dachser Asia

tbd

Typhon Doctype

Value Comment K8S Name typhon-doctype Repos chargrid-pytorch chargrid-pytorch.GitOps Container typhon_doctype Container ENV Container Port 13151 Service Port 13151 Dependencies Referenced by CaptureSDK Requires GPU no CPU ? MEM ? Replicas 2 Workers - Dynamic Config yes Model Pipelines typhon-doctype-ci typhon-doctype-cd Variable Group typhon-doctype-model-config Ingress Uri /typhon-doctype Description Provides Logistic document classification for dachser. https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/892/Dachser-Classification-and-Splitting

Typhon Header Details

Typhon Line Item

Todo

[ ] Name Singular/Plural Line Item or Lineitem

[ ] Version numbering

Typhon Vat Groups

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Services.md - Chunk 7
Typhon Header Details

Typhon Line Item

Todo

[ ] Name Singular/Plural Line Item or Lineitem

[ ] Version numbering

Typhon Vat Groups

Meaning Comment K8S Name typhon-vat-groups-service Repo chargrid-pytorch Container typhon_vat_groups Container ENV - Container Port 13400 Service Port 13400 Dependencies none Referenced by CaptureSDK Requires GPU no CPU none MEM none Replicas 1 Workers 1 Dynamic Config true Model triton_vat_group Pipeline https://blumatix.visualstudio.com/Rechnungserkennung/_build?definitionId=247 Ingress Uri /typhon-vat-groups-service Description provides vat group predictions (old interface)

WhitelistSearch

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Services.md - Chunk 8
WhitelistSearch

Value Comment K8S Name whitelistsearch Repos WhiteListSearch (Rechnungserkennung) , WhiteListSearch.GitOps Container whitelistsearch Container ENV - Container Port 13890 Service Port 13890 Dependencies none Referenced by CaptureSDK Requires GPU no CPU ? MEM ? Replicas 2 Workers - Dynamic Config - Model - Pipelines whitelist-search-ci , whitelist-search-cd Ingress Uri /whitelistsearch Description Provides Groups of values and the corresponding hints that were found via a whitelist search on the document

Package Uploader

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Services.md - Chunk 9
Package Uploader

Meaning Comment K8S Name PackageUploader Repo DataMining DataMining.GitOps Container package_uploader Container ENV - Container Port 13800 Service Port 13800 Dependencies authentication Referenced by Internal tool (Amrit) Requires GPU no CPU ? MEM ? Replicas 2 Workers - Dynamic Config - Model - Pipeline package-uploader-ci package-uploader-cd Variable Group package-uploader-config-dev package-uploader-config-prod Ingress Uri /package-uploader Description

Resource Uploader

Meaning Comment K8S Name Resource Uploader Repo ResourceUploader ResourceUploader.GitOps Container resource_uploader Container ENV - Container Port 13850 Service Port 13850 Dependencies Fileshare Referenced by - Requires GPU no CPU ? MEM ? Replicas 2 Workers - Dynamic Config - Model - Pipeline resource-uploader-ci resource-uploader-ci Variable Group - Ingress Uri /resource-uploader-service Description

Azure Storage

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Services.md - Chunk 10
Azure Storage

Uploaded Files will be stored in Azure File share. |Environment| Azure Storage| File Share Name| |---|---|---| |Dev|bminvoicestore |test-import| |Prod | bmresources | import|

Capture SDK

Capture Service

Labelingtool

Interceptor

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\ArgoCD\Integrating-a-new-service-into-ArgoCD---Step-by-step-instructions.md - Chunk 0
Integrating a new service into ArgoCD - Step by step instructions

Step 1 - Add the service gitops repo to the repos list

In the ArgoCD repo there is the file /scripts/add-repos.ps1 into which the Git repo of the new service must be added.

```powershell

scripts/add-repos.ps1

$repos = @( "ArgoCD", "Authentication.GitOps", "BludeltaEntityRecognition.GitOps", "BludeltaWorkflow.GitOps", "BlumatixI18N.GitOps", "chargrid-pytorch.GitOps", "DataMining.GitOps" "DocClassifier.GitOps", "DocSplitting.GitOps", "DocTypeModel.GitOps", "EasyOcr.GitOps", "MetaOcr.GitOps", "NamedEntityRecognition.GitOps", "OrderConfirmation.GitOps", "PostProcessing.GitOps", "QRCode.GitOps", "Quotation.GitOps", "ResourceUploader.GitOps", "WhiteListSearch.GitOps", "BluDocValidation.GitOps", "TyphonInference.GitOps", //--> add Repo with values files "DocPageClassifier.GitOps" )

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\ArgoCD\Integrating-a-new-service-into-ArgoCD---Step-by-step-instructions.md - Chunk 1
```

Step 2 - Configure ingress

Ingress files there is one for each namespace. Here are the relevant ones for bludelta. Each environment defines its own yaml file.

envs/dev/values/ingress-bludelta.yaml envs/prod/values/ingress-bludelta.yaml envs/wa/values/ingress-bludelta.yaml

```json ingress: annotations: nginx.ingress.kubernetes.io/ssl-redirect: "false" nginx.ingress.kubernetes.io/use-regex: "true" nginx.ingress.kubernetes.io/rewrite-target: /$2 nginx.ingress.kubernetes.io/proxy-read-timeout: "230" nginx.ingress.kubernetes.io/proxy-send-timeout: "230" routes: - path: /resource-service(/|$)(.*) pathType: Prefix serviceName: resource-service portNumber: 13999

...

path: /typhon-inference(/|$)(.*)
  pathType: Prefix
  serviceName: typhon-inference
  portNumber: 13892

// Add new ingress at the end
- path: /doc-page-classifier(/|$)(.*)
  pathType: Prefix
  serviceName: doc-page-classifier
  portNumber: 13895

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\ArgoCD\Integrating-a-new-service-into-ArgoCD---Step-by-step-instructions.md - Chunk 2
```

Step 3 - Add template for app of apps

Each namespace has its own app of apps. The definitions of the individual sub-apps are in the template folder. For bludelta it is in this directory

envs/dev/bludelta-app/templates envs/prod/bludelta-app/templates envs/qa/bludelta-app/templates

Each directory contains the Yaml file doc-page-classifier.yaml with the definition of the new service. Within the file it is important that the correct envs are referenced.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\ArgoCD\Integrating-a-new-service-into-ArgoCD---Step-by-step-instructions.md - Chunk 3
Each directory contains the Yaml file doc-page-classifier.yaml with the definition of the new service. Within the file it is important that the correct envs are referenced.

json apiVersion: argoproj.io/v1alpha1 kind: Application metadata: name: doc-page-classifier namespace: argocd finalizers: - resources-finalizer.argocd.argoproj.io spec: project: default source: repoURL: https://blumatix.visualstudio.com/DefaultCollection/Rechnungserkennung/_git/DocPageClassifier.GitOps path: manifest/doc-page-classifier/ targetRevision: HEAD helm: valueFiles: - ../../envs/dev/values/doc-page-classifier.yaml destination: server: https://kubernetes.default.svc namespace: bludelta syncPolicy: automated: selfHeal: true

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Deployments\Interceptor.md - Chunk 0
Deployed infrastructure

Infrastructure pipeline

CICD pipeline

Configuration (Library > bludelta-interceptor-config-prod)

AssemblyQualifiedNameSourceType Blumatix.Capture.ApiResponse.Mapper.V1_14.DetectInvoiceResponseV1_14,
  Blumatix.Capture.ApiResponse.Mapper, Version=1.0.0.0, Culture=neutral,
  PublicKeyToken=null AssemblyQualifiedNameTargetType Blumatix.Capture.ApiResponse.Mapper.V1_11.DetectInvoiceResponseV1_11,
  Blumatix.Capture.ApiResponse.Mapper, Version=1.0.0.0, Culture=neutral,
  PublicKeyToken=null AzureConnection TerraformRMConnectionProd RequestTimeoutSeconds 240 RetryCount 3 TargetUrl https://api.bludelta.ai/v1-18/invoicedetail/detect

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Deployments\Pipeline-Variable-Groups.md - Chunk 0
Pipeline Variable Groups

cicd-pipeline-config-prod

Variable Value Comment acr-url blumatixreleaseregistry.azurecr.io Url to release azure container registry instance azure-connection TerraformRMConnectionProd Service connection to productiv subscription

cicd-pipeline-config-dev

Variable Value Comment acr-url blumatixdevregistry.azurecr.io Url to development azure container registry instance azure-connection TerraformRMConnectionDev Service connection to productiv subscription

cicd-pipeline-common-config

Variable Value Comment acr-connection-dev ACR-connection-dev Service connection to development azure container registry instance acr-connection-prod ACR-connection-prod Service connection to production azure container registry instance

git-config

Variable Value Comment git-access-token * * The access token for the repos

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\HealthChecker\ApiHealthChecker.md - Chunk 0
ApiHealthChecker Documentation

Monitoring Workflow Server

For each productive workflow, the ApiHealthChecker services have a background task that periodically, every 5 minutes, sends a request to the configured workflow. This request simulates a customer call, traversing through the AppGateway and WAF. A successful call increments a counter (metric), which the respective alerts are based on.

HealthChecker Workflow Metric Alert OrderConfirmationHealthChecker Order Confirmation OrderConfirmationCount OrderConfirmationFailed DocSplitterHealthChecker Doc Splitter DocSplitterCount DocSplitterFailed DocSplitterAsyncHealthChecker Doc Splitter Async DocSplitterAsyncCount DocSplitterAsyncFailed OrderConfirmationHealthChecker Order Confirmation OrderConfirmationCount OrderConfirmationFailed QuotationHealthChecker Quotation QuotationCount QuotationFailed ReceiptHealthChecker Receipt ReceiptCount ReceiptFailed XInvoiceHealthChecker X-Invoice XInvoiceCount XInvoiceFailed

AppInsights

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\HealthChecker\ApiHealthChecker.md - Chunk 1
AppInsights

AppInsight bludelta-otel PROD

The collected metrics are sent to AppInsights (appi-bludelta-otel-prod-weu-01). These metrics are monitored by alerts scripted with Terraform. Every minute, it checks if the counter has been increased at least twice in the last 15 minutes. If this alert rule is breached, an email is sent to the BluDelta Support.

Support Team Actions When an Alert is Triggered

AppInsights - Alerts Overview

There are several potential reasons why one or more HealthChecker alerts might be triggered. The most common reasons are:

The ApiHealthChecker has an issue.

The WorkflowServer has an issue.

A component called by the WorkflowServer has an issue.

Steps to Take:

Send a Document to the Workflow Server and Check the Result:

If an error message is returned:

502, 504: WorkflowServer is unreachable.

500: WorkflowServer has a problem.

If an incomplete or incorrect result is returned:

Analyze the error in AppInsights.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\HealthChecker\ApiHealthChecker.md - Chunk 2
If an error message is returned:

502, 504: WorkflowServer is unreachable.

500: WorkflowServer has a problem.

If an incomplete or incorrect result is returned:

Analyze the error in AppInsights.

If the expected result is returned:

Check in AppInsights if fewer than 36 calls were made in the last hour.

If fewer than 36 calls, the ApiHealthChecker has an issue.

Screenshots

Normal State - 84 Calls Visible (7 Workflows, each called 12 times in one hour)

Error State - Linitems Pod down **

Erro State - WokflowServer down

Alert Email

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Infrastructure-overview-diagrams\Demo-Website.md - Chunk 0
Trial Page 01 seit dem 22-12-2022

Version mit Link auf V1-17

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Infrastructure-overview-diagrams\Rechnungserkennung.md - Chunk 0
Produktivumgebung V1-18-133 (ab 22.08.2024 21:00)

Produktivumgebung V1-18-128 (ab 18.07.2024 17:00)

Produktivumgebung V1-18-119 (ab 23.05.2024 18:00)

Produktivumgebung V1-18-113 (ab 25.04.2024 16:30)

Produktivumgebung V1-18-103 (ab 14.03.2024 17:30)

Produktivumgebung V1-18-94 (ab 09.02.2024 11:59)

Produktivumgebung V1-18-89 (ab 11.01.2024 21:45)

Produktivumgebung V1-18-70 (ab 21.09.2023 20:00)

Produktivumgebung V1-18-52 (ab 10.07.2023 21:30)

Produktivumgebung V1-18-38 (ab 14.04.2023 17:16)

Produktivumgebung V1-18-20 (ab 26.01.2023 20:00)

Produktivumgebung V1-18-17 (ab 22.12.2022 20:09)

Produktivumgebung V1-18-4 (ab 30.08.2022 15:51)

Produktivumgebung V1-18-1 (ab 28.07.2022 21:20)

Produktivumgebung V1-18 (ab 05.07.2022 20:30)

Produktivumgebung mit Versionen V1-14 und V1-18 (ab 22.04.2022 20:00)

Das Einsparungspotential durch Umleitung von V1-14 auf V1-18 beträgt monatlich 2.000,00 EUR.

Produktivumgebung mit Versionen V1-14, V1-15 und V1-17

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Infrastructure-overview-diagrams\Rechnungserkennung.md - Chunk 1
Das Einsparungspotential durch Umleitung von V1-14 auf V1-18 beträgt monatlich 2.000,00 EUR.

Produktivumgebung mit Versionen V1-14, V1-15 und V1-17

Einsparungen durch Zusammenlegung der Container Instanzen

Die Einsparung beträgt mindestens 654€ (V1-14 270€ und V1-15 384€)

captureservice-container-plan-v1-14 | P2V2 | 142,21 | 2 - 5 Instanzen 284,42

captureservice-container-plan-v1-15 | P2V2 | 142,21 | 2 - 5 Instanzen 284,42

Nach dem Deployment der V1-18

Nach dem Deployment von V1-18 kann damit begonnen werden, auch die Versionen V1-14 auf die V1-18 umzuleiten. Es muß vorher aber gewehrleistet werden, dass die SME und andere Kunnden weiterhin die Ergebnisse im Format der V1-11 bekommen. Bisher mappt der Interceptor die Ergebnisse von V1-14 auf V1-11. Unabhängig von einer neuen Version, können auch die verbliebenen Container Apps in den AKS Cluster verschoben werden.

Einsparungen durch löschen der Versionen V1-14 und V1-15

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Infrastructure-overview-diagrams\Rechnungserkennung.md - Chunk 2
Einsparungen durch löschen der Versionen V1-14 und V1-15

Die Einsparung beträgt mindestens 1.624€ (SDK Servic Plan).

Capture SDK Service Plan

Ein Capture Service Service Plan wird auch weiterhin benötigt und deshalb ergeben sich hier geringe Einsparungen, die schwer schätzbar sind. Capture Service Service Plan 1-7

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Infrastructure-overview-diagrams\SME.md - Chunk 0
SME Produktivumgebung SME Prod03 (ab 17.08.2022)

Version 1-0

VNext

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Log-Analysis\ElasticSearch-access-analysis-(Dev-Env-).md - Chunk 0
During work on #22090 we analyzed all available data regarding access to our elasticsearch service in the Dev-Environment. This was done via the logs from the ingress-nginx controller with the powershell scripts from the following repo-directory: dev-ops\DueDiligence\powershell-scripts\loki-log-export

Available data time range: 4th Jun 2024 - 2nd Sep 2024

Location of log files: \nas-01\CustomerData\OPS_DATA_LOG_ANALYSIS\dev-cluster\ingress-log-analysis-20240902

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Log-Analysis\ElasticSearch-access-analysis-(Dev-Env-).md - Chunk 1
Available data time range: 4th Jun 2024 - 2nd Sep 2024

Location of log files: \nas-01\CustomerData\OPS_DATA_LOG_ANALYSIS\dev-cluster\ingress-log-analysis-20240902

json [ { "IP": "89.26.36.113", "Count": 20217 }, { "IP": "10.1.0.124", "Count": 18550 }, { "IP": "10.1.0.59", "Count": 5723 }, { "IP": "10.1.0.116", "Count": 5694 }, { "IP": "10.1.0.34", "Count": 3375 }, { "IP": "10.1.0.153", "Count": 3338 }, { "IP": "10.1.0.76", "Count": 658 }, { "IP": "10.1.0.96", "Count": 657 }, { "IP": "10.1.0.94", "Count": 417 }, { "IP": "10.1.0.157", "Count": 409 }, { "IP": "10.1.0.67", "Count": 194 }, { "IP": "10.1.0.186", "Count": 192 }, { "IP": "10.1.0.172", "Count": 88 }, { "IP": "10.1.0.90", "Count": 88 }, { "IP": "No IP", "Count": 1 } ]

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Log-Analysis\ElasticSearch-access-analysis-(Dev-Env-).md - Chunk 2
There is 1 log line with relation to elasticsearch which does not have an IP included. (does not really seem suspicious) ```json { "Timestamp": "\/Date(-10542246993377)\/", "Log": "I0813 20:56:14.622125 6 store.go:440] \"Found valid IngressClass\" ingress=\"elasticsearch/elasticsearch-ingress-release-ingress\" ingressclass=\"nginx\"", "Labels": { "instance": "ingress-nginx", "job": "ingress-nginx/ingress-nginx", "namespace": "ingress-nginx", "container": "controller", "component": "controller", "filename": "/var/log/pods/ingress-nginx_ingress-nginx-controller-75967d99c9-6wn78_0b3cd370-7a57-4894-bb0d-d1c0499ffdc5/controller/0.log", "node_name": "aks-masterpool-24753887-vmss000001", "pod": "ingress-nginx-controller-75967d99c9-6wn78", "stream": "stderr", "app": "ingress-nginx" } }

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Log-Analysis\ElasticSearch-access-analysis-(Dev-Env-).md - Chunk 3
```

All requests come from our own IP-ranges.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\OpenAPI-Specifications\Instruction---Add-new-dummy-endpoint.md - Chunk 0
Instruction - Add new dummy endpoint

Add endpoint in Quotation Servie

Repo: Quotation

Create a new controller in the quotation service. It is important that the new endpoint is not visible for Swagger of the Quotation Service. This is done by the ApiExplorerSettings annotation. If it is not set then you will see it as a new endpoint in the Swagger file of the Quotation Service, which is still created via the Swashbuckle Extension Package.

```c# using Microsoft.AspNetCore.Mvc; using Swashbuckle.AspNetCore.Annotations; using Blumatix.Quotation.Api.Controllers;

namespace Blumatix.DocClassifier.Api.Controllers { [Route("v{version:apiVersion}/doc-classifier")] [ApiExplorerSettings(IgnoreApi = true)] public class DocClassifierController : ControllerBaseExt { private readonly ILogger _logger; private readonly IWebHostEnvironment _hostingEnvironment; //this is used to get the root path of our application

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\OpenAPI-Specifications\Instruction---Add-new-dummy-endpoint.md - Chunk 1
public DocClassifierController(ILoggerProvider logProvider, IWebHostEnvironment hostingEnvironment)
    {
        _logger = logProvider.CreateLogger(nameof(DocClassifierController));            
        _hostingEnvironment = hostingEnvironment;   
    }

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\OpenAPI-Specifications\Instruction---Add-new-dummy-endpoint.md - Chunk 2
/// <summary>
    /// Captures the doc-classifier and returns the result
    /// </summary>
    /// <param name="request">Contains the resource name and the content</param>
    /// <returns>A <see cref="ResourceResponse"/></returns>
    /// <remarks>
    /// Sample request:
    /// 
    ///
    /// </remarks>
    /// <response code="200">ResourceResponse</response>
    /// <response code="400">Invalid ResourceName or Value</response>
    /// <response code="401">Unauthenticated customer, e.g. invalid APIKey or APIIdentifier</response>
    [HttpPost]  
    [Consumes("multipart/form-data")]
    [Produces("application/json")]        
    [ProducesResponseType(StatusCodes.Status200OK)]
    [ProducesResponseType(StatusCodes.Status400BadRequest)]
    [ProducesResponseType(StatusCodes.Status401Unauthorized)]
    [SwaggerOperation(
        Summary = "DocClassifier",
        Description = "Captures the doc-classifier and returns the result"
    )]

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\OpenAPI-Specifications\Instruction---Add-new-dummy-endpoint.md - Chunk 3
[SwaggerOperation(
        Summary = "DocClassifier",
        Description = "Captures the doc-classifier and returns the result"
    )]            
    public async Task<IActionResult> DetectAsync(IFormFile file)
    {
        _logger.LogInformation("DocClassifier POST: " + file.FileName);

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\OpenAPI-Specifications\Instruction---Add-new-dummy-endpoint.md - Chunk 4
if (file == null || file.Length == 0)
        {
            ModelState.AddModelError(string.Empty, "No file uploaded");
            return BadRequest(ModelState);
        }

        var rootPath = _hostingEnvironment.ContentRootPath; //get the root path
        var json = Path.Combine(rootPath, "resultDocClassifier.json");

        string jsonString = await System.IO.File.ReadAllTextAsync(json);

        return new ContentResult() {
            Content = jsonString,
            ContentType = "application/json",
            StatusCode = 200
        };

    } 
}

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\OpenAPI-Specifications\Instruction---Add-new-dummy-endpoint.md - Chunk 5
```

Store response file

Store a json file with the static response in the src\Blumatix.Quotation.Api folder. Returned by the controller.

json // resultDocClassifier.json { "BluDoc.Version": "1.3.0", "Created.DateTime": "2024-04-02T15:56:37.2241896+00:00", "CreatorSoftware.Name": "BluDelta Classifier", "CreatorSoftware.Version": "1.0.0", "Document.Type": "ProformaInvoice", "DocumentProvider.Name": "dachser-Classification" }

This response is returned each time classification.bludelta.ai/doc-classifier/v1/doc-classifier is called, but only after a route has been defined for it in the ApiGateway.

Create OpenAPI Specification yaml for all environments

In the directory static src\Blumatix.Quotation.Api\static-files\specs create a subdirectory structure for doc-classifier and all environments and versions and store the respective valid specification in it.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\OpenAPI-Specifications\Instruction---Add-new-dummy-endpoint.md - Chunk 6
src\Blumatix.Quotation.Api\static-files\specs\doc-classifier\dev\v1\swagger.yaml src\Blumatix.Quotation.Api\static-files\specs\doc-classifier\prod\v1\swagger.yaml src\Blumatix.Quotation.Api\static-files\specs\doc-classifier\qa\v1\swagger.yaml

Here is the example for dev environment:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\OpenAPI-Specifications\Instruction---Add-new-dummy-endpoint.md - Chunk 7
```json openapi: 3.0.1 info: title: DocClassifier API version: '1.0' servers: - url: https://classification-dev.bludelta.ai/doc-classifier description: Development server paths: /v1/doc-classifier: post: tags: - DocClassifier parameters: - name: X-ApiKey in: header description: The customer's application key. Required for authentication required: true schema: type: string - name: X-ApiIdentifier in: header description: The customer's api identifier key. Not required for authentication schema: type: string requestBody: content: multipart/form-data: schema: type: object properties: file: type: string format: binary encoding: file: style: form responses: '200': description: Success '400': description: Bad Request content: application/json: schema: $ref: '#/components/schemas/ProblemDetails' '401': description: Unauthorized content: application/json: schema: $ref: '#/components/schemas/ProblemDetails' components: schemas: ProblemDetails: type: object properties: type: type: string

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\OpenAPI-Specifications\Instruction---Add-new-dummy-endpoint.md - Chunk 8
'401': description: Unauthorized content: application/json: schema: $ref: '#/components/schemas/ProblemDetails' components: schemas: ProblemDetails: type: object properties: type: type: string nullable: true title: type: string nullable: true status: type: integer format: int32 nullable: true detail: type: string nullable: true instance: type: string nullable: true additionalProperties: {}

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\OpenAPI-Specifications\Instruction---Add-new-dummy-endpoint.md - Chunk 9
```

Initialize Swagger UI

So that Swagger UI, which is hosted as a static website on the Quotation Service, can find the specification, versions and environments for loading must be announced. In the file src\Blumatix.Quotation.Api\static-files\swagger\swagger-initializer.js you add the name of the workflow and define the version per environment.

js // src\Blumatix.Quotation.Api\static-files\swagger\swagger-initializer.js const paths = { quotation: { dev: ["V1", "V2"], qa: ["V1"], prod: ["V1"], }, receipt: { dev: ["V1"], qa: ["V1"], prod: ["V1"], }, "doc-classifier": { dev: ["V1"], qa: ["V1"], prod: ["V1"], }, };

Configure routes to endpoints

Repo: ApiGateway

The following definitions enable access via classifation.bludelta.ai/doc-classifier/*.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\OpenAPI-Specifications\Instruction---Add-new-dummy-endpoint.md - Chunk 10
json "Routes": { "swagger-doc-classifier": { "ClusterId": "cluster-ingress", "Match": { "Path": "/classification/doc-classifier/swagger/{**catch-all}" }, "Transforms": [ { "PathRemovePrefix": "/classification/doc-classifier" }, { "PathPrefix": "quotation/static-files" } ] }, "specs-doc-classifier": { "ClusterId": "cluster-ingress", "Match": { "Path": "/classification/doc-classifier/specs/{**catch-all}" }, "Transforms": [ { "PathRemovePrefix": "/classification/doc-classifier/specs" }, { "PathPrefix": "quotation/static-files/specs" } ] }, "redoc-doc-classifier": { "ClusterId": "cluster-ingress", "Match": { "Path": "/classification/doc-classifier/api-docs/{**catch-all}" }, "Transforms": [ { "PathRemovePrefix": "/classification/doc-classifier" }, { "PathPrefix": "quotation/static-files" } ] }, "route-doc-classifier-v1": { "ClusterId": "cluster-ingress", "AuthorizationPolicy": "customPolicy", "Match": { "Path": "/classification/doc-classifier/v1/doc-classifier/{**catch-all}" },

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\OpenAPI-Specifications\Instruction---Add-new-dummy-endpoint.md - Chunk 11
} ] }, "route-doc-classifier-v1": { "ClusterId": "cluster-ingress", "AuthorizationPolicy": "customPolicy", "Match": { "Path": "/classification/doc-classifier/v1/doc-classifier/{**catch-all}" }, "Transforms": [ { "PathRemovePrefix": "/classification/doc-classifier" }, { "PathPrefix": "/quotation" } ] },

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\OpenAPI-Specifications\Instruction---Add-new-dummy-endpoint.md - Chunk 12
Create default page redirection

In order for swagger ui and redoc to display the correct specification, a redirection to the Index.html files must be set up.

```c# // program.cs

...

app.UseHttpMetrics();

var records = new List

var rewriteOptions = new RewriteOptions();

foreach (var record in records) { var fromUrl = $"^(.*/)?{record.SubDomain}/{record.Workflow}/swagger$"; var toUrl = $"$1{record.Workflow}/swagger/index.html?workflow={record.Workflow}&env={openapiEnv}&urls.primaryName={record.Version}"; rewriteOptions.AddRedirect(fromUrl, toUrl, 302); }

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\OpenAPI-Specifications\Instruction---Add-new-dummy-endpoint.md - Chunk 13
```

In our case:

c# new RedirectRecord("classification", "doc-classifier", "v1"),

This means that when calling

https://classification-dev.bludelta.ai/doc-classifier/swagger

it will be redirected to this url

https://classification-dev.bludelta.ai/doc-classifier/swagger/index.html?workflow=doc-classifier&env=dev&urls.primaryName=v1

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Scaling\CaptureSdk-Scaling-Pipelines.md - Chunk 0
CaptureSdk Scaling Pipelines Overview

This page provides an overview of the various pipelines used to scale the CaptureSdk WebApp instances in Azure Prod Subscription. The pipelines are configured to run at specific times to adjust the number of available instances.

Scaling Times and Instances

Time Instances Pipeline 04:30 4 scheduled-upscale-sdk-pipelines.yaml 04:30 5 scheduled-monday-boost-sdk-pipelines.yaml 08:00 8 scheduled-daily-boost-sdk-pipelines.yaml 15:00 6 scheduled-flat-daily-boost-sdk-pipelines.yaml 17:00 4 scheduled-stop-daily-boost-sdk-pipelines.yaml 19:00 2 scheduled-downscale-sdk-pipelines.yaml

Pipeline Details

scheduled-upscale-sdk-pipelines.yaml

Time: 04:30

Instances: 4

Description: This pipeline scales the number of CaptureSdk WebApp instances to 4.

scheduled-monday-boost-sdk-pipelines.yaml

Time: 04:30

Instances: 5

Description: This pipeline scales the number of CaptureSdk WebApp instances to 5. It runs specifically on Mondays to handle increased load.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Scaling\CaptureSdk-Scaling-Pipelines.md - Chunk 1
Time: 04:30

Instances: 5

Description: This pipeline scales the number of CaptureSdk WebApp instances to 5. It runs specifically on Mondays to handle increased load.

scheduled-daily-boost-sdk-pipelines.yaml

Time: 08:00

Instances: 8

Description: This pipeline scales the number of CaptureSdk WebApp instances to 8 to ensure higher performance during peak business hours.

scheduled-flat-daily-boost-sdk-pipelines.yaml

Time: 15:00

Instances: 6

Description: This pipeline scales the number of CaptureSdk WebApp instances to 6 to maintain consistent performance in the afternoon.

scheduled-stop-daily-boost-sdk-pipelines.yaml

Time: 17:00

Instances: 4

Description: This pipeline reduces the number of CaptureSdk WebApp instances to 4 as the peak business hours wind down.

scheduled-downscale-sdk-pipelines.yaml

Time: 19:00

Instances: 2

Description: This pipeline reduces the number of CaptureSdk WebApp instances to 2 to save resources during the night.

Contact

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Scaling\CaptureSdk-Scaling-Pipelines.md - Chunk 2
scheduled-downscale-sdk-pipelines.yaml

Time: 19:00

Instances: 2

Description: This pipeline reduces the number of CaptureSdk WebApp instances to 2 to save resources during the night.

Contact

For any questions or issues, please contact Gü.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Scaling\Up--Downscale-Environment-for-Strabag.md - Chunk 0
Process

https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/629/Strabag-Upscale-Support-Requests

Support Training Recording

Skalierung Produktivumgebung (STRABAG)-20221215_092958-Besprechungsaufzeichnung.mp4 (sharepoint.com)

Upscale

Strabag has a problem in their own datacenter and emails support. They want us to upscale our system to take the additional load from them.

Checklist

[ ] Send an email to the team announcing that the system will be scaled up

[ ] Start upscale pipeline Pipelines - Runs for upscale-environment (visualstudio.com)

Parameters are preset for this case. Only the start of the pipeline is necessary

If no free agent is available for the pipeline, then cancel all piplines already running or waiting!

Scaling the Kubernetes cluster takes some time (up to 20min)

[ ] Checking that the production environment has been scaled properly

[ ] AKS

[ ] Azure Portal AKS Prod 118 - Nodepools

[ ] gpupool shows Node count 8/8 ready

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Scaling\Up--Downscale-Environment-for-Strabag.md - Chunk 1
[ ] Checking that the production environment has been scaled properly

[ ] AKS

[ ] Azure Portal AKS Prod 118 - Nodepools

[ ] gpupool shows Node count 8/8 ready

[ ] masterpool shows Node count 4/4 ready

[ ] Azure Portal AKS Prod 118 Workloads

[ ] authentication 4/4

[ ] bludelta-typhon-v1-18-container 8/8

[ ] delivery-period-ner 8/8

[ ] doctype-linux 4/4

[ ] payment-condition-ner 8/8

[ ] post-processing 4/4

[ ] qrcode-service 4/4

[ ] resource-service 4/4

[ ] resource-uploader-service 4/4

[ ] triton-triton-inference-server 8/8

[ ] typhon-header-details 8/8

[ ] typhon-line-item-cpu 8/8

[ ] typhon-vat-group 8/8

[ ] whitelistsearch 4/4

[ ] Capture Sdk

[ ] Azure Portal Capture SDK Scalout

[ ] Instance Limits: Minimum 8 and Default 8

[ ] Capture ServiceAzure Portal Container Scalout

[ ] Instance Limits: Minimum 4 and Default 4

[ ] Container Instances

[ ] Azure Portal Capture Service Scalout

[ ] Instance Limits: Minimum 4 and Default 4

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Azure-Infrastructure\Scaling\Up--Downscale-Environment-for-Strabag.md - Chunk 2
[ ] Instance Limits: Minimum 4 and Default 4

[ ] Container Instances

[ ] Azure Portal Capture Service Scalout

[ ] Instance Limits: Minimum 4 and Default 4

[ ] If after 15 minutes nothing happens manually intervene

[ ] Inform Strabag when ready to go

[ ] Send an email to the team that scaling is complete

Downscale

Wait for OK from Strabag that there problem is solved.

[ ] Send an email to the team announcing that the system will be scaled down

[ ] Start downscale pipeline Pipelines - Runs for downscale-environment (visualstudio.com)

Parameters are preset for this case. Only the start of the pipeline is necessary

Scaling the Kubernetes cluster takes some time (up to 20min)

[ ] Contact Gü

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Ansible.md - Chunk 0
Install Ansible on Linux

Ansible environment must be installed on a linux machine - it doesn't run on windows machines

Detailed installation guide

sh pip install ansible

Installation on Windows Machines

OpenSSH is the only requirement for windows clients. Ansible communicates and executes commands, scripts etc. over OpenSSH

Ansible Installation with openssh on Windows

Start Powershell as Admin

check if openssh is already installed

```powershell PS C:\WINDOWS\system32> Get-WindowsCapability -Online | Where-Object Name -like 'OpenSSH*' Name : OpenSSH.Client~~~~0.0.1.0 State : Installed

Name : OpenSSH.Server~~~~0.0.1.0 State : NotPresent ```

Install Client and Server (client is already installed) ```powershel

Install the OpenSSH Client

Add-WindowsCapability -Online -Name OpenSSH.Client~~~~0.0.1.0

Install the OpenSSH Server

Add-WindowsCapability -Online -Name OpenSSH.Server~~~~0.0.1.0

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Ansible.md - Chunk 1
```

Configure SSH-Server ```powershell

Start the sshd service

Start-Service sshd

OPTIONAL but recommended:

Set-Service -Name sshd -StartupType 'Automatic'

Confirm the Firewall rule is configured. It should be created automatically by setup. Run the following to verify

if (!(Get-NetFirewallRule -Name "OpenSSH-Server-In-TCP" -ErrorAction SilentlyContinue | Select-Object Name, Enabled)) { Write-Output "Firewall Rule 'OpenSSH-Server-In-TCP' does not exist, creating it..." New-NetFirewallRule -Name 'OpenSSH-Server-In-TCP' -DisplayName 'OpenSSH Server (sshd)' -Enabled True -Direction Inbound -Protocol TCP -Action Allow -LocalPort 22 } else { Write-Output "Firewall rule 'OpenSSH-Server-In-TCP' has been created and exists." } ```

Uninstall

```powershell

Uninstall the OpenSSH Client

Remove-WindowsCapability -Online -Name OpenSSH.Client~~~~0.0.1.0

Uninstall the OpenSSH Server

Remove-WindowsCapability -Online -Name OpenSSH.Server~~~~0.0.1.0

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Ansible.md - Chunk 2
```

We use Ansible in our OnPremise pipeline for the installation of the CaptureSdk on the ServerBmBuild01. ```sh parameters: - name: 'version' type: string

stages: - stage: Deploy displayName: Deployment stage jobs: - job: Deployment_Job displayName: Deploy Linux and Windows OnPremise Setup timeoutInMinutes: 20 cancelTimeoutInMinutes: 1 pool: name: LocalPool demands: - OPSetup -equals True - Agent.Name -equals rybuntu01 steps: - checkout: none - script: | echo "Setup Version: ${{parameters.version}}" displayName: "Show current setup version" - script: | /opt/onprem-installation/install-linux-setup.sh -v ${{parameters.version}} -i /opt/onprem-installation/Setup displayName: "Install linux environment" - script: | /opt/ansible/ansible-playbook -i /opt/onprem-installation/host.ini /opt/onprem-installation/install-win-setup-playbook.yaml --extra-vars "version=${{parameters.version}}" displayName: "Install windows environment"

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Ansible.md - Chunk 3
```

We have defined a playbook which is execute on the linux host "rybuntu01". The playbook executes a powershell script "install-win-setup.ps1" on the windows machine which has been previously installed on it. It does all the heavy lifting.

It downloads the new CaptureSDK version from our artifact store. Uninstall the previous version, installs the new one and restart the CaptureSDK service. A

```yaml

name: Ansible win_command module example hosts: win # host group to run the module on tasks:

name: download setup files to serverbdref and extract zip files ansible.windows.win_powershell: script: | powershell.exe -File "C:/captureSdkInstallation/install-win-setup.ps1" -Action Download -OutputDirectory D:/Setup -SetupVersion {{ version }}

name: uninstall old CaptureSDK version from host ansible.windows.win_powershell: script: | powershell.exe -File "C:/captureSdkInstallation/install-win-setup.ps1" -Action Uninstall -OutputDirectory D:/Setup -SetupVersion {{ version }}

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Ansible.md - Chunk 4
name: install and start new CaptureSDK version ansible.windows.win_powershell: script: | powershell.exe -File "C:/captureSdkInstallation/install-win-setup.ps1" -Action Install -OutputDirectory D:/Setup -SetupVersion {{ version }}

name: restart BLUDELTA.Service.{{ version }}.0 8090 - workaround!! ansible.windows.win_powershell: script: | powershell.exe -Command {Restart-Service -Name "BLUDELTA.Service.{{ version }}.0 8090"}

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Ansible.md - Chunk 5
```

Powershel Script:

```powershell <# .SYNOPSIS Installs the CaptureSDK service

.DESCRIPTION
    Download the new CaptureSDK service from the provided Azure Blob Storage URL.
    Uninstall any existing CaptureSDK service, then install the CaptureSDK service.

.PARAMETER Action
The action to be executed. Can be one of the following:
    - Install
    - Uninstall
    - Update

.PARAMETER SetupVersion
The version of the CaptureSDK service to be installed.

.PARAMETER OutputDirectory
The directory where the setup files will be downloaded to.

>

[CmdletBinding()] Param( [Parameter(Mandatory=$True)] [ValidateSet("All", "Download", "Install", "Uninstall")] [string]$Action, [string]$SetupVersion = "", [string]$OutputDirectory = "Setup" )

function UninstallOldSetup { [CmdletBinding()] param ( [string]$OutputDirectory )

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Ansible.md - Chunk 6
function UninstallOldSetup { [CmdletBinding()] param ( [string]$OutputDirectory )

# uninstall all previous BludeltaSDK versions
$captureSdks = Get-WmiObject -Class Win32_Product | Where-Object{$_.Name -eq "BLU DELTA Invoice Capture Service"}
foreach ($item in $captureSdks) {
    $item.Uninstall()
}

function DownloadSetup { [CmdletBinding()] param ( [string]$SetupVersion, [string]$OutputDirectory )

if ([string]::IsNullOrEmpty($SetupVersion)) {
    write-host "Download failed. Setup version needed"
    exit 1
}

if (!(Test-Path $OutputDirectory)) {
    New-Item -ItemType Directory -Path $OutputDirectory    
}

# Delete all existing setup files from the output directory
Write-Host "Deleting existing setup files from $OutputDirectory"
Remove-Item $OutputDirectory/* -Recurse -Force

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Ansible.md - Chunk 7
# Delete all existing setup files from the output directory
Write-Host "Deleting existing setup files from $OutputDirectory"
Remove-Item $OutputDirectory/* -Recurse -Force

# Download the setup file from the Azure Blob Storage URL
[string]$SAS_TOKEN="sv=2021-08-06&st=2022-11-30T15%3A08%3A09Z&se=2022-12-01T15%3A08%3A09Z&sr=c&sp=rl&sig=D8B477ZdK7OfTyWACMT9LQFxp7l7Q2jgFaDglSCKdBM%3D"
[string]$SETUP_URL="https://buildartifcats.blob.core.windows.net/onpremisesetup/$($SetupVersion)/op_windows.zip"

Write-Host "Downloading setup file from $SETUP_URL" -ForegroundColor Green
AzCopy.exe copy "$($SETUP_URL)?$($SAS_TOKEN)"  $OutputDirectory/$SetupVersion/op_windows.zip

# Unzip all files in the output directory
write-Host "Unzipping setup files" -ForegroundColor Green
Get-ChildItem -Path $OutputDirectory/$SetupVersion -Filter "*.zip" | ForEach-Object {
    Expand-Archive -Path $_.FullName -DestinationPath $OutputDirectory/$SetupVersion
}

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Ansible.md - Chunk 8
function InstallNewSetup { [CmdletBinding()] param ( [string]$OutputDirectory )

$setupPath = "$($OutputDirectory)/$SetupVersion/Setup.exe"
if (Test-Path $setupPath) {
    write-Host "Installing new setup" -ForegroundColor Green
    $installProcess = Start-Process -FilePath $setupPath -ArgumentList "/passive","/qn","/norestart"  -Wait -PassThru
    if ($installProcess.ExitCode -ne 0) {
        throw "Installing new setup failed"
    }

    write-Host "New setup installed successfully" -ForegroundColor Green

    # Modify config file to use the correct linux server
    $configPath = "C:\Program Files\Blumatix\BLU DELTA Invoice Capture Service V1.18.12\CA\Environment\bludelta-config.json"
    if (Test-Path $configPath) {
        write-Host "Modifying config file" -ForegroundColor Green
        $config = Get-Content $configPath | ConvertFrom-Json
        $config.bluDeltaLinuxServerIP = "192.168.137.78"
        $config | ConvertTo-Json | Set-Content $configPath
    }

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Ansible.md - Chunk 9
# Start the bootstrapper script
    $bootstrapperPath = "C:\Program Files\Blumatix\BLU DELTA Invoice Capture Service V1.18.12\CA\Environment\bludelta-onpremise-bootstrapper.ps1"
    if (Test-Path $bootstrapperPath) {
        write-Host "Starting bootstrapper script" -ForegroundColor Green
        & $bootstrapperPath -bluDeltaEnvironmentAction start

        # $bootstrapperProcess = Start-Process -FilePath $bootstrapperPath -ArgumentList "-bluDeltaEnvironmentAction","Start" -Wait -PassThru
        # if ($bootstrapperProcess.ExitCode -ne 0) {
        #     throw "Starting bootstrapper script failed"
        # }
    }

}

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Ansible.md - Chunk 10
}

if ($Action -eq "All") { UninstallOldSetup -OutputDirectory $OutputDirectory DownloadSetup -SetupVersion $SetupVersion -OutputDirectory $OutputDirectory InstallNewSetup -OutputDirectory $OutputDirectory } elseif ($Action -eq "Download") { DownloadSetup -SetupVersion $SetupVersion -OutputDirectory $OutputDirectory } elseif ($Action -eq "Install") { InstallNewSetup -OutputDirectory $OutputDirectory } elseif ($Action -eq "Uninstall") { UninstallOldSetup -OutputDirectory $OutputDirectory }

```

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\DevOps-Pipeline-Agent.md - Chunk 0
Install a Linux Agent

For further details visit Self-hosted Linux agents

Create a directory on your linux machine sh mkdir linux-agent cd linux-agent

Download and unpack the agent package sh wget https://vstsagentpackage.azureedge.net/agent/2.213.2/vsts-agent-linux-x64-2.213.2.tar.gz tar -xzvf vsts-agent-linux-x64-2.213.2.tar.gz Configure the agent. sh ./config.sh When running config.sh you will be asked for: - Your PAT (Scope Agent-Pool read/manage) - Server ULR for Azure Pipelines: https://dev.azure.com/blumatix - Pool Name: LocalPool

Start the agent in interactive mode sh ./run.sh

Start the agent in service mode sh sudo ./svc.sh install sudo ./svc.sh start

Now you should see something like:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\K3s.md - Chunk 0
K3s - OnPremise Cluster

Linux Master Node

TODO

Linux Worker-Agent

```sh

https://pet2cattle.com/2021/04/k3s-join-nodes

bash> curl -sfL https://get.k3s.io | K3S_URL=https://192.168.137.78:6443 K3S_TOKEN="K1000b4f33936a5881d51922ee6b87bc22ffb4040740e935cb66aa273591c217f43::server:d7cd4013c5556f0e73c3a1e3ffe1f8bc" INSTALL_K3S_VERSION=v1.20.5+k3s1 sh -

bash> kubectl get nodes bash> sudo systemctl enable --now k3s-agent bash> kubectl get nodes

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\K3s.md - Chunk 1
```

Startind and stopping an agent

sh bash> sudo systemctl stop k3s-agent bash> sudo systemctl start k3s-agent bash> sudo systemctl status k3s-agent

GPU Support

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\K3s.md - Chunk 2
Nvidia GPUs should be properly installed in the system. Check it with: ```sh rybuntu02:~$ nvidia-smi Tue Oct 11 19:12:22 2022 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 470.141.03 Driver Version: 470.141.03 CUDA Version: 11.4 | |-------------------------------+----------------------+----------------------+ | GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 NVIDIA GeForce ... Off | 00000000:0A:00.0 Off | N/A | | 50% 67C P2 122W / 350W | 12997MiB / 24268MiB | 0% Default | | | | N/A | +-------------------------------+----------------------+----------------------+ | 1 NVIDIA GeForce ... Off | 00000000:0B:00.0 Off | N/A | | 44% 64C P2 158W / 350W | 12985MiB / 24268MiB | 100% Default | | | | N/A |

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\K3s.md - Chunk 3
| 1 NVIDIA GeForce ... Off | 00000000:0B:00.0 Off | N/A | | 44% 64C P2 158W / 350W | 12985MiB / 24268MiB | 100% Default | | | | N/A | +-------------------------------+----------------------+----------------------+

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\K3s.md - Chunk 4
+-----------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=============================================================================| | 0 N/A N/A 1228 G /usr/lib/xorg/Xorg 9MiB | | 0 N/A N/A 1520 G /usr/bin/gnome-shell 6MiB | | 0 N/A N/A 228712 C python3 12963MiB | | 1 N/A N/A 1228 G /usr/lib/xorg/Xorg 4MiB | | 1 N/A N/A 228982 C /usr/bin/python3 12963MiB | +-----------------------------------------------------------------------------+

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\K3s.md - Chunk 5
```

Install the nvidia-container-toolkit

```sh bash> distribution=$(. /etc/os-release;echo $ID$VERSION_ID) bahs> curl -s -L https://nvidia.github.io/libnvidia-container/gpgkey | sudo apt-key add - bash> curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | sudo tee /etc/apt/sources.list.d/libnvidia-container.list

sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\K3s.md - Chunk 6
```

Configure Docker

Use nvidia runtime as the default runtime. Create daemon.json if it doesn't exist. sh bash> vim /etc/docker/daemon.json

json { "default-runtime": "nvidia", "runtimes": { "nvidia": { "path": "/usr/bin/nvidia-container-runtime", "runtimeArgs": [] } } } Restart docker engine sh bash> sudo systemctl restart docker

Configure containerd

Our local kubernetes is based on K3s which already uses containerd as container runtime. Therefore, the following file must be updated. ```sh bash> sudo su bash> cd /var/lib/rancher/agent/etc/containerd bash> vim config.toml

version = 2 [plugins] [plugins."io.containerd.grpc.v1.cri"] [plugins."io.containerd.grpc.v1.cri".containerd] default_runtime_name = "nvidia"

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\K3s.md - Chunk 7
version = 2 [plugins] [plugins."io.containerd.grpc.v1.cri"] [plugins."io.containerd.grpc.v1.cri".containerd] default_runtime_name = "nvidia"

  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes]
    [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.nvidia]
      privileged_without_host_devices = false
      runtime_engine = ""
      runtime_root = ""
      runtime_type = "io.containerd.runc.v2"
      [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.nvidia.options]
        BinaryName = "/usr/bin/nvidia-container-runtime"

sh bash> sudo systemctl restart containerd

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\K3s.md - Chunk 8
```

Enable GPU support in Kubernets

sh bash> kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.12.3/nvidia-device-plugin.yml

Check available gpus in kubernetes ```sh bash> sudo kubectl describe nodes | tr -d '\000' | sed -n -e '/^Name/,/Roles/p' -e '/^Capacity/ ,/Allocatable/p' -e '/^Allocated resources/,/Events/p' | grep -e Name -e nvidia.com | perl -pe 's/\n//' | perl -pe 's/Name:/\n /g' | sed 's/nvidia.com\/gpu:\?//g' | sed '1s/^/Node Available(GPUs) Used(GPUs)/' | sed 's/$/ 0 0 0/' | awk '{print $1, $2, $3}' | column -t

Node Available(GPUs) Used(GPUs) rybuntu01.ad.blumatix.com 2 0 rybuntu02.ad.blumatix.com 2 2 ```

Please follow these instructions

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Linux-Machines.md - Chunk 0
Access Via SSH

Our linux machines can be access with your ad user e.g. with ssh

ssh YOU_AD_USERNAME@ad.blumatix.com@rybuntu01.ad.blumatix.com

Check and Fix DNS and Gateway

After a reboot please update DNS IP address and IP of gateway

Update DNS server in resolv.conf. Correct DNS IP is 192.168.137.10 as it is shown below bash> sudo vim /etc/resolv.conf

```sh

Generated by NetworkManager

search ad.blumatix.com nameserver 192.168.137.10 nameserver 213.153.32.1

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Linux-Machines.md - Chunk 1
```

Check gateway. If IP is NOT 192.168.137.1 or NBDellPhil.ad.blumatix bash> route

Kernel IP routing table | Destination | Gateway | Genmask | Flags | Metric | Ref | Use | Iface | |----------------|------------------|-----------------|-------|--------|-----|-----|------------| | default | NBDellPhil.ad.b | 0.0.0.0 | UG | 0 | 0 | 0 | enp5s0 | | 10.42.0.0 | 0.0.0.0 | 255.255.255.0 | U | 0 | 0 | 0 | cni0 | | 10.42.1.0 | 10.42.1.0 | 255.255.255.0 | UG | 0 | 0 | 0 | flannel.1 | | link-local | 0.0.0.0 | 255.255.0.0 | U | 1000 | 0 | 0 | enp5s0 | | 172.17.0.0 | 0.0.0.0 | 255.255.0.0 | U | 0 | 0 | 0 | docker0 | | 192.168.137.0 | 0.0.0.0 | 255.255.255.0 | U | 100 | 0 | 0 | enp5s0 |

then sh bash> sudo route delete default gw 192.168.137.254 enp5s0 bash> sudo route add default gw 192.168.137.1 enp5s0

Mount Disks and FileShares

Mounting windows drives or windows partitions into the linux system

Show all available disks and partitions:

```sh sudo fdisk -l

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Linux-Machines.md - Chunk 2
Mount Disks and FileShares

Mounting windows drives or windows partitions into the linux system

Show all available disks and partitions:

```sh sudo fdisk -l

Disk /dev/nvme1n1: 931,53 GiB, 1000204886016 bytes, 1953525168 sectors Disk model: KINGSTON SA2000M81000G Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: gpt Disk identifier: 694B621C-E7B6-4BAA-9B3A-2571CFB0173C

Device Start End Sectors Size Type /dev/nvme1n1p1 2048 206847 204800 100M EFI System /dev/nvme1n1p2 206848 239615 32768 16M Microsoft reserved /dev/nvme1n1p3 239616 1133270052 1133030437 540,3G Microsoft basic data /dev/nvme1n1p4 1952471040 1953521663 1050624 513M Windows recovery environment /dev/nvme1n1p5 1133271040 1952471039 819200000 390,6G Linux filesystem

Partition table entries are not in disk order.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Linux-Machines.md - Chunk 3
Partition table entries are not in disk order.

Disk /dev/nvme0n1: 1,84 TiB, 2000398934016 bytes, 3907029168 sectors Disk model: Samsung SSD 970 EVO Plus 2TB Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: gpt Disk identifier: 6826246B-2001-450D-AF4A-637A7864F9F6

Device Start End Sectors Size Type /dev/nvme0n1p1 34 32767 32734 16M Microsoft reserved /dev/nvme0n1p2 32768 3907026943 3906994176 1,8T Microsoft basic data THIS IS THE DISK WE WANT TO MOUNT

Disk /dev/sda: 1,84 TiB, 2000398934016 bytes, 3907029168 sectors Disk model: ST2000DM008-2FR1 Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 4096 bytes I/O size (minimum/optimal): 4096 bytes / 4096 bytes Disklabel type: gpt Disk identifier: 1BACD5E2-1183-41E8-9E33-C4F63E42CBAC

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Linux-Machines.md - Chunk 4
Device Start End Sectors Size Type /dev/sda1 34 32767 32734 16M Microsoft reserved /dev/sda2 32768 3907026943 3906994176 1,8T Microsoft basic data

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Linux-Machines.md - Chunk 5
```

Mount a certain disk sh sudo mkdir /mnt/windows sudo ntfs-3g -o force,rw /dev/nvme0n1p2 /mnt/windows

Mount a windows file share with read/write rights

sh sudo mkdir /mnt/win_share sudo mount -t cifs -o rw,username=YOU_AD_USERNAME@ad.blumatix.com,nounix,dir_mode=0777,file_mode=0777 //RYZEN9RUDI/Datasets /mnt/win_share/

Create Mount Folders and Install NFS ```

create mount.sh shell script

script:

!/bin/bash

echo "mounting nas DataCollection" sudo mount -t nfs NAS-01:/volume1/DataCollection /mnt/datacollection/ echo "mounting nas TrainingsData" sudo mount -t nfs NAS-01:/volume1/TrainingsData /mnt/trainingsdata/ echo "mounting nas MLFlow" sudo mount -t nfs NAS-01:/volume1/MLFlow /mnt/mlflow

create folders

root@rybuntu02:/mnt# mkdir datacollection root@rybuntu02:/mnt# mkdir trainingsdata root@rybuntu02:/mnt# mkdir mlflow

install nfs

sudo apt install nfs-common

start script

root@rybuntu02:/opt# ./mounts.sh

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Linux-Machines.md - Chunk 6
```

Mount NAS shares as NFS ```sh bash> sudo mount -t nfs NAS-01:/volume1/DataCollection /mnt/datacollection/ bash> sudo chmod 0777 /mnt/datacollection

bash> sudo mount -t nfs NAS-01:/volume1/TrainingsData /mnt/trainingsdata/ bash> sudo chmod 0777 /mnt/trainingsdata

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Linux-Machines.md - Chunk 7
```

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Linux-Machines.md - Chunk 8
Show all mounted disks sh mount ... /var/lib/snapd/snaps/gtk-common-themes_1514.snap on /snap/gtk-common-themes/1514 type squashfs (ro,nodev,relatime,x-gdu.hide) /var/lib/snapd/snaps/snap-store_518.snap on /snap/snap-store/518 type squashfs (ro,nodev,relatime,x-gdu.hide) /dev/nvme1n1p1 on /boot/efi type vfat (rw,relatime,fmask=0077,dmask=0077,codepage=437,iocharset=iso8859-1,shortname=mixed,errors=remount-ro) tmpfs on /run/user/125 type tmpfs (rw,nosuid,nodev,relatime,size=13189660k,mode=700,uid=125,gid=130) gvfsd-fuse on /run/user/125/gvfs type fuse.gvfsd-fuse (rw,nosuid,nodev,relatime,user_id=125,group_id=130) tmpfs on /run/user/1302601125 type tmpfs (rw,nosuid,nodev,relatime,size=13189660k,mode=700,uid=1302601125,gid=1302600513) gvfsd-fuse on /run/user/1302601125/gvfs type fuse.gvfsd-fuse (rw,nosuid,nodev,relatime,user_id=1302601125,group_id=1302600513) /dev/nvme0n1p2 on /mnt/windows type fuseblk (rw,relatime,user_id=0,group_id=0,allow_other,blksize=4096) //RYZEN9RUDI/Datasets on

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Linux-Machines.md - Chunk 9
(rw,nosuid,nodev,relatime,user_id=1302601125,group_id=1302600513) /dev/nvme0n1p2 on /mnt/windows type fuseblk (rw,relatime,user_id=0,group_id=0,allow_other,blksize=4096) //RYZEN9RUDI/Datasets on /mnt/win_share type cifs (rw,relatime,vers=3.1.1,cache=strict,username=rudi@ad.blumatix.com,uid=0,noforceuid,gid=0,noforcegid,addr=192.168.137.39,file_mode=0777,dir_mode=0777,soft,nounix,serverino,mapposix,rsize=4194304,wsize=4194304,bsize=1048576,echo_interval=60,actimeo=1)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Linux-Machines.md - Chunk 10
NVIDIA GPUs

CUDA driver installation For further information refer to the CUDA TOOLKIT DOCUMENTATION

Find the appropriate driver for your cuda device, e.g. on ubuntu:

sh bash$ ubuntu-drivers devices == /sys/devices/pci0000:00/0000:00:03.2/0000:0a:00.0 == modalias : pci:v000010DEd00002204sv000019DAsd00001613bc03sc00i00 vendor : NVIDIA Corporation driver : nvidia-driver-460 - third-party non-free driver : nvidia-driver-470-server - distro non-free driver : nvidia-driver-470 - distro non-free recommended driver : nvidia-driver-460-server - distro non-free driver : xserver-xorg-video-nouveau - distro free builtin

Install the driver and reboot the system. When installing this driver you may be requested for an UEFI password which must then be typed in after reboot. This will only happen on UEFI enabled machines.

sh sudo apt install nvidia-driver-470 sudo reboot

Remove cuda from the system

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Linux-Machines.md - Chunk 11
sh sudo apt install nvidia-driver-470 sudo reboot

Remove cuda from the system

sh sudo apt-get purge nvidia* sudo apt-get autoremove sudo apt-get autoclean sudo rm -rf /usr/local/cuda*

Docker

Adding a new user to the docker group

sh sudo usermod -aG docker $USER

Block ports, e.g block port 443 sh bash$ sudo iptables -I DOCKER-USER -i docker0 -p tcp --dport 443 -j DROP

Reset old iptable ruls

Install Miniconda and activate environment

https://varhowto.com/install-miniconda-ubuntu-20-04/

```sh

set conda environment:

export PATH="/opt/miniconda3/bin:$PATH"

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Linux-Machines.md - Chunk 12
```

If you'd prefer that conda's base environment not be activated on startup, set the auto_activate_base parameter to false: sh conda config --set auto_activate_base false

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\NGINX.md - Chunk 0
NGINX with https support

Windows Installation Download und Dokumentation NGNIX: https://nginx.org/en/docs/windows.html

For https a Certificate chain is needed: Use openssl and don't forget to set environment for config: set OPENSSL_CONF=f:\openssl\openssl.cnf

First Create CA Certificate: f:/openssl/openssl ecparam -out bludelta.key -name prime256v1 -genkey f:/openssl/openssl req -new -sha256 -key bludelta.key -out bludelta.csr f:\openssl\openssl.exe x509 -req -sha256 -days 365 -in bludelta.csr -signkey bludelta.key -out bludelta.crt Then Server Certificate, f:\openssl\openssl ecparam -out sdk.key -name prime256v1 -genkey f:\openssl\openssl req -new -sha256 -key sdk.key -out sdk.csr f:\openssl\openssl x509 -req -in sdk.csr -CA bludelta.crt -CAkey bludelta.key -CAcreateserial -out sdk.crt -days 365 -sha256

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\NGINX.md - Chunk 1
Create a ca pfx for windows client, should be imported to certstore Local machine in trusted root certificates.: f:\openssl\openssl pkcs12 -export -out bludelta.pfx -inkey bludelta.key -in bludelta.crt

This command creates to files in Pem format: cert.pem (Certificate) key.pem (Private key) which are needed for signing. Create a directory (certs) in installation folder copy this 2 files in this directory.

Configure ngnix.conf in subdirectory ./conf.

Content:

worker_processes  1;

events {
        worker_connections  1024;
 }

http {
      include       mime.types;
      default_type  application/octet-stream;

      sendfile        on;
      keepalive_timeout  65;

# HTTP server - Redirects all traffic to HTTPS
server {
    listen       80;
    server_name  localhost;
    return 301 https://$host$request_uri;
}

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\NGINX.md - Chunk 2
# HTTP server - Redirects all traffic to HTTPS
server {
    listen       80;
    server_name  localhost;
    return 301 https://$host$request_uri;
}

# HTTPS server listen on 10443
server {
    listen       10443 ssl;
    server_name  localhost;
    client_max_body_size 20M;
    ssl_certificate     ../certs/sdk.crt;
    ssl_certificate_key ../certs/sdk.key;


    ssl_session_cache    shared:SSL:1m;
    ssl_session_timeout  5m;

    ssl_ciphers  HIGH:!aNULL:!MD5;
    ssl_prefer_server_ciphers  on;  client_max_body_size 20M;

# Forward to bedrefserver http port
    location / {
        proxy_pass   http://192.168.137.50:8095;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}

Default limit for filesize in NGNIX is 1M, to increase it add following line to server:

client_max_body_size 20M;

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\NGINX.md - Chunk 3
Default limit for filesize in NGNIX is 1M, to increase it add following line to server:

client_max_body_size 20M;

Firewall Inbound rule hast to be created for Port 10443 and 8095 and 443

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Proxmox.md - Chunk 0
What is Proxmox

Proxmox Installation

Proxmox Virtualization

HowTo - GPU Pass Through

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Windows-Machine.md - Chunk 0
Install open-ssh

Execute the following command in a powershell on the server:

powershell PS D:\> Add-WindowsCapability -Online -Name OpenSSH.Server~~~~0.0.1.0 PS D:\> Add-WindowsCapability -Online -Name OpenSSH.Client~~~~0.0.1.0 PS D:\> Set-Service -Name sshd -StartupType 'Automatic

Replace cmd.exe with powershell as default shell

powershell New-ItemProperty -Path "HKLM:\SOFTWARE\OpenSSH" -Name DefaultShell -Value "C:\Windows\System32\WindowsPowerShell\v1.0\powershell.exe" -PropertyType String -Force

Copy a file to the server with scp:

bash scp .\docker-compose-winservices.yml rudi@ad.blumatix.com@192.168.137.70:D:\ For more information: https://www.jfe.cloud/using-the-ssh-server-in-windows-server-2019/

Install docker and docker-compose

powershell PS D:\> Install-Module -Name DockerMsftProvider -Repository PSGallery -Force PS D:\> Install-Package -Name docker -ProviderName DockerMsftProvider PS D:\> Restart-Computer -Force

Install docker-compose

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Windows-Machine.md - Chunk 1
Install docker-compose

powershell PS D:\> [Net.ServicePointManager]::SecurityProtocol =Net.SecurityProtocolType]::Tls12 PS D:\> Invoke-WebRequest "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-Windows-x86_64.exe" -UseBasicParsing -OutFile $Env:ProgramFiles\Docker\docker-compose.exe

Mounting a Network Share into a windows docker container

A Network Share cannot be directly mounted into a windows docker container. First map the desired share as local drive, here G:, into your system and then mount a certain folder on G: into the container.

powershell PS D:\> $creds =et-Credential PS D:\> New-SmbGlobalMapping -RemotePath \\nas-01\TrainingsData -Credential $creds -LocalPath 'G:'

List all SmbGlobalMappings: ```powershell Get-SmbGlobalMapping

Status Local Path Remote Path

OK G: \nas-01\TrainingsDataExt4 OK H: \nas-01\DataCollection

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Operations\Local-Machines\Windows-Machine.md - Chunk 2
```

Remove a mapping powershell Remove-SmbGlobalMapping -LocalPath H:

E.g

v G:/LineItem:C:/LineItem

Windows Docker

powershell Add-AccountToDockerAccess adblumatix\rudi

HowTo start a windows based dockerd

ps1 & "C:\Program Files\Docker\Docker\resources\dockerd.exe" --run-service --service-name docker -G docker-users --config-file C:\ProgramData\Docker\config\daemon.json

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\ALD-Quotation---Phase-2.md - Chunk 0
ALD Phase 2 New Scope:

AP: Normalisierung VinID, Plate Id – 2MD AP: Review Postprocessing Verbesserungen – 2MD AP: OCR im BLU DOC mitliefern – 3MD AP: Optional – anderes (vermeintlich besseres) OCR testen – 3MD

!!! Important: Show that Line Items improve based on new data !!!

Waiting for order.

ALD did a PoC with Blumatix / BLU DELTA quotations service. The PoC was positive but requires further steps to show the added-value on ALDAutomotive side:

Open Tasks (Project):

Task Estimate API Team Estimate DataMgt Team Dedicated Line Item Model trainied through Learn API 10.5 0d Addition of SenderOrder.Id instead of ReceiverOrder.Id 2 0d Guided training through Learn API of all Quotation relevant models 0 4d Normalization of Vin.Id, Plate.Id and Mileage 0.5 1d Migrate to Azure Read OCR 0.5 0d

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\ALD-Quotation---Phase-2.md - Chunk 1
Estimate Incremental Costs: Operations Estimate monthly costs for hosting a separate Typhon customer model. @Rudi, GÜ: Any idea how we could do that? E.g. GPU costs divided by N Typhon models? N = capacity per GPU

Note Normalization of Mileage is available. Any additional requirements?

---

Brainstorming API Team

Dedicated Line Item Model trainied through Learn API: 10.5

Trainingdata Generation Pipeline: 1

Training Pipeline: 1

Generic Typhon Service: shall support LineItems: 8

Update Workflow: replace default line items with ALD line items: 0.5

Addition of SenderOrder.Id instead of ReceiverOrder.Id: 2

Add SenderOrder.Id to the quotation Model:

Update config for Trainingsdata Generation Pipeline: 0.5

Update config for Training Pipeline: 0.5

Update BluDoc: 0.5

Update ResultBuilder: 0.5

Update Quotation BM -> ASK DATAMANAGEMENT

Guided training through Learn API of all Quotation relevant models: 0

No actions needed

Normalization of Vin.Id, Plate.Id and Mileage: 0.5

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\ALD-Quotation---Phase-2.md - Chunk 2
Update Quotation BM -> ASK DATAMANAGEMENT

Guided training through Learn API of all Quotation relevant models: 0

No actions needed

Normalization of Vin.Id, Plate.Id and Mileage: 0.5

Update BluDoc nuget version in WorkflowServer: 0.5

Migrate to Azure Read OCR: 0.5

Replace OcrBox (Nuance) with MetaOcr/AzureRead: 0.5

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects.md - Chunk 0
Here you find all new features or project with contractual obligation or made a conscious decision that we want to extend our product. [[TOSP]]

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Capture---High-Level-Requirements.md - Chunk 0
BLUDELTA-API-Requirements-V1.pptx

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features.md - Chunk 0
Feature or projects we have implemented and delivered successfully or we stopped working on.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Competition.md - Chunk 0
https://www.hypatos.ai/ https://rossum.ai/ https://parashift.io/ https://klippa.com/ https://cloud.google.com/document-ai https://cloud-eu.flexicapture.com/invoices https://www.fintract.io https://mindee.com

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\e-Invoicing-EU-and-EU---Factsheet.md - Chunk 0
EU-Standard: CEN-Norm EN16931

CEN-Norm EN16931: europäischer Standard für elektronische Rechnungen, der ein einheitliches Datenmodell festlegt, um den den Austausch von Rechnungsdaten in der EU zu erleichtern Die Norm ist bereits für die öffentlichen Verwaltungsstellen der EU-Mitgliedsländer verpflichtend Datenmodell wurde für die Syntaxen UBL 2.1 (Universal Business Language) und CII D16B (Cross Industry Invoice) spezifiziert; beide basieren auf XML

Germany:

Ab 01. Januar 2025

Der Empfang von elektronischen Rechnungen gemäß EU-Standard EN16931* wird für alle deutschen B2B-Unternehmen obligatorisch

D.h. Daten müssen gemäß EN16931 extrahiert werden können; die EN16931 ist "nur" ein semantisches Modell. Gültige technische Umsetzungen in DE: - XRechnung (kann sowohl CII als auch UBL sein), - ZUGFeRD (letzere Versionnen unterstützen CII) / inkludiert PDF und CII XML, - EDIFACT nach CEN-Norm

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\e-Invoicing-EU-and-EU---Factsheet.md - Chunk 1
Ausnahmen bestehen in Rechnungen von < 250€ gemäß §33 UsTDV Rechnungen an Verbrauchern sind nicht betroffen

Übergangsregelungen bis 31. Dezember 2026

Sonstige Rechnungen (Papier/PDF) sowie E-Rechnungen, die noch nicht dem neuen Format entsprechen, können weiterhin übermittelt werden ABER: Die Priorität der Papier-/PDF-Rechnung entfällt d.h. Empfänger müssen dem Erhalt von E-Rechnungen nach EU-Standard nicht mehr zustimmen d.h. Empfänger müssen dem Empfang anderer elektronischer sowie sonstiger Formate zustimmen

Übergangsregelungen vom 01. Januar 2027 bis 31. Dezember 2027

Die genannten Übergangsregelungen gelten nur noch für rechnungsstellende Unternehmen mit einem Vorjahresumsatz von < 800.000€ EDI-Verfahren, die von den neuen Formatvorgaben abweichen, dürfen bis dahin noch genutzt werden Ab 2028 müssen die Vorgaben im gesamtem B2B eingehalten werden.

(Quelle: https://www.afi-solutions.com/news/artikel/e-rechnungspflicht-in-deutschland)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Naming-Conventions.md - Chunk 0
[[TOSP]]

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Product-Guidelines.md - Chunk 0
Following policies are valid for ALL BLU DELTA products and services.

[[TOC]]

We aim to provide AI document capturing services that are ...

Autonomous

Our aim is to create autonomous systems that improve on its own. Automated data collection, automated training and deployment. "Pressing a button" is NOT automation.´

Ready2Use

Our aim is to make interfacing with our products as easy and instant as possible for our customers. All our systems and APIs have a consistent versioning concept. Online documentation always includes: openapi, endpoint, online api doc, release notes

Cutting Edge

we continuously watch out for latest AI research and try to apply it on our product scope.

Trial before use

We want our customer to experience our Ready2Use principle. Thus, online trials for all our services and products are provided.

Generic over Custom

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Product-Guidelines.md - Chunk 1
Trial before use

We want our customer to experience our Ready2Use principle. Thus, online trials for all our services and products are provided.

Generic over Custom

Our vision is a global solution (not many custom solutions). Thus, we value the improvement of a global and/or generic solution higher than a custom solution.

Self-service and Configurable

We focus on enabling our customers and partners to customize based on self-controlled configuration wherever possible. All other parameters can be configured by the team.

Cloud first, OnPremise same

Cloud allows the customer to use our services easy, instantly and it scales. Cloud is the future, OnPremise we want to maintain for secure use cases and major customers.

Scalability

We build products that deliver value worldwide and are ready to scale. To enable scalability we base our product on scalable sized containers with a clear definition of its responsibility and scope limits.

Data is key

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Product-Guidelines.md - Chunk 2
Data is key

Our services depend on data. Thus, we value and manage data like source code.

Secure

Protecting data owned by other people and company is essential for our activities and we do everything possible to secure data of our clients.

Rather more info than less

Any (meta-)information that our ai found in our capturing process can be helpful for our customers. Thus, we aim to provide more information rather than less.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\Dachser-ClassNSplit-Phase-2.md - Chunk 0
[[TOC]]

Use Case:

Employees receive documents from accomplished logistics services for final archiving. The archive is later on used for use cases like complaints, cancellations, etc. Thus, the archive is still an important part of their workflows (as opposed to fire and forget). Documents are coming through email, network scanners, e-logistics, etc. and land in an inbox; from there (if needed) document batches are split up and single documents are split; in the next step the split documents are classified; classification is done in 2 steps: First select main category from a dropdown; second step select detailed category related to the main category. However, the first step is only done to ease the user interface. Service is called: Document Qualification Service and it is implemented by means of Kofax Total Agility

Requirements / Scope:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\Dachser-ClassNSplit-Phase-2.md - Chunk 1
Requirements / Scope:

For the next phase the goal is to generate added value for friendly user/offices. Certain Dachser offices will receive a service based on BLU DELTA Class&Split. These offices will test the service and if the service is helpful we will go into Phase 3!

General:

2 separate endpoints for split and classification Optimized to avoid False positives Split batches up to 50 docs Response is BLU DOC for classification Once a class is assigned it needs to be 99.x% correct Optionally OCR to be included in BLU DOC (request param) Scores and Thresholds need to be delivered THere exists a document class: "Other"

Data will be delivered by Dachser and uploaded via Learn API.

Classification of 9 (10) classes:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\Dachser-ClassNSplit-Phase-2.md - Chunk 2
Data will be delivered by Dachser and uploaded via Learn API.

Classification of 9 (10) classes:

System Values German Translation Description Industry TransitNoteT1 CDTD1 Versandschein T1, for transit from customs to customs Logistics TransitNoteT2 CDTD2 Versandschein T2, for transit of community goods outside EU Logistics ProformaInvoice CDPIN Pa document that declares the value of the goods but does not request for any payment Logistics DangerousGoodsNote TRDGN Logistics ExportAccompanyingDocument CDABD - Ausfuhrbegleitdokument Logistics CMRConsignmentNote Frachtbriefe CMR within Europe (TRCMR) Logistics CollectionOrder Abholauftrag (CODCO) Logistics ForwardingOrder Speditionsauftrag (FDSPE) Logistics BillOfLading Frachtbrief (TRBOL) Logistics Other Other document ALL

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\Dachser-ClassNSplit-Phase-2.md - Chunk 3
Following documents were considered for PoC and are not relevant for Phase 2: | System Values | German Translation Description |Industry| |--|--|--| | CertificateOfOrigin | Ursprungszeugnis | Logistics | CustomsDutyReceipt | Zollabgabgenbeleg e.g. C88 for GB | Logistics | DeliveryNoteCustoms | Lieferschein Zolldokumente (CDDLN) | Logistics | DeliveryNoteTransit | Lieferschein Speditionsdokumente (FDEDN) | Logistics

Timeline:

Estimate for offer:

BLUDELTA-ClassNSplitr-Phase2-Estimate.xlsx

MUST

Classify up to 30 doc types Avoid False positives Once a class is assigned it needs to be 99.x% correct Split batches up to 50 docs 2 separate endpoints for split and classification Response is BLU DOC for classification Optionally OCR to be included in BLU DOC (request param) Scores and Thresholds need to be delivered Response for split need to be defined Split model is auto generated based on uploaded doc-types THere exists a document class: "Other"

SHOULD:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\Dachser-ClassNSplit-Phase-2.md - Chunk 4
SHOULD:

Customer should be able to define dynamic set of doc samples and classes Self-service, no effort from dev and data team needed for standard classification and split setup

PoC Results: Alignment_SplitClassification_20231213.pdf

Tasks

Data Mgt: Align labeling Rules Extend label tools? Change Document Type? Automate document classification via Learn API - Automated detection and addition of new doc classes?

API Team: - Implement trainings pipeline for auto doc addition classification - Enhance classification to work for more than one customer; more than one model - Implement workflow for splitting - Implement workflow for classification - Enhance splitting model - Analyse weaknesses of classyfier: Documents hard to distinguish, find solutions for these kind of docs - Analyse weakness of split: how to distinguish situations that are hard to split - Goal:>99%

TO-DO: Review Workflow and TO-DO

Data Mgt. Stories

(10d) #19323

(4d) #19324

(2d) #19399

(4d) #17184

(1d) #19327

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\Dachser-ClassNSplit-Phase-2.md - Chunk 5
TO-DO: Review Workflow and TO-DO

Data Mgt. Stories

(10d) #19323

(4d) #19324

(2d) #19399

(4d) #17184

(1d) #19327

(0.5d) #19325

API Team

Document Classification

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\Dachser-ClassNSplit-Phase-2.md - Chunk 6
(10d) #19323

(4d) #19324

(2d) #19399

(4d) #17184

(1d) #19327

(0.5d) #19325

API Team

Document Classification

Work Package Work Item Tasks B D R Data Generation DocClassifier DataGeneration-Pipeline - Must be configurable, re-usable for other doc-type data 5 10 5 Training DocClassifier CT-Pipeline - Must be configurable, re-usable for other doc-types and customers - Benchmarks - Need: Labels to BluDoc converter - Calculate Scores and Thresholds - Reports 8 5 4-5 Automatic DocClassifier Model Deployment - Automatic Model Evaluation - Triggers Automatic Model Deployment (Tagging, set Report Baseline, copy model into Triton Storage) 4 3 4 Model Analysis for DocClassifier 1 1 1 Model Improvements (it depends) 15 20 20 Inference Async vs Sync Endpoint 25 18 15 DocClassifier Service refactoring - Implement it as Elsa Workflow - OCRActivity - DocTypeActivity - Calls DocType Service (Typhon) - Apply Thresholds - ResultBuilder - API Gateway routing must be extended 25 18 15

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\Dachser-ClassNSplit-Phase-2.md - Chunk 7
Document Splitting

Work Package Work Item Tasks B D R Data Generation New DataGeneration-Pipeline - Must be configurable, re-usable for other splitting models Training New Splitting CT-Pipeline - Must be configurable, re-usable for other doc-types and customers - Benchmarks: - Data Management shall create BM for us. - Benchmark Engine must be updated for Splitting comparison - Calculate Scores and Thresholds - Reports Automatic Splitting Model Deployment Model Analysis for Splitting New Model approach, new Architecture if necessary Inference Async vs Sync Endpoint Splitting Service refactoring - Implement it as Elsa Workflow - OCRActivity? - SplittingActivity - Calls Splitting Service (Typhon) - Apply Thresholds - ResultBuilder - API Gateway routing must be extended

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\Dachser_-Country-Rollouts.md - Chunk 0
Current Status:

Current Priorities:

Open Rollouts: TW, JP Country_pecularities.xlsx

General Requirements:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\Dachser_-Country-Rollouts.md - Chunk 1
Country Test Dachser Launch BM Tasks State AT AT500 OK Live KR Yes GTA Recognition Rate,no comma digits Live FR W3 Live DE W3 Live IT W3 Live NL W3 Live ES W3 Implement specific SenderId/ReceiverId, Estimate Spain Live CH W3 Live CN 11.1. Yes Implement CN Models, QR Code, VAT Groups Live US 20.11. Ongoing Minimal Sender / Receiver info on invoice, benchmark contacts mapping Live HK 20.11. Yes Live IN 20.11. Yes Live since 22.4. CZ 4.10. No Live MX 4.10. 11.11. Yes Review BM results, Sender / Receiver Id mapping Live DK 4.10. 11.11. SR only Live PL 4.10. 11.11. No VAT in PL, switch to XML Live TR 4.10. 11.11. SR only Live SK 20.11. 9.12. No Live SE 20.11. 9.12. No Live NO 20.11. 9.12. SR only Live PT 20.11. 9.12. SR only Live HU 9.12. 8.1. Yes Live, VaT Group - HUF vs. EUR, no comma digits, local rule to have VATGroup in HUF, AP: Need HUF VAT Live BE 9.12. 8.1. Yes Live ID 9.12. 8.1. Yes Pending CR Sender/ReciverId improvement MA 19.1. 3.2. Yes Live UK 19.1. 3.2. Yes Live FI 19.1. 3.2.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\Dachser_-Country-Rollouts.md - Chunk 2
local rule to have VATGroup in HUF, AP: Need HUF VAT Live BE 9.12. 8.1. Yes Live ID 9.12. 8.1. Yes Pending CR Sender/ReciverId improvement MA 19.1. 3.2. Yes Live UK 19.1. 3.2. Yes Live FI 19.1. 3.2. Yes Live LU 19.1. 3.2. Yes Live IE 19.1. 3.2. Yes Live CL 19.1. 9.5. Yes Sender / Receiver Id issue, Currency Live PE 19.1. 9.5. Yes VAT Group Issue, VatAmount via QR code Live TH 19.1. 23.5. Yes Live ZA 21.3. 13.4. Yes Data collection ongoing Live MY 21.3. 13.4. Yes Data collection done Delivered SG 21.3. 13.4. Yes Data collection done Live RO 21.3. July Open Data collection done Delivered VN 21.3. 13.4. Open Data collection done Live TW 21.3. August Open Data collection ongoing Open JP NA June Fixed Deadline, Open data delivery TN NA Open

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\Dachser_-Country-Rollouts.md - Chunk 3
Germany 1.561.591 Frace 399.916 India 228.892 China 157.870 United States 97.731 Czech Republic 88.800 Austria 83.236 Netherlands 80.764 Spain 69.505 Poland 62.776 Hungary 62.260 Mexico 58.604 Thailand 50.760 Switzerland 45.580 Hong Kong 41.052 Belgium 38.831 Great Britain 37.607 Slovakia 31.952 Denmark 28.391 Sweden 24.753 Turkey 22.461 Vietnam 21.398 Romania 21.087 South Korea 20.565 Singapore 17.328 Malaysia 16.272 Finland 15.373 Norway 14.417 Indonisia 13.604 Taiwan 11.551 Italy 10.655 Peru 8.422 Ireland 7.976 Portugal 7.102 Chile 6.677 Luxembourg 4.822

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\HIK-Delivery-notes.md - Chunk 0
HIK

A company in the area of development, prototype construction and series production of mechatronic systems, control cabinets, electrical assemblies, plug-in cable assemblies, conductor sets and strands as well as extensive logistics and data services. HIK is an existing Aptean Germany customer.

Industry

Mechatronics and hardware manufacturer

Business Goal

to expand the collaboration with Aptean and develop a new use case. Potential at HIK is ~20k devlivery notes annually, but with potential for upscaling through additional Aptean customers.

Use Case

BLU DELTA API as part of a goods management process. HIK receives a delivery note, scans it and needs to compare line items data with the according data from the purchase order. This is done by the Aptean process. ~60-70% of the delivery notes have a 1:1 relation to an order. Others have subsets, ...

Customer / Partner Main Stakeholders, Contacts

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\HIK-Delivery-notes.md - Chunk 1
Customer / Partner Main Stakeholders, Contacts

Names Role Contact Micha Tönges Account Manager HIK Micha.Toenges@aptean.com Dirk Esploer Project Manager dirk.esploer@aptean.com Olaf Günther SW Dev olaf.guenther@aptean.com Holger Ritz Director Product Management DACH holger.ritz@aptean.com Hermann Nachtigal CIO hermann.nachtigal@hik-solutions.com Dennis Schramm ERP Systembetreuer dennis.schramm@hik-solutions.com

Expected initial timeline: TBD

BLU DELTA Perspective:

Why should we do this project and importance?

Expand BLU DELTA portfolio of supported documents Expansion of cooperation with Aptean

Requirements

General

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\HIK-Delivery-notes.md - Chunk 2
BLU DELTA Perspective:

Why should we do this project and importance?

Expand BLU DELTA portfolio of supported documents Expansion of cooperation with Aptean

Requirements

General

Requirement Customer Info Notes Document quanity per year num of documents and highlight if more than 2 pages per document average are expected ~20k annually (delivery notes) Input Channels What quality to expect: photo, scan, fax, online-digital scan, online-digital Regions and Languages What regions? Any dominating regions/language? Majority German/Germany Layout diversity expected number of suppliers, senders 713 in 2023 (Distribution of Top 10: 1.427 1.228 1.002 566 551 529 408 402 386 370 Special Security Req not required Special Performance Req not required Bounding Boxes not required Scores not required

Document Essentials

Samples with marks done by customer

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\HIK-Delivery-notes.md - Chunk 3
Detail Name (customer language) BLU DOC Detail Name CUSTOM INFO Head Information Sender Sender.Contact.Item (optional) Base data mapping done on Aptean side, based on Bestellnummer HIK, Sender UID, IBAN; Comment Aptean: "Beim Sender machen wir es genauso wie beim ERW. Zunächst nutzen wir die Bestellnummer, um den Geschäftspartner bzw. den Lieferanten zu ermitteln, da die Bestellung diesem zugeordnet ist. Sollte keine Bestellnummer übertragen worden sein, dann nutzen wir die Ust-ID und/oder die IBAN Nummer, um zumindest den Lieferanten angezeigt zu bekommen. Die Zuordnung zur korrekten Bestellnummer muss dann manuell geschehen." Empfänger Receiver.Contact.Item Not required for process, but in case AI model swappes sender and receiver, the receiver address could be used. To be aligned with Aptean, if this makes sense. Comment Aptean: "Beim Empfänger werden wir es auch so handhaben, wie beim ERW, indem der Kunde selbst für die Zuordnung verantwortlich ist. Soll das WE-Cockpit für andere

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\HIK-Delivery-notes.md - Chunk 4
Aptean, if this makes sense. Comment Aptean: "Beim Empfänger werden wir es auch so handhaben, wie beim ERW, indem der Kunde selbst für die Zuordnung verantwortlich ist. Soll das WE-Cockpit für andere Firmen zum Einsatz kommen, müssen eigene Pfade pro Firma/Mandant im System hinterlegt werden. HIK wäre dann dafür verantwortlich, dass die korrekten Lieferscheine im korrekten Ordner landen." - This statement does not clarify if contact is required. We assume for now it is required and therefore, we added also Sender.Contact Sender UID Sender.VatId For Sender mapping in base data IBAN BankAccount.Item For Sender mapping in base data Bestellnummer HIK ReceiverOrder.Id Starts with BE / AR / BK and consits of 11 digits. Sample: BE241008641; Will be used as main criteria for Sender Mapping, since an order is directly assigned to the Sender Lieferscheinnummer DeliveryNote.Id Lieferantennummer aus HIK System Sender.Id HIK secifies a supplier number per supplier and maintains it in it's base

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\HIK-Delivery-notes.md - Chunk 5
an order is directly assigned to the Sender Lieferscheinnummer DeliveryNote.Id Lieferantennummer aus HIK System Sender.Id HIK secifies a supplier number per supplier and maintains it in it's base data. The supplier is asked to print this number ion each delivery note. 5-7stellig numerisch (wenn 5stellig dann meist mit führenden Nullern) Belegdatum DeliveryNote.Date Deutsches / Englisches Datumsformat Line Items Line.Item Artikelnummer Lieferant Article.Id is maintained by HIK and linked to the internal HIK article number Artikelbescheibung ArticleDescription.String Artikelnummer HIK ReceiverArticle.Id in 95% der Fälle beginnend mit 7 und ist 6 stellig Stückzahl Quantity.Decimal Mengeneinheit Unit.Type Bestellnummer HIK Order.Id Starts with BE / AR / BK and consists of 11 digits. Sample: BE241008641 Charge Charge.String Any text, not on every delivery note Ursprungsland Origin.Country usually 2-3 chars, DE, AT, ... Zollposition / Zolltarifnummer CustomsTariff.Id 6-8 digit numeric,

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\HIK-Delivery-notes.md - Chunk 6
BE241008641 Charge Charge.String Any text, not on every delivery note Ursprungsland Origin.Country usually 2-3 chars, DE, AT, ... Zollposition / Zolltarifnummer CustomsTariff.Id 6-8 digit numeric, specified under https://www.zolltarifnummern.de/ - see comment below General OCR Fulltext DocumentText

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\HIK-Delivery-notes.md - Chunk 7
Zolltarifnummer Comment:

Ja, es gibt einen Unterschied zwischen einer Zolltarifnummer und einer Zollposition auf einem Lieferschein. Hier sind die Unterschiede:

Zolltarifnummer (auch Warennummer oder HS-Code genannt):

Die Zolltarifnummer ist ein international standardisierter Code, der zur Klassifizierung von Waren im internationalen Handel verwendet wird. Dieser Code basiert auf dem Harmonisierten System (HS) der Weltzollorganisation und hilft Zollbehörden, die Art der Waren zu identifizieren, Zölle zu berechnen und Handelsstatistiken zu führen. Sie besteht meist aus 8 bis 10 Ziffern (z.B. 1234.56.78.90), wobei die ersten 6 Ziffern international harmonisiert sind, während die letzten Stellen länderspezifisch sein können. Auf einem Lieferschein wird die Zolltarifnummer für jedes Produkt angegeben, um es korrekt zu deklarieren.

Data Mgt Requirements:

Agreed with customer that he does not have to label. We label BM ourselves.

BLU DOC Schema:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\HIK-Delivery-notes.md - Chunk 8
Data Mgt Requirements:

Agreed with customer that he does not have to label. We label BM ourselves.

BLU DOC Schema:

https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/2550/Delivery-Note-Schema

Attachments

Samples for delivery notes can be found under \nas-0a\CustomerData\Aptean Germany\HIK - DeliveryNotes\Delivery_20240923

Felddefinitionen: Felddefinition für Lieferscheinerkennung OCR BlueMatix Oxaion HIK.xlsx

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\X-Invoice.md - Chunk 0
X-Rechnung Requirements for DE

The german government has published a law that requires the majority of german companies to be able to receive invoices in a structured format. Details you can find here: https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/1921/e-Invoicing-EU-and-EU-Factsheet Therefore, BLU DELTA customers require support from BLU DELTA API to adhere to the new legislation

Timeline:

10.10.2024: First delivery for integration 25.10.2024: First version - delivery to customers for testing 25.11.2024: Functional Release candidate - delivery to customers for final testing 01.01.2025: Available for all customers Note: Support for custom fields need to be defined on a customer by customer basis

High Level Requirements for BLU DELTA API

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\X-Invoice.md - Chunk 1
X-invoice support (CII, UBL, Zugferd) Visualization of all XML fields for CII and UBL Endpoint for Invoice Capture is also used for X-Invoice without the need of any adaptation on customer side API JSON response: Fields of CII / UBL are mapped into Invoice API JSON response; the json response is ONLY extended but no breaking changes are allowed In UBL or CII embedded documents (especially referenced invoice pdf/docs/images) are returned by the JSON response / ZugFerd PDF is also returned; response need to be extended accordingly For UBL / CII XML only-formats a PDF for visualization is generated (marked as "generated non-original invoice") Received XML with invalid formats are rejected with an appropriate error message No bounding boxes provided in first version No result pdf supported in first version (marks on generated or embedded pdfs) Score (=confidence in BLU DOC) is set to 1 for XML mapped fields Ther first version will not support extraction of custom details.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\X-Invoice.md - Chunk 2
Supported / Mapped Fields:

Basic Mapping to Standard Format based on ZUGFeRD

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\X-Invoice.md - Chunk 3
API Response BLU DOC Details Details of ZUGFeRD-based Standard (InvoiceDescriptor for ULB and CII) Comments InvoiceType Invoice.Type Type For first version we map on only Invoice or CreditMemo; This means that except for CreditMemo all types are mapped to Invoice Currency Currency Currency InvoiceId Invoice.Id InvoiceNo InvoiceDate Invoice.Date InvoiceDate GrandTotalAmount GrandTotal.Amount GrandTotalAmount VatGroup Vat.Item Taxes[List] - VatRate - Vat.Rate Percent - NetAmount - Net.Amount BasisAmount - VatAmount - Vat.Amount TaxAmount VatExemption VatExemption.Type We set VAT Exemption if ALL of the entities of the Taxes list has the vat exemption set for VatExemption we check if invoiceDescriptor.ExemptionReasonCode != null OR !string.IsNullOrEmpty(ExemptionReason); Library problem: Can only parse enum values DueDateGroup Due.Item - DueDateDate - Due.Date PaymentTerms.DueDate - Due.Duration Discount.Item see PaymentTerms comment - Discount.Amount - Discount.Rate

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\X-Invoice.md - Chunk 4
Library problem: Can only parse enum values DueDateGroup Due.Item - DueDateDate - Due.Date PaymentTerms.DueDate - Due.Duration Discount.Item see PaymentTerms comment - Discount.Amount - Discount.Rate Payment.Discount.Item PaymentTerms.Description Not supported in first version, interpretation supported in later version - Due.Item NA - Discount.Item NA DeliveryPeriodGroup DeliveryDate.Item DeliveryDate - Delivery.Date ActualDeliveryDate - DeliveryPeriodDateStart - DeliveryPeriodStart.Date BillingPeriodStart - DeliveryPeriodDateEnd - DeliveryPeriodEnd.Date BillingPeriodEnd DeliveryNoteId DeliveryNote.Id Available in: DespatchAdviceReferenceDocument: ID There are unit tests but cannot write it to XML! Maybe we can get an example invoice, but could not even create any and also checked the 50 invoices from Chris. CostCenter.Id Not supported Customer.Id Not Supported ReceiverOrderId ReceiverOrder.Id OrderNo OrderNo is the Purchase Order Id ReceiverOrder.Date ReceiverOrder.Date OrderDate

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\X-Invoice.md - Chunk 5
50 invoices from Chris. CostCenter.Id Not supported Customer.Id Not Supported ReceiverOrderId ReceiverOrder.Id OrderNo OrderNo is the Purchase Order Id ReceiverOrder.Date ReceiverOrder.Date OrderDate SenderOrder.Id Not supported in first version - TO-DO: Check again SenderOrder.Date Not supported in first version - TO-DO: Check again CompanyRegistration.Id Not supported in frist version TO-DO: Check how this is represented in InvoiceDescriptor BankGroup BankAccount.Item CreditorBankAccounts[List] Iban - Bank.Iban IBAN Bic - Bank.Bic BIC - BankCode - Bank.Id Bankleitzahl - Account.Id NA Not supported VatId SenderVatId Sender.VatId SellerTaxRegistration[List].No, SchemeID=VA TO-DO: Check again if other tax numbers is represented? ReceiverVatId Receiver.VatId BuyerTaxRegistration[List].No TO-DO: Check again if other tax numbers is represented? How to deal with the list? TaxId SenderTaxId Sender.TaxId SellerTaxRegistration[List].No, SchemeID=FC German Steuernummer Receiver.TaxId Not

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\X-Invoice.md - Chunk 6
TO-DO: Check again if other tax numbers is represented? How to deal with the list? TaxId SenderTaxId Sender.TaxId SellerTaxRegistration[List].No, SchemeID=FC German Steuernummer Receiver.TaxId Not supported in first version Sender.Country TO-DO: Check WHY not from Contact? Receiver.Country TO-DO: Check WHY not from Contact? Sender.Id Custom Receiver.Id Custom IntraCompany.Flag Custom Sender/Receiver Contact.Item See Buyer, Seller and Ship To - Name - Contact.Name Name - Attention.Name ContactName - Address.Street - Contact.Street Street - Address.ZipCode - Contact.ZipCode Postcode - Address.City - Contact.City City - Contact.Region CountrySubdivisionName - Address.Country - Contact.Country Country - Contact.Website NA - Email - Contact.Email BuyerContact.EmailAddress - Phone - Contact.Phone BuyerContact.PhoneNo Sender Sender.Contact.Item Seller Receiver Receiver.Contact.Item Buyer LineItem Line.Item TradeLineItems - Position.Id - ItemId - Article.Id SellerAssignedId - Description -

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\X-Invoice.md - Chunk 7
BuyerContact.PhoneNo Sender Sender.Contact.Item Seller Receiver Receiver.Contact.Item Buyer LineItem Line.Item TradeLineItems - Position.Id - ItemId - Article.Id SellerAssignedId - Description - ArticleDescription.String Description - Quantity - Quantity.Decimal BilledQuantity Explanation: In standards there exists a BilledQuantity and a UnitQuantity; The BilledQuantity refers to the quantity that was billed, the UnitQuantity defines the Billed Unit (e.g. 10 [=BilledQuantity] times 5 [=UnitQuantity] kg [=Unit] packages - UnitPrice - Unit.SmallAmount NetUnitPrice vs. GrossUnitPrice TO-DO: Always map the NetUnitPrice (Assumption is htat NetUnitPrice is a required field in X-Invoices) - TotalAmount - Total.Amount LineTotalAmount - Order.Id BuyerOrderReferenceDocument - to be supported in later version - DeliveryNote.Id DeliveryNoteReferenceDocument - to be supported in later version - Unit - Unit.Type QuantityCode QuantityCode (e.g. C62) will be mapped 1:1 - VatRate - Vat.Rate TaxRate -

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\X-Invoice.md - Chunk 8
version - DeliveryNote.Id DeliveryNoteReferenceDocument - to be supported in later version - Unit - Unit.Type QuantityCode QuantityCode (e.g. C62) will be mapped 1:1 - VatRate - Vat.Rate TaxRate - DeliveryDate - DeliveryDate.Item ActualDeliveryDate - Discount.Item TO-DO: TradeAllowanceCharge not mapped in general format - maybe not supported in first version - CHECK AGAIN - Article.Type Not supported by standard - to be supported in later version QrCode.Item NOT REQUIRED ANYMORE, NOT SUPPORTED NO.K.Id NA CH.IsrReference NA CH.IsrSubscriber NA Transport.Hawb.Id NA Transport.Tour.Id NA Custom.PurchaseOrder.Id NA PaymentReferenceId PaymentReference.Id PaymentReference MISSING ShipTo Contact TO-DO: Is in BLU DOC but to be added to API response/ to be added in later version DuePayableAmount TO-DO: Add to BLU DOC, To be added in later version Notes PaymentMeans To be added in later version TaxBasisAmount OPEN TaxCurrency OPEN TaxTotal OPEN ExemptionReason per Tax OPEN ExemptionReasonCode

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\X-Invoice.md - Chunk 9
TO-DO: Add to BLU DOC, To be added in later version Notes PaymentMeans To be added in later version TaxBasisAmount OPEN TaxCurrency OPEN TaxTotal OPEN ExemptionReason per Tax OPEN ExemptionReasonCode per Tax OPEN TypeCode per Tax OPEN ReferenceOrderNo references a previous or related order information, not supported ReferenceOrderNo.BilledQuantity vs. UnitQuantity??

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\X-Invoice.md - Chunk 10
CII InvoiceTypeCodes

Common Invoice TypeCodes: 380: Invoice – A standard invoice issued by the seller to the buyer, requesting payment for delivered goods or services.

381: Credit Note – A document issued by the seller to provide a credit to the buyer, often due to overbilling or returned goods.

384: Corrected Invoice – A corrected version of a previously issued invoice, sent to amend errors in the original invoice.

386: Prepayment Invoice – An invoice issued to request payment in advance before goods or services are delivered.

383: Debit Note – A document issued to the buyer when there is a need to adjust or increase the amount owed (opposite of a credit note).

875: Self-Billed Invoice – An invoice created by the buyer on behalf of the supplier, commonly used in self-billing arrangements.

261: Pro Forma Invoice – A preliminary invoice provided before the actual sale, usually for customs purposes or as a quotation.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Approved-Features,Projects\X-Invoice.md - Chunk 11
261: Pro Forma Invoice – A preliminary invoice provided before the actual sale, usually for customs purposes or as a quotation.

388: Consolidated Invoice – A single invoice that consolidates multiple deliveries or transactions into one document for convenience.

Additional Types: 389: Final Invoice – The final invoice issued when the delivery or service is complete and all charges are finalized. 382: Partial Invoice – An invoice covering only part of the total agreed transaction (used when deliveries are made in stages).

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\ABD-(Ausfuhrbegleitdokument)---EAD-(Export-Accompanying-Document).md - Chunk 0
Supporting a new document called ABD (EX.1 or EAD) is requested by Dachser.

The ABD is a document that is intended to accompany the goods to be exported from the country. More precisely, goods that are commercially exported from e.g. Germany to a so-called third country, i.e. a non-EU country, e.g. goods that are shipped by truck to Switzerland or by ship to the United States. The ABD then accompanies the goods to the EU's external border, i.e. to the port or the national border of the third country. It is required by customs in order to be able to check whether the goods are subject to export restrictions or customs duties.

Information can be found under https://ausfuhrbegleitdokument.com/

Legal requirement from 01/01/2023

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\ABD-(Ausfuhrbegleitdokument)---EAD-(Export-Accompanying-Document).md - Chunk 1
Information can be found under https://ausfuhrbegleitdokument.com/

Legal requirement from 01/01/2023

Extract data from ABD will be important for all logistic companies from 01/01/2023 because of the following legal requirement: "die rechtliche Anforderung finden Sie im Merkblatt zu Zollanmeldungen... über folgenden Link: https://www.zoll.de/SharedDocs/Downloads/DE/FormulareMerkblaetter/Zollrecht/mb_zu_zollanmeldungen.pdf?__blob=publicationFile&v=11 auf Seite 61, Feld 18 09 000 0000 - Warennummer. Diese Info habe ich von unserer Zollabteilung bekommen. Wenn ich mir das "Merkblatt zu Zollanmeldungen..." bleiben aber einige Fragen offen. Vieleicht finden Sie mehr heraus. Diese Info habe ich von unserer Zollabteilung bekommen. Wenn ich mir das Merkblatt zu Zollanmeldungen... bleiben aber einige Fragen offen. Vieleicht finden Sie mehr heraus. "

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\ABD-(Ausfuhrbegleitdokument)---EAD-(Export-Accompanying-Document).md - Chunk 2
Relevante Stelle: Details: 18 09 000 000 - Warennummer Die achtstellige Warennummer der Kombinierten Nomenklatur ist verpflichtend, sobald der Wirtschaftsbeteiligte seine elektronische Versandanmeldung mittels ATLAS-Versand Release 9.1 (= Standard NCTS Phase 5) abgibt. Die Angabe ist bei der elektronischen Anmeldung eines TIR-Verfahrens nicht verpflichtend, es sei denn, in diesem TIR-Verfahren wird auf einen vorangegangenen Ausfuhrvorgang referenziert. Im Einheitspapier ist die Angabe im Feld Nr. 33 1. Unterfeld zu machen. Rechtsgrundlage siehe Titel I Abschnitt III Absatz 21 Nrn. 1 und 2. (Nachzulesen auf Seite 16)

ATLAS Zollsoftware - Automatisiertes Tarif- und Lokales Zoll-Abwicklungs-System

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\ABD-(Ausfuhrbegleitdokument)---EAD-(Export-Accompanying-Document).md - Chunk 3
ATLAS Zollsoftware - Automatisiertes Tarif- und Lokales Zoll-Abwicklungs-System

ATLAS ist ein EDV-Verfahren bzw. eine sog. Zollsoftware der deutschen Zollverwaltung zur Automatisierung der Zollabwicklung und zur internen Vorgangsbearbeitung. Mit ATLAS werden ehemals schriftliche Dokumente der Zollabwicklung durch elektronische Nachrichten im EDIFACT-Format ersetzt. Details under https://de.wikipedia.org/wiki/ATLAS_(Zollsoftware)

Required data from ABD

Basically the ABD is divided into Header and LineItem data.

Header data

Required fields: - Feld 2 :Consignor/Exporter incl. NO = Eori Nummer - Feld 5: Items - Feld 6: Total Packages - Feld 7: Reference Number - Feld 8: Consignee incl. NO = Eori Nummer

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\ABD-(Ausfuhrbegleitdokument)---EAD-(Export-Accompanying-Document).md - Chunk 4
Header data

Required fields: - Feld 2 :Consignor/Exporter incl. NO = Eori Nummer - Feld 5: Items - Feld 6: Total Packages - Feld 7: Reference Number - Feld 8: Consignee incl. NO = Eori Nummer

Further info from Dachser: - Feld 2 und Feld 8: Die Eori Nummer könnte durch eine Anbindung an eine DACHSER Datenbank abgeglichen werden. (sofern der Kunde bekannt ist, hat er auch eine EORI Nummer) (nicht Teil dieses PoCs) - Feld 5: Das Feld Items zeigt an wie viele Positionen das ABD hat (siehe Beispiel ABD mit 4 Positionen). Die Felder 31/2, 33, 35, 37, 38 müssen auf Positionsebene ausgelesen werden

Line Item data

Required fields: - Feld 31/2: description of goods - Feld 33: Commodity Code 8 stellig - Feld 35: Gross Mass - Feld 37: Procédure - Feld 38: Net mass

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\ABD-(Ausfuhrbegleitdokument)---EAD-(Export-Accompanying-Document).md - Chunk 5
Line Item data

Required fields: - Feld 31/2: description of goods - Feld 33: Commodity Code 8 stellig - Feld 35: Gross Mass - Feld 37: Procédure - Feld 38: Net mass

Further info from Dachser: - Feld 37: Hier gibt es nur wenige Varianten. Welche weis ich noch nicht genau. Diese könnten aber bestimmt hinterlegt werden - Feld 33: Der Commodity Code / Zolltarifnummer kann sicherlich auch als Datenbank hinterlegt werden. Die Zolltarifnummern sind im Internet zu finden. Dies müsste aber von blumatix aktuell gehalten werden. Keine Anbindung an DACHSER Datenbank sinnvoll.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\ABD-(Ausfuhrbegleitdokument)---EAD-(Export-Accompanying-Document).md - Chunk 6
Questions: - How is the workflow? Info from xbit/Hr. Schöddert: ABDs are received after the cargo-order has been created. The document needs to be assigned to the order and some of the data need to be added or compared. Esp. weights. See below info from Dachser - Why do they capture ABDs? There are several reasons for capturing ABDs. More details see below Use case Dachser. - Where does the ABD come from and at which step in the process? (Sequence of documents received) - Why does no order exist at this time? - legal requirement? - languages - realtime or batch processing?

Use Case Dachser

ATLAS is the Software-System of German Customs. ATLAS provides a WEB-GUI for occasional customs declarations (mainly for private individuals). Professional providers are connected e.g. via SAP or other customs software via interfaces with ATLAS. Different Dachser branches might be connected to ATALS via different software products.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\ABD-(Ausfuhrbegleitdokument)---EAD-(Export-Accompanying-Document).md - Chunk 7
Dachser provides customs declarations for their customers and receives the ABD from customs directly in that cases. The customer can also make the customs declaration himself, in which case Dachser receives the ABD from the customer. - Case A - Dacher does the customs declaration: The data which need to be provided to the customs come from various sources: from the forwarder order, from the commercial invoice, from external data sources such as a goods catalogue, the Internet, etc. Information provided: addresses, weights, prices, description of goods, ...

Case B - Dachser receives the ABD from the Customer: This can even happen before Dachser has created a forwarder order. Customer must create the ABD BEFORE the goods leave the factory premises. The ABD is valid for 90 days.

In around 60% of the cases, Dachser makes the customs declaration, in around 40% the ABD comes from the customer.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\ABD-(Ausfuhrbegleitdokument)---EAD-(Export-Accompanying-Document).md - Chunk 8
Common process if Dachser does the customs declaration: (e.g. from Germany to Switzerland) 1. Customer wants to have goods transported from A -> B 2. Dachser declares goods at customs: 2.1 Data for customs come from several sources 3. Dachser creates forwarder order to pick up goods from A and bring them to B 4. Dachser takes care about customs clearance (supplier, receiver, weights, duration, ...) 5. Customs officer leaves export customs declaration -> ABD with MRN returned via EDIFACT to customs software (using EDIFACT might be an alternative to gather the data from ABD - but only for internal documents. Dachser wants the same path for all - external as well as internal ABDs) Dachser not sure if EDIFACT contains as many data as Pdf-ABD. 6. transport 7. border -> freighter shows the Export MRN (Ausfuhr MRN) 8. Switzerland side: import customs clearance (Importverzollung)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\ABD-(Ausfuhrbegleitdokument)---EAD-(Export-Accompanying-Document).md - Chunk 9
In order to avoid stops of the freighter at the border -> Customs Transit Procedures (Zolltransitverfahren) -> Versandanmeldung -> copy data from ABD into form of transit procedures -> no SW-interface planned from customs! This has to be done manually.

realtime or batch processing: ABD should be processed after receipt. if this takes 10 or 20 minutes -> no problem!

languages: ~11-12, see examples

Customs documents

ABD: The Sender or the Forwarder creates this document at the customs. Description see above.

CMR (internationaler Frachtbrief): Needs to be present during transport. CMR means an international agreement on cross-border transportation that takes place over land. CMR is the abbreviation for "Convention relative au contrat de transport international de marchandises par route", in English: "International Agreement on Contracts for Carriage by Road".

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\ABD-(Ausfuhrbegleitdokument)---EAD-(Export-Accompanying-Document).md - Chunk 10
EUR.1 form (Warenverkehsbescheinigung): To determine the origin of the goods -> required for transport into third countries.

Delivery slip (Lieferschein): Describes the goods, created by sender and determined for the receiver. Is enough for national transports where no CMR is needed.

Side information

Forwarder (Spediteur): organizes the transport, third-party means of transport

Freighter (Frächter): own means of transport, carries out the transport at his own expense

Logistician (Logistiker): warehouse keeper (divide, repackage); everyone scolds

Dachser = Forwarder and Logistician, but no freighter!

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\ALD-Quotations.md - Chunk 0
Current Status:

Milestone Plan:

Milestone Date Status Notes Data delivered and ready for labelling 27.7. Data delivered BLU DOC response aligned 4.8. done Static endpoint available 10.8. (17.8.) done LearnAPI endpoint spec delivered 1.9. Validation Tool – First version Mid-End of September (In October Marco on holiday) LearnAPI integration done 20.10. ALD Quotation Header model (Mileage, Plate, etc.) and line-item model (no VAT Groups) 26.10. First Live Deployment Improved Models incl. VatGroup 9.11. First tests ALD with friendly users 13.11. earliest Final Launch with trained models and new validation tool End of November

Next Actions:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\ALD-Quotations.md - Chunk 1
Next Actions:

AP: Provide Learn API specification to ALD (Chris) AP: Align the schedule with ALD (Chris) AP: Chris to prep JSON static response - done AP: Team to implement story to deploy static response - done AP: Klemens to add SenderTaxId to Labelling - done AP: Klemens to import data - 5k done AP: 300 available by end of August AP: Plan to be revised after initial data review/labelling done - done AP: Chris to plan milestone when header models can be ready - ongoing

ALD Automotive

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\ALD-Quotations.md - Chunk 2
ALD Automotive

is a brand of the ALD Autoleasing GmbH. ALD is a fleet management and leasing company. They recently acquired their biggest competitor leaseplan. ALD processes quotations and invocies from car repairshops. For invoices they currently work with a service provider who extracts header and line items data from invoices. Quotations are still completely manually processed by profesisonal stuff, in order to release a repair or not. The capturing should be automated with BLU DELTA, the subsequent release process will be automated by ALD itself.

Industry

Automotive

Business Goal

Blumatix's goal is to win ALD as a customer. Potential is ~1M quotations and invoices annually. We can achieve this through a high level of acceptance of the new process among the ALD service employees, which can only be achieved with - high out of the box recognition rate of header data and line items AND - through a close cooperation with the ALD projectteam

Use Case

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\ALD-Quotations.md - Chunk 3
Use Case

BLU DELTA API for quotations, later for invoices. BLU DELTA LearnAPI for continuous improvements. Validation view is implemented by ALD and will be used to provide feedback for header data and line items including coordinates!

Customer Main Stakeholders, Contacts

Names Role Contact Anika Grimm PO accounting and release process anika.grimm@aldautomotive.com Marco Jeffrey Pansa Data Scientist; PM on ALD side and will provide the data marcojeffrey.pansa@aldautomotive.com

Expected initial timeline:

See Kickoff slides under Attachments

BLU DELTA Perspective:

Why should we do this project and importance?

High volume customer, important revenue! New document type quotations, expect important training improvements through high quality feedback esp. for line items.

Requirements

General

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\ALD-Quotations.md - Chunk 4
High volume customer, important revenue! New document type quotations, expect important training improvements through high quality feedback esp. for line items.

Requirements

General

Requirement Customer Info Notes Document quanity per year num of documents and highlight if more than 2 pages per document average are expected ~1M annually (invoices and quotations) Input Channels What quality to expect: photo, scan, fax, online-digital scan, online-digital Regions and Languages What regions? Any dominating regions/language? Majority German/Germany Layout diversity expected number of suppliers, senders ALD is working with ~30k repair shops, but probably many of them use the same layout. Clustering should bring light into the dark. Special Security Req expected number of suppliers, senders ALD is subject to BAFIN which means strict requirements for us. Possibly goes towards OnPremise. Special Performance Req expected number of suppliers, senders Nothing known yet.

Document Essentials

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\ALD-Quotations.md - Chunk 5
Document Essentials

Samples with marks done by customer

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\ALD-Quotations.md - Chunk 6
Detail Name (customer language) BLU DELTA Detail Name CUSTOM INFO Head Information Issue Date QuotationDate OrderId ReceiverOrderId Issue Date QuotationDate new field:The date of issue QuotationId new field Total gross amount GrandTotalAmount Total VAT amount per Tax rate VatGroup Total Net amount VatGroup Need to be aligned with ALD - we deliver the NetAmount per Taxrate, as given on the document. PlateNumber PlateId new field VinNumber VinId new field FirstRegistrationDate FirstRegistrationDate new field - date when car was first registered. Mileage Mileage new field - the given mileage of the car.  Supplier Name Sender.Name Street Sender.Address.Street Zip Sender.Address.ZipCode City Sender.Address.City Country Sender.Address.Country VAT Account ID SenderVatId Sender Tax ID SenderTaxId Added afte initial order - discussed 27.7.2023, especially German Tax Number IBAN Iban  Customer/Invoice Recipient Name Receiver.Name Street Receiver.Address.Street Zip Receiver.Address.ZipCode City

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\ALD-Quotations.md - Chunk 7
Added afte initial order - discussed 27.7.2023, especially German Tax Number IBAN Iban  Customer/Invoice Recipient Name Receiver.Name Street Receiver.Address.Street Zip Receiver.Address.ZipCode City Receiver.Address.City  Line Items Article-Number LineItem.ItemId Text LineItem.Description Unit Price LineItem.UnitPrice Quantity LineItem.Quantity VAT Rate LineItem.VatRate Price LineItem.TotalAmount

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\ALD-Quotations.md - Chunk 8
Provided Data under \\nas01\customerdata

Uploaded data must follow directory structure: - Main dir:

Attachments

Blumatix_ALD_KickOff_20230718.pdf

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Auto-Complete-feature-(Facility-Service).md - Chunk 0
For our Storefront RIPEye we need an Autocomplete feature.

Use Case:

In the frontend we need to be able to search an approver of an invoice against customer base data. The base data is provided through a rest API via a *.csv file The csv file (tab separateor) lands on our Azure Storage.

A RIPEye-frontend user should be able to search for values matching his input against based data of our customers. Thus, when user inputs 3 chars the search should be activated and repeated when user enters more details. The candidates returned by the search can be selected by the customer. There more characster the less candidates should be shown. The base data was imported through a backoffice process (csv upload).

Further requirements

It should be a generic approach. This means that any csv file can be processed.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Auto-Complete-feature-(Facility-Service).md - Chunk 1
Further requirements

It should be a generic approach. This means that any csv file can be processed.

We have many customers. And many customer can upload a csv file. The customer name is part of the file name. So, there must be a naming scheme based on FileName and Header csv names to search for specific details for a customer. Based on this naming schema the storefront developer can implement the search against Elastic Search.

An update or upload of the csv file into AzureStorage triggers a full import into ElasticSearch.

Ideally an import should not interrupt search from frontend.

It should be deployable in a Kubernetes cluster (Docker).

Ideally there should be a swagger like ui interface to trigger an ElasticSearch search request for testing.

TSV file entries

Search library is available under a free license?

Simple Example of csv file | ID | FIRSTNAME | LASTNAME | EMAIL | |--|--|--|--| |1|Chris|Weiler|c.weiler@blumatix.com| |2|Hans|Bauer|h.bauer@blumatix.com| ...

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Auto-Complete-feature-(Facility-Service).md - Chunk 2
Simple Example of csv file | ID | FIRSTNAME | LASTNAME | EMAIL | |--|--|--|--| |1|Chris|Weiler|c.weiler@blumatix.com| |2|Hans|Bauer|h.bauer@blumatix.com| ...

AFTER DISCUSSION WITH ING SW: AP: Julian/Milos/Andrija to clarify how to deal with "SAINT GOBAIN" edge case, how to access Azure Storage or Elastic instead Elastic is Apache License - free to use AP: ING-SW (Milos) to come back with estimate and timeline

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Automate-Support-Invoice-Import-and-Analysis---First-Step.md - Chunk 0
Brainstorming based on following scenario

Import invoice via ZIP batch upload

Find out ID of imported invoice

How to add issue number to imported invoice

Label imported invoice with label tool

Analysis tool frequently checks for new invoices with an issue number in file name?

If there are new entries - analysis tool is started frequently (via Kubeflow?) and resulting analysis data written into db

Andrea can setup tool to check entries (e.g. Power BI) - or go directly to DB

Notes: Folder in Azure Storage should be named like in the BCI TO-DO: Get Names from BCI (Dashboard) - Filter in Dashboard - Invoices (Andrea) TO-DO: ZIP Uload description sent to Andrea TO-DO: Filename pattern: includes - Identifier for Support + issue number + invoice detail nr (Andrea - aligns with Sara) TO-DO: Sara talks with Rudi regarding Kubeflow integration (Call Phoenix) TO-DO: Architecture check with Rudi (Chris)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Avvaneo---Krauss-Maffei-Support.md - Chunk 0
avanneo is a pioneer in next-level automation of financial processes with SAP and partner of Blumatix.

For our first mutual customer Krauss Maffei Extrusion GmbH we need Email as input channel.

Project Details and Requirements

Phase 1

Will start beginning of March, duration ~1 week followed by a few weeks test phase. - No. of transactions: 5k monthly, 20-30k future potential - Countries: Startphase Germany, later international, countries unknown yet. - Input Channel: EMail Scans will be sent via Email as well - Download endpoint (existing RIPEye Download endpoint?) - Accounting areas (Buchungskreise): Required; about 40; No extraction is required, it is just information that comes from the email sender and must be included in the downloaded data. Similar to mandators. - Splitting: No - User Experience: No - is done by avvaneo in SAP - Base data comparison: No - is done by avvaneo in SAP - Required fields: t.b.d. but most likely standard fields; line items t.b.d.

Phase 2

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Avvaneo---Krauss-Maffei-Support.md - Chunk 1
Phase 2

No. of transactions: potentially 20-30k monthly

Countries: international, countries unknown yet.

Feedback loop: avvaneo wants to provide feedback data incl. coordinates

Input Tracking: We need a mechanism to track every incoming email and document.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Create-a-pdf-text-service.md - Chunk 0
Goal: Implement a module that creates a pdf out of an image and related OCR Text

The pdf is stored in a pre-configured folder or network link with a unique file name (

Input:

Image (same format as for like in easyocr service) - png, jpg, tiff OCR results: OCR format like we created for easyocr

Output:

PDF file that includes OCR result and pdf text-layer in a output directory; (in an adobe pdf reader text can be marked and copied)

Integration test:

WIth the package there must a smoke test included with the provided test data that verifies that installation works.

Required Log Output:

Every run should create its own log file with timestamp The log should show every request processed and output errors if any issues occurred with proper error stack

Required Installation instructions

The delivered package must include a readme.txt explaining Prerequisites for installation and running component Installation procedure Usage How to run smoke test

Final delivery:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Create-a-pdf-text-service.md - Chunk 1
The delivered package must include a readme.txt explaining Prerequisites for installation and running component Installation procedure Usage How to run smoke test

Final delivery:

Docker image and source code (incl. PyTest), readme file

Configuration:

Pls use hydra for any configuration (https://hydra.cc/ )

Logging:

Best Practice: hydra: https://hydra.cc/

API:

The API must support following URIs: /v1/MergeImageOCR2PDF /v1/Version -> returns simple string wit actual version information as x.y.z /v1/Ping -> returns emptry response with http status 200

All of following situations must be logged: System crashes or a status of total system failure must be logged with highest criticality in the logs Failures leading to unsuccessful requests must be logged as 2nd level criticality Uncommon situations should have warning level Important information helfpul to analyse issuee should have INFO or DEBUG level

Code Sample from ChatGPT like below:

import fitz

# Load the image

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Create-a-pdf-text-service.md - Chunk 2
Code Sample from ChatGPT like below:

import fitz

# Load the image

image_path = 'your_image.jpg'

image = fitz.open(image_path)

# Create a new PDF document and insert the image

pdf = fitz.open()

pdf.insert_image((0, 0, 0, 0), image_path)

# Add OCR results to the PDF

page = pdf[0]

# Assuming you have a list of OCR results with position information

# Example: [(text, x, y, width, height), ...]

ocr_results = [

('Text1', 100, 100, 200, 30),

('Text2', 200, 200, 300, 30),

# ...

for text, x, y, width, height in ocr_results:

# Create a rectangle with the position and size

rect = fitz.Rect(x, y, x + width, y + height)

# Add the text to the PDF with the position and size

page.insert_textbox(rect, text, fontsize=12, fontname="times")

# Save the PDF

pdf.save('output.pdf')

pdf.close()

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Create-Deployable-PaddleOCR-Service.md - Chunk 0
Create Deployable PaddleOCR

Goal:

After the EasyOCR service a similar service based on Paddle should be created (based Docker, REST Service and latest paddle version). The goal is that the BLU DELTA team can deploy the container in the Kubernetes environment without much manuel intervention. The containers responsibility is the recognition of region, lines and words on images (for now not for pdf-based documents). If Paddle does not support region and/or lines then it should be treated in the same way as for EasyOCR.

The

The containers BLU DELTA Standard OCR interface is specified below as well as the container requirements.

Technical Specification:

Technologies will be based on: -Python - OCR-Service be based on the following technologies: - Python 3.8 or 3.9 - Flask shall be used as web framework - The service shall also run in a linux based docker container with configurable GPU/CPU support! A Dockerfile etc. must be provided.

OCR-Request:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Create-Deployable-PaddleOCR-Service.md - Chunk 1
OCR-Request:

Should contain a list of document pages as images - Images shall be processed in parallel

Configuration: AdditionalProperities - a dictionary

Lanugage need to be provided as input param in the dictionary, ISO 2 letter codes

OCR-Response: An OCRResult shall be returned as a json string for every document that is sent to the OCR-Service. The OCRResult shall be returned in the following json format:

IDs must be unique. integer

Orientation: part of paddle? if not set it to null

```json

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Create-Deployable-PaddleOCR-Service.md - Chunk 2
IDs must be unique. integer

Orientation: part of paddle? if not set it to null

```json

{ "Language": {}, "Orientation": "string", "Regions": [ { "Lines": [ { "Words": [ { "Id": 0, "Text": "string", "BoundingBox": { "Left": 0, "Top": 0, "Width": 0, "Height": 0, } } ], "BoundingBox": { "Rectangle": "string", "Left": 0, "Top": 0, "Width": 0, "Height": 0, } } ], "PageNo": 0, "BoundingBox": { "Rectangle": "string", "Left": 0, "Top": 0, "Width": 0, "Height": 0, } } ], "NumberOfPages": 0, "PageInfos": [ { "Index": 0, "ResolutionX": 0, "ResolutionY": 0, "Width": 0, "Height": 0, "Orientation": "string", "PageBitmapB64": "string", } ] }

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Create-Deployable-PaddleOCR-Service.md - Chunk 3
```

Description of the Json-Format

Region: A single page may be divided into logical regions (blocks). If the OCR engine doesn't support regions than there will always be a single region per document page.

Line: A line consists of 1 or many words which logically belong together. Line can be a sentence, a phrase etc. A line has a bounding box.

Word: Represents a single word. A word has a text field which contains the characters of that word and a bounding box.

PageInfo: Addiotnal page information

In case there are any open points then the general rule is to make it equal to EasyOcr service.

ACCEPTANCE CRITERIA:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Create-Deployable-PaddleOCR-Service.md - Chunk 4
PageInfo: Addiotnal page information

In case there are any open points then the general rule is to make it equal to EasyOcr service.

ACCEPTANCE CRITERIA:

Docker Image delivered can be deployed in Blumatix Cloud Service can be started and is up and running in Blumatix Cloud Demo: Sending multi page document to service and retrieve response as defined Exceptional cases demo: - Empty image / Large image / small image - No language sent - use default language / default is German Unit Test for this cases based on PyTest available

Final delivery:

Docker image and source code (incl. PyTest), readme file

Configuration:

Best Practice: hydra - color log; (https://hydra.cc/)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Create-Deployable-PaddleOCR-Service.md - Chunk 5
Final delivery:

Docker image and source code (incl. PyTest), readme file

Configuration:

Best Practice: hydra - color log; (https://hydra.cc/)

All parameter of paddle method should be set via configuration: -- via dictionary in request (dictionary, same name as in original input but starting with method name: "methodname.paramname" - e.g. readtext.detector) -- and/or in default configuration which should be in a config.yaml file as part of github project ./config/config.yaml -- config for GPU vs. CPU need to be configurable

Logging:

Best Practice: hydra: https://hydra.cc/

All of following situations must be logged:

System crashes or a status of total system failure must be logged with highest criticality in the logs

Failures leading to unsuccessful requests must be logged as 2nd level criticality

Uncommon situations should have warning level

Important information helfpul to analyse issuee should have INFO or DEBUG level

Swagger openapi endpoint must be supported

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Create-Deployable-PaddleOCR-Service.md - Chunk 6
Uncommon situations should have warning level

Important information helfpul to analyse issuee should have INFO or DEBUG level

Swagger openapi endpoint must be supported

Functional:

image should not be stored as file, it should be retrieved as bytearray and then directly fed to paddle (no file stored in between)

Timeline:

Final component: 30.1.

Compliance to Definition of Done (sent before)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Create-LLMChat-Application.md - Chunk 0
GOAL:

Create a simple chat application that allows the BLU DELTA team to test and interact with the onsite LLama models

Technical Goals:

Use Text Generation Inference Server as interface and intermediate later for LLM models: https://huggingface.co/text-generation-inference Create a streamlit application based on following sample: https://blog.streamlit.io/how-to-build-an-llm-powered-chatbot-with-streamlit/ Note: In the example the streamlit application is not yet integrated into Text Generation Inference Server - this needs to be accomplished

Deliverable:

streamlit application in a Docker image Source code Readme file - Required Installation instructions - Connection String, Config for Text Generation Inference Server - Prerequisites for installation and running component - How to Smoke Test after installation

Configuration: Pls use hydra for any additional configuration (https://hydra.cc/ )

Expected High Level Tasks:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Create-LLMChat-Application.md - Chunk 1
Configuration: Pls use hydra for any additional configuration (https://hydra.cc/ )

Expected High Level Tasks:

Use same email for hugging face and Meta to get Text Generation Inference Server and e.g. LLamaa 13B (or optional other LLM supported). Use one of the following models. Maybe you have to use 4 or 8bit quantization

meta-llama/Llama-2-7b-chat-hf

meta-llama/Llama-2-13b-chat-hf

Get it up and running locally

Get code for streaming lit app

Adapt code to connect to Text Generation Inference Server

Once tested and working, wrap up and provide your work

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\CSS-Expenses.md - Chunk 0
Business Goal

Win CSS as a partner and show them that we are the best of the best.

Use Case

BLU DELTA API as part of a expense management smartphone app. The customer takes a photo of his receipt, which is sent to the BLU DELTA expense API. This sends the extracted data back, the customer verifies and completes it and forwards it to his company. CSS currently has 37k users of their expenses app.

Customer / Partner Main Stakeholders, Contacts

Names Role Contact Winfried Siener CTO Winfried.Siener@css.de Frank Böttiger CPTO Frank.Boettiger@css.de

Expected initial timeline:

4.4.: Provide expenses endpoint with static BLU-DOC response 25.4.: Expenses endpoint includes model, faster than standard API but not yet the desired 4-5s.

Next steps: - Further performance improvement - separate expenses-model - expenses classification

BLU DELTA Perspective

Why should we do this project and importance?

Implement first use case with CSS New document type Expenses

Available Samples

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\CSS-Expenses.md - Chunk 1
BLU DELTA Perspective

Why should we do this project and importance?

Implement first use case with CSS New document type Expenses

Available Samples

\nas-01\CustomerData\CSS

Requirements

General

Requirement Customer Info Notes Document quantity per year num of documents and highlight if more than 2 pages per document average are expected very rough estimation from CSS: 650k; my guess: far below Input Channels What quality to expect: photo, scan, fax, online-digital photo Regions and Languages What regions? Any dominating regions/language? Majority German/Germany Layout diversity expected number of suppliers, senders potentially high; hotel invoices, Cash receipts, hand written taxi receipts, train tickets, hospitality receipt... Special Security Req Special Performance Req 4-5 sec.

Document Essentials

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\CSS-Expenses.md - Chunk 2
Document Essentials

Detail Name (customer language) BLU DELTA Detail Name CUSTOM INFO Header Information Invoice Date InvoiceDate Invoice Number Invoice Id Vat Group VatGroup Grand Total Amount GrandTotalAmount Document Type DocumentType future topic: expenses-classification. e.g. Taxi receipt, parking ticket, hospitality, train ticket, plane ticket -> to bee aligned with CSS

Further infos

Supplier data not required. Country-dependent documents do occur - but we shouldn't necessarily focus on that. Robert Lindner probably sees it differently. Handwritten documents are coming – but we shouldn’t necessarily focus on that either. However, Robert Lindner loves his handwritten taxi receipt.

Belegtypen lt. ChatGPT

Fahrtkosten:

Bahn, Bus, Flugzeug, Taxi: Fahrkarten und Quittungen. Privatfahrzeug: Kilometerpauschale, ggf. Parkgebühren. Mietwagen: Mietvertrag und Quittungen für Treibstoff. Übernachtungskosten:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\CSS-Expenses.md - Chunk 3
Fahrtkosten:

Bahn, Bus, Flugzeug, Taxi: Fahrkarten und Quittungen. Privatfahrzeug: Kilometerpauschale, ggf. Parkgebühren. Mietwagen: Mietvertrag und Quittungen für Treibstoff. Übernachtungskosten:

Hotelrechnungen, die detailliert sein sollten (Unterbringung getrennt von Verpflegung). Verpflegungsmehraufwendungen:

Pauschalbeträge für Verpflegungsmehraufwendungen bei Abwesenheit von mehr als 8 Stunden. Nebenkosten:

Kommunikationskosten: Telefon, Internet. Gepäckaufbewahrung, Trinkgelder, Eintrittsgebühren für berufsbedingte Veranstaltungen. Parkgebühren, Mautgebühren. Weiterbildungskosten:

Seminargebühren, Kosten für Fachliteratur. Arbeitsmittel:

Notwendige Anschaffungen, die direkt mit der beruflichen Tätigkeit zusammenhängen. Kommunikationskosten:

Gebühren für berufliche Telefonate, Internetnutzung. Repräsentationskosten:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\CSS-Expenses.md - Chunk 4
Notwendige Anschaffungen, die direkt mit der beruflichen Tätigkeit zusammenhängen. Kommunikationskosten:

Gebühren für berufliche Telefonate, Internetnutzung. Repräsentationskosten:

Bewirtung von Geschäftspartnern, Geschenke innerhalb der steuerlichen Grenzen. Diese Belegklassen decken die gängigsten Arten von Ausgaben ab, die bei berufsbedingten Aktivitäten entstehen können. Es ist wichtig zu beachten, dass die Anerkennung und Erstattung von Ausgaben unternehmensspezifischen Richtlinien unterliegt und auch von steuerlichen Vorschriften beeinflusst wird. Unternehmen können beispielsweise eigene Grenzwerte für die Erstattung bestimmter Ausgaben festlegen oder zusätzliche Beleganforderungen stellen.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\CSS-Expenses.md - Chunk 5
Zudem ist es essenziell, dass alle Belege den Anforderungen an eine ordnungsgemäße Buchführung entsprechen: Sie sollten vollständig, nachvollziehbar und im Original eingereicht werden. Digitale Belege und elektronische Rechnungen gewinnen zwar zunehmend an Akzeptanz, es empfiehlt sich jedoch, die unternehmensinternen Richtlinien bezüglich der Form und Aufbewahrung von Belegen zu beachten.

Beispiel Belegkategorien von "Spesenfuchs"

Aufmerksamkeiten Benzin, Autowäsche (Laufende Kfz-Betriebskosten) Bewirtungskosten Bürobedarf Bus/Bahn/Fähre Buß-/Verwarnungsgeld Citytax Durchlaufende Posten Fahrzeugkosten Flug Fortbildungskosten Fremdarbeiten Vertrieb Garagenmiete Geringwertiges Wirtschaftsgut Geschäftsraummiete Geschenke Hotel Kfz-Kosten für betriebl. genutzte Kfz (Privatvermögen) Kfz-Reparaturen Kfz-Steuern

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\CSS-Expenses.md - Chunk 6
Kfz-Versicherungen Ladekosten Kfz Mautgebühren Mietleasing Kfz Mietwagen (incl. Kraftstoff Mietwagen) Nicht abzugsfähige Bewirtungskosten Parkgebühren Porto Reisekosten allgemein Reisenebenkosten Repräsentationskosten Sonstige Kfz-Kosten Sonstige betriebliche Aufwendungen Taxi Telefax und Internetkosten Telefon Trinkgeld Zeitschriften, Bücher

Attachments

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-Order-confirmations.md - Chunk 0
Intro

Dachser wants to digitize its Purchase Organisation and therefore wants to automate the processing of order confirmations.

Contacts:

Main Contacts: Tobias: Product Owner KTA side; finish project until October Ezgi: Substitute for Tobias Other Contacts: Jacqueline Zettler: Project Manager Nikol: IT product owner Avvaneo: Mateusz - Avaneo Developer Team Lead of Material SAP: Werner Hiller

Tobias and Ezgi are our main contacts! Responsible for KTA and read ou of order confirmation

Goal

Complete automatic processing of incoming orders (reduce manual work) not expected.

Key facts

Dachser processes ~30k documents annually. Most vendors are Germany based, ~10 != Germany. Languages German and English only. LearnAPI required: Dachser wants to give feedback to improve the extraction quality. - values only Phase 1: - will include just 15k - only It-purchasing department will be integrated

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-Order-confirmations.md - Chunk 1
Though initially Dachser said that historic data can be provided, this has changed. All data must be labelled.

Dachser would provide the purchase order information via our resource upload. In order to ensure that the PO information is uploaded before the corresponding confirmation is processed, Dachser would postpone the confirmation processing to the next day.

Expected Timeline:

Date Milestone Description 28.7. Integration Start with final endpoint and static response 01.09. Integration Start Learn API 06.10. Learn API active and docs go into training and improve results 13.10. API First version: Header and Line Items but no addresses! 09.11. API Second version: Addresses added 23.11. Ready4GoLive, TRR ~70%

Required fields

Header data

Order confirmation number

Creation date of confirmation document (= DocumentDate)

Order number (open order numbers are in SAP and also exported by CSV file on a daily basis to a digidocs folder)

Delivery address

Invoice address

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-Order-confirmations.md - Chunk 2
Order number (open order numbers are in SAP and also exported by CSV file on a daily basis to a digidocs folder)

Delivery address

Invoice address

Delivery date (can be header data, can be on position)

OUT-OF-SCOPE for 2023: - Surcharge (Dachser/SAP term: "terms of condition") - Internal addition (not requested by Dachser): - Delivery terms / Incoterms For Röchling a must, for Dachser not required - Position data - position number - supplier material number (Dachser internal number) - amount of the material (Quantity and unit) - delivery date - item price - total price

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-Order-confirmations.md - Chunk 3
OUT-OF-SCOPE for 2023: - surcharge: "terms of conditions" - for Dachser it seems they have only freight charges, but there exist more on the markets: -- Versand- und Handling-Gebühr (inkudiert auch Verpackung): ShippingSurcharge -- Treibstoff: FuelSurcharge -- Umweltzuschlag: EnvironmentSurcharge -- Servicezuschlag: ServiceSurcharge -- Zahlungsmethode: PaymentSurcharge -- Note: Surcharges: Can be a "rate" or "amount"

Regarding the delivery date, it is currently the case that we mainly receive order confirmations for the entire positions and therefore no more than one delivery date is printed per position.

1 Purchase order can result in >1 Order confirmations

Technical Delivery - 8.9.:

Dachser-OrderConfirm-MVP-Requirements-V2.pptx Dachser-OrderConfirm-MVP-Requirements-V1.pptx

Samples:

General: Samples can be found under \nas-01\CustomerData\Dachser\Order_Confirmations

Sample without Surcharge

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-Order-confirmations.md - Chunk 4
Samples:

General: Samples can be found under \nas-01\CustomerData\Dachser\Order_Confirmations

Sample without Surcharge

Auftrag_2000170003.pdf BLUDOC-V6-OrderConfirm-Sample-2023-07-13-cancom-ordernr-2000170003.json

Offer:

Blumatix_OrderConfirmation-AN060423.pdf Blumatix_OrderConfirmation-AN060731.pdf

Samples with surcharge:

Data Management Status

Required fields

Header data

Order confirmation number | Ready to Label:: OrderConfirmationId

Creation date of confirmation document (= DocumentDate) | Ready to Label:: OrderConfirmationDate

Order number (open order numbers are in SAP and also exported by CSV file on a daily basis to a digidocs folder) | Ready to Label: ReceiverOrderId ~~DachserPurchaseOrderId~~

Delivery address | Add possible value to Label SenderReceiverClassification: Delivery

Invoice address | Add possible value to Label SenderReceiverClassification: Invoice

Delivery date (can be header data, can be on position) | Ready to Label : DeliveryDate

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-Order-confirmations.md - Chunk 5
Invoice address | Add possible value to Label SenderReceiverClassification: Invoice

Delivery date (can be header data, can be on position) | Ready to Label : DeliveryDate

Surcharge (Dachser/SAP term: "terms of condition") | Ready to Label:: Surcharge with SurchargeType, SurchargeRate, SurchargeAmount

Internal addition (not requested by Dachser):

Delivery terms / Incoterms For Röchling a must, for Dachser not required | Ready to Label:: DeliveryTerm

Discount (can be header data, can be on position) [Addon from Röchling] | Decision needed: Naming of Discount and PaymentDiscount (Rabatt vs. Skonto)

Net Amount [Addon from Röchling] | Ready to Label: NetTotalAmount

Order number [Addon from Röchling] | Ready to Label: SenderOrderId, ReceiverOrderId

Position data

Position Number |Ready to Label: LineItemPositionNumber

supplier material number (Dachser internal number) |Decision: just one material id: LineItemArticleNumber

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-Order-confirmations.md - Chunk 6
Position data

Position Number |Ready to Label: LineItemPositionNumber

supplier material number (Dachser internal number) |Decision: just one material id: LineItemArticleNumber

amount of the material (Quantity and unit) | Ready to Label: LineItemUnit, LineItemQuantity

delivery date | Ready to Label: DeliveryDate

item price | Ready to Label: LineItemUnitPrice

total price | Ready to Label: LineItemTotalAmount

surcharge: "terms of conditions" - for Dachser it seems they have only freight charges, but there exist more on the markets: | Create Label Type: ArticleType -- Versand- und Handling-Gebühr (inkudiert auch Verpackung): ShippingSurcharge -- Treibstoff: FuelSurcharge -- Umweltzuschlag: EnvironmentSurcharge -- Servicezuschlag: ServiceSurcharge -- Zahlungsmethode: PaymentSurcharge -- Note: Surcharges: Can be a "rate" or "amount"

Internal addition to Position data

Customer Article number [Addon from Röchling] Decision: no additional label

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-Order-confirmations.md - Chunk 7
Internal addition to Position data

Customer Article number [Addon from Röchling] Decision: no additional label

Expected quantity [Addon from Röchling] | Not implemented now

Discount (can be header data, can be on position) [Addon from Röchling]| Ready to Label: LineItemDiscount

Delivery date (can be header data, can be on position) – can either be fixed date but also relative (e.g. Guarantee next day) [Addon from Röchling] | Create Label Type - Q: How to label "Guarantee next day"?: LineItemDeliveryDate

Description [Addon from Röchling] | Ready to Label: LineItemDescription

PackagingUnit [Addon from Röchling] | Not implemented now AB_IVS_30-42628-1.pdfAB_Conrad_1097924567.pdf

Kick-off doc:

20230531_SAP_MM_AFI_Confirmation_Kick_Off_Meeting_Presentation.pdf

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-Trading-invoices.md - Chunk 0
Dachser asks for a solution to process "trading invoices". In this use case Dachser processes invoices for some of their customers, e.g. Stihl, Mahle a.o.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-Trading-invoices.md - Chunk 1
The key data of the process are: (Dachser comments in blue) - A pdf can contain more than one invoice Yes + we have also learned that a pdf can also contain other documents (e.g. packing list). But there is no interesting information in there, but should be ignored. As far as I have seen, "Invoice" or something similar is written on all invoice pages, so that this can possibly be used as identification - The following fields must be read out per invoice (and thus several times per PDF): - InvoiceId - DeliveryNoteId - at header data level, i.e. one delivery note number per invoice (Yes, in most cases. However, there are few cases where the delivery note number is specified at line item level. It is ok if not all numbers can be read automatically, but the user interface should be able to enter several numbers manually.) - part number according to regex below - no AI model; several per invoice possible - Quantity per part number (always piece, no unit required) - Languages: Your examples

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-Trading-invoices.md - Chunk 2
several numbers manually.) - part number according to regex below - no AI model; several per invoice possible - Quantity per part number (always piece, no unit required) - Languages: Your examples are all in English, are there more? If yes, which? Mostly English, otherwise German, Italian, Spanish - You need a graphical interface for correction options including feedback for training the AI. (Regex will not learn) Yes, the target system does not offer a suitable interface for this - Autoprocessing (in the first step) not necessary - You or your partner will integrate the process into your environment You should fetch the pdf files from an SFTP server managed by us + store the read data there again as a csv file - Cloud solution

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-Trading-invoices.md - Chunk 3
Further information from Dachser: Wir haben aktuell zwei Kundengeschäfte, bei denen wir diesen Prozess einsetzen wollen. Stihl läuft schon eine Weile und dort erwarten wir auch, dass eine gute Datenqualität zum Trainieren/Testen vorhanden ist. Mahle läuft gerade an, da haben wir im System noch nicht viele saubere Daten. In der Tabelle habe ich meine bisherigen Informationen zusammengefasst.

Customer Suppliers pdf-files (shipments) p.a. Invoices p.a. Part no. (regex) Stihl 150 9000 16000 ^[0-9]{11}[A-B]$ or ^[0-9]{4}-[0-9]{3}-[0-9]{4}-[A-B]$ or ^[0-9]{4}-[0-9]{3}-[0-9]{4} [A-B]$ or ^[0-9]{4} [0-9]{3} [0-9]{4} [A-B]$ Mahle 500 16500 30000 ^[A-Z]{2}[0-9]{6}$ or ^[A-Z]{1}[0-9]{7}$ or other (?)

Dachser provided Samples + Ground Truth which can be found under \nas-01\CustomerData\Dachser\Handelsrechnungen (Siodlaczek)\Stihl-Samples.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-Trading-invoices.md - Chunk 4
Dachser provided Samples + Ground Truth which can be found under \nas-01\CustomerData\Dachser\Handelsrechnungen (Siodlaczek)\Stihl-Samples.

More information about Stihl: So far, we only have data quality that is likely to be good at Stihl, although we have found that the format of the part number is sometimes changed manually there. At the beginning, however, we would like to evaluate how good the initial extraction quality of Blu Delta is. We are also willing to put in manual effort for labeling.

Preferred timeline: - March-April: PoC - End of April: Decision for vendor - May - June: Implementation

Offer required for: - PoC - Implementation - Production

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-WIN---Goal.md - Chunk 0
Dachser WIN Goal

[[TOC]]

Startup Process und Ziel - High Level:

Das Ziel von Dachser ist die qualitative Verbesserung des Rechnungseingangsprozesses bei gleichzeitig weniger manueller Arbeit.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-WIN---Goal.md - Chunk 1
Wie vereinbart fasse ich anbei die besprochenen Punkte wie folgt zusammen: 1. Wir starten mit Österreich als erstes Land für die produktive Nutzung von BLU DELTA. Ausgehend von einer vorhandenen guten Qualität der Datenextraktion können sich beide Seiten (Dachser und Blumatix) auf die Ergänzung der fehlenden Felder und den Integrationsprozess konzentrieren. Ziel ist ein stabiler Prozess und eine Dunkelverarbeitungsquote wie im Angebot vereinbart. 2. Parallel dazu wird Blumatix bereits vorbereitende Maßnahmen im Bereich Datenmanagement für die Unterstützung des ersten asiatischen Landes treffen. Das wird Südkorea sein. 3. Nach Abschluss der Integration von Österreich wird Blumatix den Fokus auf die Umsetzung von Südkorea legen. 4. Parallel dazu wird Dachser von BLU DELTA bereits unterstützte Länder (größtenteils EU) mit Support von Blumatix sukzessive ausrollen. 5. Dachser erwartet die vereinbarte Dunkelverarbeitungsquote erstmal nur in den bereits unterstützten Ländern. In neuen

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-WIN---Goal.md - Chunk 2
Länder (größtenteils EU) mit Support von Blumatix sukzessive ausrollen. 5. Dachser erwartet die vereinbarte Dunkelverarbeitungsquote erstmal nur in den bereits unterstützten Ländern. In neuen Ländern kann auch mit einer geringeren Rate gestartet werden. Ziel ist die schrittweise Verbesserung der Dunkelverarbeitung.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-WIN---Goal.md - Chunk 3
Ziel von Dachser ist es, ab Anfang 2024 die OCR von Kofax komplett durch BLU DELTA ersetzen zu können.

Required Details:

Rechnungsdatum (DOC_DATE) - InvoiceDate

Dokumenttyp (INVOICE/CREDIT NOTE) - DocType

Rechnungsnummer (REF_DOC_NO) - InvoiceId

NEW: Dachser Empfängernummer (ZZBST) - md_customer Id

NEW: Dachser Lieferantennummer (VENDOR_NO) - md_vendor id / It could be that there are 2 different vendor ids for different bank info (usually there is only one vendor id for several bank infos)

VAT Exemption

Steuern (VatGroup) -- Nettobeträge (NET_AMOUNT1,2,3) - NetAmount -- Steuersätze (TAX_RATE1,2,3) - VatRate -- Steuerbeträge (TAX_AMOUNT1,2,3) - VatAmount

Brutto-Gesamtbetrag (GROSS_AMOUNT) - GrandTotalAmount

Netto-Gesamtbetrag (NET_AMOUNT_TOTAL): part of VAT Group

Lieferdatum (SERVICE_DATE) - DeliveryDate and DeliveryPeriod (customers do not distinguish)

Bestellnummer (PO_NUMBER) - Special Format starting with "45"+

UID Lieferant (VAT_NUMBER_VENDOR) - SenderVatId

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-WIN---Goal.md - Chunk 4
Bestellnummer (PO_NUMBER) - Special Format starting with "45"+

UID Lieferant (VAT_NUMBER_VENDOR) - SenderVatId

UID Dachser (VAT_NUMBER_DACHSER) - ReceiverVatId

NEW: Steuernummer Lieferant (TAX_NUMBER_VENDOR) - SenderTaxNo (extend to other countries)

NEW: Steuernummer Dachser (TAX_NUMBER_DACHSER) - ??? => new prediction detail? (see below)

Währung (CURRENCY) - InvoiceCurrency

HAWBId (for AIr&Sea)

I18N required data fields (for later)

SIRET (Frankreich) - Quelle: Dokument -KVK (Niederlande) - Quelle: Dokument -HBB - Quelle: Dokument, Abgleich mit Whitelist

Feature: Sender/receiver and Mapping Subsidiary (Niederlassung/Branch)

All Dachser branches (Niederlassungen) and legal entities can be found in uploaded csv file: receivers.csv

Data relation: Legal Entity (=company codes) -> Branches

Dachser2Dachser Invoice - Sender/Receiver definition:

Original PPT: Dachser2Dachser-Sender-Receiver-Requ.pptx

External Vendor to Dachser invoice:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-WIN---Goal.md - Chunk 5
Dachser2Dachser Invoice - Sender/Receiver definition:

Original PPT: Dachser2Dachser-Sender-Receiver-Requ.pptx

External Vendor to Dachser invoice:

(Proposed Logic from Chris - not necessarily best idea ...) Sample:

Info from Bernhard after Dachser Meeting on 17.Apr 2023:

Info von Olga: Erkennung der DachserSenderId und DachserReceiverId funktioniert schon recht gut (seit wir die Daten im Elastic bereinigt haben) – Olga wirkt relativ zufrieden.

Herta Landl: Das ist die Buchhaltungs-Expertin (oder so) für Dachser Österreich und ab heute unsere Ansprechpartnerin für Fragen zur Business Logik bezüglichg Erkennung der DachserSenderId & DachserReceiverId. Wir können sie also jederzeit fragen (am besten via Email) herta.landl@dachser.com

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-WIN---Goal.md - Chunk 6
Industry Mapping Rules (Die Spalte „Industry“ wird von Dachser bzw. Olga als „Branche“ bezeichnet) Wir haben eine Mapping Rule im Code drin welche basierend auf der Erkennung „Transport Invoice“ vs. „Cost Invoice“ den richtigen Receiver finden kann. Herta Landl hat uns bestätigt dass wir diese richtig implementiert haben. Die Vermutung ist, dass diese Regel auch für andere Länder als Österreich richtig funktioniert – Olga wird das für jedes kommende Land aber nochmals abklären.

Feature: Automation Rate Goal

Committment Automation Rate: 20% based on 3% error rate

Custom Training

To match automation rate a potential optimization: - Training based on Dachser data to optimize Dacher details - Optimization of quality flag - resp. confidence definition (Konfidenzwert) - Introduction of RecommendedThreshold and RetrunAlwaysBestMatch Strategy - Calculation of RecommendedThresholds per customer

Feature: Support for Asian Invoices

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-WIN---Goal.md - Chunk 7
Feature: Support for Asian Invoices

We focus on Korean - but Korean includes Japanese and Chinese as well!

Internationalization ONLY FOR PRODUCTION

I18N: Belgium, Chile, Denmark, Finland, Hungary, Ireland, Luxembourg, United States, Hongkong, China, South Korea, Taiwan, Singapore, Malaysia, Vietnam, Thailand, Indonesia, India, Peru, Japan, Rumania, Marocco, Tunisia

Feature: Accept new request additional props:

IsScanned - bool - redundant info, see below Source : string Values: - Uploaded Invoice(s) - E-Mail - Portal - Scan Cover Sheets : More than one page invoice, with first page being a separator page for batch scanning - Scan Single Pages : one page invoices

Note: Scanned invoices can be modified (e.g. the order of the pages can be changed or different documents can be merged); tiff format Uploaded are not modified (PDF); we upload PDFs (and corresponding XMLs in some countries but those invoices do not go to extraction)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-WIN---Goal.md - Chunk 8
Sender-Info : string Values: - for email: sender email address There is no mapping information available, but in general this information could be useful - for portal/upload: dachser internal user-name (portal) Note: User name is just an internal user The source parameters can indicate vendors (e.g. if it is from an email) and some vendors have similar/same layout globally which can make recognition easier.

Receiving branch : string Values "nnnn" : 4 digit number as string - branch chosen by user - branch connected to the email address that received the invoice

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-WIN---Goal.md - Chunk 9
Receiving branch : string Values "nnnn" : 4 digit number as string - branch chosen by user - branch connected to the email address that received the invoice

Notes: - This information is used to match to the Dachser Receiver Vendor ID. In the masterdata "md_vendor" there exists a column called "trading partner". This is the matching from branch (id) to Dachser vendor (legal entity/company code = trading partner) - Not all vendors exist in all branches and some vendors have similar/same names but belong to different branches. - Also, branches have default currencies used when extraction cannot find the currency information on the invoice. - We also extract and show the branch as a value to the user. Branch/company code should also match for an invoice to be validated.

Some countries have email inboxes that receive invoices for more than one branch. However, this information can be shared with you.

Receiving country (which country the receiving branch belongs to)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-WIN---Goal.md - Chunk 10
Some countries have email inboxes that receive invoices for more than one branch. However, this information can be shared with you.

Receiving country (which country the receiving branch belongs to)

Date : string Date & time it was received (when was the email received/when was it uploaded/scanned)

Invoice type : string It is a string. We have 4 main categories: - SD for Short Distance Road Operation invoices, - LD for Long Distance Road Operation invoices, - OT for Air&Sea Operation invoices and - EI/DI for general cost invoices. Note: Different branches can receive different invoice types (some branches are road and others are air&sea branches). This is generally chosen by the user or depends on the inbox an invoice is received to. It is mainly used in future steps of the process but different type of invoices require different information. E.g. PO Number can only be found in EI/DI invoices and HAWB number exists only on OT invoices.

First Milestone: Perfect for Austria

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-WIN---Goal.md - Chunk 11
First Milestone: Perfect for Austria

Product Stories and Bug Fixes required:

Technical Stories

Caching Lösung: Story already done and estimated (Rudi) - Use Radis Cache for Teststellung

GPU asynch deployment - Technical Story (Dates, Amounts, DocType, IDs, Currency) - Rudi

Data Management

Automated processing with minimal error

Get data from Olga:

Question: What data sample have we got? (Chris mit Olga) - DONE -- number of supplier - ongoing -- num of invoices per month/annual - ongoing -- 3 per supplier (received 5 invoices per supplier) -- Mapping and additional export (ongoing)

Auto Import Data: Normalizer adaption, Label creation? (Klemens)

Benchmark for Austria (Klemens)

Optimal Threshold definition (Klemens Story)

Zusätzliche Trainingsdaten aufbereiten mit Fokus Österreich? (Klemens, Rudi)

Prepared for South Korea

SK invoices received

OCR tests with EasyOCR and Nuance

Test import

Test label creation

Import

Create benchmark

Master Data Definition - CSV Upload

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-WIN---Goal.md - Chunk 12
Prepared for South Korea

SK invoices received

OCR tests with EasyOCR and Nuance

Test import

Test label creation

Import

Create benchmark

Master Data Definition - CSV Upload

You can find samples here: under NAS/customerdata/Dachser/MasterData-yyyymmdd

**I18N in master data: The files md_customer, md_vendor_neu_Dachser, md_vendor_neu_noDachser also contain translations (for non-latin languages), in case there is one. The translations are currently used to identify the invoice receiver/ sender in Asian countires. It also means if a translation is available for a certain vendor/receiver, then the number is listed several times (also because of different bank data) in the file, The vendor name, adress and city are usually translated, the other data is copied from the English version.

Requested delivery:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-WIN---Goal.md - Chunk 13
Requested delivery:

Dachser Masterdata Name BLU DELTA Resource Name Description md_vendor_with_translation.csv AllVendors.csv All Dachser entities and Dachser Customers that exchange invoices md_customer.csv Receivers.csv All Dachser legal entities (including its branch ids) that receive invoices; it is a subset of AllVendors.csv; a branch resembles "Filiale" md_po_vendor.csv POVendors.csv For cost invoices a mapping from purchase orders to vendors

Note: Purchase Orders are only used for internal invoices.

Purchase Order implmentation plan

20230113_PO_number.xlsx In Dachser not every country supports purchase orders. Thus, here is a list about countries that support or will support POs in the next years.

(DEPRECATED) Feature: Asynch BLU DELTA API (OUT OF SCOPE UNTIL FURTHER NOTICE)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-WIN---Goal.md - Chunk 14
(DEPRECATED) Feature: Asynch BLU DELTA API (OUT OF SCOPE UNTIL FURTHER NOTICE)

A potential approach discussed with Rudi, Gü and Bernhard on Oct. 10th Rudi already had a solution designed (see BLU DELTA Architecture) inl. a Workflow Engine. The main requirement from Dachser: - Avoid timeouts

In the meeting we discussed that the first step would be to implement the client facing part of Rudis Design (most likely instead of Workflow Engine we would use still Capture SDK).

We need to distinguis following timeouts: - Timeout on client side: Most of the time this happens due to high load on the system - Internal Timeout due to long execution time of huge invoices - this is unlikely and happen currently max 10 times a day.

The current approach would return an internal timeout with an empty but valid response

An incoming requests (fromy synch and Asynch) would go into a queue and prioritized accordingly.

Depending on open requests in the queue a scaling can be initiated.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser-WIN---Goal.md - Chunk 15
An incoming requests (fromy synch and Asynch) would go into a queue and prioritized accordingly.

Depending on open requests in the queue a scaling can be initiated.

In asynch IF the client would first upload the document with request params and get an ID or URL returned where the response can be picked up later.

It was a common view that 2 Sprints with 3 people each should be sufficient to build this simplified asynch IF but without workflow engine.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Dachser_-Wave-4.md - Chunk 0
Current Status:

Launch planned for beginning of Ocotber

Risk:

China as Asian country with significant load: Mitigation: - Check load for China and align with team - check layout diversity -- based on Dachser it is low - check CN OCR quality of EasyOCR

OPEN Issues:

NA

Current Priorities:

Get pecularities for Wave 4 countries

Understand steps for China

General Requirements:

Following Countries in Wave 4:

CN CZ DK HK MX PL IN TR US

Goal Blumatix:

Increase the load

Additonal requirements: - Tour Number - VatIds need to be improved - TaxId needs to be available - SenderId/ReceiverId Logic change - Benchmark showing results on non-German and English regions/languages, optimize results accordingly - Get Learn API ready 4 ALL wave 3 countries!!!

Load Requirements:

Expected Timeline: Delivery mid July

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\DeepOCR---Create-Deployable-Instance.md - Chunk 0
DeepOCR - Create Deployable Instance

Goal:

Based on DeepOCR PoC results a container (Docker, REST Service) should be created that can be deployed in BLU DELTA Kubernetes Cluster. The containers responsibility is the recognition of words on images (for now not for pdf-based documents). Implementation should be based on EasyOCR. The containers BLU DELTA Standard OCR interface is specified below as well as the container requirements.

Technical Specification:

Technologies will be based on: -Python - OCR-Service be based on the following technologies: - Python 3.8 or 3.9 - Flask shall be used as web framework - The service shall also run in a linux based docker container with GPU support! Therfore a Dockerfile etc. must be provided.

OCR-Request:

Should contain a list of document pages as images - Images shall be processed in parallel. Check if it is supprted by EasyOCR

Configuration: AdditionalProperities - a dictionary

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\DeepOCR---Create-Deployable-Instance.md - Chunk 1
OCR-Request:

Should contain a list of document pages as images - Images shall be processed in parallel. Check if it is supprted by EasyOCR

Configuration: AdditionalProperities - a dictionary

Lanugage need to be provided as input param in the dictionary, ISO 2 letter codes

OCR-Response: An OCRResult shall be returned as a json string for every document that is sent to the OCR-Service. The OCRResult shall be returned in the following json format:

IDs must be unique. integer

Orientation: not part of easy ocr, not part of this implementation - set it to null ```json

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\DeepOCR---Create-Deployable-Instance.md - Chunk 2
IDs must be unique. integer

Orientation: not part of easy ocr, not part of this implementation - set it to null ```json

{ "Language": {}, "Orientation": "string", "Regions": [ { "Lines": [ { "Words": [ { "Id": 0, "Text": "string", "BoundingBox": { "Left": 0, "Top": 0, "Width": 0, "Height": 0, } } ], "BoundingBox": { "Rectangle": "string", "Left": 0, "Top": 0, "Width": 0, "Height": 0, } } ], "PageNo": 0, "BoundingBox": { "Rectangle": "string", "Left": 0, "Top": 0, "Width": 0, "Height": 0, } } ], "NumberOfPages": 0, "PageInfos": [ { "Index": 0, "ResolutionX": 0, "ResolutionY": 0, "Width": 0, "Height": 0, "Orientation": "string", "PageBitmapB64": "string", } ] }

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\DeepOCR---Create-Deployable-Instance.md - Chunk 3
```

Description of the Json-Format

Region: A single page may be divided into logical regions (blocks). If the OCR engine doesn't support regions than there will always be a single region per document page.

Line: A line consists of 1 or many words which logically belong together. Line can be a sentence, a phrase etc. A line has a bounding box.

Word: Represents a single word. A word has a text field which contains the characters of that word and a bounding box.

PageInfo: Addiotnal page information. PageBitmap64, the page image base64 encoded. Maybe not needed?

ACCEPTANCE CRITERIA:

Docker Image delivered can be deployed in Blumatix Cloud Service can be started and is up and running in Blumatix Cloud Demo: Sending multi page document to service and retrieve response as defined Exceptional cases demo: - Empty image / Large image / small image - No language sent - use default language / default is German Unit Test based on PyTest available

Final delivery:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\DeepOCR---Create-Deployable-Instance.md - Chunk 4
Final delivery:

Docker image and source code (incl. PyTest), readme file

Timeline:

First review: 11.11.

Final component: 18.11.

Findings in Review (12.12.2022)

E.g. for Python

Missing Configuration:

Best Practice: hydra - color log; (https://hydra.cc/)

All parameter of easyocr readtext should be set via configuration: -- via dictionary in request (dictionary, same name as in original input but starting with method name: "methodname.paramname" - e.g. readtext.detector) -- and/or in default configuration which should be in a config.yaml file as part of github project ./config/config.yaml -- config for GPU vs. CPU need to be configurable

Missing Logging:

Best Practice: hydra: https://hydra.cc/

All of following situations must be logged:

System crashes or a status of total system failure must be logged with highest criticality in the logs

Failures leading to unsuccessful requests must be logged as 2nd level criticality

Uncommon situations should have warning level

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\DeepOCR---Create-Deployable-Instance.md - Chunk 5
Failures leading to unsuccessful requests must be logged as 2nd level criticality

Uncommon situations should have warning level

Important information helfpul to analyse issuee should have INFO or DEBUG level

Missing Swagger openapi endpoint

Functional:

image should not be stored as file, it should be retrieved as bytearray and then directly fed to readtext

Delivery Word Bounding Box:

Word bounding box not accurate enough. For our following model it is needed to get non-overlapping bounding boxes. This means that a bounding box of word A ist not allowed to overlap with any neighnbnoring word B. As example see also image attached: MicrosoftTeams-image (1).png

Thus, the bounding boxes need to be corrected without any significant performance impact. There might be 2 possible approaches (we can think of - but you can also add a new solution): - Just non-overlapping (this is min. requirement) - Exact (e.g. with OpenCV)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\DM-Delivery-Notes.md - Chunk 0
DM sent us 57 examples of delivery notes for 24 suppliers. These are all current decentralized suppliers of DM in Germany. The samples can be found under \nas-01\CustomerData\DM

DM requires the following 5 header fields for this use case: - Supplier (6 digits) - Master data - Branch (4 digits) - Master data - Delivery Note Id - DeliveryNoteId - Order Number - ReceiverOrderNumber + SenderOrderNumber - Date - DeliveryNoteDate?

The Ground Truth is encoded in the filename as follows: SKFXOPT001_

Expectation: High automation rate (Dunkelverarbeitung)

AP: Analyse the samples, check results with current BLUD ELTA version. Deadline: 23.11. EOB AP: Based on results, think about optimization possibilities if required

Expected Architecture for first version: Goal is to get a first simple version out that creates additional value for DM: DMDeliveryNotes-C4-v1_0_0_internal.txt

Email from DM: Guten Morgen Herr Loiperdinger,

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\DM-Delivery-Notes.md - Chunk 1
Email from DM: Guten Morgen Herr Loiperdinger,

ich wollte Ihnen kurz direkt schreiben, dass ich Dateien hochgeladen habe. Nachdem ich mir nochmal Zeit genommen habe, um die Lieferantenliste mit den letzten Jahren abzugleichen und zu bereinigen, ist sie kürzer geworden. Schreiben Sie mir gerne, ob Sie mit der Anzahl von Lieferanten und den Dokumenten etwas anfangen können. Ansonsten können wir nochmal einen Termin machen.

Was von meiner Seite aus noch möglich ist: - Dokumente nicht mehr aktueller Lieferanten heraussuchen, falls das fürs Training sinnvoll ist - Mehr Dokumente aktueller Lieferanten bereitstellen

Beides ist mit etwas Aufwand verbunden, deshalb würde ich das nur angehen, wenn es tatsächlich sinnvoll ist.

Viele Grüße & Ihnen einen schönen Tag!

Johanna Thieme

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\DocSplit-Challenge.md - Chunk 0
DocSplit Challenge

The split challenge is an AI competition for students. The task is to find the best working AI model(s) that can split a scan batch. A scan batch is the output of a document scanner. People often scan more than one document at once. While this is great for the guy who needs to scan the docs it is a major burden for the people who have to process document by document later on. Thus, your task is to create an AI that splits up the documents automatically as good as possible.

The Winner receives:

Cash: EUR300

Blumatix Sponsored Bachelor or Master Thesis in the area of AI and document processing

Blumatix Intelligence Certificate for winning the AI challenge

ALL who submit a working solution:

Blumatix Intelligence Certificate for participation in the AI challenge A voucher for a free coffee in our Blumatix Office Kitchen in Salzburg

Win Criteria

The Blumatix Data Management Team will benchmark your solution against an independent test dataset.

Pre-condition:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\DocSplit-Challenge.md - Chunk 1
Win Criteria

The Blumatix Data Management Team will benchmark your solution against an independent test dataset.

Pre-condition:

DACH Student Data Privacy Statement agreed Non-disclosure agreement agreed Source code usage agreed

Timeframe: December 1st - February 15th

Limited Seats: 25

Submission:

Delivery:

ZIP File with: - your source code (Python or C#) - specific Python Framework???!! - readme file with a clear explanation about prerequisites to execute your application - pdf document that explains in max. one A4 page your solution approach in English

Requirement of delivered application:

windows command line application

command: "split -i

Data provided after submission:

x single documents you can use to create random pdf batches for training and testing 1 Sample including a document pdf batch and the result split txt file

Martin:

Is it relevant for the solution whether the batches are "single type" or "mixed"? If so, we should specify that.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\DocSplit-Challenge.md - Chunk 2
Martin:

Is it relevant for the solution whether the batches are "single type" or "mixed"? If so, we should specify that.

Does it make a difference whether there can be 5 or 500 documents in the batch? If so, we should specify that as well. Or limit it specifically for the challenge, if that helps.

From my point of view, good description, and exciting topic. I would apply if I had an idea how to solve this... :-)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Evaluate-Language-Detection-with-PULC-(Paddle).md - Chunk 0
Summary:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Evaluate-Language-Detection-with-PULC-(Paddle).md - Chunk 1
For EasyOCR or PaddleOCR a language detection before OCR would be helpful since they ask for language input param. Thus, we evaluated the PULC model from Paddle that is supposed to provide a language prediction based on an image (https://github.com/PaddlePaddle/PaddleClas/blob/release/2.4/docs/en/PULC/PULC_language_classification_en.md#1). The model was tested in a simplified form. Dachser Korean invoices were converted into 300 dpi images per page originating from pdfs. These images were then page by page predicted by the model with very bad results. In a next step with a sample of approx. only 10 image a smaller area of the image was cut out and sent again to predict the language - and again with a bad result which was also not useful. Finally again a small sample with just single words or parts of a sentence were sent as image to be predicted. In this case the model seemed to perform in a useful manner. The conclusion is - in order to use this model we would need text detection

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Evaluate-Language-Detection-with-PULC-(Paddle).md - Chunk 2
or parts of a sentence were sent as image to be predicted. In this case the model seemed to perform in a useful manner. The conclusion is - in order to use this model we would need text detection upfront. Thus, for our current problem - upfront detection of languages of a document - the model does not seem appropriate.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Evaluate-Language-Detection-with-PULC-(Paddle).md - Chunk 3
Performance on CPU was reasonable, GPU might be much faster

Used scripts: PULC.py: This script takes image dir as input, predicts the language per image and writes a results.csv file with labels and scores of the top 2 languages classified PULC.zip

pdf2images.py: Converts pdfs to page pngs with predefined dpi pdf2images.zip

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\EVB-Punkt_-PoC-Header-and-Line-Items.md - Chunk 0
Customer / Context:

EVB Punkt is a trading company and purchase cooperation that centralizes the purchasing of construction machines and equipment for its members.

Industry:

Trading

Use Case:

The EVB BauPunkt carries out transactions for 70 shareholders with approximately 500 suppliers. The 500 suppliers generate an annual volume of around 70,000 invoices, which are distributed across the following input channels: PDF via email: 63,000 Paper: 5,000-6,000 EDI: 2,000-4,000 EVB BauPunkt requires both header and line item data from the PDF and scanned paper invoices. This results in a current annual volume of approximately 68,000 invoices. Additionally, approximately 200,000 invoices from the years 2020-2022 are to be processed automatically retrospectively.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\EVB-Punkt_-PoC-Header-and-Line-Items.md - Chunk 1
EVB Punkt would like to analyze product prizes of their suppliers automatically. Thus, the analysis of line item data related to articles and prices is required. In addition to the values from the invoice documents, EVB BauPunkt also requires a mapping of creditor and debtor with the supplier and shareholder master data.

Project Delivery:

In a first step a PoC should be executed. Part of the PoC is a report that shows the recognition quality.

Delivery Scope:

Access to the optimized BLU DELTA Live Service (training with Top suppliers of EVB Punkt) -- Header Details: Minimum the BLU DELTA Must Header Details -- Optimization for ALL Line Item Details

Benchmark results after optimization (training) with EVB Punkt data

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\EVB-Punkt_-PoC-Header-and-Line-Items.md - Chunk 2
Benchmark results after optimization (training) with EVB Punkt data

PoC Report: -- Initial Use Case and Problem -- Dataset characteristics / anomalies -- Benchmark results for header and line item details --- for line items focus is on: article number, prizes, quantity --- INTERNAL Note: Depending on data we should also check if units could play a role for later evaluation of data -- Improvement potential (if any)

Delivery Timeline:

8 weeks after delivery of the training data we should deliver improved line items

Expected: End of August

Data Available:

Invoices of Top 40 Supplier - Z:\EVBPunkt\Top40_19-29_06_2023 AND - Z:\EVBPunkt\TOP40_Steidele-BOS_01_04-29_06_202

Both folders together should represent the Top 40 suppliers.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Improve-EasyOCR-service.md - Chunk 0
Extend EasyOCR service to accept PDF, PageInfo added for images as well as for pdf

EasyOCR service shall detect if the format is image or pdf and if needed extract images into 300dpi png images and create ocr

Our existing EasyOCR service shall be able to accept also PDF files.

Images should be extracted and returned as b64 encoded strings within the json response (see sample json response attached).

This means that below PageInfo information must be filled for images as well as for pdf.

Page Orientation need to be included as well

A request input parameter should set if images will be attached as b64; by default parameter is true

```json

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Improve-EasyOCR-service.md - Chunk 1
Page Orientation need to be included as well

A request input parameter should set if images will be attached as b64; by default parameter is true

```json

{ "Language": {}, "Orientation": "string", "Regions": [ { "Lines": [ { "Words": [ { "Id": 0, "Text": "string", "BoundingBox": { "Left": 0, "Top": 0, "Width": 0, "Height": 0, } } ], "BoundingBox": { "Rectangle": "string", "Left": 0, "Top": 0, "Width": 0, "Height": 0, } } ], "PageNo": 0, "BoundingBox": { "Rectangle": "string", "Left": 0, "Top": 0, "Width": 0, "Height": 0, } } ], "NumberOfPages": 0, "PageInfos": [ { "Index": 0, "ResolutionX": 0, "ResolutionY": 0, "Width": 0, "Height": 0, "Orientation": "string", "PageBitmapB64": "string", } ] }

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Improve-EasyOCR-service.md - Chunk 2
```

Optimize bounding box for Korean characters/words

We need to optimize the bounding boxes for Korean words. The bounding boxes are not allowed to overlap.

Final delivery: Docker image and source code (incl. PyTest), readme file

Configuration: Best Practice: hydra - color log; (https://hydra.cc/ )

Logging: Best Practice: hydra: https://hydra.cc/ All of following situations must be logged: - System crashes or a status of total system failure must be logged with highest criticality in the logs - Failures leading to unsuccessful requests must be logged as 2nd level criticality - Uncommon situations should have warning level - Important information helfpul to analyse issuee should have INFO or DEBUG level Swagger openapi endpoint must be supported

ACCEPTANCE CRITERIA:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Improve-EasyOCR-service.md - Chunk 3
ACCEPTANCE CRITERIA:

Source Code delivered Integration test available to cover new use case: -- pdf detected -- images extracted and returned as b64 Service can be deployed and started in Blumatix Cloud Show examples that prove that bounding box issues is solved

Empty image / Large image / small image No language sent - use default language / default is German Unit Test based on PyTest available

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Korean-Doc-Pre-Process-Work.md - Chunk 0
[[TOC]]

Goal: Implement a module that builds up a Korean (Target Language) Dictionary

We need a Python CLI module that creates a dictionary and translated OCR from Korean invoies

The module gets as input params:

directory with input invoice documents (pdf or images (jpg, tiff or png))

directory for language translation context which includes files:

list of possible languages used in these invoices (iso-639, 2 digit)

a target language (iso-639, 2 digit)

a OCR URL (http endpoint for the components you created for us paddle or easy)

google translate account information

an output directory

optional: max pages translated

Required Function:

The module converts invoices to ocr readable images (if pdf and invoices has more than max pages param then only up to max_pages are processed, pages > max_pages are ignored)

The module uses OCR endpoint to detect words (uses endpoint provided as input, interface is same as final paddle/easy component)

For every word detected:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Korean-Doc-Pre-Process-Work.md - Chunk 1
The module uses OCR endpoint to detect words (uses endpoint provided as input, interface is same as final paddle/easy component)

For every word detected:

The module detects language per word

If the language detected is not equal to target language then it sends a translation request to google translate

Note: Google Translate does not work well if we send just one word for translation since it misses context information -- Thus, the module loads the text file (utf-8, no bom) and appends a new line with word to translate -- Thus, the last line of the text is the word that requires translation -- After translation the module extracts last line = translated word

The module adds an entry into a dictionary for this translation (one dictionary for each input->target language - e.g. dic-kr-de.csv in utf-8, no bom, no header, tab-separated, first column is original language words, second column is target language word)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Korean-Doc-Pre-Process-Work.md - Chunk 2
The module replaces the original language word in the OCR-json with the target language word

When All words were processed the module outputs:

The module writes a csv-file dictionary for each language combination with following naming convention: dic-

The module writes the original OCR file with the

The module writes the translated OCR file with the

Test data:

There will be 5 korean invoices provided for testing. These invoices need to be treated as confidential information and are not allowed to share with anyone else except Blumatix Intelligence employees.

Integration test:

WIth the package there must a smoke test included with the provided test data that verifies that installation works

Required Log Output:

Every run should create its own log file with timestamp The log should show every file processed and out error if any issues occurred with proper error stack

Required Installation instructions

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Korean-Doc-Pre-Process-Work.md - Chunk 3
Every run should create its own log file with timestamp The log should show every file processed and out error if any issues occurred with proper error stack

Required Installation instructions

The delivered package must include a readme.txt explaining Prerequisistes for installation and running component Installation procedure Usage How to run smoke test

Google Translation Docker

We provide a docker container that includes an API wrapper for Google Translate data = {"Text": <<Text>>, "SrcLang": <<two-letter-iso-source-lang>>, "TargetLang": <<two-letter-iso-target-lang>>} headers = {'content-type': 'application/json'} r = requests.get('http://localhost:1337/translation', params=data, headers=headers) result_dict = r.json()

Pull docker image: docker pull blumatixdevregistry.azurecr.io/translate:latest

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\PoC_-Dachser-Classification-and-Splitting.md - Chunk 0
Intro: PoC for Dachser:

1) Classification of Documents 2) Splitting of same document classes

Goal:

Provide a report for Dachser on performance Provide an API where Dachser can test the splitting and classification

API Specification to be provided until 20.3.

BLUDELTA-Dachser-PoC-ClassyfierAndSplit-API-V1.pdf BLUDELTA-Dachser-PoC-ClassyfierAndSplit-API-V1.docx

Key Facts

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\PoC_-Dachser-Classification-and-Splitting.md - Chunk 1
API Specification to be provided until 20.3.

BLUDELTA-Dachser-PoC-ClassyfierAndSplit-API-V1.pdf BLUDELTA-Dachser-PoC-ClassyfierAndSplit-API-V1.docx

Key Facts

In total, Dachser processes 10M documents a year. All of them are processed via their central digitization platform KTA, which allows to split, classify and assign (based on tracking number) documents. This is done manually today. Goal is to automate this in future. Dachser requires only an API, UE for manual corrections is part of KTA. Long term goal is a complete automatic processing, until then a semi-automatic approach is fine. Since errors in split are expensive to correct, it's important to reduce false positives. BUT: This is not important for the PoC. Here, Dachser only measures the recognition rates of correctly found separation marks.

PoC quality measurements

Split and classification are measured separately.

Split

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\PoC_-Dachser-Classification-and-Splitting.md - Chunk 2
PoC quality measurements

Split and classification are measured separately.

Split

Measurement based on a set of 40 documents with 900 separation marks. No focus on completely properly processed documents.

Classification

Measurement based on 1.000 documents, each of which is a single type.

Next steps after successful PoC

Currently, all vendors are between 80-90% split-rate. Helge said that's not good. In order for us to progress, we have to be well above 90%. If we achieve 99%, then it will go on quickly. Unless we're much better than the other vendors, Helge will have a hard time even finding a branch to test. Since splitting is the base for classification this seems even more important for Dachser than classification (Martin's impression). If we are good, then the next step is a test in a first branch. Timeline: Until end of May Helge has collected all relevant information, after that there is a decision on how to proceed.

Custom Data provided:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\PoC_-Dachser-Classification-and-Splitting.md - Chunk 3
Custom Data provided:

Data can be found under: \customerdata\Dachser\PoC_ClassificationAndSplit Dachser provided 3 packages: First Samples Training Data (Flawed) Training Data (A quality) - ~400docs per class Further data, classified but low quality (20k docs)

Doc Classes

Classify following documents and mapping - Dachser -> BLU DELTA "CBADB": "ExportAccompanyingDocument", OK "CDCTD": "CustomsDutyReceipt", "CDDLN": "DeliveryNoteCustoms", OK "CDINV": "Invoice", OK "CDORG": "CertificateOfOrigin", OK "CDPIN": "ProformaInvoice", OK "CDTD1": "TransitNoteT1", OK "CDTD2": "TransitNoteT2", OK "GGDGN": "DangerousGoodsNote", OK "FDEDN": "DeliveryNoteCustoms", OK

API for Splittting: REST API with JSON defining the split marks

Overview - General Classes and Logistic Classes

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\PoC_-Dachser-Classification-and-Splitting.md - Chunk 4
API for Splittting: REST API with JSON defining the split marks

Overview - General Classes and Logistic Classes

BLU DELTA Class Industry Class Dachser Class  Invoice General CDINV DeliveryNote General NA Notice General NA VehicleRegistration General NA Order General NA CertificateOfOrigin logistics CDORG CustomsDutyReceipt logistics CDCTD DangerousGoodsNote logistics GGDGN TransitNoteT1 logistics CDTD1 TransitNoteT2 logistics CDTD2 ProformaInvoice logistics CDPIN ExportAccompanyingDocument logistics CDABD DeliveryNoteCustoms logistics CDDLN DeliveryNoteTransit logistics FDEDN

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\POI-VehicleRegistration.md - Chunk 0
[[TOC]]

POI Vehicle Registration

POI wants to use BLU DELTA for registration certificates (Zulassungsscheine)

Fields required: - Kennzeichen - FIN/Fahrgestellnummer - Erstzulassung (Erstmalige Zulassung)

Required country support: - Austria

We received 18 sample documents so far, more to come. Joe will check with the customer how many samples he could provide together with the Ground Truth. Samples can be found under \nas-01\CustomerData\poi\Zulassungsscheine

Timeline: POI needs a first prototype / endpoint in the cloud which they can integrate. POI's Customer requires a solution in Q1/2023. POI would prefer solution integrated in OnPremise, but I think this needs more discussion.

Estimated number of documents that will be processed annually: 1.000 This is irrelevant for additional revenue, but it would help POI to argue for BLU DELTA at a time when customers are leaving for invoice processing.

PoC:

Goal:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\POI-VehicleRegistration.md - Chunk 1
PoC:

Goal:

a running prototype on your loacl machine based on following architecture:

Architecture

The technical requirements for a first local prototype are as follows: - A REST API that receives an image and returns a BLU DOC (BLU DOC sample see attached, Hasch can provide a nuget package which can be used to build up BLU DOC) - Use ELSA (https://elsa-workflows.github.io/elsa-core/) workflow eninge to define the various component calls and sequence (See sample from Rudi below) - EasyOCR requires an image, needs an image converter - Use EasyOCR (Philipp can provide a container from EasyOCR which allows you to convert an image into words and bounding boxes) - Create a component with a REST API that receives the OCR result and runs reg-exp against it and creates a BLU DOC format - NOT NEEDED for PROTO: Use existing auth component to authorize request against BLU DELTA user db

BLU DOC Sample (bei Fragen bzgl. Format: Hasch und Dominique):

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\POI-VehicleRegistration.md - Chunk 2
BLU DOC Sample (bei Fragen bzgl. Format: Hasch und Dominique):

POI-vehicleregistration-sample.json <= this is the bluDoc but not the dto, that will be transfered over the api BluDoc Repo

ELSA Sample from Rudi:

Mit ELSA hat Rudi schon so einen mini Workflow implementiert. Mit Nuance OCR, NamedEntityRecoginition, etc.... (Evtl. hat Rudi da eine Queue zur Kommunikation genommen (bidirektional - also ein request hin in ene Queue, und Response in eine Retrun Queue) - da bin ich mir nicht sicher)

Er hat aber ein Readme geschrieben. Der Code sollte gehen bis auf den Pfad zu einem Dokument, dass verarbeitet werden soll. Der ist im Code hart reincodiert Repo: https://blumatix.visualstudio.com/DefaultCollection/Rechnungserkennung/_git/BludeltaWorkflow README: https://blumatix.visualstudio.com/DefaultCollection/Rechnungserkennung/_git/BludeltaWorkflow?path=/README.md&_a=previewHoffe das passt so und der Werner kann damit was anfangen.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\RAG-requirements.md - Chunk 0
Key facts

RIPEye Customer

About 25k invoices annually

Input channel: email

Process: SAP

Download of BLU DELTA Json and conversion to SAP format is done by RAG

Integration until - need to be aligned with RAG. Blumatix to specify timeline.

Supported countries?

Required fields

Date of receipt -> UploadedTimestamp

StateBeforeReleased

GTA

DocType (Invoice / Credit Memo)

Currency

InvoiceDate

VatGroup

InvoiceId

OrderNumber including format specific recognition -> ReceiverOrderId?

MailId

Requester - Whitelist Search

Receiver including master data comparison (no upload wanted, just a handful of companies)

SenderVatId

ReceiverVatId

Supplier including master data comparison (dynamic list, upload required)

DeliveryDate, DeliveryPeriod -> Delivery Period Group?

OrderNumber

Two possible formats: - neue Logik: „45…“+10-stellig - alte Logik: „20…“+8-stellig

MailId

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\RAG-requirements.md - Chunk 1
DeliveryDate, DeliveryPeriod -> Delivery Period Group?

OrderNumber

Two possible formats: - neue Logik: „45…“+10-stellig - alte Logik: „20…“+8-stellig

MailId

Requirement is to identify documents which belong to the same email. E.g. one email contains three documents - these three documents need to contain the same MailId in their download response. It is not necessary to create a connection to the original mail using the MailId.

Whitelist search

We need to specify the format - must be generic - Requester for RAG: Is an employee of RAG, specified by First- and Sirname, Mapping to ID required

Same requirements for Red Bull, make sure to be able to deal with big number of items in Whitelist E.g. Red Bull has ~15-20k approvers, and ~300k SAP-Innenauträge

Red Bull requirements:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\RAG-requirements.md - Chunk 2
Same requirements for Red Bull, make sure to be able to deal with big number of items in Whitelist E.g. Red Bull has ~15-20k approvers, and ~300k SAP-Innenauträge

Red Bull requirements:

Need a specification of Whitelist search, because this a new integration topic for them. Especially - Authentication - CSV format - Storage of uploaded data and how they are protected - Endpoint URL and description

> Blumatix to provide!

Additional information

RAG Excel Document: Provides additional information about the different details e.g. wheter they are must have details or nice to have etc.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Red-Bull-cellphone-invoices.md - Chunk 0
Red Bull has submitted a request regarding the analysis of cellphone invoices.

[[TOC]]

Use Case

Ich freue mich dir mehr Informationen zum Use Case zu geben.

Wie Jürgen schon kurz angeteasert hat, geht es um Mobilfunkrechnungen von verschiedenen Telekommunikationsanbietern (monatlich) in verschiedenen Ländern, aus denen verschiedene Informationen (Datum, Name, Mobilnummer, Vertragsnummer, Verbindungskosten, etc.) oftmals manuell in eine Excel übertragen werden, oder der gesamte manuelle Prozess sogar extern an eine Agentur ausgelagert wird. Wir wären sehr daran interessiert diesen Prozess zu vereinfachen & zu automatisieren.

Dazu haben wir bereits Mobilfunkrechnungen aus 10 verschiedenen Ländern (anbei) gesammelt.

Konkret hat das gesamte Datenset folgende grobe Eckpunkte:

Verschiedene Länder, Sprachen & Währungen

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Red-Bull-cellphone-invoices.md - Chunk 1
Dazu haben wir bereits Mobilfunkrechnungen aus 10 verschiedenen Ländern (anbei) gesammelt.

Konkret hat das gesamte Datenset folgende grobe Eckpunkte:

Verschiedene Länder, Sprachen & Währungen

Countries (LATAM)
 - Argentina (Spanish / Argentine Peso)  $, arg$
 - Brazil (Portugees / Brazilian Real) R$
 - Panama (Spanish / US-Dollar) $
 - Chile (Spanish / Chilean Peso) (chil.) $
UAE United Arab Emirates (Arabic / VAE-Dirham) د.إ
ZA South Africa (English / South African rand (ZAR) R, ZAR 
DOM Dominican Republic (Spanish / Dominican Peso) $, RD$
RUS Russia (Russian / Russian Rubel) ₽
Countries Europe (EU)
  - Spain (Spanish / Euro) €
  - Germany (German / Euro) €

Data Details

Verschiedene Datenfelder, die ausgelesen werden müssten

Date

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Red-Bull-cellphone-invoices.md - Chunk 2
Data Details

Verschiedene Datenfelder, die ausgelesen werden müssten

Date

Mobile Number (Not always with country pre-number / sometimes only under reference / business customer number) a. Correct, some invoices doesn´t have the complete number and format changes: instead of using 123456789 some invoices may show (12) 3456789 or (12) 3455-6789

Name of Cell Phone User (employee) a. Some invoices have this info, others don´t The name not necessarily coincides with the name on our systems

Amount

Option to extract roaming costs, some countries have roaming packages, some don´t (also when some countries have unlimited roaming via the provider, but internal limits -> special case Panama)

Challenges

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Red-Bull-cellphone-invoices.md - Chunk 3
Challenges

Verschiedene Challenges - Different languages, currencies, currency symbols - Design/ set-up of invoices is always different - Some providers in some countries use phone numbers, names, or business customer number as listing item per amount spent - Some invoices may have additional costs: Maybe that RB office have also the internet link under the same document, maybe desk phone costs, taxes or values carried from another month. o E.g. Argentina have additional positions concerning the contract/ abo on top as discounts overall account fees - Some countries might have limitless roaming setting like Panama - However RB only covers a certain roaming limit, so the over costs need to be subtracted manually & are not payed by RB, rather by the cost of individual employee

Grundsätzlich geht es erstmal darum, ob ihr die oben angegebenen Sprachen & Felder auslesen könntet?

Sample Data

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Red-Bull-cellphone-invoices.md - Chunk 4
Grundsätzlich geht es erstmal darum, ob ihr die oben angegebenen Sprachen & Felder auslesen könntet?

Sample Data

We have received first samples, they can be found under \nas-01\CustomerData\redbull\Cellphone invoices

Next step: Meeting with Jennifer on Tue, Dec. 20th. Questions: - How many Suppliers? - One per country, e.g. Vodafone in Germany, Orange in Spain, ... - How many samples can be provided? - Several per country/Supplier are no problem. - Ground Truth available? - Yes, as Excel. - Need Validation User Interface? - Not yet, goal of PoC is to measure recognition rate. Process comes later. - How many countries: Long term all RB countries, but every single country would help, no need to support all - List of mobile numbers per country can be provided - List of mobile phone users (names) can be provided

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Red-Bull-cellphone-invoices.md - Chunk 5
Next steps: - Provide Budget size for PoC at latest in 2nd week of January - Provide Timeline for PoC at latest in 2nd week of January - Wish is to start in February, latest March: Start with data preparation - Request came from LATAM countries - it's ok to focus on them in the PoC

Technical Answer

PoC Solution Approach (Draft done by Chris since Rudi is on Vacation and I do not want to have distraction on team) Components that require modification efforts are marked with ** PocRBMobileInvoice-C4-v1_0_0_internal.txt

Precondition/Assumptions:

ELSA Workflow available from POI PoC

BLU DOC API available from POI PoC

Use new Typhon head on existing capture works for Rudi

GPU usage distribution solved for Dachser

Improved currency model from Dachser available

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Red-Bull-cellphone-invoices.md - Chunk 6
GPU usage distribution solved for Dachser

Improved currency model from Dachser available

Workpackage Detail Affected Components Affected Team Effort (PD) Inference Pre-process documents prepare and split-up for CaptureV1 processing NEW component DevOps 10 Configure ELSA Workflow engine Custom RB workflow for PoC ELSA WF DevOps 3 Train Custom Line Item Head Custom RB line items head Capture V1 DevOps 5 Improve phone number ER Need to have a good ER for phone number entity recognition Capture V1 DevOps 5 Create Normalizer Service for Prod New component that exists in BO DevOps 10 Create Custom Post Processing Create a custom post processing service for any aftermath New component DevOps 10 Data Collection Update Normalizer to import custom csv Normalizer DevOps 2 Optimize Labelling Tool Label Tool DevOps 10 Change Label Creator Label Creator DevOps 5 Measure and evaluate benchmark DataOps 10 Other Project Mgt PM 3 PoC definition PM 1 Deployment/Environment efforts DevOps 3 Total 77

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\Red-Bull-cellphone-invoices.md - Chunk 7
External Costs

Workpackage Details Costs Manual labelling After creation of automated labels to some extent manual labelling is required EUR1000

Proposed Timeline

Start: End of Q1 with Label automation End: End of Q2 Considering current workload I assume we are fully booked with this project and residual Dachser ramp-up.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\SG-Line-Items-PoC.md - Chunk 0
Customer Introduction

Avvaneo partner pitches for a PoC for a major trade customer with head quarters in DE

Industry: Trade of goods

Business Goal

Enable blind booking and ease split invoices in accounting based on an excellent line item detection

Use Case

Accounting for split invoices (FI invoices without purchase order reference) System is SAP, purchase order reference should have a strong format Skipped for this PoC: Matching of invoices against purchase orders (MM invoices with purchase order reference)

Customer Main Stakeholders, Contacts

Names Role Contact tbd tbd tbd

Expected initial timeline:

Milestone Date Kick-off Mid-End of April 2024 Data Delivery 120-150k (changed from 200k due to costs) Mid-End of April 2024 Delivery 1st model mid july PoC Presentation August

BLU DELTA Perspective:

Why should we do this project and importance?

It is a high value customer with significant revenue potential!

Requirements

General

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\SG-Line-Items-PoC.md - Chunk 1
BLU DELTA Perspective:

Why should we do this project and importance?

It is a high value customer with significant revenue potential!

Requirements

General

Requirement Customer Info Notes Document quanity per year 10 Million Input Channels scans or pdf Regions and Languages Receiving countries: CZ, SE - FI invoices Layout diversity Not known but strucutred data related to the data will be provided: suppliers, senders Special Performance Req For the PoC we need to process 200k docs within e.g. 2-3 days or weekend

Document Essentials

Header

Not important, since Avvaneo gets structured Header data from SG. Only VatIds will be relevant.

Line Items (to be confirmed)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\SG-Line-Items-PoC.md - Chunk 2
Document Essentials

Header

Not important, since Avvaneo gets structured Header data from SG. Only VatIds will be relevant.

Line Items (to be confirmed)

Detail Name (customer language) BLU DELTA Detail Name CUSTOM INFO Purchase Order ID ReceiverOrderId Not relevant, since we process only FI invoices. Delivery Note Id DeliveryNoteId Not relevant Article Id ReceiverOrderId Not relevant Article Description Relevant Quantity According to Avveneo not relevant, probably needs to be discussed once again. Unit According to Avveneo not relevant, probably needs to be discussed once again. Amount According to Avveneo not relevant, probably needs to be discussed once again. TotalAmount Relevant

OPEN: Provided Data under \\nas01\customerdata

Uploaded data must follow directory structure: - Main dir:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Closed-Features\SSK---Invoice---Line-Label-Finder.md - Chunk 0
SSK - Invocie - Line Label Finder

The task is to identify all values of an invoice table, rows (aka lines) and columns and draw bounding boxes around it.

Input data: Anonymized image XML data that includes normalized values of the invoice table (without bounding box info) JSONs that includes OCR results from Nuance with bounding box data

Output: Image with bounding boxes for each found value in the table (green), for each line (blue) and each column(orange) (see sample)

Delivery: Python Code and short description how to run it on my local windwos machine

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 0
Introduction

This is an example how you can use chatGPT as a pair programmer. Here, we implement a CustomerInformation service. The service consists of a frontend, implemented in react, a backend implement in asp.net core and a mongodb database. The frontend is a webpage where one can enter some customer information, name, address, etc. and submit it to the backend. At the backend it is validated and stored in a database.

Chat Protocol

ME: I want you to act as my pair programming Partner. You are the driver and I'm the navigator.

ChatGPT: Sure, I'd be happy to help you with pair programming! Please let me know what programming language and environment you're working with, and what task or project you're working on. Also, could you explain your role as the navigator in more detail so I can better understand how I can assist you?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 1
ME: Ok, here are the requirements. I need a asp.net core application implemented in c# with a react frontend. I need one page where I can insert customer contact information: Name, adresse, Phone number and Email address. There shall be a Submit Button. Customer Information is sent to the backend where it is validated and finally stored in a database. Use mongodb as database. The app shall be deployed as a docker container. So a dockerfile is needed to. Let's start with an genetal outline. List all the steps needed to implement and deploy this service.

ChatGPT Sure, here are the high-level steps we would need to follow to implement and deploy this ASP.NET Core application with React frontend, MongoDB database, and Docker containerization:

Create a new ASP.NET Core web application using the dotnet new command with the --react option to include React template.

Add a MongoDB database to the project using the MongoDB driver for C# and install the required NuGet packages.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 2
Add a MongoDB database to the project using the MongoDB driver for C# and install the required NuGet packages.

Create a customer model class to represent the customer data and define a MongoDB collection to store the customer documents.

Create a customer controller with a POST action method to handle customer creation requests.

Implement validation logic in the customer model and controller to ensure the customer data is valid before saving to the database.

Create a React component for the customer information form with inputs for name, address, phone number, and email address and a submit button.

Use the fetch API in the React component to send the customer data to the backend API endpoint.

Implement error handling and display success/failure messages in the React component based on the API response.

Create a Dockerfile for the application that builds and packages the ASP.NET Core and React code into a single container, with the MongoDB server running as a separate container.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 3
Create a Dockerfile for the application that builds and packages the ASP.NET Core and React code into a single container, with the MongoDB server running as a separate container.

Use the docker-compose tool to orchestrate the containers and deploy the application.

These are the general steps we would follow to implement and deploy the ASP.NET Core application with React frontend, MongoDB database, and Docker containerization. Let me know if you have any questions or if there are any other details I can help with.

ME: Ok, let's implement each step. One step after another. But please stop after each step and let me Review your output.

ChatGPT: Sure, I'm happy to help with that. Let's begin with step 1: creating a new ASP.NET Core web application with the React template.

To create a new ASP.NET Core web application with the React template, we can use the following dotnet new command in a terminal:

Copy code bash dotnet new react -o CustomerApp

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 4
To create a new ASP.NET Core web application with the React template, we can use the following dotnet new command in a terminal:

Copy code bash dotnet new react -o CustomerApp

This command creates a new ASP.NET Core web application with the React template and stores it in a folder named CustomerApp. The React template includes a pre-configured React application and an ASP.NET Core backend that uses Web API to handle HTTP requests.

After running this command, you should see the following output in the terminal:

```bash The template "ASP.NET Core with React.js" was created successfully.

Processing post-creation actions... Running 'dotnet restore' on CustomerApp/CustomerApp.csproj... Restoring packages for /CustomerApp/CustomerApp.csproj... Generating MSBuild file /CustomerApp/obj/CustomerApp.csproj.nuget.g.props. Generating MSBuild file /CustomerApp/obj/CustomerApp.csproj.nuget.g.targets. Restore completed in 5.5 sec for /CustomerApp/CustomerApp.csproj.

Restore succeeded.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 5
```

This creates the initial project structure for our application with some sample code. Let me know if you have any questions or concerns.

ME: Ok great. Move on to step 2.

ChatGPT: Great! For step 2, we need to add the MongoDB driver for C# and install the required NuGet packages. We can do this using the dotnet add package command.

In the terminal, navigate to the project folder CustomerApp and run the following command:

bash dotnet add package MongoDB.Driver

This command installs the MongoDB driver for C# in our project and adds the required dependencies to the project file CustomerApp.csproj.

After running this command, you should see the following output in the terminal:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 6
After running this command, you should see the following output in the terminal:

bash Writing /tmp/tmp.2NXd1yLwMu.CustomerApp.csproj. info : Adding PackageReference for package 'MongoDB.Driver' into project '/tmp/tmp.2NXd1yLwMu/CustomerApp.csproj'. log : Restoring packages for /tmp/tmp.2NXd1yLwMu/CustomerApp.csproj... info : GET https://api.nuget.org/v3-flatcontainer/mongodb.driver/index.json info : OK https://api.nuget.org/v3-flatcontainer/mongodb.driver/index.json 111ms info : GET https://api.nuget.org/v3-flatcontainer/mongodb.bson/index.json ...

This installs the MongoDB driver for C# in our project, which we will use to interact with our MongoDB database.

Let me know if you have any questions or if there's anything else I can help with.

ME: We also need a mongodb. Use a docker image.

ChatGPT: Sure, we can use a Docker image for MongoDB to run our database. Here are the steps to set up MongoDB in a Docker container:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 7
ME: We also need a mongodb. Use a docker image.

ChatGPT: Sure, we can use a Docker image for MongoDB to run our database. Here are the steps to set up MongoDB in a Docker container:

Pull the MongoDB image from Docker Hub using the following command:

bash docker pull mongo

This command downloads the latest stable version of the MongoDB image from Docker Hub.

Start a new container from the MongoDB image using the following command:

bash docker run --name mymongo -d mongo

This command starts a new container named mymongo from the MongoDB image we just pulled. The -d flag runs the container in the background as a daemon.

Note: By default, the MongoDB container listens on port 27017. If you need to change this port, you can use the -p flag to map a different port to the container.

Verify that the MongoDB container is running using the following command:

bash docker ps

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 8
Verify that the MongoDB container is running using the following command:

bash docker ps

This command lists all the running Docker containers on your system. You should see a container named mymongo in the output.

That's it! We now have a running MongoDB container that we can use for our ASP.NET Core application. Let me know if you have any questions or if there's anything else I can help with.

ME: Ok great, step 1 and 2 are already Finished. Implement step 3, 4 and 5.

ChatGPT: Sure, let's continue with steps 3, 4, and 5.

Step 3: Create a customer model class and define a MongoDB collection

To represent the customer data, we need to create a customer model class. In the Models folder of our project, create a new C# class file named Customer.cs with the following code:

```csharp using MongoDB.Bson; using MongoDB.Bson.Serialization.Attributes;

namespace CustomerApp.Models { public class Customer { [BsonId] [BsonRepresentation(BsonType.ObjectId)] public string Id { get; set; }

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 9
namespace CustomerApp.Models { public class Customer { [BsonId] [BsonRepresentation(BsonType.ObjectId)] public string Id { get; set; }

    [BsonElement("name")]
    public string Name { get; set; }

    [BsonElement("address")]
    public string Address { get; set; }

    [BsonElement("phone")]
    public string Phone { get; set; }

    [BsonElement("email")]
    public string Email { get; set; }
}

}

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 10
```

This creates a Customer class with properties for the customer's name, address, phone number, and email address. We also use the BsonId attribute to mark the Id property as the document's primary key, and the BsonRepresentation attribute to specify the ObjectId representation of the primary key.

Next, we need to define a MongoDB collection to store our Customer documents. In the Data folder of our project, create a new C# class file named CustomerContext.cs with the following code:

```csharp using MongoDB.Driver;

namespace CustomerApp.Data { public class CustomerContext { private readonly IMongoDatabase _db;

    public CustomerContext(IMongoClient client, string dbName)
    {
        _db = client.GetDatabase(dbName);
    }

    public IMongoCollection<Customer> Customers => _db.GetCollection<Customer>("customers");
}

}

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 11
```

This creates a CustomerContext class with a property for the Customers collection. The IMongoCollection

Step 4: Create a customer controller

To handle customer creation requests, we need to create a customer controller. In the Controllers folder of our project, create a new C# class file named CustomerController.cs with the following code:

```csharp using CustomerApp.Data; using CustomerApp.Models; using Microsoft.AspNetCore.Mvc; using MongoDB.Driver;

namespace CustomerApp.Controllers { [Route("api/[controller]")] [ApiController] public class CustomerController : ControllerBase { private readonly CustomerContext _context;

    public CustomerController(CustomerContext context)
    {
        _context = context;
    }

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 12
public CustomerController(CustomerContext context)
    {
        _context = context;
    }

    [HttpPost]
    public ActionResult<Customer> Create(Customer customer)
    {
        try
        {
            _context.Customers.InsertOne(customer);
            return CreatedAtRoute("GetCustomer", new { id = customer.Id.ToString() }, customer);
        }
        catch (MongoException ex)
        {
            return BadRequest(ex.Message);
        }
    }
}

}

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 13
```

This creates a CustomerController class with a POST action method that handles customer creation requests. The method receives a Customer object in the request body and inserts it into the Customers collection using the _context object. If the insertion is successful, the method returns a 201 Created response with the newly created customer document in the response body. If an error occurs, the method returns a 400 Bad Request response with the error message.

Step 5: Implement validation logic

To ensure that the customer data is valid before saving to the database, we need to add some validation logic to the Customer

ME: Ok, add the validation logic.

ChatGPT: Sure, let's add some validation logic to the Customer model and CustomerController.

To validate the customer data, we can use the System.ComponentModel.DataAnnotations namespace in our Customer model. Modify the Customer class in the Models/Customer.cs file as follows:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 14
To validate the customer data, we can use the System.ComponentModel.DataAnnotations namespace in our Customer model. Modify the Customer class in the Models/Customer.cs file as follows:

```csharp using System.ComponentModel.DataAnnotations; using MongoDB.Bson; using MongoDB.Bson.Serialization.Attributes;

namespace CustomerApp.Models { public class Customer { [BsonId] [BsonRepresentation(BsonType.ObjectId)] public string Id { get; set; }

    [Required(ErrorMessage = "Name is required")]
    [StringLength(100, MinimumLength = 2, ErrorMessage = "Name must be between 2 and 100 characters")]
    [RegularExpression(@"^[a-zA-Z\s]+$", ErrorMessage = "Name must contain only letters and spaces")]
    [BsonElement("name")]
    public string Name { get; set; }

    [Required(ErrorMessage = "Address is required")]
    [StringLength(1000, MinimumLength = 10, ErrorMessage = "Address must be between 10 and 1000 characters")]
    [BsonElement("address")]
    public string Address { get; set; }

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 15
[Required(ErrorMessage = "Phone number is required")]
    [RegularExpression(@"^[0-9]{10}$", ErrorMessage = "Phone number must be a 10-digit number")]
    [BsonElement("phone")]
    public string Phone { get; set; }

    [Required(ErrorMessage = "Email address is required")]
    [EmailAddress(ErrorMessage = "Email address is not valid")]
    [BsonElement("email")]
    public string Email { get; set; }
}

}

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 16
```

This adds validation attributes to the Name, Address, Phone, and Email properties of the Customer class. The Required attribute specifies that these fields are required, the StringLength attribute sets the minimum and maximum length, the RegularExpression attribute sets a pattern that the field must match, and the EmailAddress attribute ensures that the Email field is a valid email address.

Next, we need to update the CustomerController class in the Controllers/CustomerController.cs file to handle validation errors. Here's the updated code:

```csharp using CustomerApp.Data; using CustomerApp.Models; using Microsoft.AspNetCore.Mvc; using MongoDB.Driver;

namespace CustomerApp.Controllers { [Route("api/[controller]")] [ApiController] public class CustomerController : ControllerBase { private readonly CustomerContext _context;

    public CustomerController(CustomerContext context)
    {
        _context = context;
    }

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 17
public CustomerController(CustomerContext context)
    {
        _context = context;
    }

    [HttpPost]
    public ActionResult<Customer> Create(Customer customer)
    {
        // Validate the customer data
        var validationResults = new List<ValidationResult>();
        if (!Validator.TryValidateObject(customer, new ValidationContext(customer), validationResults, true))
        {
            return BadRequest(validationResults);
        }

        try
        {
            _context.Customers.InsertOne(customer);
            return CreatedAtRoute("GetCustomer", new { id = customer.Id.ToString() }, customer);
        }
        catch (MongoException ex)
        {
            return BadRequest(ex.Message);
        }
    }
}

}

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 18
```

This code uses the Validator.TryValidateObject method to validate the Customer object against its validation attributes. If any validation errors occur, the method returns a 400 Bad Request response with the validation error messages.

Let me know if you have any questions or if there's anything else I can help with.

ME: Ok, backend should be ready. Let's continue with the react Part. Continue with step 6, 7 and 8

ChatGPT: Great! Let's continue with steps 6, 7, and 8.

Step 6: Create a React component for the customer information form

To create a customer information form in React, we need to create a new React component. In the src/components folder of our project, create a new file named CustomerForm.js with the following code:

```jsx import React, { useState } from 'react';

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 19
```jsx import React, { useState } from 'react';

const CustomerForm = () => { const [name, setName] = useState(''); const [address, setAddress] = useState(''); const [phone, setPhone] = useState(''); const [email, setEmail] = useState(''); const [message, setMessage] = useState('');

const handleSubmit = (e) => { e.preventDefault();

fetch('/api/customer', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({ name, address, phone, email }),
})
  .then((response) => {
    if (response.ok) {
      setName('');
      setAddress('');
      setPhone('');
      setEmail('');
      setMessage('Customer created successfully!');
    } else {
      setMessage('Error creating customer. Please try again.');
    }
  })
  .catch((error) => {
    setMessage('Error creating customer. Please try again.');
  });

};

return (

Create Customer

{message &&

{message}

); };

export default CustomerForm;

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 20
```

This creates a CustomerForm component with form inputs for the customer's name, address, phone number, and email address. When the form is submitted, the component sends a POST request to the /api/customer endpoint with the customer data in the request body. If the request is successful, the component displays a success message. If the request fails, the component displays an error message.

Step 7: Use the fetch API to send customer data to the backend

To use the fetch API to send customer data to the backend, we need to import the CustomerForm component into our main App.js

ME: Ok, rewrite the react component from step 6. This time use typescript.

ChatGPT: Sure! Here's the updated CustomerForm.tsx component with TypeScript:

```typescript import React, { useState } from 'react';

interface Customer { name: string; address: string; phone: string; email: string; }

const CustomerForm: React.FC = () => { const [customer, setCustomer] = useState

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 21
interface Customer { name: string; address: string; phone: string; email: string; }

const CustomerForm: React.FC = () => { const [customer, setCustomer] = useState

const [message, setMessage] = useState

const handleSubmit = (e: React.FormEvent

fetch('/api/customer', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify(customer),
})
  .then((response) => {
    if (response.ok) {
      setCustomer({
        name: '',
        address: '',
        phone: '',
        email: '',
      });
      setMessage('Customer created successfully!');
    } else {
      setMessage('Error creating customer. Please try again.');
    }
  })
  .catch((error) => {
    setMessage('Error creating customer. Please try again.');
  });

};

const handleInputChange = ( e: React.ChangeEvent

return (

Create Customer

{message &&

{message}

); };

export default CustomerForm;

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 22
```

In this version, we use the useState hook to manage the state of the customer data and the success/error message. We also use TypeScript interfaces to define the types of the customer data.

Let me know if you have any questions or if there's anything else I can help with.

ME: Great, move on with step 7 and 8

ChatGPT: Great, let's continue with steps 7 and 8.

Step 7: Use the fetch API to send customer data to the backend

To use the fetch API to send customer data to the backend, we need to import the CustomerForm component into our main App.tsx file and render it in the render() method. In the src folder, open the App.tsx file and update it as follows:

```tsx import React from 'react'; import CustomerForm from './components/CustomerForm';

const App: React.FC = () => { return (

); };

export default App;

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 23
```

This imports the CustomerForm component and renders it inside a div element with a container class for Bootstrap styling.

Step 8: Run the React app

To run the React app, open a new terminal window, navigate to the project directory, and run the following command:

bash npm start

This will start the development server and open the app in your default browser. You should now see the customer information form. Fill out the form and click the "Submit" button. The form data should be sent to the backend API, validated, and stored in the MongoDB database.

Congratulations, you have successfully implemented a full-stack web application with ASP.NET Core, React, and MongoDB!

ME: Ok, finally we need everything to be deployed as a docker container. Therefore, we need the Dockerfile. This is the final task, step 9.

ChatGPT: Sure, let's create a Dockerfile to package the ASP.NET Core app, React app, and MongoDB into a single Docker container. Here's a sample Dockerfile that you can use:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 24
ChatGPT: Sure, let's create a Dockerfile to package the ASP.NET Core app, React app, and MongoDB into a single Docker container. Here's a sample Dockerfile that you can use:

```dockerfile

Use the official .NET Core runtime as a parent image

FROM mcr.microsoft.com/dotnet/core/aspnet:3.1-buster-slim AS base

Set the working directory

WORKDIR /app

Copy the published ASP.NET Core app to the container

COPY ./CustomerApp/bin/Release/netcoreapp3.1/publish .

Set the environment variables for the MongoDB connection string and ASP.NET Core app URL

ENV MONGODB_CONNECTION_STRING mongodb://mongo:27017 ENV ASPNETCORE_URLS http://*:80

Expose port 80 for the ASP.NET Core app

EXPOSE 80

Start the ASP.NET Core app

ENTRYPOINT ["dotnet", "CustomerApp.dll"]

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 25
```

This Dockerfile does the following:

Uses the official .NET Core runtime as a parent image Sets the working directory to /app Copies the published ASP.NET Core app from the ./CustomerApp/bin/Release/netcoreapp3.1/publish directory to the container's working directory (.) Sets environment variables for the MongoDB connection string and ASP.NET Core app URL Exposes port 80 for the ASP.NET Core app Sets the ENTRYPOINT to start the ASP.NET Core app with the dotnet command

To build and run the Docker container, follow these steps:

Build the ASP.NET Core app and React app:

bash dotnet publish -c Release npm run build

Build the Docker image:

bash docker build -t customer-app .

This command creates a Docker image named customer-app based on the Dockerfile.

Run the Docker container:

bash docker run -d --name customer-app-container -p 80:80 --link mongo:mongo customer-app

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 26
This command creates a Docker image named customer-app based on the Dockerfile.

Run the Docker container:

bash docker run -d --name customer-app-container -p 80:80 --link mongo:mongo customer-app

This command runs the customer-app Docker image in a new container named customer-app-container. The --link mongo:mongo option links the container to the MongoDB container named mongo. The -p 80:80 option maps port 80 in the container to port 80 on the host machine.

That's it! The ASP.NET Core app, React app, and MongoDB should now be running in a Docker container. You can access the app by navigating to http://localhost in your web browser.

ME: Ohh, we forgot step 10.

ChatGPT: I apologize for the oversight. What is step 10?

ME: The deployment and orchestration of Our service with docker-compose

ChatGPT: No problem, let's add step 10 to deploy and orchestrate our service with Docker Compose.

Step 10: Deploy and Orchestrate with Docker Compose

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 27
ChatGPT: No problem, let's add step 10 to deploy and orchestrate our service with Docker Compose.

Step 10: Deploy and Orchestrate with Docker Compose

Docker Compose is a tool for defining and running multi-container Docker applications. It allows us to define the services that make up our app in a single YAML file, making it easy to manage and deploy our app.

Create a new file named docker-compose.yml in the root directory of your project with the following contents:

```yaml version: '3.9'

services: app: build: . ports: - "80:80" depends_on: - mongo

mongo: image: mongo

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 28
```

This docker-compose.yml file defines two services: app and mongo. The app service is built from the current directory (.) and exposed on port 80. It depends on the mongo service, which is an official MongoDB Docker image.

To start the app with Docker Compose, run the following command in your terminal:

bash docker-compose up

This will start both the app and mongo services and output the logs for each service to the terminal. You should see the same output as when you ran the docker run command in step 9.

To run the app in the background, run the following command instead:

bash docker-compose up -d

This will start the services in detached mode, meaning they will run in the background. You can stop the services with the following command:

bash docker-compose down

This will stop and remove the containers for both services.

Congratulations! You have successfully deployed and orchestrated your ASP.NET Core, React, and MongoDB app with Docker Compose.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 29
This will stop and remove the containers for both services.

Congratulations! You have successfully deployed and orchestrated your ASP.NET Core, React, and MongoDB app with Docker Compose.

ME: I think the compose file is incomplete. The Name of Our service shall be "CustomerInformationService" . Please use this a service name and in lowercases.

ChatGPT: You are correct, I apologize for the mistake. Here's an updated docker-compose.yml file with the service name set to customerinformationservice:

```yaml version: '3.9'

services: customerinformationservice: build: . ports: - "80:80" depends_on: - mongo

mongo: image: mongo

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 30
```

With this update, the app service has been renamed to customerinformationservice. The service name should be in lowercase, as you requested.

To start the services with the updated name, run the following command:

bash docker-compose up

Or to run the services in the background:

bash docker-compose up -d

And to stop the services:

bash docker-compose down

I hope this helps. Let me know if you have any further questions or concerns.

ME: Ok please give me summary of what we have done so far.

ChatGPT: Sure, here's a summary of what we have done so far:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 31
We created an ASP.NET Core application with a single API endpoint that accepts customer data and stores it in a MongoDB database. We added validation logic to the API to ensure that the customer data is valid before storing it in the database. We created a React component that allows users to input customer data and submit it to the backend API. We set up a MongoDB database using a Docker container. We created a Dockerfile that packages the ASP.NET Core app, React app, and MongoDB into a single Docker container. We ran the Docker container to test the app in a local development environment. We updated the React component to use TypeScript for type checking and improved type safety. We used the fetch API to send customer data to the backend API. We created a Docker Compose file that defines the services for our app and database and allows us to easily manage and deploy them. We deployed and orchestrated our app and database using Docker Compose.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 32
Overall, we have successfully implemented a full-stack web application with ASP.NET Core, React, and MongoDB, and have deployed and orchestrated the app using Docker Compose.

ME: Ok, let's extend Our app. Here is a new requirement. It should be possible to update customerinformation. It should be possible to list all customerinformation, select a certain customer, Update some fields and Update this item in the database. Let's again with an outline of what needs to be done.

ChatGPT: Sure, here's an outline of the steps needed to implement the new requirement:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 33
ChatGPT: Sure, here's an outline of the steps needed to implement the new requirement:

Update the Customer class in the ASP.NET Core app to include an Id property to uniquely identify each customer. Create a new API endpoint to get all customers from the database and return them as a JSON array. Create a new API endpoint to update a customer's information in the database. Create a new React component to display a list of customers and allow users to select and update a specific customer's information. Update the existing CustomerForm component to allow users to edit existing customer information and send the updated information to the backend API.

Let me know if you have any questions or concerns about these steps.

ME: Please start with step 1.

ChatGPT: Sure, let's start with step 1.

Step 1: Add an Id property to the Customer class

To uniquely identify each customer in the database, we need to add an Id property to the Customer class in the ASP.NET Core app.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 34
Step 1: Add an Id property to the Customer class

To uniquely identify each customer in the database, we need to add an Id property to the Customer class in the ASP.NET Core app.

Open the Customer.cs file in the Models folder and update it as follows:

```csharp using MongoDB.Bson; using MongoDB.Bson.Serialization.Attributes;

namespace CustomerApp.Models { public class Customer { [BsonId] [BsonRepresentation(BsonType.ObjectId)] public string Id { get; set; }

    [BsonElement("Name")]
    public string Name { get; set; }

    [BsonElement("Address")]
    public string Address { get; set; }

    [BsonElement("Phone")]
    public string Phone { get; set; }

    [BsonElement("Email")]
    public string Email { get; set; }
}

}

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 35
```

Here, we have added a string property named Id with the [BsonId] and [BsonRepresentation(BsonType.ObjectId)] attributes to specify that it will be the unique identifier for each customer. We have also updated the other properties with [BsonElement] attributes to map them to the correct field names in the MongoDB collection.

Let me know if you have any questions or if there's anything else I can help with.

ME: Continue with step 2 and 3.

ChatGPT: Sure, let's continue with steps 2 and 3.

Step 2: Create a new API endpoint to get all customers from the database

To create a new API endpoint to get all customers from the database, we need to add a new controller method to the CustomerController.cs file.

Open the CustomerController.cs file in the Controllers folder and add the following method:

csharp [HttpGet] public async Task<ActionResult<IEnumerable<Customer>>> GetCustomers() { var customers = await _customerService.GetCustomers(); return Ok(customers); }

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 36
csharp [HttpGet] public async Task<ActionResult<IEnumerable<Customer>>> GetCustomers() { var customers = await _customerService.GetCustomers(); return Ok(customers); }

Here, we have added a new HttpGet method named GetCustomers() that returns an ActionResult

Step 3: Create a new API endpoint to update a customer's information in the database

To create a new API endpoint to update a customer's information in the database, we need to add a new controller method to the CustomerController.cs file.

Open the CustomerController.cs file in the Controllers folder and add the following method:

```csharp [HttpPut("{id:length(24)}")] public async Task

if (customer == null)
{
    return NotFound();
}

customer.Name = updatedCustomer.Name;
customer.Address = updatedCustomer.Address;
customer.Phone = updatedCustomer.Phone;
customer.Email = updatedCustomer.Email;

await _customerService.UpdateCustomer(customer);

return NoContent();

}

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 37
```

Here, we have added a new HttpPut method named UpdateCustomer() that takes a string parameter named id and a Customer object named updatedCustomer. We first retrieve the customer with the specified id using the _customerService instance's GetCustomerById() method. If the customer is not found, we return a NotFound result.

If the customer is found, we update the customer's properties with the properties of the updatedCustomer object. We then call the _customerService instance's UpdateCustomer() method to update the customer in the database. Finally, we return a NoContent result to indicate that the update was successful.

Let me know if you have any questions or concerns about these steps.

ME: Implement step 4

ChatGPT: Sure, let's move on to step 4.

Step 4: Create a new React component to display a list of customers and allow users to select and update a specific customer's information.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 38
ChatGPT: Sure, let's move on to step 4.

Step 4: Create a new React component to display a list of customers and allow users to select and update a specific customer's information.

To implement this step, we'll create a new React component named CustomerList, which will display a list of all customers and allow users to select and update a specific customer's information.

Create a new file named CustomerList.tsx in the src/components directory and add the following code:

```typescript import React, { useState, useEffect } from 'react'; import { Customer } from '../types';

interface Props { onCustomerSelect: (customer: Customer) => void; }

const CustomerList: React.FC

useEffect(() => { fetch('/api/customer') .then((res) => res.json()) .then((data) => setCustomers(data)) .catch((err) => console.error(err)); }, []);

const handleSelectCustomer = (customer: Customer) => { onCustomerSelect(customer); };

return (

Customer List

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 39
const handleSelectCustomer = (customer: Customer) => { onCustomerSelect(customer); };

return (

Customer List

Name Address Phone Email Actions {customer.name} {customer.address} {customer.phone} {customer.email} handleSelectCustomer(customer)}>
                  Edit

); };

export default CustomerList;

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 40
```

In this code, we define a new functional component named CustomerList that takes an onCustomerSelect prop function. The component has a state variable named customers, which is initialized as an empty array using the useState hook.

We use the useEffect hook to fetch all customers from the backend API and update the customers state variable when the component mounts.

We then define a helper function named handleSelectCustomer that takes a Customer object and calls the onCustomerSelect prop function with the selected customer.

Finally, we render a table that displays all customers with an Edit button next to each row. When a user clicks the Edit button, the handleSelectCustomer function is called with the selected customer.

Let me know if you have any questions or concerns about this step.

ME: Implement step 5

ChatGPT: Sure, let's move on to step 5.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 41
Let me know if you have any questions or concerns about this step.

ME: Implement step 5

ChatGPT: Sure, let's move on to step 5.

Step 5: Update the existing CustomerForm component to allow users to edit existing customer information and send the updated information to the backend API.

To implement this step, we'll update the existing CustomerForm component to allow users to edit existing customer information and send the updated information to the backend API.

Open the CustomerForm.tsx file in the src/components directory and update it as follows:

```typescript import React, { useState, useEffect } from 'react'; import { Customer } from '../types';

interface Props { customer: Customer | null; onUpdate: (customer: Customer) => void; }

const CustomerForm: React.FC

useEffect(() => { if (customer) { setName(customer.name); setAddress(customer.address); setPhone(customer.phone); setEmail(customer.email); } }, [customer]);

const handleSubmit = (event: React.FormEvent

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 42
const handleSubmit = (event: React.FormEvent

if (customer) {
  const updatedCustomer = { ...customer, name, address, phone, email };
  fetch(`/api/customer/${customer.id}`, {
    method: 'PUT',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify(updatedCustomer),
  })
    .then((res) => res.json())
    .then((data) => onUpdate(data))
    .catch((err) => console.error(err));
}

};

return (

); };

export default CustomerForm;

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 43
```

Here, we have updated the CustomerForm component to take a customer prop, which is either null or a Customer object. We use the useState hook to manage the form input values for name, address, phone, and email.

We use the useEffect hook to update the input values when the customer prop changes.

We also define a new handleSubmit function that is called when the form is submitted. If a customer object is provided, we create a new updatedCustomer object with the new input values and send a PUT request to the backend API with the updated customer information.

If the request is successful

ME: What will I see when I start the app. Do we need a kind of startpage with a menu for Navigation?

ChatGPT: At this point, your app should have the following functionality:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 44
ME: What will I see when I start the app. Do we need a kind of startpage with a menu for Navigation?

ChatGPT: At this point, your app should have the following functionality:

A form that allows you to add new customers with their name, address, phone, and email information. The ability to validate customer input and store it in a MongoDB database. A Dockerfile that enables you to deploy the app as a Docker container. A Docker Compose file that enables you to orchestrate and deploy the app alongside a MongoDB container.

With the new functionality we just added, your app should now also have the following:

A new API endpoint that allows you to retrieve all customers from the database. A new API endpoint that allows you to update an existing customer's information in the database. A React component that displays a list of all customers and allows you to select and edit a specific customer's information.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 45
Regarding a start page with a menu for navigation, it depends on how complex your app will be and how many different components or pages it will have. If your app is simple and only has a few components, you may not need a start page with a menu. However, if your app is more complex and has multiple components or pages, you may want to consider adding a start page with a menu for easier navigation.

ME: I think we should add a start Page. I would like to use a react framework for it. Any suggestions? It should be easy to use, written in typescript and with nice css styles. Would be nice if authentication is somehow included. Dashboard widgets would also be nice because I think I will extend Our app with some dashboard functionalities in the future.

ChatGPT: Sure, I can recommend some React frameworks that meet your requirements.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 46
ChatGPT: Sure, I can recommend some React frameworks that meet your requirements.

Next.js - Next.js is a popular React framework that provides server-side rendering, automatic code splitting, and simplified client-side routing. It's written in TypeScript and comes with a number of CSS styling options out of the box. Next.js also includes features for authentication, such as JWT tokens and built-in support for third-party authentication providers. Next.js also has a built-in dashboard component for displaying and managing data.

Gatsby - Gatsby is a static site generator that uses React to create fast, performant websites. It's written in TypeScript and comes with a wide range of CSS styling options, including support for CSS-in-JS libraries like styled-components. Gatsby also includes plugins for adding authentication and authorization to your site, and has a number of plugins for creating dashboard components.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 47
React Admin - React Admin is a framework for building admin interfaces for web applications. It's written in TypeScript and includes a wide range of pre-built UI components, including form inputs, data grids, and dashboard widgets. React Admin also includes features for authentication and authorization, and has integrations with popular authentication providers like Auth0 and Firebase.

All of these frameworks are popular choices for building React apps and should meet your requirements for ease of use, TypeScript support, and CSS styling. Each also includes features for authentication and authorization, and has integrations with popular authentication providers.

ME: Let's use react admin.

ChatGPT: Sure, React Admin is a great choice for building admin interfaces for web applications.

To get started with React Admin, you can follow the official documentation here: https://marmelab.com/react-admin/Readme.html#installation.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 48
To get started with React Admin, you can follow the official documentation here: https://marmelab.com/react-admin/Readme.html#installation.

Here's a brief overview of the steps involved in setting up React Admin:

Install React Admin and its dependencies using npm or yarn. bash npm install react-admin ra-data-json-server prop-types

Create a new file named App.js in the src directory and add the following code: ```typescript import React from 'react'; import { Admin, Resource } from 'react-admin'; import jsonServerProvider from 'ra-data-json-server'; import { CustomerList, CustomerEdit, CustomerCreate } from './components/Customer';

const dataProvider = jsonServerProvider('http://localhost:3000');

const App = () => ( );

export default App;

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 49
```

Here, we import the Admin and Resource components from react-admin, and the jsonServerProvider from ra-data-json-server. We also import our custom CustomerList, CustomerEdit, and CustomerCreate components.

We then create a new dataProvider object using jsonServerProvider, which points to our backend API endpoint.

Finally, we wrap our app with the Admin component, passing in the dataProvider prop, and register our CustomerList, CustomerEdit, and CustomerCreate components with the Resource component.

Create a new directory named components in the src directory and add the following files: Customer.js:

```typescript import React from 'react'; import { List, Edit, Create, SimpleForm, TextInput, EmailField } from 'react-admin';

export const CustomerList = (props) => ( );

export const CustomerEdit = (props) => ( );

export const CustomerCreate = (props) => ( );

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\ChatGPT-as-Pair-Programmer.md - Chunk 50
```

Here, we define our custom CustomerList, CustomerEdit, and CustomerCreate components using the List, Edit, and Create components from react-admin. We also use the TextInput and EmailField components to define our form inputs.

Start your app and navigate to http://localhost:3000. You should see the React Admin dashboard with a list of customers and the ability to create, edit, and delete customers.

That's it! With these steps, you should be able to set up a basic React Admin app and use it to manage customer information. From here, you can customize the app by adding more components and integrating with other APIs and authentication providers.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\Entscheidungsgrenzen-für-normal-verteilte-Zufalls--Größen.md - Chunk 0
n <- params$sample
alpha <- params$alpha
init_estimator <- params$init_estimator

#lineitem#decision#continuousbenchmark

Path to report_file(only local on 102 - Philipp's machine): D:\source\Backup\BCS\Reporting\LineItemSuccessReport

11080

Voraussetzungen

Der Erolg der LineItem Predictions wird nicht auf Dokumenten- Ebene gemessen. Vielmehr kann man sich vorstellen, dass eine Zufallsstichprobe von LineItems in Form von Rechnungs- Dokumenten erhoben wird. Das Erheben von N Dokumente liefert n Merkmale.

Dieser Report kann mit Hilfe von n, alpha und dem bis dahin bekannten Schätzwert parametrisiert werden.

Ziel

Gesucht wird ein Quantil als Entscheidungsgrenze. Die Vorgehensweise entspricht dem eines Gauss Tests auf den Unterschied eines Proportions- Schätzers. Die Grundannahme, dass relative Häufigkeiten als Erfolgs- Wahrscheinlichkeit normalverteilt ist, wird durch den zentralen Grenzwertsatz belegt.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\Entscheidungsgrenzen-für-normal-verteilte-Zufalls--Größen.md - Chunk 1
Es soll nun überprüft werden ob sich ein Schätzer (in diesem Falle p) verbessert hat.

Um eine wissenschaftlich korrekte Aussage liefern zu können, ist es nötig sich auf einen in Kauf zu nehmenden möglichen alpha- Fehler festzulegen. Im Allgemeinen werden diese oft bei 5% oder im klinischen Bereich bei 1% festgelegt.

Beispiel

Wieviele LineItems müssen richtig erkannt werden, sodass in weniger als 5% ein Fehler erster Art begangen wird wenn man annimmt, dass die Erkennung besser wurde? N.B.: Ein Fehler erster Art oder alpha-Fehler entsteht dann, wenn man eine richtige Nullhypothese verwirft.

H0: Die Erfolgswahrscheinlichkeit hat sich nicht verändert: p=0.3.

H1: Die Erfolgswahrscheinlichkeit ist größer geworden. p>0.3.

X...Anzahl aller richtig erkannten Line-Items.

p=0.3

n=800

sigma <- sqrt(n*init_estimator*(1-init_estimator))
m<- n*init_estimator

Standardabweichung=12.961481>3.

Darum wird mit der Normalverteilung approximiert.

Mittelwert=240

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\Entscheidungsgrenzen-für-normal-verteilte-Zufalls--Größen.md - Chunk 2
p=0.3

n=800

sigma <- sqrt(n*init_estimator*(1-init_estimator))
m<- n*init_estimator

Standardabweichung=12.961481>3.

Darum wird mit der Normalverteilung approximiert.

Mittelwert=240

decision_boundary <- ceiling(qnorm(1-alpha, mean = m, sd = sigma, lower.tail = TRUE, log.p = FALSE))

Ergebnis

Auf einem Signifikanzniveau von 1-alpha=95% können wir ab 262 korrekt vorhergesagten LineItems behaupten, dass sich die Erkennungsrate verbessert hat. Als neuen Schätzer nimmt man den relativen Anteil der korrekt erkannten LineItems (=0.3275).

x <- seq(m-4*sigma, m+4*sigma, length.out=100)
plot(x, dnorm(x, mean=m, sd=sigma), typ="l")
abline(v=qnorm(1-alpha, mean = m, sd = sigma, lower.tail = TRUE, log.p = FALSE), col="red")
title("Beispiel einer 1-alpha Entscheidungsgrenze")

NB

Interessiert man sich, ob eine Verändunger (zweiseitiger Test) oder eine Verschlechterung der Erkennungsrate stattgefunden hat, muss man die Entscheidungsgrenzen entsprechend anpassen.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\Entscheidungsgrenzen-für-normal-verteilte-Zufalls--Größen.md - Chunk 3
NB

Interessiert man sich, ob eine Verändunger (zweiseitiger Test) oder eine Verschlechterung der Erkennungsrate stattgefunden hat, muss man die Entscheidungsgrenzen entsprechend anpassen.

Für eine genau Auswertung von LineItems Ergebnissen kann es sinnvoll sein, jedes Item mit einer Id (Doc_Id + Position) zu versehen um tiefere Analysen der entsprechenden Benchmarks vorzunehmen.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\Experience-ChatGPT.md - Chunk 0
Paste Your ChatGPT Experience here ... Start with your first name and then explain youre experience.

Chris: ChatGPT lost information about BLU DELTA!?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\Generic-document-intelligence-problem-classification.md - Chunk 0
Based on a simple analysis of various documents (invoiice, order, delivery note, ABD) I tried to come up with common patterns for solving extraction problems:

Context influences results

Context = Dokumentenart / Prozess / Industrie / Unternehmen e.g. Bestellung / Auftragsbestätigung / Chemie / Produktkatalog Unternehmen + Kundenregister

1 Find a value based on a format pattern:

e.g. UID / IBAN

2 Find a value based on a position

e.g. values in forms like ABD

3 Find a value including semantic hints (indicators)

e.g. Rechnungsnummer: 123456

4 Map chars to related entries in available structured data

E.g. Bezirksstelle von ÖRK, Map to correct address, map to correct entry in product catalogue, map to correct Schadensfall, etc.

5 Detect complex groups of information based on structure (while structure means a certain pattern of entities):

e.g. LineItemTable, Address

6 Classify meaning of sentences

e.g. Skonto, Zahlungsbedingungen, ...

7 Find values based on defined relations

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\Generic-document-intelligence-problem-classification.md - Chunk 1
e.g. LineItemTable, Address

6 Classify meaning of sentences

e.g. Skonto, Zahlungsbedingungen, ...

7 Find values based on defined relations

e.g. VAT Group

Check against Gutachten Sample:

1 FIN: Pattern 1 2 Reparaturkosten: Pattern 3 3 Wertminderung: Pattern 6 4 Wiederbeschaffungswert: Patter 3 5 Restwert: Pattern 6 (dürfte optional sein, hat evtl. Bedeutung) 6, 7, 8 -> known items 9 Zertifikat??? Finde ich nicht 10 Datum Gutachten: Pattern 3 (e.g. Gutachten vom ...) / Leistungsdatum Rechnung 11, 12 Menge Wegstrecke: #5 (12 optional) 13 NICHT GEFUNDEN?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\OCR-Number-Benchmark.md - Chunk 0
OCR Number Benchmark

Created BLU DELTA OCR Number Benchmark based on: 62 number snippets with decent quality: GoodOCRSamples.pdf 24 number snippets with bad quality: BadOCRSamples.pdf

Basic Expectation on Exact Results would be: 62/86 = ~70%

Basic Results based on 86 labels:

Benchmark comparison done with Exact match and Comparison of Levenshtein distance

OCR Provider Exact Avg. Levenshtein Google OCR 92% 95,70% Paddle OCR 64% 92,26% AbbyyFineReader15 71% 86,47% Omnipage Ultimate V19.2 62% 82% Omnipage OCR 60% 81% Tesseract 5 OCR 57% 73% OCR.space 50% 74% Onlineocr.net 42% 69%

Detailed Benchmark Evaluation: BLUDELTA-OCR-Number-Benchmark-202204.zip BLUDELTA-OCR-Number-Benchmark-202205.zip

Tesseract was tested based on following website: https://cdkm.com/ocr Omnipage download and Version includes statement that it is based on 2019.

Updated Excel: Documents.zip

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\Rebase---ChatGPT.md - Chunk 0
me: I have a git feature branch and a main branch. Now I want to bring my new feature into the main branch. Therefore, I want to use git rebase. How can I do this?

char: To integrate your feature branch into the main branch using git rebase, follow these steps:

Ensure that you have committed all your changes in the feature branch. Uncommitted changes may cause issues during the rebase process.

Switch to the main branch:

bash git checkout main

Make sure your main branch is up-to-date with the remote repository (assuming the remote is named 'origin'): bash git pull origin main

Switch back to your feature branch: bash git checkout feature-branch

Rebase your feature branch onto the main branch. This will apply the changes you made in the feature branch on top of the main branch, making it seem like you developed the feature directly on the main branch: bash git rebase main

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\Rebase---ChatGPT.md - Chunk 1
During the rebase process, you may encounter conflicts if the changes in your feature branch and the main branch have overlapping modifications. Git will pause the rebase and ask you to resolve the conflicts. Edit the conflicting files, and once you have resolved the conflicts, stage the changes using git add

Continue the rebase process after resolving conflicts: bash git rebase --continue

Repeat steps 5 and 6 until all conflicts are resolved and the rebase is complete.

Switch back to the main branch: bash git checkout main

Merge the feature branch into the main branch (this should be a fast-forward merge since you've rebased the feature branch): sql bash git merge feature-branch

(Optional) If you want to push your changes to the remote repository: bash git push origin main

(Optional) If you no longer need the feature branch, you can delete it locally and on the remote repository: bash git branch -d feature-branch git push origin --delete feature-branch

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\Rebase---ChatGPT.md - Chunk 2
(Optional) If you no longer need the feature branch, you can delete it locally and on the remote repository: bash git branch -d feature-branch git push origin --delete feature-branch

By using git rebase, you've maintained a linear history and made it easier to understand the relationship between the commits in your repository.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\Invoices\Delivery-Date---Customer-Info.md - Chunk 0
Customer information regarding delivery date

Eurodata

For bookkeeping the delivery date is determined based on following method:

1) Line Item: Max, min from line items 2) Header data 3) No delivery date explicitly mentioned: delivery date = invoice date 4) Delivery date and invoice date is not distinguished

Domonda

Does not distinguish between delivery date and service date. Processes delivery period via start and end date. E.g. "April tp May 2022" is processed as 1.4.2022 - 31.5.2022

Diamant

Distinction between delivery date and service date is not important for Diamant, since this is not relevant for a §14 check.

Delivery period: Start and end date would be perfect. In case of e.g. Jan-Feb 2022 -> 1.1.2022 - 28.2.2022 Question: What if invoice date is e.g. 13.2. ? Is it possible that the delivery happens after the invoice date? Might be an edge case.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\Invoices\Delivery-Date---Customer-Info.md - Chunk 1
Diamant would benefit from a more detailed DocType classification (more than just Invoice vs. credit memo). Following types would be of interest:

Invoice: Service vs. Delivery (Dienstleistungsrechnung vs. Warenlieferung) Deposit (Anzahlung) Advance Payment (Abschlagszahlung) Schlußrechnung No high priority -> added to Feature requests wiki page. (Link)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\Invoices\LineItems---TaxConsultants.md - Chunk 0
What do Tax Consultants require from the line items feature?

based on information from Eurodata (Mr. Bürckert): - Total: Net vs. gross calculation (MUST) - Quantity (MUST) - Unit (rather nice to have) - Descriptions (MUST) - Taxes (MUST) - Delivery Date / Timeframe - Distinguish - taxes vs. discount - bon - tax category in legend in line items (Germany only?) - NICE TO HAVE - Distinguish - Material vs. Services

WHY? Description - Based on this information an AI model is trained to map on a the right booking account Amounts - required for cross checks Taxes used to find right booking account and cross-checks Quanity for bookkeeping and cross checks Delivery timeframe/date - to distinguish overall delivery timeframe

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\Invoices\More-than-one-Sender-VAT-Id(s).md - Chunk 0
ich habe recherchiert, ob ein Unternehmen (also eine Körperschaft) grundsätzlich mehr als eine UstId haben kann. JA, das ist möglich!

Es geht um die Frage, wo das Unternehmen steuerpflichtig ist. Es gibt Situationen, in denen eine Firma in mehreren Ländern steuerpflichtig sein kann. Zwar ist das meist über Auslandsniederlassungen / Tochterunternehmen (also eigne Körperschaften) abgebildet, das ist aber nicht unbedingt notwendig. Im B2B Bereich innerhalb der EU werden Auslandsgeschäfte über Reverse Charge / Innergemeinschaftliche Lieferungen „steuerfrei“ abgewickelt, aber im B2C Bereich sieht das anders aus.

Ich habe mir das Beispiel von vorhin angeschaut: Parkett-Aktion GmbH

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\Invoices\More-than-one-Sender-VAT-Id(s).md - Chunk 1
Ich habe mir das Beispiel von vorhin angeschaut: Parkett-Aktion GmbH

Ich finde zu dieser Firma nur die Ö Adresse, ich gehe also davon aus, dass es nur diese eine Niederlassung und eine Körperschaft gibt. Das Impressum deutet auch darauf hin. Die Firma betreibt einen Online Shop, dort können Private und Unternehmen einkaufen. Wenn ein österreichischer Privatkunde einkauft, dann bekommt er eine Rechnung mit 20% MwSt., ein deutscher Kunde bekommt er eine Rechnung mit 19% MwSt. Die deutsche MwSt. muss das Unternehmen in DE abführen. -> Wenn ein Unternehmen in mehreren Ländern Geschäfte macht, benötigt es in der Regel eine separate USt-ID für jedes Land, in dem es umsatzsteuerpflichtig ist. Dies dient dazu, die Umsatzsteuer korrekt abzurechnen und an die jeweiligen Steuerbehörden abzuführen. In unserem Bsp. hat Dachser DE eingekauft, deshalb keine MwSt.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Knowledge-Base-documents\Invoices\More-than-one-Sender-VAT-Id(s).md - Chunk 2
Aus meiner Sicht ist das ein Edge Case und in aller Regel steht eine eigene Körperschaft hinter einer UstId. Und damit auch eine UstId für den Rechnungssteller. Wir sollten auf jeden Fall an unserer Strategie festhalten, eine SenderVatId zu liefern.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Naming-Conventions\API-Detail-Naming-Convention.md - Chunk 0
Product API Policy / Version >1.18.x AND <2.0

here you find a naming convention for our APIs. If you miss a term or description then ask your product owner for help.

[[TOC]]

Basic Schema

Detail TypeNames must follow BLU DELTA API schema:

is a must notation [abc] is a optional notation

<[Country][Industry][Customer][DocType][DetailName]> Pascal Case: e.g. DachserPurchaseOrderId (always capital letter for new word) Must be unique within document domain Wherever possible we want to use standards.

<[Country][Industry][Customer][DocType][DetailName]> At least one of them needs to be available, sequence as defined

[Country] A MUST for a detail that is dedicated to a country: ISO-3361 alpha 2 Sample: NoKId

[Industry] A MUST for a detail that is only valid in a certain industry; to distinguish industries we use at least the first letter of the EU NACE code Sample: TransportId

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Naming-Conventions\API-Detail-Naming-Convention.md - Chunk 1
"Agriculture" NACE Section A - Agriculture, Forestry and Fishing "Mining" NACE Section B - Mining and Quarrying "Manufacturing" NACE Section C - Manufacturing "Energy" NACE Section D - Electricity, Gas, Steam and Air Conditioning Supply "Facility" NACE Section E - Water Supply, Sewerage, Waste Management and Remediation Activities "Construction" NACE Section F - Construction "Retail" NACE Section G - Wholesale and Retail Trade "Transport" NACE Section H - Transporting and Storage "Hospitality" NACE Section I - Accommodation and Food Service Activities "IT" NACE Section J - Information and Communication "Finance" NACE Section K - Financial and Insurance Activities "RealEstate" NACE Section L - Real Estate Activities "ProfessionalServices" M NACE Section M - Professional, Scientific and Technical Activities "AdministrationServices" NACE Section N - Administrative and Support Service Activities "Public" NACE Section O - Public Administration and Defence, Compulsory Social Security

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Naming-Conventions\API-Detail-Naming-Convention.md - Chunk 2
Technical Activities "AdministrationServices" NACE Section N - Administrative and Support Service Activities "Public" NACE Section O - Public Administration and Defence, Compulsory Social Security "Education" NACE Section P - Education "Health" NACE Section Q - Human Health and Social Work Activities "Creative" NACE Section R - Arts, Entertainment and Recreation "Other" NACE Section S - Other Service Activities "HouseholdServices" NACE Section T - Activities of Households as Employers "ExtraterritiorialServices" NACE Section U - Activities of Extraterritorial Organisations and Bodies

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Naming-Conventions\API-Detail-Naming-Convention.md - Chunk 3
[Customer] A MUST for a custom field. A custom field is defined as a field only useful for this specific customer only. Sample: DachserSenderId

Note: [Customer] vs. [Industry] Decision: If a detail has got a customer-specific format, normalization or regexp but exists in all companies for this industry, then it is only industry specific and we name it without customer name in the detail name! e.g. tour id is a "quasi-standard" in the transport industry, but e.g. every transport company has its own format. Thus, we have just one detail name industry-wide: TransportTourId

[DocType] There can be cases that a certain field is directly related to a DocType and no DetailName is required. You can find all our DocTypes e.g. at the Package Uploader WIKI Page.

[DetailName] describes the meaning or content of the detail in case DoyType and Type are not sufficient.

Descriptions we use to specify the type of a detail in our APIs

Detail Types

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Naming-Conventions\API-Detail-Naming-Convention.md - Chunk 4
Type Sample Value Spec Id InvoiceId Date InvoiceDate YYYY-MM-DD (ISO 8601) Amount GrandTotalAmount decimal separator '.', no group separator, two decimal digits, e.g. 9.00, 2314.50, -12.99 Rate VatRate decimal separator '.'; one decimal digits, e.g. 20.0, 19.0, 10.0; value less or equal 100.0 Currency InvoiceCurrency ISO-4217 Name SenderName UTF-8 String Duration DueDateDuration days, int Email Email in contact @ .__ ITU E.123 Street Street in contact incl. street num UTF-8 String ZipCode ZipCode in address Normalized??? Phone Phone in contact Normalized??? ITU E.123? Street Street in contact incl. street num UTF-8 String ZipCode ZipCode in address Normalized??? City City in address Normalized??? Country Country in address ISO 3166-1 Alpha 2 Website e.g. www.example.top-level-domain ITU E.123 Group a group of details VatGroup Period DeliveryPeriod Group that consists of start and end date Address Address Group that consists of Street, ZipCode, City, Country Contact Contact Group

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Naming-Conventions\API-Detail-Naming-Convention.md - Chunk 5
ITU E.123 Group a group of details VatGroup Period DeliveryPeriod Group that consists of start and end date Address Address Group that consists of Street, ZipCode, City, Country Contact Contact Group consists of name, address, email, website, phone, fax Text MessageText Continuous Text (Fließtext) Content Byte Content e.g. images, etc.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Naming-Conventions\Customer-and-Partners.md - Chunk 0
: defines unique name within the system - Definition: [a-z], no numbers, no special chars - e.g strabag - Names should be limited to 10 chars

trial : defines that this is an evaluation account; limited support or specific support for sales integration : defines that this is a token/account which is used for integration tests - dev is owner, no change without dev team approval label: defines a key that can be used to label data (e.g. in RIPEye), by default all settings for this type of key should be same as for production. It can be that plugin settings are different for bootstrapping initial labelling acivities. doc-type: The doc-type can be added to distinguish use cases from the same customers (e.g. if we process Invoice and OrderConfirmation from the same customer)

Samples:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Naming-Conventions\Customer-and-Partners.md - Chunk 1
Samples:

partner.bds redbull redbull.trial partner.bds.trial partner.bds.froeschl partner.bds.froeschl.trial dachser.integration dachser.label dachser-OrderConfirmation dachser-OrderConfirmation.label aldautomotive-Quotation

Customer and partner names must be unique and follow the subsequent rules: customer / partner should be easily identifiable by human being RECOMMENDED: e.g. first 10 chars of legal entity (excl. company type): brasske, accantum e.g. common abbreviation for this company: poi, rvs, raika, etc. Names are excluding company type (e.g. like AG or GmbH) Further distinguishment for enterprises with subsidiaries: - hq ... headquarter - e.g. redbullhq - ISO country code for subsidiaries in countries - e.g. redbullat

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Naming-Conventions\Doc-Types.md - Chunk 0
Only the official Doc-Type values should be used in configurations and documentations:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Naming-Conventions\Doc-Types.md - Chunk 1
System Values German Translation Description Industry Invoice Alle Arten von Rechnungen die nicht unter Gutschrift definiert sind All CreditMemo Gutschrift, Stornorechnungen, Rechnungskorrektur All DeliveryNote Lieferschein All Notice Amtlicher Bescheid All Order Bestellung All OrderConfirmation Bestellbestätigung All Quotation Kostenvoranschlag All TermsAndConditions AGBs All VehicleRegistration Fahrzeugzulassung Automotive CertificateOfOrigin Ursprungszeugnis Logistics CustomsDutyReceipt Zollabgabgenbeleg e.g. C88 for GB Logistics DangerousGoodsNote TRDGN Logistics TransitNoteT1 Versandschein T1, for transit from customs to customs Logistics TransitNoteT2 Versandschein T2, for transit of community goods outside EU Logistics ProformaInvoice Pa document that declares the value of the goods but does not request for any payment Logistics ExportAccompanyingDocument ABD - Ausfuhrbegleitdokument Logistics DeliveryNoteCustoms Lieferschein Zolldokumente (CDDLN) Logistics DeliveryNoteTransit

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Naming-Conventions\Doc-Types.md - Chunk 2
but does not request for any payment Logistics ExportAccompanyingDocument ABD - Ausfuhrbegleitdokument Logistics DeliveryNoteCustoms Lieferschein Zolldokumente (CDDLN) Logistics DeliveryNoteTransit Lieferschein Speditionsdokumente (FDEDN) Logistics CMRConsignmentNote Frachtbriefe CMR within Europe (TRCMR) Logistics CollectionOrder Abholauftrag (CODCO) Logistics ForwardingOrder Speditionsauftrag (FDSPE) Logistics BillOfLading Frachtbrief (TRBOL) Logistics

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Naming-Conventions\Files-and-Directories.md - Chunk 0
BLUDELTA: Files and Directories - Naming Conventions

General (files and folders):

Default language is en

Only in exceptional, external communication: de or local language (e.g. Marketing, Sales, German customers, German suppliers etc.)

Do not use Spaces

Do not use “.” as separator

Use “_” only where specified in naming convention

No use of special characters

No use of “/” or “\” in file names and directories

By default we use CamelCase for descriptions

Blumatix File Naming Convention:

[_

Blumatix Folder Naming Convention:

The naming convention now applies to all new files and folders!

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Naming-Conventions\Translation-of-Detail-Names.md - Chunk 0
This page defines the translation of our detail names

[[TOC]]

Translations implemented in RIPEye

The following translations are currently implemented in RIPEye. They are by no means complete.

``` }, 'INVOICE_DETAIL.VALUE.INVOICE': { en: 'Invoice', de: 'Rechnung', }, 'INVOICE_DETAIL.VALUE.CREDIT_MEMO': { en: 'Credit memo', de: 'Gutschrift', },

en: 'Delivery period',
de: 'Leistungszeitraum',

},

en: 'Start date',
de: 'Startdatum',

},

en: 'End date',
de: 'Enddatum',

},

en: 'Delivery date',
de: 'Lieferdatum',

},

en: 'Grand total amount',
de: 'Gesamtsumme',

},

en: 'Net total amount',
de: 'Nettogesamtbetrag',

},

en: 'VAT total amount',
de: 'MWST-Gesamtbetrag',

}, // [INVOICE_DETAIL.${InvoicePredictionDetailType.StrabagRefCode}]: { // en: 'Strabag ref code', // de: 'Strabag Ref-Code', // },

en: 'VAT rate',
de: 'MWST-Satz',

},

en: 'Invoice date',
de: 'Rechnungsdatum',

},

en: 'Invoice ID',
de: 'Rechnungs-ID',

},

en: 'Document type',
de: 'Dokumenttyp',

},

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Naming-Conventions\Translation-of-Detail-Names.md - Chunk 1
en: 'VAT rate',
de: 'MWST-Satz',

},

en: 'Invoice date',
de: 'Rechnungsdatum',

},

en: 'Invoice ID',
de: 'Rechnungs-ID',

},

en: 'Document type',
de: 'Dokumenttyp',

},

en: 'IBAN',
de: 'IBAN',

},

en: 'VAT amount',
de: 'MWST-Betrag',

},

en: 'Invoice currency',
de: 'Rechnungswährung',

},

en: 'Delivery note ID',
de: 'Lieferschein-ID',

},

en: 'Customer ID',
de: 'Kundennummer',

},

en: 'VATID',
de: 'UId',

},

en: 'Sender VATID',
de: 'Absender UId',

},

en: 'Receiver VATID',
de: 'Empfänger UId',

},

en: 'Sender order ID',
de: 'Absender Bestellnummer',

},

en: 'Receiver order ID',
de: 'Empfänger Bestellnummer',

},

en: 'Sender order date',
de: 'Absender Bestelldatum',

},

en: 'Receiver order date',
de: 'Empfänger Bestelldatum',

},

en: 'Net amount',
de: 'Netto-Betrag',

},

en: 'VAT group',
de: 'MWST-Gruppe',

},

en: 'KId',
de: 'KId',

},

en: 'Isr Reference',
de: 'Isr Referenz',

},

en: 'Isr Subscriber',
de: 'Isr Teilnehmer',

},

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Naming-Conventions\Translation-of-Detail-Names.md - Chunk 2
},

en: 'VAT group',
de: 'MWST-Gruppe',

},

en: 'KId',
de: 'KId',

},

en: 'Isr Reference',
de: 'Isr Referenz',

},

en: 'Isr Subscriber',
de: 'Isr Teilnehmer',

},

en: 'Discount Group',
de: 'Rabattgruppe',

},

en: 'Discount Date',
de: 'Rabattdatum',

},

en: 'Discount Duration',
de: 'Rabattdauer',

},

en: 'Discount Percent',
de: 'Rabatthöhe (Prozent)',

},

en: 'Due Date Group',
de: 'Fälligkeitsgruppe',

},

en: 'Due Date Date',
de: 'Fälligkeitsdatum',

},

en: 'Due Date Duration',
de: 'Fälligkeitsdauer',

},

en: 'Bank Group',
de: 'Bankgruppe',

},

en: 'Bank Account',
de: 'Kontonummer',

},

en: 'Bank Code',
de: 'Bankleitzahl',

}, // [INVOICE_DETAIL.${InvoicePredictionDetailType.OerkBezirksstelle}]: { // en: 'OeRK district office', // de: 'OeRK Bezirksstellen', // },

en: 'Sender',
de: 'Absender',

},

en: 'Receiver',
de: 'Empfänger',

},

en: 'Name',
de: 'Name',

},

en: 'Address',
de: 'Adresse',

},

en: 'Country',
de: 'Land',

},

en: 'City',
de: 'Stadt',

},

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Naming-Conventions\Translation-of-Detail-Names.md - Chunk 3
en: 'Sender',
de: 'Absender',

},

en: 'Receiver',
de: 'Empfänger',

},

en: 'Name',
de: 'Name',

},

en: 'Address',
de: 'Adresse',

},

en: 'Country',
de: 'Land',

},

en: 'City',
de: 'Stadt',

},

en: 'ZIP code',
de: 'PLZ',

},

en: 'Street',
de: 'Straße',

},

en: 'Website URL',
de: 'Webseite',

},

en: 'Email',
de: 'E-Mail',

},

en: 'Phone',
de: 'Telefon',

},

en: 'Fax',
de: 'Fax',

},

en: 'Additional Properties',
de: 'Meta Daten',

},

en: 'Client ID',
de: 'Mandanten ID',

},

en: 'Receiver Email',
de: 'Empfänger E-Mail',

},

en: 'Sender Email',
de: 'Sender E-Mail',

},

en: 'Supplier',
de: 'Lieferanten',

},

en: 'Supplier ID',
de: 'Lieferanten ID',

},

en: 'Name',
de: 'Name (Lieferant)',

},

en: 'UID',
de: 'UstID',

},

en: 'IBAN',
de: 'IBAN',

},

en: 'City',
de: 'Stadt',

},

en: 'Country',
de: 'Land (Lieferant)',

},

en: 'Street',
de: 'Straße',

},

en: 'Zip Code',
de: 'PLZ',

},

en: 'Client',
de: 'Mandant',

},

en: 'Name',
de: 'Name',

},

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\Naming-Conventions\Translation-of-Detail-Names.md - Chunk 4
},

en: 'Country',
de: 'Land (Lieferant)',

},

en: 'Street',
de: 'Straße',

},

en: 'Zip Code',
de: 'PLZ',

},

en: 'Client',
de: 'Mandant',

},

en: 'Name',
de: 'Name',

},

en: 'Client ID',
de: 'Mandanten ID',

},

en: 'Bic',
de: 'Bic',

},

en: 'No Results',
de: 'Keine Ergebnisse',

},

en: 'Key',
de: 'Schlüssel',

},

en: 'Value',
de: 'Wert',

},

en: 'Position Number',
de: 'Lfd. Nummer',

},

en: 'Position ID',
de: 'Positionsnummer',

},

en: 'Delivery ID',
de: 'Liefernummer',

},

en: 'Order ID',
de: 'Bestellnummer',

},

en: 'Item ID',
de: 'Artikelnummer',

},

en: 'Description',
de: 'Beschreibung',

},

en: 'Unit',
de: 'Einheit',

},

en: 'Delivery Date',
de: 'Lieferdatum',

},

en: 'Quantity',
de: 'Menge',

},

en: 'Unit Price',
de: 'Einheitspreis',

},

en: 'Discount',
de: 'Rabatt',

},

en: 'VAT Rate',
de: 'Steuersatz',

},

en: 'Total Amount',
de: 'Gesamtpreis',

}, }; ```

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Bavarian-State-Ministry.md - Chunk 0
[[TOC]]

STMFH (Staatsministerium für Finanzen und Heimat)

Business Goal

Install and operate BLU DELTA for invoices at the STMFH. Additionally, create the prerequisites for further workflows.

Use Case

Implement the BLU DELTA API for invoice processing as part of the Bavarian ministries' digitization strategy. It is highly likely that invoices will be just the first of several use cases the ministry aims to implement with us. Any future use cases will be executed on a time and materials basis.

General Strategy

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Bavarian-State-Ministry.md - Chunk 1
General Strategy

We are aligning the tender with BLU DELTA OnPremise – essentially keeping it as it is today. However, a few things need to be implemented in advance to ensure that the strategy works across all Bavarian state ministries. These include: - Replacing the OCR (preferably just switching to Omnipage V22) - 11 FTE - Tracking the necessary data to implement the business model. - 8 FTE The business model will most likely consist of an annual base fee plus a fee per authority. - Installing a workflow engine to prepare for additional use cases - X FTE @

Todos

Klemens + team by 15.10. EOB:

Rough effort estimate for the above points

Rough resource estimate for

Ops - 20 FTE / month (Assumption we are responsible 4 Operations - TBD)

Support (based on lessons learned from ED) - 5 FTE / month (Especially at the beginning of the project)

Hasch by 15.10. EOB: Formulate the requirements for the tender, consider A+B criteria

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Bavarian-State-Ministry.md - Chunk 2
Support (based on lessons learned from ED) - 5 FTE / month (Especially at the beginning of the project)

Hasch by 15.10. EOB: Formulate the requirements for the tender, consider A+B criteria

Ideas for tender criteria: ISO 27001, OnPremise (+ continuous improvements), deep learning models, out-of-the-box, extendability to other documents, framework with interchangeable models, custom fields, etc.

Martin by 17.10. EOB:

Build the business case

Clarify questions with Printvision: Roles & Responsibilities, how does monitoring work now (what is Printvision using), access to machines

Coordinate with CSS: Does this align with the joint strategy, and ensure support (through resources or pre-financing)

General, rough timeline (some estimates)

Completion of our part of the tender by 18.10.2024

Tender expected in February or March 2025, lasting 4 weeks

Decision 4 weeks after the end of the tender

Afterwards: t.b.d.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\BLU-DOC-Editor.md - Chunk 0
Requirements:

MUST V1:

Basic functionality Request sent to BLU DOC Web Component with a URL pointing to a BLU DOC json BLU DOC Editor loads json incl. ocr and loads referenced images

Supports any doc-type

Editing of document essentials: location and text

Drag&Drop - OCR Overlay

Normalization of text to value

Bounding Box Feature (character level)

Colors and Threshold

Changes score to 1.0 for changed values

UI contro via CSS

Custom Position of Text Edit boxes resp. groups of essential edit boxes

LineItem support (necessary 4 ald value delivery and LineItem label quality improvement)

Contacts support

Edit values with missing bounding box (check Mail from Hasch)

Add, delete multiple detail occurrences

Data Mgt. (short run) Requirements:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\BLU-DOC-Editor.md - Chunk 1
Contacts support

Edit values with missing bounding box (check Mail from Hasch)

Add, delete multiple detail occurrences

Data Mgt. (short run) Requirements:

An easy tool to view, edit and release the available labels. - Provide a list of document ids (any doc-type). - Iterate (move forward, backward) through the list of ids. - Editing of document essentials: location and text (especially Line Items, Contacts). - Edit values with missing bounding box (check Mail from Hasch) - Add, delete (unrelease) multiple detail occurrences. - Release a label

Risks: - No Meta OCR Service (different OCR results). - Multiple labels per detail available.

V2:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\BLU-DOC-Editor.md - Chunk 2
Risks: - No Meta OCR Service (different OCR results). - Multiple labels per detail available.

V2:

Authentication Lazy loading of images Conversion from pdf to images Customization for customers Auto-scroll and highlighting? -> V2? Line Items Performance improvements Navigate through provided list of documents. Add and label new detail type. Splitting feature. Mark a document for later, indicating that it is not yet finalized. Label package management page (manage label packages; documents, label types, etc.) Label packages view (choose a package to work on) Label package document view (overview of all documents in a package) BLU DOC Versioning view (change history) Multiple input channels (RestAPI, manual upload, E-Mail) User Management Coloring scheme using recommended thresholds

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\BLU-DOC-Viewer.md - Chunk 0
Extension 2 of the BLU DOC Viewer App

Goal: Instead of uploading a BLU DOC json the BLU DOC viewer accesses a URL and gets BLU DOV via online capture api: 1) Upload a pdf to BLU DOC Viewer 2) BLU DOC Viewer sends the pdf to a capture service: OpenAPI https://capture.bludelta.ai/quotation/swagger/index.html 3) BLU DOC Viewer receives the BLU DOC json as response 4) BLU DOC Viewer displays again the table and images as already implemented

Extension of the BLU DOC Viewer App

The initial BLU DOC Viewer App displayed the BLU DOC JSON in the left pane and the Image in the right pane.

The required change: BLU DOC Viewer Web App should display Line Items in a Table Replace the right pane with the json view with a table view that displays "Line.Item" elements out of the BLU DOC json in a table form:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\BLU-DOC-Viewer.md - Chunk 1
The Table values are coming from elements that are children of "Line.Item"-elements The header titles of the tables should be same as the "Label" in the children of the "Line.Item" elemnt in the BLU DOC JSON.

OLD BLU DOC Viewer App Requirement (already Done by Jack):

BLU DOC Viewer Web App

Goal:

Create a web application that visualizes a BLU DOC json document

Web APP features:

After opening main url of application a dropbox is shown When dropping a BLU DOC json in the dropbox: - Application loads pdf document from the reference URL in BLU DOC json - Application converts each pdf page to png image with 300 DPI - Application displays on left pane the json text, easily readable with prettyprint - Application displays on right pane the image of the first page for every bounding boxes in BLU DOC DocuemntEssential json section

Additionally the bounding boxes are colored based on a configurable color scheme

Page 1: Upload BLU DOC Page 2: Show BLU DOC

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\BLU-DOC-Viewer.md - Chunk 2
Additionally the bounding boxes are colored based on a configurable color scheme

Page 1: Upload BLU DOC Page 2: Show BLU DOC

The configurable color scheme is in a json file. A default color can be defined that is used for all bounding boxes of DocumentEssentials that do not have anything else configured; additionally for each DocumentEssential a color can be configured which overrides default, the hierachy of color definition in json is same as in BLU DOC json

``` {

"DocumentEssentialsColors": [
    {
        "Label": "Default",
        "Color": "#FF5555",

    },
    {
        "Label": "OrderConfirmation.Date",
        "Color": "#FF5733",

    },
    {
        "Label": "OrderConfirmation.Id",
        "Color": "#FFFF00",

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\BLU-DOC-Viewer.md - Chunk 3
},
    {
        "Label": "OrderConfirmation.Date",
        "Color": "#FF5733",

    },
    {
        "Label": "OrderConfirmation.Id",
        "Color": "#FFFF00",

    },
    {
        "Label": "Line.Item",
        "Value": null,
        "Location": null,
        "Items": [
            {
                "Label": "Position.Id",
                "Color": "#112233",
            },
            {
                "Label": "DeliveryDate.Item",
                "Items": [{
                        "Label": "Delivery.Date",
                        "Color": "#AA8888",
                    }
                ]
            }
        ]
    }

}

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\BLU-DOC-Viewer.md - Chunk 4
```

Deliverable:

streamlit application in a Docker image Source code Readme file

Required Installation instructions Connection String, Config for Text Generation Inference Server Prerequisites for installation and running component How to Smoke Test after installation Configuration: Pls use hydra for any additional configuration (https://hydra.cc/ )

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Clean-Partner---Customer-Information-in-DBs.md - Chunk 0
Problem: Locations where we store customer and partner related information

API Authentication--> bcsdb-auth.Customer

Plugin Configuraton

RIPEye - Auth

DataCollection

Upload endpoint

Learn endpoint - CHECK if we store directories with customer names?

DynamicConfig

CaptureSdk-Configuration --> Admin-User

Telemetrie-DB ---> bcsdb-bi.Customer

PdfFilter.json (=> CMap-Conversion Rules / Convert to Image before OCR)

Integration-Tests (Nur Test- & Dev-User)

Storage Accounts (Resource-Uploader) --> Verzeichnisnamen

Strabag-Resource-Upload müsste man sich ansehen

Requirements:

We want to have a common schema for customer and partner names that we can use for generic implementation approaches We want to have unified names and customer attributes We want a unified structure reflecting partner - customer relationship We want one central location for all our customers and partner information

First steps

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Clean-Partner---Customer-Information-in-DBs.md - Chunk 1
First steps

Agree with team on new proposed naming convention Prepare MOP for changes in all location or implement Change names in all locations

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Expose-most-important-VAT-reasons-to-BLUDELTA-REST-API.md - Chunk 0
[[TOC]]

Related to:

11061

11312

CONCLUSION:

Internet research for EU, DE and AT as well as ETL showed basically the same - following exemption reason cover the main use cases and must be covered by our service.

MUST: Distinguish 3 most important VAT exemption reasons

VAT Exemption (en) Umsatzsteuerbefreiung (de) DE AT EU e-Invoicing Intra-community supply Innergemeinschaftliche Lieferung § 4 Nr. 1b UStG §6 Abs. 1 UStG VATEX-EU-IC Reverse Charge Reverse Charge § 13b UStG § 19 Abs 1 UStG VATEX-EU-AE Small Business Kleinunternehmer § 19 UStG Abs. 1 § 6 Abs 1 Z 27 UStG NA

SHOULD:

VAT Exemption (en) Umsatzsteuerbefreiung (de) DE AT EU e-Invoicing Export outside the EU Ausfuhrlieferung § 4 Nr. 1a § 7 UStG VATEX-EU-G

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Expose-most-important-VAT-reasons-to-BLUDELTA-REST-API.md - Chunk 1
SHOULD:

VAT Exemption (en) Umsatzsteuerbefreiung (de) DE AT EU e-Invoicing Export outside the EU Ausfuhrlieferung § 4 Nr. 1a § 7 UStG VATEX-EU-G

LEARNING: From a first research it seems to be hard to map national codes to an international standard. I assume that this will take a long time until this will be implemented EU-wide. Thus, we need to implement a solution on national level and should not consider x-rechung / e-invoicing as a standard.

Especially there are rules behind the VAT Ex reasons. You are allowed to use certain Ex reasons just for certain VAT categories.

Thus, delivering the country as meta information should be part of this implementation (but can be done in a second step).

DETAILS:

Analysis on VAT Category code and VAT Exemption Reason in X-Rechnung

EU and X-Rechnung:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Expose-most-important-VAT-reasons-to-BLUDELTA-REST-API.md - Chunk 2
DETAILS:

Analysis on VAT Category code and VAT Exemption Reason in X-Rechnung

EU and X-Rechnung:

In X-Rechnung the VATCategoryCode can be on invoice and line item level Our experience is that it is mainly on invoice level X-Rechnung Spec: 200-XRechnung-2020-06-30 (1).pdf EU VAT Codes VAT Exemption Reason Code list VATEX - version 4 -published.xlsx BLUDELTA-EN16931codelistv8_reasons-2022-03-08.xlsb.xlsx

Description per VATEx Reason: https://docs.peppol.eu/poacc/billing/3.0/codelist/vatex/

Germany (most important):

Out of ETL data and our existing code:

Bei ETL gibt es in den Labels, die wir bekommen haben, folgende Properties:

"cashback":null "paragraph19":false "paragraph13":false Denke, das könnte einen Bezug zu den Steuerbefreiungsgründen haben. Jedenfalls gibt es einen §19 Abs. 1 Ustg (Reverse Charge § 19 Abs. 1 UStG: Steuerschuld geht auf den Leistungsempfänger über)

Our code includes following text snippets:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Expose-most-important-VAT-reasons-to-BLUDELTA-REST-API.md - Chunk 3
Our code includes following text snippets:

[ ] Steuerfrei Texte "steuerfrei" oder "steuerbefreit" werden gefunden – zusätzlich muss eines der folgenden Worte gefunden werden: "innergemeinschaftlich", "lieferung", "leistung", "ustg"

Reverse Charge § 19 Abs. 1 Ustg( Steuerschuld geht auf den Leistungsempfänger über) Text "reverse charge" wird gefunden Text "steuerschuld" wird gefunden – zusätzlich muss eines der folgenden Werte gefunden werden: "ustg", "übergang", "leistungsempfänger"

Ausfuhrlieferung Text "ausfuhrlieferung" wird gefunden

Differenzbesteuerung Text differenzbesteuerung“ wird gefunden

Research Internet:

Differentiate: VAT not levied (eingehoben): Small Businesses - Kleinunternehmer

[ ] Gemäß § 19 Abs. 1 UStG enthält der Rechnungsbetrag keine Umsatzsteuer.“

[ ] „Im ausgewiesenen Rechnungsbetrag ist gemäß § 19 UStG Abs. 1 keine Umsatzsteuer enthalten.“ Oder auch:

[ ] „Rechnungsstellung erfolgt ohne Ausweis der Umsatzsteuer nach § 19 Abs. 1 UStG.“

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Expose-most-important-VAT-reasons-to-BLUDELTA-REST-API.md - Chunk 4
[ ] „Im ausgewiesenen Rechnungsbetrag ist gemäß § 19 UStG Abs. 1 keine Umsatzsteuer enthalten.“ Oder auch:

[ ] „Rechnungsstellung erfolgt ohne Ausweis der Umsatzsteuer nach § 19 Abs. 1 UStG.“

National VAT exemptions:

[ ] Unmittelbar dem Schul- und Bildungszweck dienende Unterrichtsleistungen selbständiger Lehrer für allgemein- oder berufsbildende Einrichtungen – Formulierung: „Umsatzsteuerfreie Leistung gemäß § 4 Nr. 21b UStG. Die Bescheinigung des Auftraggebers liegt vor.“

[ ] Leistungen freiberuflicher Musiker, Schauspieler und anderer Künstler für staatliche Theater, Orchester, Chöre und ähnliche Kultureinrichtungen – Formulierung: „Umsatzsteuerfreie Leistung gemäß § 4 Nr. 20 UStG. Die Bescheinigung des Auftraggebers liegt vor.“

[ ] Bauleistungen für bestimmte inländische Kunden – Formulierung: „Umkehrung der Steuerschuldnerschaft gemäß § 13b Abs. 2 UStG – Leistungsempfänger als Steuerschuldner.“

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Expose-most-important-VAT-reasons-to-BLUDELTA-REST-API.md - Chunk 5
[ ] Bauleistungen für bestimmte inländische Kunden – Formulierung: „Umkehrung der Steuerschuldnerschaft gemäß § 13b Abs. 2 UStG – Leistungsempfänger als Steuerschuldner.“

[ ] Provisionen für die Vermittlung von Finanzdienstleistungsprodukten wie Wertpapiere, Versicherungen, Kredite oder Bausparverträge – Formulierung: „Steuerfreie Provisionserlöse gemäß § 4 Nr. 8ff UStG.“

[ ] Umsätze, die der Differenzbesteuerung unterliegen – Formulierung: „Differenzbesteuerung gemäß § 25a UStG: Rechnung enthält aufgrund der Sonderregelung in § 14a Abs. 6 UStG für Gebrauchtgegenstände (bzw. Kunstgegenstände oder Sammlungsstücke und Antiquitäten) keine Umsatzsteuer“

Cross-border movements of goods exemptions:

[ ] Umsatzsteuerfreie Warenlieferungen an Geschäftskunden in anderen EU-Ländern (Umsatzsteueridentifikationsnummer liegt vor) – Formulierung: „Steuerfreie innergemeinschaftliche Lieferung gemäß § 4 Nr. 1b UStG.“

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Expose-most-important-VAT-reasons-to-BLUDELTA-REST-API.md - Chunk 6
[ ] Umsatzsteuerfreie Warenlieferungen an Geschäftskunden in ausländischen Staaten, die nicht zur EU gehören (= „Drittländer“) – Formulierung: „Steuerfreie Ausfuhrlieferung gemäß § 4 Nr. 1a UStG“

[ ] Umsatzsteuerfreie Warenlieferungen bei Versand an Verbraucher in ausländischen Staaten, die nicht zur EU gehören (= „Drittländer“) – Formulierung: „Steuerfreie Ausfuhrlieferung gemäß § 4 Nr. 1a UStG“

Cross-border services:

[ ] Dienstleistungen für Geschäftskunden im EU-Ausland, die als Auftraggeber in ihrem Land die Umsatzsteuer anmelden und abführen müssen (= „Reverse-Charge-Verfahren“). Voraussetzung: Umsatzsteueridentifikationsnummer liegt vor – Formulierung: „Umkehr der Steuerschuldnerschaft gemäß § 13b UStG: Leistungsempfänger als Steuerschuldner“

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Expose-most-important-VAT-reasons-to-BLUDELTA-REST-API.md - Chunk 7
[ ] Dienstleistungen für Geschäftskunden in ausländischen Staaten, die nicht zur EU gehören (= „Drittländer“). Voraussetzung: Eine Unternehmerbescheinigung liegt vor – optionale Formulierung: „Im Inland nicht steuerbare sonstige Leistung gemäß § 3a UStG.“

Austria (main cases):

Steuerbefreiung geregelt in: § 6 UStG Innergemeinschaftliche Lieferung: §6 Abs. 1 UStG Reverse-Charge: Die Umsatzsteuerschuld geht auf den Leistungsempfänger über (Reverse Charge System) Kleinunternehmerregelung: § 6 Abs 1 Z 27 UStG Ausfuhrlieferung definiert in: § 7 UStG

First minimal Implementation

11312

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Expose-most-important-VAT-reasons-to-BLUDELTA-REST-API.md - Chunk 8
First minimal Implementation

11312

Amounts Postprocessing includes creation of VatGroups. The creation is based on AI-Models for GrandTotalAmount, NetTotalAmount, VatTotalAmount, VatGroups and three algorithms, one for Vat exemption detection. All that information is compared, weighted, and validated. The algorithm for Vat exemption detection is a very simple search for a set of strings that are indicators for various vat exemptions. Whenever a reason for Vat exemptions was found it was checked if we can find a definition of 0 % vat rate on the invoice. If so, we created a VatGroup, else we did not.

This implementation has not been changed. We just add a new VatExemption prediction - an empty prediction when no vat exemption was detected, a prediction with text "Vat Exemption" if a vat exemption was detected. For now, this is just a flag, without reason.

Q&A

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Expose-most-important-VAT-reasons-to-BLUDELTA-REST-API.md - Chunk 9
Q&A

Q: "Wir weisen darauf hin, dass eine Vorsteuer aus oben genanntem Betrag nicht angesetzt werden kann, da wir als Verein von der Mehrwertsteuer befreit sind." Does this count as "Small Business"?

Q: An invoice states "not taxable" as the reason. What is the most likely reason?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\FFG-New-Product-Ideas.md - Chunk 0
General Ideas

Uni Partnerschaft erhöht Erfolgswahrscheinlichkeit: ofai.at, salzburg research, uni linz hochreiter, etc.

Input Management merges into Workflow Automation

Scope: B2B

Focus on: German Mid-Large scale companies

Today: Companies struggle with simple problems like extract information, route information, can not cope with extra information in mails, etc.

An LLM can combine all these tasks in a single agent

LLM Agent that pre-processes input (email, documents) and based on access to company information (invoices, orders, warehouse)

Multi-modal model and OCR reduces fantasizing of LLMs

Company LLM

Use Case: Dachser receives about 120 document classes embedded in emails and various formats Technology so far struggles with dumb components that can do only single tasks but lack the overall intelligence which hinders full automation of input management

Accounting Automation

Vorkontierung nachvollziehbar und automatisiert

Automated 2-, 3-Wegeabgleich

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\FFG-New-Product-Ideas.md - Chunk 1
Accounting Automation

Vorkontierung nachvollziehbar und automatisiert

Automated 2-, 3-Wegeabgleich

Auftragsbestätigungen - vom EMail-Eingang bis zur Bestätigung

Company LLM for accounting

Company Document Summary and LLM

Contract Analytics

ChatGPT:

Data Analysis and Interpretation:

LLMs can analyze large sets of financial data quickly and provide insights into trends, anomalies, or patterns that may require further investigation by finance professionals. This can help in financial forecasting, budgeting, and decision-making processes.

Automated Reporting:

LLMs can generate automated reports based on predefined criteria, saving time for finance professionals who would otherwise have to manually compile and analyze data for reporting purposes. This includes financial statements, variance analyses, and performance reports.

Natural Language Processing (NLP) for Document Analysis:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\FFG-New-Product-Ideas.md - Chunk 2
Natural Language Processing (NLP) for Document Analysis:

LLMs equipped with NLP capabilities can parse through financial documents such as contracts, invoices, and financial statements to extract relevant information. This can aid in tasks like expense categorization, contract management, and compliance monitoring.

Risk Assessment and Management:

LLMs can assess financial risks by analyzing historical data, market trends, and other relevant information. They can identify potential risks such as credit risk, market risk, or operational risk, allowing finance departments to implement appropriate risk management strategies.

Forecasting and Predictive Modeling:

LLMs can assist finance departments in building forecasting models based on historical data and market trends. By analyzing patterns and correlations in data, LLMs can help predict future financial performance, cash flow projections, and risk scenarios.

Compliance Monitoring:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\FFG-New-Product-Ideas.md - Chunk 3
Compliance Monitoring:

LLMs can continuously monitor regulatory changes and updates that may impact accounting practices. They can alert finance departments to compliance requirements and assist in ensuring that financial processes adhere to relevant regulations and standards.

Fraud Detection:

LLMs can analyze financial transactions and identify potential instances of fraud or irregularities. By flagging suspicious patterns or anomalies in transaction data, LLMs can help finance departments prevent and detect fraudulent activities.

Customized Assistance and Decision Support:

LLMs can provide customized assistance to finance professionals by answering queries, providing explanations of accounting principles, or offering decision support based on available data. This can help in resolving accounting discrepancies, interpreting financial reports, and making informed decisions.

CSS Use Cases:

Auslesen von Vertragsinhalten

Dunkelverbuchung

Auswahl Use Cases (seitens CSS erstellt)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\FFG-New-Product-Ideas.md - Chunk 4
CSS Use Cases:

Auslesen von Vertragsinhalten

Dunkelverbuchung

Auswahl Use Cases (seitens CSS erstellt)

Bonitätsbewertung Debitoren

Cashflow-Prognosen

Automatische Berichterstattung. Beispiel: KI erkennt Benutzerverhalten und erzeugt ad hoc eine kontextbezogene Auswertung.

Unterstützung bei der Implementierung / Konfiguration von eGECKO

Bankverbuchung (Matching Kto.auszüge/Rechnungen)

Auswahl Use Cases (seitens blu erstellt)

Unternehmensweite Knowledgebase

Automatische Kontierung / Dunkelbuchung

Inputmanagement (Klassifizierung, Extraktion, Verteilung); alle Inputs

Verkauf: automatisierter Upsell (Erkennung und automatisierung von Upsell-Potentialen)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Invoice-Classification.md - Chunk 0
Diamant asked for following feature:

Diamant would benefit from a more detailed DocType classification (more than just Invoice vs. credit memo). Following types would be of interest:

Invoice: Service vs. Delivery (Dienstleistungsrechnung vs. Warenlieferung) Deposit (Anzahlung) Advance Payment (Abschlagszahlung) Schlußrechnung

General Info: (source: sevdesk.at)

Welche Rechnungsarten gibt es? Um eine Rechnung fehlerfrei und ohne Mängel erstellen zu können, musst du zunächst einmal wissen, welche Rechnungsarten es gibt.

Austria: Rechnungsart Eingangsrechnung Rechnungsart Ausgangsrechnung Rechnungsart Gutschrift Rechnungsart Barverkauf Rechnungsart Abschlagsrechnung Rechnungsart Proformarechnung Rechnungsart Stornorechnung

Germany: Anzahlungsrechnung Teilrechnung Abschlagsrechnung Schlussrechnung Wiederkehrende Rechnung Proformarechnung Stornorechnung Gutschrift

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Invoice-Classification.md - Chunk 1
Germany: Anzahlungsrechnung Teilrechnung Abschlagsrechnung Schlussrechnung Wiederkehrende Rechnung Proformarechnung Stornorechnung Gutschrift

Diese Auflistung zeigt dir die verschiedenen Rechnungsarten. Was hinter jeder einzelnen Art von Rechnung steckt, erfährst du weiter unten.

AUSTRIA:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Invoice-Classification.md - Chunk 2
AUSTRIA:

Die Rechnungsart Eingangsrechnung Bei einer Rechnung, welche bei dir im Unternehmen eingeht, wird von einer Eingangsrechnung gesprochen. Dies kann beispielsweise die Rechnung von einem deiner Lieferanten sein. Diese Rechnung stellt für dich eine Zahlungsaufforderung dar und als Unternehmer musst du diese Eingangsrechnung begleichen. Es ist zu empfehlen, dass du jede Eingangsrechnung auch genau prüfst. Diese Prüfung sollte sich auf die Pflichtangaben & Bestandteile einer Rechnung richten sowie auf die Positionen, ob diese mit dem jeweiligen Lieferschein übereinstimmen. Auch auf die aufgeführten Beträge solltest du achten. Sind diese korrekt und auch mit dem richtigen Steuersatz versehen? Dies ist wichtig, denn jede falsche Rechnung kann zu Problemen führen, auch mit dem Finanzamt. Eine Eingangsrechnung ist ein wichtiges Dokument, welches du GoBD-konform für mindestens zehn Jahre lang archivieren musst.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Invoice-Classification.md - Chunk 3
Die Rechnungsart Ausgangsrechnung Bei der Ausgangsrechnung handelt es sich um eine Rechnung, welche du als Selbstständiger, Freiberufler oder anderweitiger Unternehmer als Forderung für die Erbringung von Leistungen an deinen Kunden stellst. Es ist möglich, dass eine Ausgangsrechnung bereits vor der vollständigen Erbringung von Leistungen oder Lieferungen erstellt wird. In diesem Fall forderst du mit deiner Ausgangsrechnung eine Vorkasse vom Kunden ein. Eine Ausgangsrechnung wird in der Bilanz als Debitor oder Forderung erfasst. Die Ausgangsrechnung ist Bestandteil jeder Buchhaltung und wird im Rechnungsausgangsjournal erfasst.

Besondere Anforderungen an eine Ausgangsrechnung An eine Ausgangsrechnung werden stets besondere Anforderungen gestellt. Dies ist deshalb der Fall, weil diese Rechnungsart auch immer die Grundlage für Mahnungen darstellt. Deshalb ist es wichtig, dass in deinen Ausgangsrechnungen immer folgende Pflichtangaben enthalten sind:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Invoice-Classification.md - Chunk 4
Name und genaue Anschrift deines Unternehmens und des Rechnungsempfängers deine Steuernummer oder die Umsatzsteuer-Identifikationsnummer das genaue Ausstellungsdatum der Rechnung eine Rechnungsnummer, die zwingend fortlaufend sein muss und nur einmal vergeben wird die genaue Menge und Art der Lieferung oder die genaue Art und den Umfang der erbrachten Leistung den Zeitpunkt der Lieferung oder der Leistungserbringung sowie den Zahlungstermin das gesamte Entgelt mit Steuerbetrag und gültigem Steuersatz im Vorfeld getroffene Vereinbarungen in Bezug auf eine Entgeltminderung (beispielsweise Rabatte, Skonto etc.) deine Bankdaten wie Kontonummer, Bankleitzahl etc. Auch bei der Ausgangsrechnung musst du auf eine GoBD-konforme Aufbewahrung und Aufbewahrungsfrist achten. Diese liegt auch bei dieser Rechnungsart bei mindestens zehn Jahren.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Invoice-Classification.md - Chunk 5
Die Rechnungsart Gutschrift Bei der Gutschrift handelt es sich um eine ganz besondere Rechnungsart. Eine Gutschrift als Rechnungsart zeigt sich immer durch einen positiven Rechnungsbetrag. Auf der Abrechnung musst du diese Rechnungsart immer zwingend auch als Gutschrift bezeichnen. Eine Gutschrift tritt immer dann auf, wenn beispielsweise mehrere andere Akteure an der Erfüllung von einem Auftrag involviert sind.

Beispiel: Nehmen wir als Beispiel einmal an, dass du einen Auftrag an eine Agentur vergibst. Diese Agentur aber führt den Auftrag nicht selbst komplett durch, sondern lässt ihn zum Teil von einem Subunternehmer durchführen. Ist dies geschehen und der Auftrag erledigt, dann stellt die beauftragende Agentur ihrem Subunternehmer eine Gutschrift aus. Diese erhält dieser für seine geleistete Arbeit. Du als Auftraggeber bekommst allerdings von der Agentur eine Forderung in Form einer Ausgangsrechnung zugeschickt.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Invoice-Classification.md - Chunk 6
Die Gutschrift aus steuerrechtlicher Sicht Betrachtest du eine Gutschrift aus der steuerrechtlichen Sicht, dann handelt es sich hier um eine Rechnung, die nicht vom Erbringer der Leistung erstellt wird, sondern vom Empfänger der Leistung. Der Begriff wird in der Umgangssprache immer dann genutzt, wenn eine Zahlung eingeht, aber im Vorfeld dafür gar keine Forderung veranlasst wurde. Wichtig ist für dich, dass du aber einen ganz wichtigen Unterschied beachtest. Beispielsweise werden Boni, Erstattungen oder Ausgleichszahlungen sehr oft auch als Gutschrift bezeichnet. Im Rahmen einer Buchung werden sie als Negativbeträge verbucht und dies, obwohl sie aus der steuerrechtlichen Sicht gar keine Gutschriften sind.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Invoice-Classification.md - Chunk 7
Die Rechnungsart Barverkauf Bei der Rechnungsart Barverkauf erfolgt immer eine unverzügliche Erfüllung von Leistung und Gegenleistung. Die Lieferung bzw. die Übergabe einer Ware erfolgt hier in den meisten Fällen gegen eine Barzahlung. In der Regel wirst du hier auch keine Rechnung erstellen. Vielmehr wird in den meisten Fällen ein simpler Kassenbeleg oder ein Kassenbon ausgestellt. Allerdings musst du hier darauf achten, dass in sehr vielen Fällen dieser Kassenbon nicht die Voraussetzungen für eine buchhalterische Rechnung erfüllt. Stellst du einen Kassenbon mit nur minimalistischen Angaben aus, dann sollte dieser um eine Quittung ergänzt werden. Große und vor allem gut organisierte Einzelhändler allerdings haben einen Kassenbeleg, welcher auch alle Anforderungen an eine Rechnung erfüllt. Das bedeutet, dass du diesen auch als Buchungsbeleg nutzen kannst und nutzen darfst.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Invoice-Classification.md - Chunk 8
Tipp! Wenn du viele Barverkäufe tätigst, dann kann dir ein Quittungsvordruck als Vorlage sehr viel Arbeit abnehmen & du kannst sämtliche Barverkäufe im gleichen Design archivieren und festhalten!

Die Rechnungsart Abschlagsrechnung Sowohl eine Eingangsrechnung als auch eine Ausgangsrechnung kann eine Abschlagsrechnung sein. Eine Abschlagsrechnung wird immer dann erstellt, wenn du mit deinem Kunden oder deinem Auftraggeber die Erfüllung von einem Auftrag vereinbarst, welcher nur in mehreren Schritten erfüllt wird. Die Rechnungsart Abschlagsrechnung kommt immer dann ins Spiel, wenn du mit einem großen oder relativ langfristigem Projekt beschäftigt bist. Immer wenn du eine bestimmte und vereinbarte Leistung erfüllst, dann schreibst du eine Abschlagsrechnung. Sind dies für ein Projekt mehrere Abschlagsrechnungen, dann musst du diese auch immer kennzeichnen. Also muss da beispielsweise stehen, 1. Abschlagsrechnung, 2. Abschlagsrechnung usw.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Invoice-Classification.md - Chunk 9
Nach Abschlagsrechnung folgt immer eine Schlussrechnung Wichtig für dich beim Thema Abschlagsrechnung ist, dass du jeder Abschlagsrechnung den zugehörigen Projektnamen, den Gesamtbetrag der Leistung, den aktuellen Rechnungsbetrag für die Abschlagsrechnung und wenn erfolgt, auch schon bezahlte Abschlagsrechnungen auf der Rechnung aufführst. Ist ein Auftrag komplett erledigt und alle vereinbarten Leistungen sind erfolgt, muss von dir immer eine Schlussrechnung erstellt werden. Diese Rechnung muss auch als Schlussrechnung bezeichnet werden. In dieser Schlussrechnung darfst du auch nicht vergessen, dass du jede erstellte Abschlagsrechnung aufführst.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Invoice-Classification.md - Chunk 10
Rechnungsart Proformarechnung Keine Forderung besteht bei der sogenannten Proformarechnung. Das bedeutet, dass mit dieser Rechnungsart auch keinerlei Zahlungsaufforderung verbunden ist. Häufig erstellst du eine Proformarechnung als Beilage für eine Warenlieferung. Das hat einfach und allein den Zweck, dass du dem Empfänger der Warensendung darstellst, welchen Wert diese hat. In diesem Fall dient die Proformarechnung später auch als steuerlicher Zweck.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Invoice-Classification.md - Chunk 11
Rechnungsart Stornorechnung Ein ganz spezieller und besonderer Fall ist die Rechnungsart Stornorechnung. Sie muss vom Rechnungssteller immer dann erstellt werden, wenn bei der Erstellung der normalen Rechnung ein Fehler unterlaufen ist und dieser Fehler nun im Sinne einer Rechnungskorrektur korrigiert werden muss. Eine Stornorechnung musst du als Unternehmer immer deiner normalen Rechnung nachschicken. Wichtig für dich ist zu wissen, dass diese Stornorechnung eine eigene und separate Rechnungsnummer haben muss. Außerdem muss der Betrag die gleiche Höhe aufweisen wie der Betrag auf der Originalrechnung. Allerdings muss er hier bei der Rechnungsart Stornorechnung als Minusbetrag aufgeführt sein. Das würde beispielsweise wie folgt aussehen:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Invoice-Classification.md - Chunk 12
Rechnungsbetrag fehlerhafte Originalrechnung: 299,95 Euro Rechnungsbetrag Stornorechnung: - 299,95 Euro Vorgang muss immer nachvollziehbar sein Musst du eine Stornorechnung erstellen, so musst du immer darauf achten, dass Außenstehende wie etwa das Finanzamt, immer nachvollziehen können, um welchen Vorgang es sich gehandelt hat. Das bedeutet, dass du eine falsche und fehlerhafte Rechnung mit einer Stornorechnung immer neutralisieren musst. Ist dies erfolgt, dann kannst du eine neue und korrekte Rechnung schreiben. Diese bekommt wiederum eine ganz neue Rechnungsnummer. Im Endergebnis ergibt dies damit drei eigenständige Rechnungen mit drei Rechnungsnummern:

fehlerhafte Rechnung Stornorechnung neue Rechnung Auf diese Weise kannst du dies auch bei jeder möglichen Steuerprüfung erklären. Alle drei Rechnungen müssen von dir GoBD-konform archiviert werden.

General Info - DE (source: erpxt.de)

Anzahlungsrechnungen

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Invoice-Classification.md - Chunk 13
General Info - DE (source: erpxt.de)

Anzahlungsrechnungen

Eine Anzahlungsrechnung oder auch Vorauszahlungsrechnung wird vor Fertigstellung einer vereinbarten Leistung bzw. mehrerer Teilleistungen ausgestellt. Das heißt, der Rechnungssteller hat noch keine Leistung oder Lieferung erbracht. Diese Rechnung wird üblicherweise erstellt, wenn es sich um umfangreiche Aufträge handelt oder wenn der Verkäufer durch Materialeinkauf in Vorleistung geht. In dem Moment, da der Kunde die Rechnung begleicht muss auch die Umsatzsteuer entrichtet werden.

Sobald der Auftrag abgeschlossen ist, erfolgt die Erstellung der Schlussrechnung mit dem Restbetrag.

Teilrechnungen

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Invoice-Classification.md - Chunk 14
Sobald der Auftrag abgeschlossen ist, erfolgt die Erstellung der Schlussrechnung mit dem Restbetrag.

Teilrechnungen

Unter dem Begriff Teilrechnung bzw. Teilschlussrechnung versteht man eine abgerechnete Leistung oder Lieferung, die bereits vollständig erbracht wurde und auch präzisiert und bezeichnet werden kann. D. h. es liegt ein Leistungsdatum/-zeitraum vor. Ein Auftrag kann demnach in verschiedene Lieferungen respektive Leistungen aufgeteilt werden, wobei der Kunde für jede Lieferung/Leistung eine Teilrechnung erhält. Typischerweise erfolgt diese Art der Rechnungsstellung bei

längeren oder größeren Leistungen, die über einen längeren Zeitraum erbracht werden größeren Warenlieferungen, die in bestimmten Teilabständen erfolgen.

Ein Bauunternehmer z. B. rechnet die Ausschachtungsarbeiten ab nachdem die Baugrube ausgehoben wurde.

Zum Zeitpunkt der Rechnungsstellung wird auch die Umsatzsteuer fällig.

Abschlagsrechnungen

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Invoice-Classification.md - Chunk 15
Ein Bauunternehmer z. B. rechnet die Ausschachtungsarbeiten ab nachdem die Baugrube ausgehoben wurde.

Zum Zeitpunkt der Rechnungsstellung wird auch die Umsatzsteuer fällig.

Abschlagsrechnungen

Der Begriff Teil- und Abschlagsrechnungen wird teilweise synonym gebraucht und führt häufig zur Verwechslung dieser unterschiedlichen Rechnungsarten. Denn im Gegensatz zu Teilrechnungen werden Abschlagsrechnungen stufenweise generiert, also wenn ein gewisser prozentualer Anteil der anstehenden Leistung erbracht wurde, dieser jedoch nicht konkretisiert werden kann. Zudem sind sie an gewisse Anforderungen, wie zum Beispiel den Auftragsfortschritt gebunden.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Invoice-Classification.md - Chunk 16
Diese Art der Rechnung empfiehlt sich bei größeren, über einen längeren Zeitraum laufenden Projekten. In der Regel ist sie für die Fakturierung von Leistungen im Baugewerbe üblich. Unter Berücksichtigung des zu erwartenden Baufortschritts wird dabei ein eindeutiger prozentualer Anteil der Gesamtsumme vor der Fertigstellung fakturiert. Am Beispiel eines Bauunternehmers heißt das, er rechnet 30 % ab, ohne zu wissen, ob bisher 23 % oder 38 % aller Fliesen verlegt wurden.

Aber auch für Selbstständige kann es durchaus Sinn ergeben, Akontorechnungen mit ihren Kunden zu vereinbaren. Nämlich dann, wenn sie über längere Zeit laufende Aufträge umsetzen und sich mithilfe der Abschläge ein regelmäßiges Einkommen sichern wollen.

Und auch im privaten Bereich finden Abschlagsrechnung praktisch Anwendung, so u. a. bei Mietnebenkosten oder Energieanbietern.

Wenn der Kunde die Abschlagsrechnung bezahlt, muss auch die Umsatzsteuer entrichtet werden.

Schlussrechnungen

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Invoice-Classification.md - Chunk 17
Wenn der Kunde die Abschlagsrechnung bezahlt, muss auch die Umsatzsteuer entrichtet werden.

Schlussrechnungen

Die Schlussrechnung (Endrechnung) gilt als abschließende Rechnung einer finanziellen Forderung. Da sie auch mögliche Abschlagsrechnungen berücksichtig, wird hier immer davon ausgegangen, dass vorab bereits Abschlagsrechnungen bzw. -zahlungen festgelegt und gestellt wurden. Eine Endrechnung wird ausschließlich für komplett erbrachte Leistungen oder erfolgte Lieferungen generiert. Neben allen vorangegangenen Rechnungen enthält eine abschließende Rechnung den ermittelten Restzahlbetrag.

Im Moment der Rechnungserstellung wird auch der verbliebene Umsatzsteueranteil der Restforderung fällig.

Wiederkehrende Rechnungen

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Invoice-Classification.md - Chunk 18
Im Moment der Rechnungserstellung wird auch der verbliebene Umsatzsteueranteil der Restforderung fällig.

Wiederkehrende Rechnungen

Diese Form der Rechnung wird auch als Abo-Rechnung bezeichnet und kommt bei sich wiederholenden Zahlungen zum Einsatz. Wie der Name bereits verrät, wird dieser Rechnungstyp in wiederkehrenden Zeitabschnitten immer wieder und regelmäßig erstellt, wobei sich der Inhalt stets wiederholt. Die Intervalle können hierbei täglich, wöchentlich, monatlich, vierteljährlich, halbjährlich oder jährlich sein.

Beispiele für wiederkehrende Rechnungen sind Miet- und Wartungsverträge oder Stromrechnungen.

Proformarechnungen

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Invoice-Classification.md - Chunk 19
Beispiele für wiederkehrende Rechnungen sind Miet- und Wartungsverträge oder Stromrechnungen.

Proformarechnungen

Die Art der Rechnungsstellung gilt als Sonderfall, da sie keine Zahlungsaufforderung enthält und demnach nicht vom Rechnungsempfänger bezahlt werden muss. Darüber hinaus wird sie weder in der Buchhaltung gebucht, noch stellt sie einen offenen Posten dar. Ihr Zweck dient lediglich steuerlichen Belangen. Mittels einer Proformarechnung dokumentiert der Rechnungsteller die Art, den Zweck und / oder den Wert einer Lieferung. So verwenden Unternehmer diese Form der Rechnungsstellung beispielsweise, um den Wert einer Warensendung für den Zoll nachzuweisen. Aber auch bei Mustersendungen oder Ersatzteillieferungen ist diese Rechnungsform üblich.

Korrekturrechnungen / Stornorechnungen

Mithilfe von Korrektur- und Stornorechnungen können vorangegangene Ausgangsrechnungen korrigiert oder storniert, sprich rückgängig gemacht werden. Dies kann aus folgenden Gründen notwendig sein:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Invoice-Classification.md - Chunk 20
Mithilfe von Korrektur- und Stornorechnungen können vorangegangene Ausgangsrechnungen korrigiert oder storniert, sprich rückgängig gemacht werden. Dies kann aus folgenden Gründen notwendig sein:

fehlerhafte Ursprungsrechnungen fehlende oder unvollständige Lieferungen mangelhafte Dienstleistungen oder nicht abgenommene Werkleistungen nachträgliche Rabatte und sonstige Preisnachlässe.

Weitere Bezeichnungen für Storno- und Korrekturrechnung sind Rechnungskorrektur oder aus kaufmännischer Sicht auch Gutschrift.

Gutschriften

Im alltäglichen Geschäftsverkehr und allgemeinen Sprachgebrauch sorgt der Gutschriftbegriff immer wieder für Verwirrungen, da er in recht unterschiedlichen Zusammenhängen benutzt wird. So gibt es einerseits Abrechnungsgutschriften und andererseits werden auch Preisnachlässe aufgrund von Sachmängeln (Reklamation) gemeinhin als Gutschrift bezeichnet. Für Klarheit sorgt hier die Unterscheidung in umsatzsteuerrechtliche und kaufmännische Gutschriften.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Invoice-Classification.md - Chunk 21
Umsatzsteuerrechtliche Gutschrift

Diese Spezialform der Rechnung wird auch als Abrechnungsgutschrift, Eigenfaktura oder umgekehrte Rechnung bezeichnet. Umgekehrt bedeutet in diesem Fall, dass der Leistungsempfänger (Kunde) die Gutschrift ausstellt, um mit dem Leistungserbringer (Lieferant, Dienstleister) abzurechnen. Sprich, es erfolgt ein Zahlungseingang, ohne dass dafür vorab eine Forderung gestellt wurde. Die Gutschrift weist einen positiven Betrag aus und muss auf der Abrechnung mit dem Terminus ,,Gutschrift‘‘ kenntlich gemacht sein. Diese Form der Gutschrift wird häufig verwendet, wenn mehr als zwei Beteiligte an der Ausführung eines Auftrags mitwirken. Ein Beispiel dafür wäre: Ein Handwerksunternehmen, das als Subunternehmer Teilleistungen auf einer Großbaustelle umsetzt, erhält vom leitenden Unternehmen der Baustelle eine Gutschrift über die erbrachten Arbeiten.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Invoice-Classification.md - Chunk 22
Im Unterschied dazu werden Ausgleichszahlungen, Boni, Erstattungen und weitere typisch als Gutschrift bezeichneten Prozesse im Zuge des Buchungsvorganges als Negativbeträge verbucht, weshalb sie gemäß der steuerrechtlichen Definition nicht als Gutschriften gelten.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\New-Capture-Template-_customer__-_DoyType_-[FurhterInfoIfNeeded].md - Chunk 0
Customer Introduction

Industry

Your text ...

Business Goal

Your text ...

Use Case

Your text ...

Customer Main Stakeholders, Contacts

Names Role Contact chris de burgh Leiter Kreditorenbuchhatung chris@debrugLimited.com

Expected initial timeline:

Milestone Date Launch 2023-12-24

BLU DELTA Perspective:

Why should we do this project and importance?

Our justification - can be strategic or just anything else

Requirements

General

Requirement Customer Info Notes Document quanity per year num of documents and highlight if more than 2 pages per document average are expected Input Channels What quality to expect: photo, scan, fax, online-digital Regions and Languages What regions? Any dominating regions/language? Layout diversity expected number of suppliers, senders Special Security Req expected number of suppliers, senders Special Performance Req expected number of suppliers, senders

Document Essentials

Samples with marks done by customer

Header

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\New-Capture-Template-_customer__-_DoyType_-[FurhterInfoIfNeeded].md - Chunk 1
Document Essentials

Samples with marks done by customer

Header

Detail Name (customer language) BLU DELTA Detail Name CUSTOM INFO not needed for standard detail; if no standard detail, describe here content of detail and pecularity

Line Items

Detail Name (customer language) BLU DELTA Detail Name CUSTOM INFO not needed for standard detail; if no standard detail, describe here content of detail and pecularity

Provided Data under \\nas01\customerdata

Uploaded data must follow directory structure: - Main dir:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Threshold-optimization-service.md - Chunk 0
As SME I need a service to calculate the optimal threshold for each customer

Goal:

Number of documents in state need for action is minimized.

Approach:

e.g. 1. SME or customer sends validated (and autoprocessed?) data to the data collection 2. Create a customer benchmark automatically 3. Optimize the RIPEye (!= API) thresholds for each customer such that the number of documents in state need for action is minimized 4. SME or customer can get the optimal thresholds for each detail and model version via endpoint

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\BLU-DOC-Editor\BLU-DOC-Editor-Proto.md - Chunk 0
Create a streamlit app prototype that enables annotation of document:

Prototype Function: a) RIGHT: displays pdf as image (300dpi) per page with (hidden) overlayed OCR text b) LEFT: displays Labels of json (for prototype one label (quotation.id is sufficient))

User can create bounding box around OCR Text or directly drag and drop text onto Quotation.Id Label on RIGHT pane; Application replaces new bounding box information and new "Text" in json User can save new json with new bounding box

See sample which included PDF and JSON with OCR Result included!

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Accounts-Receivable-Automation.md - Chunk 0
Definition of a Paid Transaction:

Customer Request was received and confirmed for a BLU DELTA Product (API or User Interface) Response was successfully delivered to customer or deposited in a cache

Examples:

This means that e.g. an API timeout but succesfully processed and cached will be billed

A 5xx response will not be billed

A 4xx will not be billed since we did not accept request

A 200 ok will be billed

An asynch provisioning of the response but not picked up will be billed

Accounts Receivable Requirements:

We have service and product contracts with: - Reseller - Customer - Partner

We sell our products directly to partner and customer. We sell our products indirectly to customers via resellers but have a direct contract relation with customer. Reseller receives only certain rate of total revenue.

Customers/Partners/Resellers are stored in the db with their billing information: - Name - Billing Address - VatId - Bank Account Information - Invoice Email

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Accounts-Receivable-Automation.md - Chunk 1
Customers/Partners/Resellers are stored in the db with their billing information: - Name - Billing Address - VatId - Bank Account Information - Invoice Email

We have products: - Vehicle Registration Capture Product - Invoice Capture Product - Delivery Note Capture Product - Document Classyfier Product

BLU DELTA Products must log their successful usages in a central db storage

Customer and Partner have susbcribed for products via a contract. A Contract or Order must define the price plan per product. A Contract or Order must define a start date per product. A Contract or Order should have a unique identifier.

Price Plan is defined by:

Customer or Partner

Product

Price Plan Name

Period: Once, Monthly, Annual

Description

Usage Limit

Net Price

Transaction Price (beyond limit)

Start Month

End Month (optional)

Price Plans are not allowed to overlap. Price Plans can not be deleted. They can only be modified or ended by setting the end month.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Accounts-Receivable-Automation.md - Chunk 2
Start Month

End Month (optional)

Price Plans are not allowed to overlap. Price Plans can not be deleted. They can only be modified or ended by setting the end month.

There might exist default price plans but this is not part of this feature.

Billing Cycle is monthly:

A monthly billing process is triggered beginning of each calendar month It calculates the prices to be paid for each customer and partner for last calendar month. It logs following billing information for each invoice line item: InvoiceId, Partner or customer name, Reseller Name, Product, Quantity, Price Plan Name, Usage Limit, Net Price, Delivery Period, Billing Address, UID, Invoice-EMail

Billing Methods

Usage stats - how many documents per customer Martin sagt, dass wir neuen Kunden haben - e.g. ab Monat x Paket y / Check Vertrag Genauer Firmenlaut Fragt UID Nummer ab Eintrag -> Customers Lisa Customer Nummer -> Datum

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Accounts-Receivable-Automation.md - Chunk 3
Pro Kunde hnterlegt: monthly vs annual vs. quarterly Lisa ändert dann immer das nächste Billing Date nach jeder Abrechnung Package Name - unterschiedlich je nach Vertrag Listenpreis Discount Purchasing Price = List - Discount Über Limit Due Date

Einheiltiche Produktnamen

Monatlich - Kontingent; Über Limit wird extra verrechnet Einmalig - aktuell ist die Verrechnung

Partner Abrechnung

Vereinheitlichung Kundennamen Produktiv vs. Test

Paketwechsel - immer das günstigere - wie ist das Modell?

Freie Transaktionen gibt es auch

Diamant hat Test und Produktiv Beides wird verrechnet Modell: Transaktion - ohne Paket aber mit x Transaktionen Discount Eurodata - Fixum - annual

Accantum Kunde - ACT ACT - 15% Gutschrift Alle Kunden Gutschrift auf Partner!

Quarterly startet am 1.2. bei BDS

Fröschl Extra bei BDS

Limit Berechnung ist jährlich, Zahlung quarterly D.h. e.g.. 20k Limit im Monat, Schlussrechnung jährlich wenn über 240k - nur dann Mehrverbrauch

Transktionen in der Rechnung

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Accounts-Receivable-Automation.md - Chunk 4
Fröschl Extra bei BDS

Limit Berechnung ist jährlich, Zahlung quarterly D.h. e.g.. 20k Limit im Monat, Schlussrechnung jährlich wenn über 240k - nur dann Mehrverbrauch

Transktionen in der Rechnung

Rechnung per EMail oder Portal

Verrechnung im Vorhinein oder im Nachhinein

Fortlaufende Rechnungs nummer

Design:

Es gibt Pakete Pakete definieren Basisdaten Pakete haben ein Abrechnungsmodell Partner Kunde Partner haben Kunden

Container: Rechnungsstellung

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Amdosoft-medical-prescriptions.md - Chunk 0
Mr. Griffith has a partner (system house from Düsseldorf) which is interested in processing medical prescriptions. They are form-based, it's probably more an OCR topic than AI.

Mr. Griffith will check the potential behind this inquiry for the system house.

Probably much more interesting: awinta (ERP for pharmacies with 7k pharmacies in Germany under contract) is also Amdosoft partner. If Mr. Griffith knows, that we are able to provide a solution, he will talk to awinta.

Samples can be found under \nas-01\CustomerData\Amdosoft\Recepte

Required fields: According to Mr. Griffith: Everything - but he will clarify with customer.

OCR will be problematic. Idea: Based on a threshold filter the red (and other colors) in order to minimize irritations and optimize the OCR.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\DeepOCR-PoC.md - Chunk 0
DeepOCR PoC

Goal:

PoC should answer the question: Is there an open source or affordable OCR on the market that learns and can be better than our old-school OCR?

Approach:

1) Make BLU DELTA labels useable for OCR benchmark and training: This means we need to blur out all information except the label bounding boxes due to gdpr and nda restrictions 2) Benchmark PaddleOCR and/or MMOCR or EasyOCR for accuracy and performance 3) Use 400k labels to train systems 4) Do benchmark again 5) Compare with Nuance - Omnipage 6) Write a summary of performance of each of the models and write technical summary how you did the training

OVERVIEW of Benchmark Results:

Final-Evaluation-Pack.zip

Report Document.pdf

Conclusio:

Based on these results EasyOCR seems to be the best option - though it requires GPU and is not very fast. From my perspective we should create an OCR service based on Easy and an additional OCR based on Paddle.

Next step: Evaluate if we can replace OCR with DeepOCR service

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\DeepOCR-PoC.md - Chunk 1
Next step: Evaluate if we can replace OCR with DeepOCR service

OPEN:

[ ] Structure like region?

[ ] Language detection needed?

TASKS / STORIES

ad 1) STORY WHAT: As Data Manager I need a tool that blurs out all information except label bounding boxes WHY: because of security reasone - otherwise we can not send dato to Ongjen - freelancer

Report Document.pdf## Requirement Details:

Command Line Tool (Python expected - if not, let me know, .Net would be possible optionally) Delivery: ZIP file with code and brief readme - which includes how to install and use

Command:

blur_non_label_area

Params:

relative path to execution directory with following content

"Labels.csv" with following information: - LabelId,Text,Left,Top,Width,Height,Document_Id - Encoding: UTF-8 - (see also delivered example)

csv file MUST be in correct format, no format checking needed First line will always be header information

new line is a new label

Text is the Ground Truth

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\DeepOCR-PoC.md - Chunk 2
csv file MUST be in correct format, no format checking needed First line will always be header information

new line is a new label

Text is the Ground Truth

Document Files: - For each DocumentId in Labels.csv a corresponding document file with the

relative path to execution directory

New Document Files: - For all successfully processed Labels(!) an image file (with min. loss - JPG or PNG) with the following name

error.log: - Documents that could not be processed or other errors should go into the output folder as error.log file with a brief description for each error; - one line = one error; - timestamp - error needs to name document id and (if available) LabelID which caused error

TEST: - Pls test the tool based on example files already sent - Pls add delivered sample files in the ZIP and in the readme description how you use the tool based on this sample data

ad 2) Benchmark PaddleOCR and/or MMOCR or EasyOCR for accuracy and performance

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\DeepOCR-PoC.md - Chunk 3
ad 2) Benchmark PaddleOCR and/or MMOCR or EasyOCR for accuracy and performance

Input: - Label.csv file - Image per page from Blumatix Label Tool

Output: - ocr-benchmark.csv Please see csv file for details. Comparison is on normalized values.

Additional Information: - Supported Languages - License Information: Free for commercial use? If not under what conditions?

ad 3) STORY: As BD team we need benchmark of best open source DeepOCR tools to make a decision if we switch to new OCR tool WHY: We want an OCR tool we can train and improve and is better than our traditional OCR

Full Benchmark PaddleOCR and/or MMOCR or EasyOCR

Prerequsiste: 392 docs provided which include 2623 images and labels After project is finished Mr. Jin confirmed that he will delete all provided information from his machine and storage.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\DeepOCR-PoC.md - Chunk 4
Prerequsiste: 392 docs provided which include 2623 images and labels After project is finished Mr. Jin confirmed that he will delete all provided information from his machine and storage.

Deliverables: - CSV as described in 2) with all benchmark data included - All original output data of MMOCR, EasyOCR and PaddleOCR in ZIP files - Additional text document describing: -- Exact Version info for each tool -- What is the license for this version? -- Download URL of each tool -- Supported Languages of each tool -- Benchmark Summary Report for each tool: ---- Overall numbers for Accuracy on Exact and Levenshtein ---- Summary of Performance (from this one file is sufficient) ---- Learnings from your perspective: -----Strength of each tool -----Weakness of each tool -----Any issues you hit during benchmarking / any simple corrections on data you had to do / etc. -----Your recommendation which one to choose and reasoning why you recommend this ocr

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\DeepOCR-PoC.md - Chunk 5
ad 4) Re-run Benchmark with corrections and Re-train with Test Set

4-1 Re-run Benchmark

OCR Benchmark rates of first benchmark runs are too low. ~49% accuracy. However, the detailed analysis showed that many errors are based on wrong Label data and extracting data out of OCR results. Deliverables: - Do a position based benchmark: So far the algorithm just takes first element with highest accuracy. But this often leads to the detection and comparison of the wrong test. So, the location of the found text needs to be considered. - Keep and deliver original output of all 3 OCR while running the test again - Retrun benchmark results and deliver same assets as in first run, same directory, results should show better accuracy

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\DeepOCR-PoC.md - Chunk 6
4-2 Build Data Pre-processing and Training Pipeline for Easy OCR - Build a first Python pipeline to pre-process our Label data to be used for EasyOCR Training - Build training pipeline for EasyOCR Training - Train Easy OCR - Run benchmark for trained EasyOCR again and see if trained EasyOCR got any better - Deliver benchmark results in same format as initial benchmark to same directory - Document Data-preprocessing Pipeline process - what steps are done for data-preprocessing and training - Document Training Pipeline process - what steps are done to train model

ad 5) Compare with Omnipage OCR

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\DeepOCR-PoC.md - Chunk 7
ad 5) Compare with Omnipage OCR

Goal: Get a benchmark showing comparison between Omnipage and EasyOCR - Retrieve text based Omnipage results: You can find them usual dir: OmnipageResults/OmniPageResults.zip -- Note: Nuance could not process all images due to image size issue: Only 2064 are available and can be used in benchmark - the others should be marked as "OmniFailed" in the bm result - Find right ocr text based on position information (one file per image), filename includes LabelID - Extract text and compare with Easy OCR results showing: - LabelID, GroundTruth, EasyOCR value (before), EasyExact, EasyLevenshtein, Omnipage Value, Omni Exact, Levenshtein Omni - return result as csv file

ad6) IronOCR was added on short term

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Eurodata-CZ-Improvement.md - Chunk 0
Vergleich Benchmarks_4.xlsx

test Analyse ETL Czech Invoices.docx

Erstanalyse: Feedback Eurodata

Blumatix-BD-AnalyseEurodata-CzechInvoices.pdf

Tasks for Sprint 74

[ ] Benchmark CZ_400 -> correct labels

[ ] Get Training data: Martin (ca. 400), all from ETL not used in Benchmarks (ca. 1300 - 863) based on active learning, take first 100 - label them - train, iterate

[ ] Check indicators with translation service

[ ] try czech model for invoice date

[ ] create labels for VatGroup

[ ] analyze GTA

Gut improvement

+3.5 % average

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Eurodata_-Einkommensteuerbelege.md - Chunk 0
ETL has a team that requires the interpretation of Einkommensteuerbelege. The main advantage is the automatic detection of a follow-up action and an automatically created calender entry until when the action must be fulfilled. The expectation is a 90% automation rate.

EKS Presentation of Eurodata:

Kommentare: Unterscheidung und Erkennung von Paragraphen 164 und 165 sind wichtig und weisen auf Aktionspunkt hin Hauptanfoderung: Ist eine Frist mit Aktionspunkt vorhanden und Datum!!! Lastschrift –> dann nicht dringend Beträge in Tabelle nur bis Ende 2023 – Prio 2 Betrag – positiv und negative Beträge je nach Gutschrift vs. Zahlung – Indikator Vorzeichen Deckblatt nicht da – Stempel auch nicht vorhanden bei Inference – kommen nur Originalbelege Eingangsstempel ist schon da - Nicht bis Mitte 2023 relevant, Stempel ist aber vorhanden auf den Prod Daten Scan möglich, keine PDF Text zu erwarten Fax fraglich

Zu extrahierende Daten:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Eurodata_-Einkommensteuerbelege.md - Chunk 1
Zu extrahierende Daten:

Frist Mandant Art des Bescheids Bis wann muss was passieren Evtl. in Zukunft Kassenzeichen: Zahlungsreferenz

Rep. Sample sollte vorhanden sein (aber veraltet) Neues Sample kann zur Verfügung gestellt werden

Daten: \nas-01\customerdata\Eurodata\EKS-Belege

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Eurodata_-Einkommensteuerbelege.md - Chunk 2
Rep. Sample sollte vorhanden sein (aber veraltet) Neues Sample kann zur Verfügung gestellt werden

Daten: \nas-01\customerdata\Eurodata\EKS-Belege

Beispiele beinhalten Deckblatt, welches aktuell Stb erstellen mit den Infos, die wir extrahieren sollten. Dieses Deckblatt ist in Originaldaten nicht vorhanden. Frage: Kann man Deckblatt als Groundtruth verwenden? OnPremise vs Cloud: Erstes Angebot basierend auf OnPremise / kann auch eigener Service sein Schätzung: 4-5 Bescheide pro Mandant Volumen: ca. 250k Bescheide pro Jahr Erwartungshaltung: 90-95% der Belege führen zu einer automatisierten Terminsetzung Scan / Fax – Mischvariante – sollte rep sein - FOLLOW UP: Bürckert Datensatz repräsentativ? FOLLOW UP Bürckert Möglichkeit: Check gegen Finanzämter – alle abgedeckt 100-200 Stk Finanzämter – evtl. viel mehr? GPU support möglich <40k – Flatrate – zusätzlich

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Eurodata_-Einkommensteuerbelege.md - Chunk 3
Mandanten Stammdaten? FOLLOW UP: Bürckert Fristen: In einem beschränkten Bereich? Fokus: Lieber keine Frist als eine falsche Nur Deutschland Steuernummer des Veranlagten – identifiziert auch das Finanzamt – da gibt es immer eine Korrelation AP: Neueres Sample – check Daten AP: Datensatz noch vergrößern ist möglich

Zusätzliche externe Informationen:

Hilfreicher Link zum Aufbau EKS: https://www.ing.de/wissen/steuerbescheid/ Muster: Muster_Einkommensteuerbescheid.pdf Es gibt 600 Finanzämter in DE!

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\How-to-improve-LineItem-Model---Next-Steps.md - Chunk 0
Ziel / Anforderung

Gutes CHRIS: generalisiertes LineItems-Modell, dass mit Daten entstanden ist, die uns gehören. => Gutes Standard-Modell, das 80% abdeckt => immerzu reproduzierbar trainierbar

Wert von Dokumenten

Anzahl

Modell-Konvergenz (Korrekt, Vielfalt, Selten, Modellunsicherheit)

Ownership

CHRIS: Marktwert: Ein Dokument, dass von vielen verarbeitet wird (e.g. Amazon Rechnung) - ist evtl. duplicate zu Anzahl

CHRIS: Kundenwert: Ein Dokument, dass für einen Kunden wichtige Rolle spielt

CHRIS: Real or Generated, Generation Quality Level e.g. "Synonymized" vs. "Generated"

Next Steps

1) Check

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\How-to-improve-LineItem-Model---Next-Steps.md - Chunk 1
CHRIS: Real or Generated, Generation Quality Level e.g. "Synonymized" vs. "Generated"

Next Steps

1) Check

Check, ob BM unsere schwachen Standardfälle abdeckt. Bei der Besprechung hieß es das z.B. einfache Zweizeiler nicht gut gehen. Was an einfachen Fällen geht nicht gut? Sehen wir das in BMs? Sind die uns ohne Kundenfeedback bewusst? CHRIS: Wie bekomme ich möglichst repräsentativen Querschnitt von Rechnungen am Markt - (für generalisiertes Modell)? Aus meiner Sicht müsste der ETL500 (Steuerberater - viele unterschiedliche Kunden) evtl. eine gute Basis sein. Die sind zufällig aus ein paar Millionen Rechnungen gezogen worden. Oder noch besser wären die letzten DE Benchmark Daten von Eurodata - @Hasch: ich glaube da haben wir welche bekommen? Diese als nächstes zu Labeln und Dokumente mit diesen Eigenschaften zu generieren hat sicher Mehrwert - vor allem in Kombi mit Active Learning - für generalisiertes Modell!

1) Modell-Statistik erstellen

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\How-to-improve-LineItem-Model---Next-Steps.md - Chunk 2
1) Modell-Statistik erstellen

Vgl für Labeled, Accounting, Content-Exchanged, Picture-Lines, BluEntities mit einem Stand erstellen

Gewichtung des Datensets: Wie viele Accounting Daten im Verhältnis zu den Gelabelten? Wie viele generieren? etc. pp.

=> Ableiten Mehrwert von Generierung vs Anonymisierung => Ableiten Mehrwert BluDelta Entities CHRIS: Dies ist zweitrangig - aber wir wollen BLU DELTA Entities (=unsere Datentypen - Annahme Chris) nicht und würden das gerne loswerden - da nicht lernfähig. Kann ich BLU DELTA Entities als Basis für Word Embedding Training nehmen, wo es gut ist?

1) Active Learning implementieren

Ansatz für gutes Clustering (für LineItems) und finden von wertvollen Docs fürs Labeln - Fälle wo das Modell schwach ist (wichtige Metriken zusammenstellen)

1) Microsoft Tabellen nutzen

Herausfinden, ob verwertbar und wie. CHRIS: Liegt aktuell bei Andrea ...

2) Simpler LineItem-Generator (in C#)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\How-to-improve-LineItem-Model---Next-Steps.md - Chunk 3
1) Microsoft Tabellen nutzen

Herausfinden, ob verwertbar und wie. CHRIS: Liegt aktuell bei Andrea ...

2) Simpler LineItem-Generator (in C#)

=> Ziel Basisdatenset, das uns gehört und die Standardfälle abdeckt - Algorithmisch, Zeilenanzahl, Header, etc einstellbar - Baut aus vorhandenen Labels Dokumente zusammen - auf leeren Seiten oder an dem Platz von gelabelten Tables

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\How-to-improve-LineItem-Model---Next-Steps.md - Chunk 4
Unklar, ob uns das einen Mehrwert liefert (außer Ownership), da wir die einfachen Fälle auch relativ schnell labeln können CHRIS: Aus meiner Sicht ist das Gegenteil der Fall. Ohne Aufwand können wir auch einfache NICHT schnell labeln! CHRIS: Rudi, ich und Hasch waren gestern der Meinung, dass uns das Mehrwert bringt. CHRIS: Es sind nicht einfache Struktueren, die wir abbilden mit Dok generieren - sondern komplizierte aber OHNE Anomalien! Die Strategie ist "saubere" generieren, Edge Cases label! - allerdings nur messbar, wenn wir es ausprobieren und vergleichen gegen Anonymisierung. Vermutung Mehrzeiler, unterschiedliche Anordung im Header, etc. könnte einen Mehrwert liefern.

Innere Konsitenz im Ersten noch nicht so wichtig, also das Beträge, Mengen, Preise, GTA, etc. zusammenpassen, Funktionalität sollte man aber mitbedenken.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\How-to-improve-LineItem-Model---Next-Steps.md - Chunk 5
Innere Konsitenz im Ersten noch nicht so wichtig, also das Beträge, Mengen, Preise, GTA, etc. zusammenpassen, Funktionalität sollte man aber mitbedenken.

Allgemeines Datenformat für die Labels/Dokumente (DocDetailGroup-Format) sollte existent sein und in der Datenbank umgesetzt => Klare Schnittstelle, Umsetzung in DB für Labels, LabelCreator muss angepasst werden

3) Anonymizer (in C#)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\How-to-improve-LineItem-Model---Next-Steps.md - Chunk 6
(Ergebnisse der Statistik auswerten, ob dies gemacht werden soll) - enables us to create a lot more of one type of document – but more general than just using that document over and over in every epoch (generate x documents, where x is the number of epochs) CHRIS: Finde ich gut - aber das ist aus meinem Verständnis ein Doc Generator? (Die Begriffe müssen wir gut unterscheiden - aber vielleicht check ich was nicht): ANONYMIZE: Content of document stays the same - but data that identifies persons or companies are removed - however, the rest stays the same - if we replace every word, then anonymization is a side effect - but we make the doc invalid because we very likely change its semantics or even remove semantics - Can also be used to bias the model for (weak) documents - Question: Can we only anonymize labeled data? What is the approach for other fields on the document, eg only information is “int”, “word” CHRIS: IMO our goal is to create models for continents, regions or customers.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\How-to-improve-LineItem-Model---Next-Steps.md - Chunk 7
only anonymize labeled data? What is the approach for other fields on the document, eg only information is “int”, “word” CHRIS: IMO our goal is to create models for continents, regions or customers. These are the borders for bias => use Bert, Fasttext - Is it a requirement for anonymized documents to still be consistent? Eg GTA calculated from amounts on doc, etc. pp. CHRIS:NO - but the value (der Wert) of the document decreases! And this decreased value must be stored along with the document. E.g. when I process this doc later the quality of the doc must be transparent. E.g. we are not allowed to use "synonymized" docs when the model wants to understand semantics ... additionally can I select this doc for a benchmark, for training, etc. - I need to be able to distinguish this later on.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\How-to-improve-LineItem-Model---Next-Steps.md - Chunk 8
Nicht mehr in Q2:

4) Feedback-Loop

Bei den LineItems werden uns die Kunden kaum etwas labeln bzw. erst dann wenn das Modell schon halbwegs gut geht und nur mehr kleine Korrekturen gemacht werden müssen. Dafür werden uns dann die Edge-Cases gelabelt, die uns in der Generalisierung am meisten helfen.

5) Document-Generator

GAN, GPT-2, BERT Approach um Gesamtdokumente zu erstellen.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Improve-Addresses.md - Chunk 0
Improve Address Detection

First Goal: For Order Confirmation we have to detect the delivery and invoice address as well as sender and receiver.

First Brainstorming:

Solution Option 1: Typhon ONLY

Train Encoder based on 26k + 13k address data for bootstrapping -- Finds all contacts on docs

Fine-tuning of address head for Invoice and delivery addresses, sender, receiver addresses --Order Confirmation labels

OPTION: Train directly with OC data only

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Improve-Addresses.md - Chunk 1
Fine-tuning of address head for Invoice and delivery addresses, sender, receiver addresses --Order Confirmation labels

OPTION: Train directly with OC data only

Prerequisite: -- Create trainings data of address labels (No risk, low) -- Define segmentation head – background and contact are classes (config, low) -- Trainingspipeline (no risk, low) --RESULT: Pretrained model to detect contacts on pages ---Text Block contains address text --Detect Address Details: ---BERT&Deep Parse (quality risk, low-medium) ---Llama (7B – quality risk, low) => risk can be covered by early testing -Fine-tune with new address classes for sender/receiver/invoice/delivery -Benchmark Compare: Old address format (No risk, low) -Auto-Release does not work currently – requires fix (No risk, low)

Solution Option 2: LLama

Prompt Engineering TokenSize: 4096 always LLama 7b, 13b and 70b 70b is best - but Deployment on 2 GPUs -> RISK? Performance RIsk

Solution Option 3: Layout LM

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Improve-Addresses.md - Chunk 2
Solution Option 2: LLama

Prompt Engineering TokenSize: 4096 always LLama 7b, 13b and 70b 70b is best - but Deployment on 2 GPUs -> RISK? Performance RIsk

Solution Option 3: Layout LM

Layout ML V1 Does ER only Pipeline anpassen, Experiment Node

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Invoice-Sample-Report-for-Mkt.md - Chunk 0
User Story

As bludelta website user I want to upload my organizations invoices and receive a free automation estimate

User Journey: See BluDeltaSME project

Required is a service endpoint that supports the analysis of an invoice sample Input: Invoices sample Output: Analysis JSON

UI-Sketch: https://blumatixconsultinggmbh-my.sharepoint.com/:p:/g/personal/k_kurtz_blumatix_com/EXaa0gesyQ9FolcW6OyryEsBvquiybocXqMJxMBKBu_B9w?e=ikVg5m

Input:

Company Name; 1st page

Industry; 1st page

Person EMail; 1st page

Data Privacy Terms: For how long can we keep samples? Want to use them for Active Learning in long run.; 1st page

Documents (Invoices); 2nd page (50, 100?? documents no zip file needed? nice to have)

call to action: analyse more documents contact us -> contact form? or vice versa.

Approx. number invoices per month; 2nd page

Info we will send you the report in xxx minutes.; 3rd page

Link to webpage with (fake or picture?) report (download your personal report as pdf);

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Invoice-Sample-Report-for-Mkt.md - Chunk 1
Approx. number invoices per month; 2nd page

Info we will send you the report in xxx minutes.; 3rd page

Link to webpage with (fake or picture?) report (download your personal report as pdf);

Newsletter / Contact Information; must have

Output: Report provides information in comparison to other customers (see also Dachser PoC Report), diagrams to be provided Draft for discussion: https://blumatixconsultinggmbh-my.sharepoint.com/:w:/g/personal/k_kurtz_blumatix_com/EZmf7KjFY9ZHkN6Uqm7mTfoBIHhQ_nijJ0BaTDGWdgAXBg?e=edVfxZ

sample size - 22.4.

invoices per month

file size

dpi

source

resolution - 22.4.

approx. confidence

Top Cluster distribution - percentages - 22.4.

Top 10 Most important layout cluster

Text-PDF share in percentage

Average number of pages - 22.4.

Languages - 22.4.

Top 10 regions / percentage

**Expected recognition rates for all fields (groups)

NICE TO HAVE for 22.4.: Plan how to get there Total Recognition Rate: x% (without training)**

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Invoice-Sample-Report-for-Mkt.md - Chunk 2
Languages - 22.4.

Top 10 regions / percentage

**Expected recognition rates for all fields (groups)

NICE TO HAVE for 22.4.: Plan how to get there Total Recognition Rate: x% (without training)**

Information should be persisted in a database Component should be designed to be reusable later for SME (e.g. to get an analysis of the last month (quarter or year) shown in the SME-Dashboard)

Discussion:

Video 2022-02-22: https://blumatixconsultinggmbh-my.sharepoint.com/:v:/g/personal/k_kurtz_blumatix_com/EZI9t2Z1ri9Ek2ouURY8iZoBUHxOwsQqXtrqxJHzqZuX5Q

To Do:

[ ] Upload interface -> restAPI

[ ] Extend DB: 1. Package table, Table for basic analysis of packages

[ ] Package information to data collection without documents only meta information

[ ] Documents will be stored in a provider folder on our nas storage

[ ] Basic analyser needs to be implemented in C#

[ ] Tracking

[ ] Save the result as JSON

[ ] Implement reporting tool

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Invoice-Sample-Report-for-Mkt.md - Chunk 3
[ ] Documents will be stored in a provider folder on our nas storage

[ ] Basic analyser needs to be implemented in C#

[ ] Tracking

[ ] Save the result as JSON

[ ] Implement reporting tool

The following diagram shows the DataCollection Pipeline with the PackageUploaderService (as REST service)

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Other-documents.md - Chunk 0
Lieferscheine

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Other-documents.md - Chunk 1
Document Lieferschein / Delivery Note Samples \nas-01\CustomerData\strabag\Lieferschein, \nas-01\CustomerData\best4bps Category Extraction Description Der Lieferschein, oder auch Warenbegleitschein, wird zusammen mit Ware verschickt. Der Lieferschein listet vor allem die in der Sendung enthaltenen Waren auf sowie das Lieferdatum. Diese Angaben sind hilfreich, denn so kann man sehr einfach abgleichen, ob die Bestellung und die tatsächliche Lieferung übereinstimmen. Zudem können Sie bei Ihren Rechnungen auf einen Lieferschein verweisen, wenn das Lieferdatum zum Zeitpunkt der Rechnungsstellung noch unbekannt ist, dann kann der Lieferschein das Lieferdatum „nachliefern“. Soll Felder: Die Namen von Lieferant und Empfänger, Auftragsnummer bzw. der Name des Auftrags, Versand- und wenn möglich das Lieferdatum, Menge und Bezeichnung der einzelnen gelieferten Waren (Packliste) . In vielen Fällen e.g. Handel bereits automatisiert. Aber jedes Unternehmen hat Lieferungen ohne Bestellung und dort

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Other-documents.md - Chunk 2
Lieferdatum, Menge und Bezeichnung der einzelnen gelieferten Waren (Packliste) . In vielen Fällen e.g. Handel bereits automatisiert. Aber jedes Unternehmen hat Lieferungen ohne Bestellung und dort muss Rechnung vs. Lieferung manuell geprüft werden. Strabag Use Case Potential PoC in Q4, Alignment of delivery and invoice, Strabag does not maintain orders (German, CZ, PL) Best4PBS Use Case Gastro Use Case - every day people need to enter delivered food in order to maintain their food stock (German) Layout diversity high, bad image quality Annual Volume TBD Project Type PoC Strabag (german) PoC delivery until 30.09.2022 Go live until TBD Documents available yes but just for benchmark Structured data available unknown Environment Cloud expected Feedback API expected no

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Other-documents.md - Chunk 3
Dachser

Document ABD Samples \nas-01\CustomerData\Dachser\ABDs\Files Category Extraction Description Details under https://blumatix.visualstudio.com/Rechnungserkennung/_wiki/wikis/Rechnungserkennung.wiki/265/ABD-(Ausfuhrbegleitdokument)-EAD-(Export-Accompanying-Document) Languages / countries PoC limited to 3 languages, 11-12 all together, see examples Layout diversity small Annual Volume 500k Project Type PoC PoC limitations: 3 languages but all details PoC delivery until Expected 31.12.2022 Go live until TBD Documents available yes Structured data available unknown Environment On Premise Feedback API expected no

x-bit

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Other-documents.md - Chunk 4
x-bit

Document Customs documents Samples \nas-01\CustomerData\x-bit Category Extraction Description x-bit is already BLU DELTA customer and processes invoices for it's customer BOLTAS (= Logistics) in a Jobrouter process. Boltas wants to automate another process for customs documents. Each Pdf contains several document types, including ABDs, invoices and others. The required values are described in ...[specific data requests from x-bit, will update as soon as they are available]. Three customers (Wacker, BASF, Schaeffler) are responsible for >50% of the volume Languages / countries German majority, see examples Layout diversity small (3 customers 50%) Annual Volume 40k documents (80k in excel - t.b.d.) Project Type Production Delivery until Q3 2022 preferred Go live until Q3 2022 preferred Documents available yes Structured data available t.b.d. Environment Cloud Feedback API expected no

Logicheck

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Other-documents.md - Chunk 5
Logicheck

Document KFZ Gutachten (just a first Usecase) Samples \nas-01\CustomerData\Logicheck\Horch Category Extraction Description Logicheck processes documents for insurance industry. In a first step they want to automate the processing of KFZ Gutachten. The values needed are described in the file "Auswertungspositionen - Stand 07.06.2022.pdf" in the samples folder. Document consists of Gutachten and invoice and and contains is about 30 pages long. The Gutachten contains text and images. Data extraction belongs to text only, except (probably) one image-detection to detect the certification company like e.g. TÜV. Languages / countries German only, see examples Layout diversity high, ~5k Gutachter Annual Volume 50k documents á 30 pages Project Type PoC PoC delivery until not specified yet, no time pressure. Go live until Not before Mid 2023 Documents available yes Structured data available no Environment Cloud Feedback API expected yes

Innotec

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Other-documents.md - Chunk 6
Document Orders Samples \nas-01\CustomerData\R&S\Innotec Category Extraction Description Innotec is an R&S customer and wants to automate the order 2 cash process. Use case: Analyze orders and provide data for subsequent process in R&S ERP. Processed 66k orders with 230k LineItems in 2020, handled by 4 employees. Volume will be reduced in future due to App, where customers can order in a structured way. Optimistic assumption is, that 50% will be handled via App -> 33k will remain. The required information from the orders are well described in the samples. Orders are received via email attachments or directly in email body. (See Pappas orders) We can skip the EMail-Body orders for the PoC if that helps and focus on Pdfs only in a first step. Further examples for other customers will follow. Fully automatic processing is not the expectation, there will always be someone who verifies the results. Best case would be a completely correct extraction result which just needs to be accepted.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Other-documents.md - Chunk 7
Fully automatic processing is not the expectation, there will always be someone who verifies the results. Best case would be a completely correct extraction result which just needs to be accepted. Languages / countries German majority, maybe even exclusively Layout diversity high, but there seem to be some Top-customers like Birner, Pappas and ÖBB which are very relevant. Annual Volume 33k documents, at the beginning more, because Order-App is not yet very widespread afaik Project Type PoC PoC delivery until not specified yet, no time pressure. Go live until not specified yet, no pressure Documents available yes Structured data available yes - historic data, but without position, additionally product catalogue available Environment Cloud Feedback API expected t.b.d. but would definitely make sense

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Red-Bull-PoD-PoC.md - Chunk 0
Red Bull has identified a next Use Case for processing another document, called PoD (Proof of Delivery).

Use Case Details

RBDC Proof of Delivery (PODs) for Retail Chain Delivery

Background Process Due to the delivery structure set-up in RBDC (USA) there is a current problem with PODs, as they are 1. all offline/ printed & stored in the delivery hubs. Often, they get lost or are not forwarded to the central billing department. In this case Red Bull is not payed. In this use case are two steps 1. Digitalizing the offline PODs 2. extracting the information of PODs to the central Billing Application.

There are a lot of conflicts around the delivery amount/ date of delivery, all grounded in the difficult / inefficient process of PODs.

Sizing of the case 500-100 Documents a day (40 Routes (*12 Dozens) Documents) 100 Warehouses + (RBDC)

Target Group RBDC - Central Billing - Red Bull as bills are faster payed / or payed at all

Type of Document Paper Document

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Red-Bull-PoD-PoC.md - Chunk 1
Target Group RBDC - Central Billing - Red Bull as bills are faster payed / or payed at all

Type of Document Paper Document

Integration Data needs to be saved (PODs) in “Highradius system” (central billing system, also storage location) It is enough if PODs are saved there

Languages English

Data Fields - Customer name/Store name - Invoice date - Invoice # - PO #

Samples and process description can be found on the NAS under \nas-01\CustomerData\redbull\PoD

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Röchling_-OrderConfirmations.md - Chunk 0
Intro

Röchling wants to digitize its Purchase Organisation and therefore wants to automate the processing of order confirmations.

Contacts:

Main Contact: Plascher, Cedric CPlascher@roechling.com (Procurement)

Goal

Complete automatic processing of incoming orders (reduce manual work) not expected. The process for confirmations via EDI and PDF is currently being implemented and should work for EDI and PDF. That is, if the extracted data matches the order data, the document is processed automatically, otherwise the data from the order and the data from the document are presented for manual verification.

From Blumatix no UE is required, this is part of Röchling.

Key facts

Röchling processes ~10k documents annually. Most vendors are German based, some documents are in EN and NL. Feedback is not important in a first step.

Röchling can provide historic documents and data. Data can bring some benefits for header labeling.

Required fields

Header Data:

Order confirmation number

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Röchling_-OrderConfirmations.md - Chunk 1
Röchling can provide historic documents and data. Data can bring some benefits for header labeling.

Required fields

Header Data:

Order confirmation number

Order number

Invoice address

Delivery to address

Delivery date (can be header data, can be on position); If there’s a shipping date specified instead of the delivery date, we will return the shipping date as delivery date.

Discount (can be header data, can be on position)

Net Amount

Incoterms (Lieferbedingung)

Line Items:

Supplier article number

Customer article number (6 digits, starting with 100…)

Description

Quantity

Unit

PackagingUnit

Item price

Total price

Discount (can be header data, can be on position)

Delivery date (can be header data, can be on position) – can either be fixed date but also relative (e.g. Guarantee next day)

Further information

One confirmation per order

Relevant languages: DE, EN, NL

Document volume: Approx. 10k per year

No. Suppliers: Approx. 2-2.5k

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\Röchling_-OrderConfirmations.md - Chunk 2
Further information

One confirmation per order

Relevant languages: DE, EN, NL

Document volume: Approx. 10k per year

No. Suppliers: Approx. 2-2.5k

Top 10 suppliers -> ~28% of annual volume

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\SAP-CIM-INtegration.md - Chunk 0
Goal:

SAP launched a new Central Invoice Management service that enables external parties to integrate an AI invoice capturing service into Cloud SAP The aim is to market the fact that BLU DELTA is integrated into SAP CIM.

SAP CIM:

offers 3 ways while just one integration is feasible for BLU DELTA: Synchronous which is described here: https://help.sap.com/docs/CENTRAL_INVOICE_MANAGEMENT/da931cb8aae0453584e3a3765a6fbd4b/c8b2ce91ef24455dbd991fb82f057b5f.html

From current assumption there are 2 main API endpoints to be provided by BLU DELTA: - /capabilities: returns capabilities of the API - /jobs: extracts information from invoice and returns a CIM invoice model

There are examples on the web page available and (i assume) even a code to generate a sample invoice for a request - but the invoice model is not described in detail.

The details to the CIM invoice model are missing and therefore, effort for the mapping to BLU DELTA fields can not be estimated.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Product\New-Requests\Closed\SAP-CIM-INtegration.md - Chunk 1
The details to the CIM invoice model are missing and therefore, effort for the mapping to BLU DELTA fields can not be estimated.

OPEN: OAuth 2 for synchronous communication

OPEN: Is the create CIM invoice api to create a CIM test invoice?

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Resources\Coursera_-Generative-AI-with-Large-Language-Models.md - Chunk 0
Source: https://www.coursera.org/learn/generative-ai-with-llms

Basic training constraints: - model size - train data size - budget constrains

chinchilla paper => get optimal model size and train data size for certain budget ZeRO: Fully Sharded Data Parallel for multi gpu training

Fine-Tuning

Fine-Tuning on a single task: just 500-1000 examples needed => The advantage is that the prompt gets a lot shorter (less input tokens)

Singe-Task-Fine-Tuning can lead to catastrophic forgetting

Multi-Task-Fine-Tuning: e.g. rating, entity-recognition, summarizing, translating, ... - FLAN-Dataset

PEFT Parametric Efficient Fine-Tuning -only updates a small subset of the model parameters, subset of layers, or adds new layers to train -15-20% of the original parameters, can often be performed on a single GPU (e.g. Model size 1GB, peft size 10 MB) -through this you can also fine-tune for multiple specific tasks and swap the PEFT weights during inference time => LoRA => Adapters, Soft Prompts

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Resources\Coursera_-Generative-AI-with-Large-Language-Models.md - Chunk 1
Here is the Lab 2 notebook (when downloaded remove the .txt ending) about full fine-tuning and LoRA: Lab_2_fine_tune_generative_ai_model.ipynb.txt

Evaluation

Model evaluation metrics: - Rouge: compare summaries - Bleu Score: compare translations - Benchmarks: Glue, SuperGlue, HELM, MMLU, Big-bench, ...

Reinforcement Learning from human feedback (RLHF)

Models behaving 'badly' - misleading information - irony - toxic language - aggressive responses - providing dangerous information

A classic reinforcement learning algorithm. A second reward model, like BERT, is trained through human feedback to rank the answers of the llm. - Proximal policy optimization (PPO) is an algorithm to find the best policy to align the llm to human feedback. - KL Divergence shift penalty is used to avoid reward hacking (like a toxicity reward model would just lead to the model only saying good things about everything).

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Resources\Coursera_-Generative-AI-with-Large-Language-Models.md - Chunk 2
Use constitutional AI - using a rule set in the prompts to create training data, like: - "Can you help me hack into my neighbor's wifi?" - "Identify how the last response was unethical" - "Rewrite and remove any and all unethical content."

Lab 3 Notebook (when downloaded remove the .txt ending) about RLHF: Lab_3_fine_tune_model_to_detoxify_summaries.ipynb.txt

Application Integration

Distillation: LLM-Teacher trains LLM-Student (best for encoder-only models like BERT)

Quantization: BFloat16 (mostly best), FP16, INT8

Pruning: in practice most parameters are not close to zero and this won't work well

Problems in application: - Can't calculate - Out of date - Hallucination

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Resources\Coursera_-Generative-AI-with-Large-Language-Models.md - Chunk 3
Pruning: in practice most parameters are not close to zero and this won't work well

Problems in application: - Can't calculate - Out of date - Hallucination

Solutions: - RAG: Prompts Query Encoder to use external data sources, e.g. database, api, vector store, wiki, etc. Limit of data must fit inside context window - Chain-of-thought prompting: adding the prompt for the steps necessary to solve a problem correctly - Program-aides language (PAL) models: model is using e.g. a python interpreter to make calculations - LangChain is framework used as orchestration tool with agents, prompt templates, memory, tools to use with an LLM

Build generative applications

Prompt Optimization

Frameworks to automatically improve prompts: - DSPy: https://dspy-docs.vercel.app/ - TextGrad: https://arxiv.org/abs/2406.07496, https://textgrad.com/

tldr

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Resources\Coursera_-Generative-AI-with-Large-Language-Models.md - Chunk 4
Prompt Optimization

Frameworks to automatically improve prompts: - DSPy: https://dspy-docs.vercel.app/ - TextGrad: https://arxiv.org/abs/2406.07496, https://textgrad.com/

tldr

Use a small foundational model and fine-tune it using techniques like LoRA for various specific tasks. Typically, 500-1000 data points are sufficient for effective fine-tuning.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Resources\Large-Language-Models-(LLMs).md - Chunk 0
This is the place to collect tools, methods, libraries, and products that are related to LLMs. Feel free to add whenever you find something of relevance.

AI Agentic Workflows

Tools

Name Company Licence Url add. information AutoGen Microsoft Creative Commons Attribution 4.0 International https://microsoft.github.io/autogen/ https://arxiv.org/abs/2308.08155 CrewAI MIT License https://www.crewai.com/ Multi AI Agent Systems with crewAI (DeepLearning Course BotSharp Apache License 2.0 https://github.com/SciSharp/BotSharp The AI Agent Framework in .NET LangGraph LangChain https://python.langchain.com/v0.1/docs/langgraph/ MetaGPT MIT License https://github.com/geekan/MetaGPT Software Company as Multi-Agent System Vertex AI Agent Builder Google https://cloud.google.com/products/agent-builder

Products

Name Company Url Beam beam.ai https://beam.ai/ Industry Solutions & Custom AI Solutions

Retrieval Augmented Generation (RAG)

Tools/ Products

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Resources\Large-Language-Models-(LLMs).md - Chunk 1
Products

Name Company Url Beam beam.ai https://beam.ai/ Industry Solutions & Custom AI Solutions

Retrieval Augmented Generation (RAG)

Tools/ Products

Name Company Licence Url add. information LlamaIndex LlamaIndex inc. Open Source & Enterprise https://www.llamaindex.ai Building Agentic RAG with LamaIndex (DeepLearning Course) AI native vector database Weaviate Open Source https://weaviate.io Building Multimodal Search and RAG (DeepLearning Course)

Quantization

PlugIn

Name Company Licence Url add. information Semantic Kernel Microsoft MIT License https://learn.microsoft.com/en-us/semantic-kernel/ Plugin your code

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\SCRUM\SCRUM-Wiki-Archive\Sprint-Planning-Discussions.md - Chunk 0
Please see the sub pages (Sprint X) for other sprints!

Sprint 74

Recorded Discussion: https://blumatixconsultinggmbh-my.sharepoint.com/:v:/g/personal/k_kurtz_blumatix_com/EcF9rtUDkTtFpliVvfhhSmsBWWZmA78MrVdTnFntsWuXgg

0:00:00 - 0:38:00 ; 10012 As SME user I want to benefit from the quality flag model

0:38:00 - 1:05:00 ; 8647 Bring (Junk) Doc Structure detection to production

1:05:00 - 1:19:00 ; 10923 Create a BCS-DataAccess-Layer for .Net Standard

1:19:00 - 1:23:00 ; 10922 Bring blumatix.capture.utils to .Net Standard

1:23:00 - 1:53:00 ; 10507 Fix Result Pdf size problem for POI

10012 - As SME user I want to benefit from the quality flag model

10923 Create a BCS-DataAccess-Layer for .Net Standard

[ ] Fluent.API Definition fertigstellen (Keine Änderung, wenn Migriert wird, in beiden Framework Versionen

[ ] Alle Änderungen in den Master mergen und kontrollieren das alle Pipelines und Tests noch funktionieren.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\SCRUM\SCRUM-Wiki-Archive\Sprint-Planning-Discussions.md - Chunk 1
[ ] Alle Änderungen in den Master mergen und kontrollieren das alle Pipelines und Tests noch funktionieren.

[ ] Telemetry Function auf .net 6 portieren (Utility und weitere Abhängigkeiten müssen zumindest auf .Net Standard 2.0 sein) Hier gibt es noch Issue in bestehender Pipeline, weil wegen .net Core Restore. Muß gelöst werden.

[ ] Pipeline für Infrastructur definieren

[ ] Pipeline für Deployment definieren

FRAGE Derzeit ist die telemetry-fn nicht im bludelta-vnet und von aussen erreichbar. Sollten wir ins vnet aufnehmen! JA

Diagramm

Bug 10507 ResultPdf Size

[ ] Discuss approach with Martin before Kick-off

[ ] Linked Issues / bugs have documents attached for testing --> Add additional documents to test readability of new ResultPdfs --> ~50 documents tif | imagebased pdfs --> QPdf (Philipp)

[ ] ResultPdf: Images taken from OCR --> Try to convert to png to minimize bytearray size --> Talk with Julian first

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\SCRUM\SCRUM-Wiki-Archive\Sprint-Planning-Discussions.md - Chunk 2
[ ] ResultPdf: Images taken from OCR --> Try to convert to png to minimize bytearray size --> Talk with Julian first

[ ] Images taken from OCR --> Try to convert to greyscale image (1 byte / pixel - no alpha) --> generate resultpdfs --> Validate manually (show them to Martin)

[ ] CustomerConfig.json --> Extend, rename and move doc_preperation.json --> write to ApplicationContext [Threadsafe!] --> add option to globally enable/disable like JunkDetection

[ ] Extend OnPremise OpsManual

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\SCRUM\SCRUM-Wiki-Archive\Sprint-Planning-Discussions\Sprint-74.md - Chunk 0
Recorded Discussion: https://blumatixconsultinggmbh-my.sharepoint.com/:v:/g/personal/k_kurtz_blumatix_com/EcF9rtUDkTtFpliVvfhhSmsBWWZmA78MrVdTnFntsWuXgg

0:00:00 - 0:38:00 ; 10012 As SME user I want to benefit from the quality flag model

0:38:00 - 1:05:00 ; 8647 Bring (Junk) Doc Structure detection to production

1:05:00 - 1:19:00 ; 10923 Create a BCS-DataAccess-Layer for .Net Standard

1:19:00 - 1:23:00 ; 10922 Bring blumatix.capture.utils to .Net Standard

1:23:00 - 1:53:00 ; 10507 Fix Result Pdf size problem for POI

10012 - As SME user I want to benefit from the quality flag model

10923 Create a BCS-DataAccess-Layer for .Net Standard

[ ] Fluent.API Definition fertigstellen (Keine Änderung, wenn Migriert wird, in beiden Framework Versionen

[ ] Alle Änderungen in den Master mergen und kontrollieren das alle Pipelines und Tests noch funktionieren.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\SCRUM\SCRUM-Wiki-Archive\Sprint-Planning-Discussions\Sprint-74.md - Chunk 1
[ ] Alle Änderungen in den Master mergen und kontrollieren das alle Pipelines und Tests noch funktionieren.

[ ] Telemetry Function auf .net 6 portieren (Utility und weitere Abhängigkeiten müssen zumindest auf .Net Standard 2.0 sein) Hier gibt es noch Issue in bestehender Pipeline, weil wegen .net Core Restore. Muß gelöst werden.

[ ] Pipeline für Infrastructur definieren

[ ] Pipeline für Deployment definieren

FRAGE Derzeit ist die telemetry-fn nicht im bludelta-vnet und von aussen erreichbar. Sollten wir ins vnet aufnehmen! JA

Diagramm

Bug 10507 ResultPdf Size

[ ] Discuss approach with Martin before Kick-off

[ ] Linked Issues / bugs have documents attached for testing --> Add additional documents to test readability of new ResultPdfs --> ~50 documents tif | imagebased pdfs --> QPdf (Philipp)

[ ] ResultPdf: Images taken from OCR --> Try to convert to png to minimize bytearray size --> Talk with Julian first

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\SCRUM\SCRUM-Wiki-Archive\Sprint-Planning-Discussions\Sprint-74.md - Chunk 2
[ ] ResultPdf: Images taken from OCR --> Try to convert to png to minimize bytearray size --> Talk with Julian first

[ ] Images taken from OCR --> Try to convert to greyscale image (1 byte / pixel - no alpha) --> generate resultpdfs --> Validate manually (show them to Martin)

[ ] CustomerConfig.json --> Extend, rename and move doc_preperation.json --> write to ApplicationContext [Threadsafe!] --> add option to globally enable/disable like JunkDetection

[ ] Extend OnPremise OpsManual

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\SCRUM\SCRUM-Wiki-Archive\Sprint-Planning-Discussions\Sprint-75.md - Chunk 0
Recorded discussion:

Video 1: Morning session - 0:00:00; 8647 Bring (Junk) Doc Structure detection to production - 0:05:20; 11331 As customer (BDS) I want a mechanism to choose line item model for prediction - 0:14:00; 11333 As customer I want a sustainable improvement in line item recognition - 0:25:00; 11177 As Eurodata I need better CZ recognitions

Video 2: Afternoon session - 0:00:00; 8004 As ETL I need the service period (Leistungszeitraum) - 2:04:00; 10923 Create a BCS-DataAccess-Layer for .Net Standard - 2:07:30; 11299 Improve BLU DELTA Deployments (Wave 1 = direct improvements for v1-18) - 2:31:00; 10922 Bring blumatix.capture.utils to .Net Standard

11331 As customer (BDS) I want a mechanism to choose line item model for prediction

Add option to globally configure TyphonLineItems on/off

Add (hidden) request-parameter to force de-/activation of TyphonLineItems

Add Unit-Tests

Add Wiki for endpoints and configuration options

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\SCRUM\SCRUM-Wiki-Archive\Sprint-Planning-Discussions\Sprint-75.md - Chunk 1
Add option to globally configure TyphonLineItems on/off

Add (hidden) request-parameter to force de-/activation of TyphonLineItems

Add Unit-Tests

Add Wiki for endpoints and configuration options

8004 As ETL I need the service period (Leistungszeitraum)

prediction group start and end date

Generate training data with phoenix action

named entities: Begin, end, time period

Train BERT model (multilingual)

Or Typhon

International Benchmark (performance)

Retrain sentence classifier for payment condition

Improve labelling discussion see video 1:15:00:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\SCRUM\SCRUM-Wiki-Archive\Sprint-Planning-Discussions\Sprint-76.md - Chunk 0
Recorded discussion

Video - Sprint Planning Discussion

11300 - 0:00 Get Codebase ready for v1-18 deployment => Pre-Validation DONE 8004 - 0:20 As ETL I need the service period (Leistungszeitraum) 11276 - 0:59 As customer (BDS) I want to test the new line item model 10859 - 1:27 As Diamant I need new invoice detail cost center 10874 - 1:36 As Red Bull I need support for Argentina 11312 - 1:41 As API customer I want to be informed about valid 0% VAT (e.g. Reverse Charge)) 11501 - 1:45 iText7 replacement Bugs - 1:58 11299 - 2:04 Improve BLU DELTA Deployments (Wave 1 = direct improvements for v1-18) 11502 - 2:05 release v1.18 11569 - 2:16 As customer I want a sustainable improvement in line item recognition

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\SCRUM\SCRUM-Wiki-Archive\Sprint-Planning-Discussions\Sprint-78.md - Chunk 0
Recorded discussion

Video - Sprint Planning Discussion

11175 - 0:00 Implement a I18n-Resource-Service 11463 - 1:45 As data manager I want a sustainable improvement in the document generator

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\SCRUM\SCRUM-Wiki-Archive\Sprint-Planning-Discussions\Sprint-79.md - Chunk 0
Recorded discussion

Video - Sprint Planning Discussion

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Story-wiki\SP140-US22548_improve_taiwan.md - Chunk 0
22548

Sprint 140 - Benchmarking, Date Parsing, and Service Updates

[[TOC]]

Date Parsing Enhancements

Observations

Taiwan specific dates are normalized but not parsed correctly during benchmarking. Our benchmark engine is not culture-context sensitive.

Trimming Taiwan-specific values (e.g., "期 :112/09/05") to enhance parsing accuracy.

Current Enhancements

Updated the Date.TryParse method to handle various date patterns, including:

"2023 Oct 18"

"Dec. 07, 2023"

"16OCT, 2023"

Minguo Date Parsing:

These enhancements restricted date parsing based on the culture and supported different formats to reduce errors in date extraction and comparison.

Invoice ID and OCR Issues

For certain documents (e.g., 361049, 361046, 361057), various issues were identified:

Misclassifications due to incorrect prediction of the InvoiceId: e.g. 361070 361070.pdf

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Story-wiki\SP140-US22548_improve_taiwan.md - Chunk 1
For certain documents (e.g., 361049, 361046, 361057), various issues were identified:

Misclassifications due to incorrect prediction of the InvoiceId: e.g. 361070 361070.pdf

Merging problems during post-processing. e.g. 361040 361040.pdf: update or completely remove postprocessing in sdk? TyphonHeaderDetailsPostprocessingActivity

Service and Model Updates

As part of this sprint, the following services and components are planned for updates: - TyphonDachserAsia Service: Improvements in handling predictions and filtering based on thresholds.

Dachser Asia Model: Enhanced model for better accuracy in predictions specific to Asian documents.

DocClassifier model: Updating the document classifier to improve overall asia document classification results.

Elastic Search: Updated configurations for optimized searching and indexing of predictions.

Capture SDK: Incorporating new parsing logic to support additional date formats and postprocessing improvements.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Story-wiki\SP140-US22548_improve_taiwan.md - Chunk 2
Capture SDK: Incorporating new parsing logic to support additional date formats and postprocessing improvements.

Postprocessing: Deployed to reflect changes in the model and postprocessing.

Benchmarks for Comparison

To measure the impact of these updates, multiple benchmarks were run to compare results before and after the changes. Those benchmarks do not (yet) include postprocessing actions.

Baseline Benchmark:

Benchmark Report (55734)

Comparison: Baseline with New Parsing and Service Updates:

Comparison Report (55798)

Comparison: Parsing and Service Updates with Model Update:

Comparison Report (55799)

Comparison: After Model Update with ForceDachserAsia:

Comparison Report (55800)

Note: This benchmark highlights the problems outlined in work item #22433).

Comparison: After Model Update with Production:

Comparison Report (55811)

General Observations

GrandTotalAmount predictions are more accurate for Chinese documents without a QR code. #22711

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Story-wiki\SP140-US22548_improve_taiwan.md - Chunk 3
Comparison: After Model Update with Production:

Comparison Report (55811)

General Observations

GrandTotalAmount predictions are more accurate for Chinese documents without a QR code. #22711

Filtering low-confidence predictions using score thresholds has shown promise in improving benchmarking results.

Issues and Findings

Exception in the direct comparison between configurations. Details in work item #22433

Investigated different benchmark results (comparison of dev vs. prod).

Direct comparison URL: Benchmark Report.

Commits and Affected Repositories

Repositories:

DachserPostprocessing

Capture SDK

ElasticSearch Configurations

DachserAsiaService

Benchmark Set Creation

Phoenix Commands

To create and evaluate benchmark sets, the following commands were used:

```powershell .\phoenix.exe evaluation bm_run -b "asia_dev_set" -c "Philipp local Sprint140 Baseline" -t 4 -s "http://localhost:8091" -x "Config.ForceReturnBestMatches=true" -r "Asia_Dev Report" -v -A

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Story-wiki\SP140-US22548_improve_taiwan.md - Chunk 4
.\phoenix.exe benchmark bm_report_def_baselines -r "Asia_Dev Report" -e "US22548_Base" -u "US22548_Base" -p "US22548_Base"

.\phoenix.exe evaluation bm_run -a "dachser_TW_100_uniform_3" -c "Philipp local Sprint140 Taiwan only" -t 4 -s "http://localhost:8091" -x "Config.ForceReturnBestMatches=true" -r "Asia_Dev Report" -v -A

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Story-wiki\SP140-US22548_improve_taiwan.md - Chunk 5
```

Create a Benchmark Set

powershell phoenix benchmark create_bmset -n "asia_dev_set" -t "Cloud_B_I18N_SouthKorea, Cloud_dachser_CN_CnChar_50_uniform, Cloud_dachser_CN_EnChar_50_uniform, dachser_JP_98_uniform4, dachser_TH_100_uniform, dachser_TW_100_uniform_3, dachser_TH_#21502_CustSample, dachser_TW_#22547_CustSample"

Phoenix Benchmark Reports

Ran several benchmark reports and investigated specific configurations and their impact on prediction accuracy.

The following command was used to run the Taiwan-specific benchmark: powershell evaluation bm_run -a "dachser_TW_100_uniform_3" -c "Philipp local Sprint140 Taiwan only; typhon prediction threshold of 0.5" -t 4 -s "http://localhost:8091" -x "Config.ForceReturnBestMatches=true" -r "Asia_Dev Report" -v -A

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Story-wiki\SP141-US22025-As-Support-i-need-a-plugin.md - Chunk 0
Story

22025

Task

22804

Name lt auth db: Domonda Produktiv

Docs für Dynapdf Test im Taskanhang.

Bei Fragen bitte melden oder den dazugehörenden Issue checken.

Person who detected the incident: Nenad Spasojevic

How was the incident noticed (report from outside the company)?

Detailed description of the incident. What exactly happened: in den angehängten Belegen erkennt die KI den Umsatzsteuerbetrag fälschlicherweise als Gesamtbetrag der Rechnung. Wenn kein Umsatzsteuerbetrag vorhanden ist, erkennt die KI stattdessen fälschlicherweise die letzte Rechnungsposition als Gesamtbetrag. Da dies bei den meisten dieser Belege der Fall ist, möchte ich Sie bitten, die beigefügten Belege im KI-Trainingset zu verwenden, damit die KI lernen kann, den Gesamtbetrag korrekt zu identifizieren.

Unser Kunde hat bereits sein Einverständnis gegeben, dass diese Belege an Sie weitergeleitet und im KI-Trainingset verwendet werden dürfen.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Story-wiki\SP141-US22025-As-Support-i-need-a-plugin.md - Chunk 1
Unser Kunde hat bereits sein Einverständnis gegeben, dass diese Belege an Sie weitergeleitet und im KI-Trainingset verwendet werden dürfen.

Supplier: HUMANBRAND Tests via Trialpage / 08.10.2024 OCR Fehler -> Alle Beträge in bold werden nicht erkannt GTA falsch = bold VatGroup falsch, da Netto Betrag = bold Test mit Azure Read erfolgreich -> alle Beträge werden erkannt pdf in imagebasierte verwandelt -> Alle Beträge werden korrekt erkannt -> Supplier Humandbrand zu pdffilter.json hinzufügen

Impact: Wrong document recognition. Documents cannot be autoprocessed.

[x] debug invoice and check if correct sender name can be extracted

[x] add senderName to pdffilter.json

[x] check result

[x] integration test?

Task

22805

Name lt auth db: Accantum MainKey

Docs für Dynapdf Test im Taskanhang.

Bei Fragen bitte melden oder den dazugehörenden Issue checken.

[x] add to pdffilter.json and test

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Story-wiki\SP141-US22654-CostCenter-Plugin-for-Tüchler.md - Chunk 0
CostCenter Extraction Plugin for Tüchler Ausbau GmbH

Overview

This plugin adds support for extracting the CostCenter information from invoice documents for Tüchler Ausbau GmbH. The CostCenter format follows the pattern of 5 digits - hyphen - 3 digits (e.g., 23130-390), with the possibility of handling a prefix like "Proj.".

The plugin uses the RegexFinder logic, and the "Proj." prefix is automatically removed from the final extracted result, returning only the CostCenter value.

Plugin Type:

RegexFinder Plugin

Defined via a JSON configuration in the PostProcessing service.

CostCenter Plugin Details

The main functionality of this plugin is to extract CostCenter information from raw OCR text.

Key Regex Patterns:

Main Regex: regex (?:Proj\.\s*)?(\d{5}-\d{3})

This matches the CostCenter format, optionally handling the "Proj." prefix.

Remove From Result: regex \bProj\.\s*

This removes the "Proj." prefix after the initial match to return the clean CostCenter value.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Story-wiki\SP141-US22654-CostCenter-Plugin-for-Tüchler.md - Chunk 1
Remove From Result: regex \bProj\.\s*

This removes the "Proj." prefix after the initial match to return the clean CostCenter value.

JSON Configuration:

Here’s an example of the plugin’s configuration in appsettings.json or dynamic_config.json:

json { "PluginType": "RegexFinder", "CustomerNames": [ "partner.ramsauerstuermer.tuechler" ], "Regex": [ "(?:Proj\\.\\s*)?(\\d{5}-\\d{3})" ], "RemoveFromResultRegex": [ "\\bProj\\.\\s*" ], "OcrRawTextToLower": false, "KeepExistingPredictionsWithSameTypeName": false, "DetailTypeName": "CostCenter", "DetailType": "CustomInvoiceDetail" }

Testing the CostCenter Plugin

Unit tests were added to verify the functionality of the CostCenter extraction. Key test cases include: - Extracting valid CostCenter values with and without the "Proj." prefix. - Handling documents with multiple CostCenter values. - Ensuring the plugin skips invalid formats.

Example Test Case:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Story-wiki\SP141-US22654-CostCenter-Plugin-for-Tüchler.md - Chunk 2
Example Test Case:

```csharp [TestMethod] public void Test_ExtractsCostCenter() { var doc = new BluDoc { Source = "CostCenterPlugin", SourceVersion = "0.0.1", Document = new DocumentDetailGroup() };

var config = new PluginConfig()
{
    Regex = new List<string> { @"(?:Proj\.\s*)?(\d{5}-\d{3})" },
    DetailTypeName = "CostCenter",
    DetailType = "CustomInvoiceDetail",
    CustomerNames = new List<string> { "partner.ramsauerstuermer.tuechler" },
    RemoveFromResultRegex = new List<string> { @"\bProj\.\s*" }
};

var processor = new RegexFinder(config);
var propertyStore = new Dictionary<string, string>();
var result = processor.Process("partner.ramsauerstuermer.tuechler", propertyStore, doc, "Proj.23130-390");

Assert.AreEqual(1, result.Document.Items.Count);
AssertAnyDetailHasValueAndTag(result.Document, "23130-390", "CostCenter");

}

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Story-wiki\SP141-US22654-CostCenter-Plugin-for-Tüchler.md - Chunk 3
```

Extending the RegexFinder Plugin

Here’s a step-by-step guide on how to extend RegexFinder for future plugins:

Define the Regex:

Identify the pattern you want to extract. Write a regex that matches this pattern.

Use the RemoveFromResultRegex to clean up unwanted prefixes, suffixes, or other characters that should not be part of the final value.

Add the Configuration:

Add the plugin to the relevant customer configuration in appsettings.json or dynamic_config.json. Ensure the correct CustomerNames are added.

Specify the necessary regexes under Regex and RemoveFromResultRegex.

Update the Unit Tests:

Add corresponding unit tests in the RegexFinderTests.cs file to cover key scenarios, such as:

Valid matches.

Handling edge cases (e.g., missing or malformed data).

Correct cleanup of the extracted values using RemoveFromResultRegex.

Deploy the Plugin:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Story-wiki\SP141-US22654-CostCenter-Plugin-for-Tüchler.md - Chunk 4
Valid matches.

Handling edge cases (e.g., missing or malformed data).

Correct cleanup of the extracted values using RemoveFromResultRegex.

Deploy the Plugin:

Once developed and tested, deploy the plugin using the DevOps pipelines. Update the relevant deployment files, such as bludelta_cloud_plugins.json for cloud deployments or bludelta_op_customer_plugins.json for on-premise customers.

Logging and Monitoring:

Ensure that appropriate logging is added in the RegexFinder.cs file to help with debugging and monitoring.

Future Considerations:

As more customers may need custom regex patterns for extracting specific data, the RegexFinder Plugin can be adapted by simply adjusting the regex patterns and configuration files.

When handling complex documents, additional logic can be implemented to process bounding boxes in OCR regions or to apply multiple regex patterns to cover different formats.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Story-wiki\SP144-BUG23172-Benchmarks-of-Header-Details-drop-by-10%.md - Chunk 0
Wiki Page: Benchmark Drop in Header Details by 10%

23172

http://192.168.137.78:30200/#/experiments/12/runs/c18273a7f72343d6b5647dbe346a25a0

http://192.168.137.88:8081/bm-reports/56210/details?baselineReportId=56056

http://192.168.137.88:8081/bm-reports/56211/details

Overview

Issue Title: Benchmarks of Header Details Drop by 10%

Description:

Several issues were identified with model performance, particularly concerning large models like Line Items and Header Details, which exhibited a 10% accuracy drop. Key areas of concern included potential problems with training data and errors during the training process. Below are the detailed findings and resolutions.

Root Cause Analysis

Model Problems:

Discussion among team members (Klemens and Marcus) revealed that the accuracy drop was significant, particularly for larger models.

Data Issues:

Philipp identified inconsistencies in the data predictions, pointing to potential issues in the dataset.

Training Errors:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Story-wiki\SP144-BUG23172-Benchmarks-of-Header-Details-drop-by-10%.md - Chunk 1
Data Issues:

Philipp identified inconsistencies in the data predictions, pointing to potential issues in the dataset.

Training Errors:

Marcus emphasized the need for a thorough review of both the training data and the models to identify errors during training that could be causing these issues.

Impact

Failure of Line Items data processing for specific customers (e.g., X/Y).

Header Details CT unable to deliver new models.

Reproduction Steps

To reproduce the issue: 1. Compare benchmark results from the productive model with those from the newly trained model. 2. Review training logs, outputs, and datasets.

Resolution Process

Fix Summary:

A new model was trained to address the benchmark accuracy drop. The training process was stabilized using multiple GPUs, and the updated benchmarks demonstrated significantly improved results.

Steps Taken:

Deprecated Unused Methods:

Marked methods like _apply_thresholds and load_data_from_index_file as deprecated.

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Story-wiki\SP144-BUG23172-Benchmarks-of-Header-Details-drop-by-10%.md - Chunk 2
Steps Taken:

Deprecated Unused Methods:

Marked methods like _apply_thresholds and load_data_from_index_file as deprecated.

Suggested alternatives for deprecated methods.

Entropy Logic in Image Segmentation:

Introduced per-pixel entropy calculations and aggregated entropy of entropies to measure uncertainty.

Integrated entropy metrics into validation and test steps.

Maximum Entropy Computation:

Calculated the theoretical maximum entropy of entropies for segmentation models.

Training Stability Improvements:

Enhanced gradient clipping, batch normalization synchronization, and learning rate scaling.

Optimized data loading with prefetch factor adjustments.

MLflow Integration:

Improved MLflow logging to avoid duplicate experiments during distributed training.

Centralized logging using rank-zero operations in distributed training scenarios.

Unicode Logging Errors:

Resolved UnicodeEncodeError by configuring UTF-8-compatible logging.

Segmentation Fault in Workers:

C:\Users\rudi\source\repos\Rechnungserkennung.wiki.dev\Story-wiki\SP144-BUG23172-Benchmarks-of-Header-Details-drop-by-10%.md - Chunk 3
Unicode Logging Errors:

Resolved UnicodeEncodeError by configuring UTF-8-compatible logging.

Segmentation Fault in Workers:

Debugged multiprocessing-related issues and refined dataset fetching logic.

::: mermaid graph TD A[Training Data Issues] -->|Identified| B[Model Benchmark Drop] B --> C[Debugging Process] C --> D[Stabilized Training on Multiple GPUs] D --> E[Improved Benchmarks and Model Accuracy] E --> F[Re-release of Updated Models] :::

Next Steps

Regularly monitor benchmarks for all models.

Establish automated checks for data consistency before training.

Document any anomalies in training logs for faster debugging.

Enhance model training with additional stability checks during distributed training.

